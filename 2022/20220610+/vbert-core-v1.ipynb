{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb327f16-2349-4a3c-8db9-5110f72d711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from numpy import argmax\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class FactoryEncoder:\n",
    "\n",
    "    def __init__(self, tokenizer, device, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "    # end\n",
    "\n",
    "    # Q: WHY NOT USING PARAMETERS?\n",
    "    # A: FOR FUN\n",
    "    def get_instance(self, sentences):\n",
    "        instance = SimpleEncoder(sentences)\n",
    "        instance.set_tokenizer(self.tokenizer)\n",
    "        instance.set_device(self.device)\n",
    "        instance.set_max_length(self.max_length)\n",
    "        return instance\n",
    "    # end\n",
    "# end\n",
    "\n",
    "class SimpleEncoder(Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "    # end\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index]\n",
    "        sentence = ' '.join(sentence.split())\n",
    "#         inputs = self.tokenizer.encode_plus(\n",
    "#             sentence, None,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_length,\n",
    "#             padding='max_length',\n",
    "#             return_token_type_ids=True,\n",
    "#             truncation=True,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            sentence, None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "\n",
    "        for key in inputs:\n",
    "            inputs[key] = torch.tensor([inputs[key]], dtype=torch.long)\n",
    "            inputs[key] = inputs[key].to(self.device)\n",
    "        # end\n",
    "\n",
    "        return inputs\n",
    "    # end\n",
    "\n",
    "    def set_tokenizer(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    # end\n",
    "\n",
    "    def set_device(self, device):\n",
    "        self.device = device\n",
    "    # end\n",
    "\n",
    "    def set_max_length(self, max_length):\n",
    "        self.max_length = max_length\n",
    "    # end\n",
    "\n",
    "\n",
    "class SimpleBertClassifier(torch.nn.Module):\n",
    "\n",
    "    DEFAULT_FILENAME_CLASSIFIER = '.model.json'\n",
    "    DEFAULT_FILENAME_BERT = 'bert_config.json'\n",
    "    DEFAULT_FILENAME_MODEL = 'model.pt'\n",
    "    DEFAULT_KEYS_IGNORED_CLASSIFIER = ['metrics', 'allmetrics']\n",
    "\n",
    "    def __init__(self, path_folder_model=None):\n",
    "        super(SimpleBertClassifier, self).__init__()\n",
    "\n",
    "        filename_config_classifier = self.__class__.DEFAULT_FILENAME_CLASSIFIER\n",
    "        filename_config_bert = self.__class__.DEFAULT_FILENAME_BERT\n",
    "        filename_model = self.__class__.DEFAULT_FILENAME_MODEL\n",
    "        keys_ignored_classifier = self.__class__.DEFAULT_KEYS_IGNORED_CLASSIFIER\n",
    "\n",
    "\n",
    "        self.path_folder_model = path_folder_model\n",
    "        self.path_config_bert = os.path.join(path_folder_model, filename_config_bert)\n",
    "        self.path_config_classifier = os.path.join(path_folder_model, filename_config_classifier)\n",
    "        self.path_file_model = os.path.join(path_folder_model, filename_model)\n",
    "\n",
    "        with open(self.path_config_classifier, 'r') as file:\n",
    "            config_classifier = json.load(file)\n",
    "        # end\n",
    "\n",
    "        for key in keys_ignored_classifier:\n",
    "            del(config_classifier[key])\n",
    "        # end\n",
    "\n",
    "        # classfier parameters\n",
    "        self.classifier_input_size = config_classifier.get('bert').get('input_size')\n",
    "        self.classifier_max_length = config_classifier.get('bert').get('max_length')\n",
    "        self.classifier_output_size = config_classifier.get('bert').get('output_size')\n",
    "        #\n",
    "\n",
    "        self.labels_output_classifier = config_classifier.get('classes')\n",
    "        self.dict_label_index = {label: index for index, label in enumerate(self.labels_output_classifier)}\n",
    "\n",
    "        self.l1 = None\n",
    "        self.linear = None\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.loaded = False\n",
    "    # end\n",
    "\n",
    "#     def forward(self, input_ids=None, attention_mask=None):\n",
    "#         output_bert = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         hidden_state = output_bert[0]\n",
    "#         pooler = hidden_state[:, 0]\n",
    "#         output = self.classifier(pooler)\n",
    "#         return output\n",
    "#     # end\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        output_bert = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_bert[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "    # end\n",
    "\n",
    "    def load(self):\n",
    "        if not self.loaded:\n",
    "            print('loading BERT from: {}'.format(self.path_config_bert))\n",
    "            self.l1 = BertModel(BertConfig.from_pretrained(self.path_config_bert))\n",
    "            print('loading {} x {} linear classfier layer'.format(self.classifier_input_size, self.classifier_output_size))\n",
    "            self.classifier = torch.nn.Linear(self.classifier_input_size, self.classifier_output_size)\n",
    "\n",
    "            self.to(self.device)\n",
    "            self.load_state_dict(torch.load(self.path_file_model, map_location=torch.device(self.device)))\n",
    "\n",
    "            print('loading Tokenizer from: {}'.format(self.path_folder_model))\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(self.path_folder_model)\n",
    "            self.factory_encoder = FactoryEncoder(self.tokenizer, self.device, self.classifier_max_length)\n",
    "            self.eval()\n",
    "            self.loaded = True\n",
    "        # end\n",
    "\n",
    "        return self\n",
    "    # end\n",
    "\n",
    "    def predicts(self, samples_input):\n",
    "        encoder = self.factory_encoder.get_instance(samples_input)\n",
    "        outputs_raw = []\n",
    "        for sample_encoded in encoder:\n",
    "            with torch.no_grad():\n",
    "                output_raw = self(**sample_encoded).cpu().numpy().flatten().tolist()\n",
    "                # print('jinyuj: predicts:83 output_raw: {}'.format(output_raw))\n",
    "                outputs_raw.append(output_raw)\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        info_result = {\n",
    "            'outputs': outputs_raw,\n",
    "            'labels': self.labels_output_classifier\n",
    "        }\n",
    "\n",
    "        return info_result\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd6e976-064f-47d4-9339-8d37730bb25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading BERT from: vBERT-base-20/bert_config.json\n",
      "loading 768 x 16 linear classfier layer\n",
      "loading Tokenizer from: vBERT-base-20\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "classfier = SimpleBertClassifier('vBERT-base-20')\n",
    "classfier.load()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be3d055-70f1-4bc1-9e03-a3fb345bda80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': [[0.32176998257637024,\n",
       "   1.224564552307129,\n",
       "   -0.6085540056228638,\n",
       "   -0.46785619854927063,\n",
       "   1.0967031717300415,\n",
       "   -0.2059227079153061,\n",
       "   -1.6974825859069824,\n",
       "   0.22236327826976776,\n",
       "   -0.06567856669425964,\n",
       "   -0.16524294018745422,\n",
       "   0.14014184474945068,\n",
       "   -0.10047697275876999,\n",
       "   1.6361207962036133,\n",
       "   0.6065401434898376,\n",
       "   -0.24681268632411957,\n",
       "   -0.8894371390342712]],\n",
       " 'labels': ['esx:esx_server:resource_mgmt___cpu',\n",
       "  'esx:esx_server:unknown',\n",
       "  'esx:infrastructure:dictionary',\n",
       "  'esx:vsan:unknown',\n",
       "  'esx:host_client:host_client_release_notes',\n",
       "  'esx:host_agent:host_mgmt',\n",
       "  'esx:infrastructure:crypto',\n",
       "  'esx:esx_server:dde_storage_driver',\n",
       "  'esx:vsan_dp_data:tests',\n",
       "  'esx:host_profiles:host_profile_engine',\n",
       "  'esx:esx_server:vmkctl___infrastructure',\n",
       "  'esx:vsan:lsom',\n",
       "  'esx:esx_server:storage_vmfs',\n",
       "  'esx:esx_server:hardware',\n",
       "  'esx:nimbus:nimbus_esxdeploy',\n",
       "  'esx:vsan:vsanwitnessovf']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'timestamp failed at play deploy vm efi nvme vmxnet number timestamp task upload local file to esxi data store task path home worker workspace dw rhel number arm ansible vsphere gos validation common esxi upload data store file yml number exception in vsphere copy python when main in request python when http error default fatal localhost failed http error number not found timestamp task testing exit due to failure task path home worker workspace dw rhel number arm ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi nvme vmxnet number'\n",
    "classfier.predicts([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c77f3-ed9d-4dcd-827f-f84fdf76d204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80d2a4-f1e1-44e6-bcce-4e74768c2cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
