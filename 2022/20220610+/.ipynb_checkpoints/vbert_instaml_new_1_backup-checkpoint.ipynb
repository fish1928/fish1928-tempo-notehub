{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310fd250-d31a-4b7d-a30a-54da6ab8f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, errno\n",
    "import json\n",
    "import yaml\n",
    "import argparse\n",
    "import sys\n",
    "import traceback\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# default constants\n",
    "\n",
    "# The name of the bert model to load\n",
    "VBERT_MODEL = \"vBERT-2020-Base\"\n",
    "\n",
    "# vBERT-Base's hidden layer size is 768\n",
    "# vBERT-Large's hidden layer size is 1024\n",
    "CLASSIFICATION_LAYER_WIDTH = 768 if \"Base\" in VBERT_MODEL else 1024\n",
    "\n",
    "# Maximum string length\n",
    "# Anything longer will be truncated\n",
    "# Maximum length can not exceed 512, though generally can be shorter\n",
    "MAX_STRING_LEN = 128\n",
    "\n",
    "\n",
    "# ## Class for transforming text for input into BERT\n",
    "# \n",
    "# This class tokenizes the text and converts the tokens into tensors of token ids with an attention mask, along with the string's class label\n",
    "\n",
    "class Prepare(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data[1][index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        label = self.data[0][index]\n",
    "\n",
    "        target = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': label\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# ## vBERT Class for classification\n",
    "# \n",
    "# To use vBERT for classification, you have to add a classification layer on top of the language model. \n",
    "# vBERT encodes the data.  The classification layer receives the encoding from vBERT and claculates class probabilities.\n",
    "\n",
    "class BertClassifier(torch.nn.Module):\n",
    "    # Create a classification network that uses vBERT to encode the input and pass to a classification layer\n",
    "    #\n",
    "    # Input configurable parameters:\n",
    "    # root: full path name of the model directory, where the .pt, vocab and .model.json/bert_config.json file are found\n",
    "    # name: name of the model (for reporting/diagnostic)\n",
    "    # input_size: width of classification layer (e.g. 768)\n",
    "    # output_size: number of output classes (task dependent)\n",
    "    # max_length: maximum number of characters in input string for trainig/inference\n",
    "    # classes: array of output_size with class names\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.config = config\n",
    "        self.model_dir = config.get(\"root\", \".\")\n",
    "        self.model_name = config.get(\"name\", VBERT_MODEL)\n",
    "        self.classification_layer_width = config.get(\"input_size\", CLASSIFICATION_LAYER_WIDTH)\n",
    "        self.classes = config.get(\"classes\", [\"0\", \"1\"])\n",
    "        self.num_classes = config.get(\"output_size\", len(self.classes))\n",
    "        self.max_string_length = config.get(\"max_length\", MAX_STRING_LEN)\n",
    "        self.bert_config_file = self.model_dir + \"/bert_config.json\"\n",
    "        self.model_file_path = self.model_dir + \"/model.pt\"\n",
    "        self.device = config.get(\"device\", \"cpu\")\n",
    "        self.metrics = [ \"accuracy\", \"precision\", \"recall\", \"F-score\" ]\n",
    "\n",
    "        # Load the vBERT vocabulary into the tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.model_dir)\n",
    "\n",
    "    def load_bert_for_training(self):\n",
    "        print('Loading vBERT model: ' + self.model_name)\n",
    "        self.l1 = BertModel.from_pretrained(pretrained_model_name_or_path=self.config.bert_model_dir)\n",
    "        print(\"Adding {}x{} classification layer\".format(self.classification_layer_width, self.num_classes))\n",
    "        self.classifier = torch.nn.Linear(self.classification_layer_width, self.num_classes)\n",
    "\n",
    "    def load_bert_for_inference(self):\n",
    "        print('Loading vBERT config')\n",
    "        self.l1 = BertModel(BertConfig.from_pretrained(self.bert_config_file))\n",
    "        print(\"Adding {}x{} classification layer\".format(self.classification_layer_width, self.num_classes))\n",
    "        self.classifier = torch.nn.Linear(self.classification_layer_width, self.num_classes)\n",
    "\n",
    "    # Encode the input with vBERT, read output from the last layer of vBERT, and pass to the classification layer\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n",
    "    def do_inference(self, data_loader, test_output=None):\n",
    "        model = self.eval()\n",
    "        predictions = []\n",
    "        real_values = []\n",
    "        with torch.no_grad():\n",
    "            for data in data_loader:\n",
    "                input_ids = data['ids'].to(self.device)\n",
    "                attention_mask = data['mask'].to(self.device)\n",
    "                targets = data['targets'].to(self.device)\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                predictions.extend(preds)\n",
    "                real_values.extend(targets)\n",
    "                if test_output != None:\n",
    "                    test_output.extend(outputs)\n",
    "        predictions = torch.stack(predictions).cpu()\n",
    "        real_values = torch.stack(real_values).cpu()\n",
    "\n",
    "        test_accu = 100 * accuracy_score(real_values, predictions)\n",
    "        test_precision, test_recall, test_fscore, ignore = precision_recall_fscore_support(real_values, predictions, average='macro')\n",
    "        test_precision *= 100\n",
    "        test_recall *= 100\n",
    "        test_fscore *= 100\n",
    "        metrics = [ test_accu, test_precision, test_recall, test_fscore ]\n",
    "        return predictions, real_values, metrics\n",
    "\n",
    "    def classify_text(self, txt: str, conf=None):\n",
    "        dataset = pd.DataFrame.from_dict({ 'row': [ 0, txt ]}, orient='index')\n",
    "        prepared_set = Prepare(dataset, self.tokenizer, self.max_string_length)\n",
    "        params = {'batch_size': 1,\n",
    "                    'shuffle': False,\n",
    "                    'num_workers': 0\n",
    "                }\n",
    "        loader = DataLoader(prepared_set, **params)\n",
    "        outputs = []\n",
    "        predictions, real_values, metrics = self.do_inference(loader, outputs)\n",
    "        classes = self.classes\n",
    "        result = { 'classes': [ ], 'text': txt, 'top_class': classes[int(predictions[0])], 'top_class_index': int(predictions[0]) }\n",
    "        xi = 0\n",
    "        for x in classes:\n",
    "            result['classes'].append({ 'class_name': x, 'confidence': float(outputs[0][xi]) })\n",
    "            xi += 1\n",
    "        return result\n",
    "\n",
    "class InstaMLConfig():\n",
    "    def __init__(self, config_json_file):\n",
    "        with open(config_json_file, \"r\") as cjf:\n",
    "            self.jconf = json.load(cjf)\n",
    "        pth, fname = os.path.split(config_json_file)\n",
    "        if len(pth) < 1:\n",
    "            pth = \".\"\n",
    "        self.name = self.jconf.get('name', '')\n",
    "        self.model_dir = pth\n",
    "\n",
    "    def load_instaML_model_file(self):\n",
    "        model_info_file_name = self.model_dir + \"/.model.json\"\n",
    "        with open(model_info_file_name, \"r\") as mif:\n",
    "            self.model_info = json.load(mif)\n",
    "        return self.model_info\n",
    "\n",
    "    def save_instaML_model_file(self):\n",
    "        model_info_file_name = self.model_dir + \"/.model.json\"\n",
    "        with open(model_info_file_name, \"w\") as mif:\n",
    "            json.dump(self.model_info, mif, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6292fb0-7fec-4058-a730-c5349ab847fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(path_config):\n",
    "\n",
    "    configPath = path_config\n",
    "    print(configPath)\n",
    "\n",
    "    with open(configPath, \"r\") as yf:\n",
    "        config = yaml.safe_load(yf)\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fc4ca1-a7ef-4637-8984-c348516d34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstaMLConfig():\n",
    "    def __init__(self, config_json_file):\n",
    "        with open(config_json_file, \"r\") as cjf:\n",
    "            self.jconf = json.load(cjf)\n",
    "        pth, fname = os.path.split(config_json_file)\n",
    "        if len(pth) < 1:\n",
    "            pth = \".\"\n",
    "        self.name = self.jconf.get('name', '')\n",
    "        self.model_dir = pth\n",
    "\n",
    "    def load_instaML_model_file(self):\n",
    "        model_info_file_name = self.model_dir + \"/.model.json\"\n",
    "        with open(model_info_file_name, \"r\") as mif:\n",
    "            self.model_info = json.load(mif)\n",
    "        return self.model_info\n",
    "\n",
    "    def save_instaML_model_file(self):\n",
    "        model_info_file_name = self.model_dir + \"/.model.json\"\n",
    "        with open(model_info_file_name, \"w\") as mif:\n",
    "            json.dump(self.model_info, mif, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15be6c45-7dd9-4cf5-a056-5e8a4555119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_readymlbert(conf, device):\n",
    "    conf.load_instaML_model_file()\n",
    "\n",
    "    bert_config = { 'root': conf.model_dir, 'name': conf.model_info['name'], 'classes': conf.model_info['classes'], 'device': device }\n",
    "    bert_config.update(conf.model_info['bert'])\n",
    "    model = BertClassifier(bert_config)\n",
    "    model.load_bert_for_inference()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model.model_file_path, map_location=torch.device(device)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b043c78-e111-4672-bd15-7b2f98ce734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(env_config, dir_model, device):\n",
    "    modelDir = dir_model\n",
    "    if not os.path.exists(modelDir):\n",
    "        return None, \"Model does not exist: \" + modelDir\n",
    "\n",
    "    print(\"Importing model from\", modelDir)\n",
    "    try:\n",
    "        conf = InstaMLConfig(modelDir + \"/.model.json\")\n",
    "        model = load_model_readymlbert(conf, device)\n",
    "        return model, None\n",
    "    except Exception as e:\n",
    "        err = \"Cannot load model: \" + str(e)\n",
    "        return None, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596193b3-d4b5-4865-b352-793e5d848a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "\n",
    "    result = model.classify_text(text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb559ce-77e1-4d93-98af-c0a645362e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_load_model(path_config='config.yaml', dir_model='vBERT-base-20', device='cuda'):\n",
    "    env_config = get_config(path_config)\n",
    "    model, err = load_model(env_config, dir_model, device)\n",
    "    if not err:\n",
    "        return model\n",
    "    else:\n",
    "        raise Exception(err)\n",
    "    # end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358f5260-ed87-4407-a4de-fffdbfc2fe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.yaml\n",
      "Importing model from vBERT-base-20\n",
      "Loading vBERT config\n",
      "Adding 768x16 classification layer\n"
     ]
    }
   ],
   "source": [
    "sentence = 'timestamp failed at play deploy vm efi nvme vmxnet number timestamp task upload local file to esxi data store task path home worker workspace dw rhel number arm ansible vsphere gos validation common esxi upload data store file yml number exception in vsphere copy python when main in request python when http error default fatal localhost failed http error number not found timestamp task testing exit due to failure task path home worker workspace dw rhel number arm ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi nvme vmxnet number'\n",
    "model = main_load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3ac468-f3db-4cbd-985e-da6e6d7ee22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32176998257637024,\n",
       " 1.224564552307129,\n",
       " -0.6085540056228638,\n",
       " -0.46785619854927063,\n",
       " 1.0967031717300415,\n",
       " -0.2059227079153061,\n",
       " -1.6974825859069824,\n",
       " 0.22236327826976776,\n",
       " -0.06567856669425964,\n",
       " -0.16524294018745422,\n",
       " 0.14014184474945068,\n",
       " -0.10047697275876999,\n",
       " 1.6361207962036133,\n",
       " 0.6065401434898376,\n",
       " -0.24681268632411957,\n",
       " -0.8894371390342712]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item['confidence'] for item in model.classify_text(sentence)['classes']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
