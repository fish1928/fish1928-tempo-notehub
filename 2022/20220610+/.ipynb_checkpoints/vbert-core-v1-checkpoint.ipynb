{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb327f16-2349-4a3c-8db9-5110f72d711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from numpy import argmax\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class FactoryEncoder:\n",
    "\n",
    "    def __init__(self, tokenizer, device, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "    # end\n",
    "\n",
    "    # Q: WHY NOT USING PARAMETERS?\n",
    "    # A: FOR FUN\n",
    "    def get_instance(self, sentences):\n",
    "        instance = SimpleEncoder(sentences)\n",
    "        instance.set_tokenizer(self.tokenizer)\n",
    "        instance.set_device(self.device)\n",
    "        instance.set_max_length(self.max_length)\n",
    "        return instance\n",
    "    # end\n",
    "# end\n",
    "\n",
    "class SimpleEncoder(Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "    # end\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index]\n",
    "        sentence = ' '.join(sentence.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            sentence, None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        for key in inputs:\n",
    "            inputs[key].to(self.device)\n",
    "        # end\n",
    "\n",
    "        return inputs\n",
    "    # end\n",
    "\n",
    "    def set_tokenizer(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    # end\n",
    "\n",
    "    def set_device(self, device):\n",
    "        self.device = device\n",
    "    # end\n",
    "\n",
    "    def set_max_length(self, max_length):\n",
    "        self.max_length = max_length\n",
    "    # end\n",
    "\n",
    "\n",
    "class SimpleBertClassifier(torch.nn.Module):\n",
    "\n",
    "    DEFAULT_FILENAME_CLASSIFIER = '.model.json'\n",
    "    DEFAULT_FILENAME_BERT = 'bert_config.json'\n",
    "    DEFAULT_FILENAME_MODEL = 'model.pt'\n",
    "    DEFAULT_KEYS_IGNORED_CLASSIFIER = ['metrics', 'allmetrics']\n",
    "\n",
    "    def __init__(self, path_folder_model=None):\n",
    "        super(SimpleBertClassifier, self).__init__()\n",
    "\n",
    "        filename_config_classifier = self.__class__.DEFAULT_FILENAME_CLASSIFIER\n",
    "        filename_config_bert = self.__class__.DEFAULT_FILENAME_BERT\n",
    "        filename_model = self.__class__.DEFAULT_FILENAME_MODEL\n",
    "        keys_ignored_classifier = self.__class__.DEFAULT_KEYS_IGNORED_CLASSIFIER\n",
    "\n",
    "\n",
    "        self.path_folder_model = path_folder_model\n",
    "        self.path_config_bert = os.path.join(path_folder_model, filename_config_bert)\n",
    "        self.path_config_classifier = os.path.join(path_folder_model, filename_config_classifier)\n",
    "        self.path_file_model = os.path.join(path_folder_model, filename_model)\n",
    "\n",
    "        with open(self.path_config_classifier, 'r') as file:\n",
    "            config_classifier = json.load(file)\n",
    "        # end\n",
    "\n",
    "        for key in keys_ignored_classifier:\n",
    "            del(config_classifier[key])\n",
    "        # end\n",
    "\n",
    "        # classfier parameters\n",
    "        self.classifier_input_size = config_classifier.get('bert').get('input_size')\n",
    "        self.classifier_max_length = config_classifier.get('bert').get('max_length')\n",
    "        self.classifier_output_size = config_classifier.get('bert').get('output_size')\n",
    "        #\n",
    "\n",
    "        self.labels_output_classifier = config_classifier.get('classes')\n",
    "        self.dict_label_index = {label: index for index, label in enumerate(self.labels_output_classifier)}\n",
    "\n",
    "        self.l1 = None\n",
    "        self.linear = None\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.loaded = False\n",
    "    # end\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
    "        output_bert = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_bert[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "    # end\n",
    "\n",
    "    def load(self):\n",
    "        if not self.loaded:\n",
    "            self.l1 = BertModel(BertConfig.from_pretrained(self.path_config_bert))\n",
    "            print('loading {} x {} linear classfier layer'.format(self.classifier_input_size, self.classifier_output_size))\n",
    "            self.classifier = torch.nn.Linear(self.classifier_input_size, self.classifier_output_size)\n",
    "\n",
    "#             self.to(self.device)\n",
    "            self.load_state_dict(torch.load(self.path_file_model, map_location=torch.device(self.device)))\n",
    "\n",
    "            print('Please Ignore warning message sent by BertTokenizer below')\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(self.path_folder_model)\n",
    "            self.factory_encoder = FactoryEncoder(self.tokenizer, self.device, self.classifier_max_length)\n",
    "            self.loaded = True\n",
    "        # end\n",
    "\n",
    "        return self\n",
    "    # end\n",
    "\n",
    "    def predicts(self, samples_input):\n",
    "        encoder = self.factory_encoder.get_instance(samples_input)\n",
    "        outputs_raw = []\n",
    "        for sample_encoded in encoder:\n",
    "            with torch.no_grad():\n",
    "                output_raw = self(**sample_encoded).cpu().numpy().flatten().tolist()\n",
    "                # print('jinyuj: predicts:83 output_raw: {}'.format(output_raw))\n",
    "                outputs_raw.append(output_raw)\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        info_result = {\n",
    "            'outputs': outputs_raw,\n",
    "            'labels': self.labels_output_classifier\n",
    "        }\n",
    "\n",
    "        return info_result\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd6e976-064f-47d4-9339-8d37730bb25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 768 x 16 linear classfier layer\n",
      "Please Ignore warning message sent by BertTokenizer below\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "classfier = SimpleBertClassifier('vBERT-base-20')\n",
    "classfier.load()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0bf25c-4ffe-4836-8aa1-207c5433d101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,    13,  3478,  2012,  2377, 21296,     5,   438,   310,   202,\n",
      "          2193,    13,  4708,  2039, 11066,  2334,  5371,  2000,     7,  2951,\n",
      "          3573,  4708,  4130,  2188,  7309,  2573, 15327,  1040,  2860,   134,\n",
      "          2193,  2849,   532,     4,  2175,  2015, 27354,  2691,     7,  2039,\n",
      "         11066,  2951,  3573,  5371,   283,  2193,  6453,  1999,     4,  6100,\n",
      "         18750,  2043,  2364,  1999,  5227, 18750,  2043,  8299,  7561, 12398,\n",
      "         10611,    94,  3478,  8299,  7561,  2193,  2025,  2179,    13,  4708,\n",
      "          5604,  6164,  2349,  2000,  4945,  4708,  4130,  2188,  7309,  2573,\n",
      "         15327,  1040,  2860,   134,  2193,  2849,   532,     4,  2175,  2015,\n",
      "         27354,  2691,  3231,  5343,   283,  2193, 10611,    94,  3478,  6164,\n",
      "          5604,  2043,  6164,  5604,  2043,  8246,  2003,  2275,  2000,  2995,\n",
      "          1999,  3231,  2553, 21296,     5,   438,   310,   202,  2193,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'outputs': [[0.23458433151245117,\n",
       "   1.985474944114685,\n",
       "   -0.9938645362854004,\n",
       "   -0.26257655024528503,\n",
       "   1.3386788368225098,\n",
       "   -0.571368396282196,\n",
       "   -1.3755505084991455,\n",
       "   -0.11298679560422897,\n",
       "   0.22189024090766907,\n",
       "   -0.4230208098888397,\n",
       "   0.0988524928689003,\n",
       "   0.3769085109233856,\n",
       "   1.2184100151062012,\n",
       "   0.8001226186752319,\n",
       "   -0.3819250464439392,\n",
       "   -0.7456659078598022]],\n",
       " 'labels': ['esx:esx_server:resource_mgmt___cpu',\n",
       "  'esx:esx_server:unknown',\n",
       "  'esx:infrastructure:dictionary',\n",
       "  'esx:vsan:unknown',\n",
       "  'esx:host_client:host_client_release_notes',\n",
       "  'esx:host_agent:host_mgmt',\n",
       "  'esx:infrastructure:crypto',\n",
       "  'esx:esx_server:dde_storage_driver',\n",
       "  'esx:vsan_dp_data:tests',\n",
       "  'esx:host_profiles:host_profile_engine',\n",
       "  'esx:esx_server:vmkctl___infrastructure',\n",
       "  'esx:vsan:lsom',\n",
       "  'esx:esx_server:storage_vmfs',\n",
       "  'esx:esx_server:hardware',\n",
       "  'esx:nimbus:nimbus_esxdeploy',\n",
       "  'esx:vsan:vsanwitnessovf']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'timestamp failed at play deploy vm efi nvme vmxnet number timestamp task upload local file to esxi data store task path home worker workspace dw rhel number arm ansible vsphere gos validation common esxi upload data store file yml number exception in vsphere copy python when main in request python when http error default fatal localhost failed http error number not found timestamp task testing exit due to failure task path home worker workspace dw rhel number arm ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi nvme vmxnet number'\n",
    "classfier.predicts([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80d2a4-f1e1-44e6-bcce-4e74768c2cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
