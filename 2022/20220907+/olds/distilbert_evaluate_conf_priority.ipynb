{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ccbfe1-055f-44cc-b4a3-1b55b76dd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: 20211221+/distilbert_load_eval.ipynb\n",
    "\n",
    "# you get all pretrained model name here\n",
    "# https://huggingface.co/transformers/pretrained_models.html\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "# from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2adce6ab-61dd-4ce6-8a19-ae6a376de4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model we gonna train, base uncased BERT\n",
    "# check text classification models here: https://huggingface.co/models?filter=text-classification\n",
    "# model_name = \"bert-base-uncased\"\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model_dir = 'model_goscv_solution_distilbert_1'\n",
    "# max sequence length for each document/sentence sample\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa81bad-e92e-48a9-b820-17970189c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4405fd2-deff-4438-9e8d-ef384fc3c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_passages(path_data):\n",
    "    df = pd.read_csv(path_data)\n",
    "    documents = df['processed_log'].to_list()\n",
    "    return documents\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa514b17-f9ee-4234-883d-ea9bbbdd546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "# path_folder_data = 'datasource'\n",
    "# name_data = 'train-goscv-solution-202206211830.csv'\n",
    "# path_data = os.path.join(path_folder_data, name_data)\n",
    "# valid_texts = read_passages(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73de8b8d-7b83-4582-b0c0-19edbadea12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_texts = [\"timestamp failed at play deploy vm efi nvme vmxnet number timestamp task upload local file to esxi data store task path home worker workspace dw rhel number arm ansible vsphere gos validation common esxi upload data store file yml number exception in vsphere copy python when main in request python when http error default fatal localhost failed http error number not found timestamp task testing exit due to failure task path home worker workspace dw rhel number arm ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi nvme vmxnet number\"] * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7e2059-a049-4c2c-9644-962a586f13e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redirect model to use local files model_goscv_solution_distilbert_1\n"
     ]
    }
   ],
   "source": [
    "# model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names))\n",
    "if len(os.listdir(model_dir)) > 1:\n",
    "    info_model = model_dir\n",
    "    print('redirect model to use local files {}'.format(info_model))\n",
    "else:\n",
    "    info_model = model_name\n",
    "    print('redirect model to use official {}'.format(info_model))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f9d9869-f388-4eec-92d0-d704d08cbe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepdive', 'retry']\n"
     ]
    }
   ],
   "source": [
    "filename_label = 'labels.json'\n",
    "path_label = os.path.join(info_model, filename_label)\n",
    "with open(path_label, 'r') as file:\n",
    "    labels = json.load(file)\n",
    "# end\n",
    "target_names = labels\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5af8c00-0a2a-4a5b-990c-634b3afcd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(info_model, num_labels=len(target_names))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a437ed7-d927-4d3e-bf9b-4cd6c60e1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_conf = []\n",
    "list_label = []\n",
    "\n",
    "for text_valid in valid_texts:\n",
    "    input_valid_tokenized = tokenizer(text_valid, padding=True, truncation=True, max_length=max_length, return_tensors='pt').to('cuda')\n",
    "    with torch.no_grad():\n",
    "        out = model(**input_valid_tokenized, output_hidden_states=True, output_attentions=True)\n",
    "    # end\n",
    "\n",
    "    probas_evaluate = torch.nn.functional.softmax(out.logits, dim=-1)\n",
    "    answer_evaluate = int(probas_evaluate.argmax().cpu())\n",
    "    \n",
    "    label_evaluate = target_names[answer_evaluate]\n",
    "#     list_conf.append(max(probas_evaluate.cpu().numpy().tolist()[0]))\n",
    "    list_conf.append(probas_evaluate.cpu().numpy().tolist()[0])\n",
    "    list_label.append(label_evaluate)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99f42347-3026-402c-a1c9-7b3c3a56c5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404],\n",
       " [0.008189420215785503, 0.9918105602264404]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823c59ef-881a-4724-ba3a-94f8be71a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_folder_data = 'data'\n",
    "# name_data_origin = 'log_content_5_20220507_target.csv'\n",
    "# name_data_target = 'log_content_5_20220507_target_priority.csv'\n",
    "\n",
    "# path_data_origin = os.path.join(path_folder_data, name_data_origin)\n",
    "# path_data_target = os.path.join(path_folder_data, name_data_target)\n",
    "\n",
    "# data_all = pd.read_csv(path_data_origin)\n",
    "# data_all['conf_priority'] = list_conf\n",
    "# data_all['label_priority'] = list_label\n",
    "\n",
    "# data_all.to_csv(path_data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f779a79a-7c24-4fd1-a0b0-5a6333918b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works for investigation\n",
    "# text_valid = valid_texts[0]\n",
    "# input_valid_tokenized = tokenizer(text_valid, padding=True, truncation=True, max_length=max_length, return_tensors='pt').to('cuda')\n",
    "# with torch.no_grad():\n",
    "#     out = model(**input_valid_tokenized, output_hidden_states=True, output_attentions=True)\n",
    "# # end\n",
    "\n",
    "# probas_main = torch.nn.functional.softmax(out.logits, dim=-1)\n",
    "# answer_main = int(probas_main.argmax().cpu())\n",
    "\n",
    "# max(probas_main.cpu().numpy().tolist()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
