{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ccbfe1-055f-44cc-b4a3-1b55b76dd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: 20211221+/distilbert_load_eval.ipynb\n",
    "\n",
    "# you get all pretrained model name here\n",
    "# https://huggingface.co/transformers/pretrained_models.html\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "# from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d107ce45-4ee9-45e9-962c-a9edf6d7eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "from lit_nlp import dev_server\n",
    "from lit_nlp import server_flags\n",
    "from lit_nlp.api import model as lit_model\n",
    "from lit_nlp.api import types as lit_types\n",
    "# Use the regular GLUE data loaders, because these are very simple already.\n",
    "from lit_nlp.lib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2adce6ab-61dd-4ce6-8a19-ae6a376de4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model we gonna train, base uncased BERT\n",
    "# check text classification models here: https://huggingface.co/models?filter=text-classification\n",
    "# model_name = \"bert-base-uncased\"\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model_dir = 'models-cpqe-label'\n",
    "# max sequence length for each document/sentence sample\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa81bad-e92e-48a9-b820-17970189c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4405fd2-deff-4438-9e8d-ef384fc3c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_passages(path_data, test_size=0.1):\n",
    "    df = pd.read_csv(path_data)\n",
    "    documents = df['processed'].to_list()\n",
    "    labels_str = df['label'].to_list()\n",
    "    labels_list = sorted(list(set(labels_str)))\n",
    "    labels_all = {l:idx for idx, l in enumerate(labels_list)}\n",
    "    labels = [labels_all[label_str] for label_str in labels_str]\n",
    "    return train_test_split(documents, labels, test_size=test_size), labels_list\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d950615-e084-4753-a30f-c02f4e5f4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "path_folder_data = 'data'\n",
    "name_data = 'log_content_4.csv'\n",
    "path_data = os.path.join(path_folder_data, name_data)\n",
    "(train_texts, valid_texts, train_labels, valid_labels), target_names = read_passages(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea18b82-385c-4897-bcb4-9a4805e8704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redirect model to use local files models-cpqe-label\n"
     ]
    }
   ],
   "source": [
    "# model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names))\n",
    "if len(os.listdir(model_dir)) > 1:\n",
    "    info_model = model_dir\n",
    "    print('redirect model to use local files {}'.format(info_model))\n",
    "else:\n",
    "    info_model = model_name\n",
    "    print('redirect model to use official {}'.format(info_model))\n",
    "model = DistilBertForSequenceClassification.from_pretrained(info_model, num_labels=len(target_names))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a73e7c6f-5e1d-45db-be55-589fd0ca13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_valid = valid_texts[0]\n",
    "input_valid_tokenized = tokenizer(text_valid, padding=True, truncation=True, max_length=max_length, return_tensors='pt').to('cuda')\n",
    "with torch.no_grad():\n",
    "    out = model(**input_valid_tokenized, output_hidden_states=True, output_attentions=True)\n",
    "# end\n",
    "\n",
    "probas_main = torch.nn.functional.softmax(out.logits, dim=-1)\n",
    "answer_main = int(probas_main.argmax().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54d080d-1c0f-4973-99f1-e4ec3762393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Any, Callable, Iterable, Optional, Sequence\n",
    "from lit_nlp.components.citrus import helpers\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "DEFAULT_KERNEL_WIDTH = 25\n",
    "DEFAULT_MASK_TOKEN = '[MASK]'\n",
    "DEFAULT_NUM_SAMPLES = 256\n",
    "DEFAULT_SOLVER = 'cholesky'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb2e986-f3a8-4c0e-b3df-51b3275d2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_masks(num_samples: int,\n",
    "                 num_features: int,\n",
    "                 seed: Optional[int] = None):\n",
    "\n",
    "  rng = np.random.RandomState(seed)\n",
    "  positions = np.tile(np.arange(num_features), (num_samples, 1))\n",
    "  permutation_fn = np.vectorize(rng.permutation, signature='(n)->(n)')\n",
    "  permutations = permutation_fn(positions)  # A shuffled range of positions.\n",
    "  num_disabled_features = rng.randint(1, num_features + 1, (num_samples, 1))\n",
    "  return permutations >= num_disabled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5ed324-a96c-46f4-bfd6-2b928341d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perturbations(tokens: Sequence[str],\n",
    "                      masks: np.ndarray,\n",
    "                      mask_token: str = '<unk>') -> Iterable[str]:\n",
    "  for mask in masks:\n",
    "    parts = [t if mask[i] else mask_token for i, t in enumerate(tokens)]\n",
    "    yield ' '.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec181228-2cb3-4f9e-ae05-aba32e9d114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_kernel(\n",
    "    distance: float, kernel_width: float = DEFAULT_KERNEL_WIDTH) -> np.ndarray:\n",
    "  return np.sqrt(np.exp(-(distance**2) / kernel_width**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "747c4f6f-b999-4641-b3cc-c776e25b2ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64024/529431099.py:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all_true_mask = np.ones_like(masks[0], dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "tokenzier_lime = str.split\n",
    "mask_token = DEFAULT_MASK_TOKEN\n",
    "num_samples = DEFAULT_NUM_SAMPLES\n",
    "solver = DEFAULT_SOLVER\n",
    "seed = 233\n",
    "alpha = 1.0\n",
    "distance_fn = functools.partial(metrics.pairwise.pairwise_distances, metric='cosine')\n",
    "distance_scale = 100.\n",
    "# intialize stage ends\n",
    "\n",
    "sentence = text_valid\n",
    "\n",
    "tokens = tokenzier_lime(sentence)\n",
    "masks = sample_masks(num_samples + 1, len(tokens), seed=seed)\n",
    "assert masks.shape[0] == num_samples + 1, 'Expected num_samples + 1 masks.'\n",
    "all_true_mask = np.ones_like(masks[0], dtype=np.bool)\n",
    "masks[0] = all_true_mask\n",
    "\n",
    "perturbations = list(get_perturbations(tokens, masks, mask_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ae0b062-78f3-45ff-8919-9744b1a99687",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64024/229379367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_true_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_scale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'kernel' is not defined"
     ]
    }
   ],
   "source": [
    "distances = distance_fn(all_true_mask.reshape(1, -1), masks).flatten()\n",
    "distances = distance_scale * distances\n",
    "distances = kernel(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c38a52f7-f00a-4e4b-987d-b5b3871f779e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 10, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "\n",
    "for sample_text in perturbations:\n",
    "    input_valid_tokenized = tokenizer(sample_text, padding=True, truncation=True, max_length=max_length, return_tensors='pt').to('cuda')\n",
    "    with torch.no_grad():\n",
    "        out = model(**input_valid_tokenized, output_hidden_states=True, output_attentions=True)\n",
    "    # end\n",
    "\n",
    "    probas_main = torch.nn.functional.softmax(out.logits, dim=-1)\n",
    "    answer_main = int(probas_main.argmax().cpu())\n",
    "    outputs.append(answer_main)\n",
    "# end\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06af272b-194d-47eb-b167-f9e30f50f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(outputs)):\n",
    "    if outputs[i] != outputs[0]:\n",
    "        outputs[i] = -1\n",
    "    else:\n",
    "        outputs[i] = 1\n",
    "    # end\n",
    "# end\n",
    "\n",
    "outputs[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5aa05232-09a0-4a3a-a1c0-4234bebe32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.Ridge(\n",
    "  alpha=alpha, solver=solver, random_state=seed).fit(\n",
    "      masks, outputs, sample_weight=distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ea1e28c-18ab-4295-8b1f-2eb802557fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: -0.023183863459707625\n",
      "failed: -0.2746099995065513\n",
      "at: -0.219695197312005\n",
      "play: 0.054984703794530854\n",
      "environment: -0.0834374812746224\n",
      "setup: 0.05597365447866541\n",
      "timestamp: 0.19986559562192402\n",
      "task: 0.0777442306292182\n",
      "check: -0.21456759375613815\n",
      "vm: -0.041482927614853615\n",
      "test: 0.03773525268181391\n",
      "vm: -0.07966582208240552\n",
      "does: -0.12941320236018386\n",
      "not: 0.08789889652641769\n",
      "exist: -0.0076308324193059655\n",
      "task: 0.18039569330510727\n",
      "path: 0.01571196899571004\n",
      "home: -0.14071762399024354\n",
      "worker: 0.06741362021599813\n",
      "workspace: -0.018504082777068182\n",
      "ansible: -0.012719973737949367\n",
      "regression: -0.057050216851529084\n",
      "rocky: -0.09209717736368647\n",
      "linux: 0.06886728244756356\n",
      "8: 0.03589163450459772\n",
      "x: -0.07732930080079342\n",
      "ansible: -0.047796011986324785\n",
      "vsphere: 0.05030807705640052\n",
      "gos: 0.16725167888378406\n",
      "validation: 0.09962579683502076\n",
      "environment: -0.07236017778519066\n",
      "setup: -0.1690803137336273\n",
      "environment: -0.15728506139767678\n",
      "setup: -0.19634559645407362\n",
      "yml: 0.005076664894012131\n",
      "25: -0.05943382422686676\n",
      "fatal: -0.08801706408069536\n",
      "localhost: -0.05775792345550761\n",
      "failed: -0.01102842177819808\n",
      "can: 0.09254776562013829\n",
      "n: 0.09610873816792469\n",
      "t: -0.15364100773293\n",
      "deploy: -0.03626080606958124\n",
      "vm: 0.14959207956419085\n",
      "as: -0.024139154036246935\n",
      "a: -0.11551065663116089\n",
      "vm: -0.03007565778163278\n",
      "with: 0.03962165962761767\n",
      "same: 0.07284219093201288\n",
      "name: 0.17571842636346027\n",
      "test: 0.010637648284043462\n",
      "vm: -0.006321629532502832\n",
      "already: 0.038382475050329774\n",
      "exists: 0.34064633607509803\n",
      "please: 0.12730357917724278\n",
      "provide: 0.008603381504562559\n",
      "a: 0.10711843042272694\n",
      "new: 0.006411424126075913\n",
      "vm: -0.11081513694115427\n",
      "name: 0.19397572229050014\n"
     ]
    }
   ],
   "source": [
    "for word, contribution in zip(tokenzier_lime(perturbations[0]), model.coef_):\n",
    "    print('{}: {}'.format(word, contribution))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
