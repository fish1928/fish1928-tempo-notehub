{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d78fbbf-fd8b-4086-a662-60bee5554ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, errno\n",
    "import json\n",
    "import yaml\n",
    "import argparse\n",
    "import sys\n",
    "import traceback\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# default constants\n",
    "\n",
    "VBERT_MODEL = \"vBERT-2020-Base\"\n",
    "CLASSIFICATION_LAYER_WIDTH = 768 if \"Base\" in VBERT_MODEL else 1024\n",
    "MAX_STRING_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a91dd4-04b1-4bd3-9d7d-92ce39d275e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_base = 'data'\n",
    "name_testset = 'importance_detection_testset_200_12000.csv'\n",
    "path_testset = os.path.join(path_data_base, name_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a083aa-e8d1-485b-963f-f59454c8c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_base = 'models-instaml-finetune'\n",
    "version_model = 'v1216'\n",
    "name_file_config = '.model.json'\n",
    "path_model = os.path.join(path_model_base, version_model)\n",
    "path_config = os.path.join(path_model, name_file_config)\n",
    "\n",
    "with open(path_config, 'r') as file:\n",
    "    config_model = json.load(file)\n",
    "# end\n",
    "\n",
    "for k, v in config_model.get('bert').items():\n",
    "    config_model[k] = v\n",
    "# end\n",
    "\n",
    "config_model['root'] = path_model\n",
    "\n",
    "del config_model['allmetrics']\n",
    "del config_model['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ddd177-3c91-405f-b2a5-9ce159119fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d6203e-e775-42bf-ae6a-b8310e822b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.config = config\n",
    "        self.model_dir = config.get(\"root\", \".\")\n",
    "        self.model_name = config.get(\"name\", VBERT_MODEL)\n",
    "        self.classification_layer_width = config.get(\"input_size\", CLASSIFICATION_LAYER_WIDTH)\n",
    "        self.classes = config.get(\"classes\", [\"0\", \"1\"])\n",
    "        self.num_classes = config.get(\"output_size\", len(self.classes))\n",
    "        self.max_string_length = config.get(\"max_length\", MAX_STRING_LEN)\n",
    "        self.bert_config_file = self.model_dir + \"/bert_config.json\"\n",
    "        self.model_file_path = self.model_dir + \"/model.pt\"\n",
    "#        self.device = config.get(\"device\", \"cpu\")\n",
    "        self.device = 'cpu'\n",
    "#         self.device = 'cuda'\n",
    "        self.metrics = [ \"accuracy\", \"precision\", \"recall\", \"F-score\" ]\n",
    "\n",
    "        # Load the vBERT vocabulary into the tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.model_dir)\n",
    "    # end\n",
    "\n",
    "    def load_bert_for_training(self):\n",
    "        print('Loading vBERT model: ' + self.model_name)\n",
    "        self.l1 = BertModel.from_pretrained(pretrained_model_name_or_path=self.config.bert_model_dir)\n",
    "        print(\"Adding {}x{} classification layer\".format(self.classification_layer_width, self.num_classes))\n",
    "        self.classifier = torch.nn.Linear(self.classification_layer_width, self.num_classes)\n",
    "\n",
    "    def load_bert_for_inference(self):\n",
    "        print('Loading vBERT config')\n",
    "        self.l1 = BertModel(BertConfig.from_pretrained(self.bert_config_file))\n",
    "        print(\"Adding {}x{} classification layer\".format(self.classification_layer_width, self.num_classes))\n",
    "        self.classifier = torch.nn.Linear(self.classification_layer_width, self.num_classes)\n",
    "\n",
    "    # Encode the input with vBERT, read output from the last layer of vBERT, and pass to the classification layer\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         print(output_1.keys())\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0,:]\n",
    "#         pooler = hidden_state[:, 0]\n",
    "#         print(pooler.numpy()[0][:5])\n",
    "        output = self.classifier(pooler)\n",
    "        print(type(output))\n",
    "        print(output)\n",
    "        return output\n",
    "\n",
    "#     def do_inference(self, data_loader, test_output=None):\n",
    "#         model = self.eval()\n",
    "#         predictions = []\n",
    "#         real_values = []\n",
    "#         with torch.no_grad():\n",
    "#             for data in data_loader:\n",
    "#                 input_ids = data['ids'].to(self.device)\n",
    "#                 attention_mask = data['mask'].to(self.device)\n",
    "#                 targets = data['targets'].to(self.device)\n",
    "#                 outputs = model(input_ids, attention_mask)\n",
    "#                 _, preds = torch.max(outputs, dim=1)\n",
    "#                 predictions.extend(preds)\n",
    "#                 real_values.extend(targets)\n",
    "#                 if test_output != None:\n",
    "#                     test_output.extend(outputs)\n",
    "#         predictions = torch.stack(predictions).cpu()\n",
    "#         real_values = torch.stack(real_values).cpu()\n",
    "\n",
    "#         test_accu = 100 * accuracy_score(real_values, predictions)\n",
    "#         test_precision, test_recall, test_fscore, ignore = precision_recall_fscore_support(real_values, predictions, average='macro')\n",
    "#         test_precision *= 100\n",
    "#         test_recall *= 100\n",
    "#         test_fscore *= 100\n",
    "#         metrics = [ test_accu, test_precision, test_recall, test_fscore ]\n",
    "#         return predictions, real_values, metrics\n",
    "#     # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9fc264-f7e4-4e2e-9041-0270fade5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prepare(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, classes):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.classes = classes\n",
    "        \n",
    "        self.index_class_label = {klass:index for index, klass in enumerate(self.classes)}\n",
    "    # end\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data['log'][index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        label = self.index_class_label[self.data['pcc'][index]]\n",
    "\n",
    "#         target = torch.tensor(label, dtype=torch.long)\n",
    "        target = label\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long).to(device),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long).to(device),\n",
    "            'targets': label\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    # end\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a591be59-7104-4cd4-b26b-d4d65c96b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# def classify_text(model, txt, conf=None):\n",
    "#     tokenizer = model.tokenizer\n",
    "#     max_string_length = model.max_string_length\n",
    "    \n",
    "#     dataset = pd.DataFrame.from_csv(path_testset)\n",
    "#     prepared_set = Prepare(dataset, tokenizer, max_string_length)\n",
    "#     params = {'batch_size': 1,\n",
    "#                 'shuffle': False,\n",
    "#                 'num_workers': 0\n",
    "#             }\n",
    "#     loader = DataLoader(prepared_set, **params)\n",
    "#     outputs = []\n",
    "#     predictions, real_values, metrics = self.do_inference(loader, outputs)\n",
    "#     classes = model.classes\n",
    "#     result = { 'classes': [ ], 'text': txt, 'top_class': classes[int(predictions[0])], 'top_class_index': int(predictions[0]) }\n",
    "#     xi = 0\n",
    "#     for x in classes:\n",
    "#         result['classes'].append({ 'class_name': x, 'confidence': float(outputs[0][xi]) })\n",
    "#         xi += 1\n",
    "#     return result\n",
    "\n",
    "\n",
    "#     dataset_eval = Dataset(train_texts + valid_texts, train_labels + valid_labels)\n",
    "#     dataload_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=4, shuffle=True)\n",
    "\n",
    "#     y_hats_all = []\n",
    "#     y_true_all = []\n",
    "#     for _valid_texts, _valid_labels in tqdm(dataload_eval):\n",
    "#         outputs = predict_minibatch(model, _valid_texts)\n",
    "#         y_hats = outputs['y_hats'].tolist()\n",
    "#         y_true = _valid_labels.detach().cpu().numpy().tolist()   \n",
    "#         y_hats_all += y_hats\n",
    "#         y_true_all += y_true\n",
    "#     # end\n",
    "\n",
    "#     print('precision_score: {}'.format(precision_score(y_true_all, y_hats_all)))\n",
    "#     print('recall_score: {}'.format(recall_score(y_true_all, y_hats_all)))\n",
    "#     print('f1_score: {}'.format(f1_score(y_true_all, y_hats_all)))\n",
    "# # end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9ec5ea-cc2f-4e86-a684-c1ff1e0a7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09423524-04b5-440d-8246-715668d1318f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>comment</td>\n",
       "      <td>timestamp 5776059 admission failure in path ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>comment</td>\n",
       "      <td>timestamp cpu 2 2156005 os fs os fs get mount ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>comment</td>\n",
       "      <td>timestamp hex id debug id hex id vsan ctl get ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc      pcc                                                log\n",
       "0  comment  comment  timestamp 5776059 admission failure in path ho...\n",
       "1  comment  comment  timestamp cpu 2 2156005 os fs os fs get mount ...\n",
       "2  comment  comment  timestamp hex id debug id hex id vsan ctl get ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7894b731-e804-430a-9377-93b7ae573f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file models-instaml-finetune/v1216/config.json not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vBERT config\n",
      "Adding 768x2 classification layer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier(config_model)\n",
    "model.load_bert_for_inference()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model.model_file_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a4870-f095-4d44-baa4-c7ee7efd635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/12546 [00:03<10:50:37,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-2.1091,  1.9549]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/12546 [00:06<10:38:25,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 3.0900, -2.9522]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/12546 [00:08<9:55:05,  2.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.1257, -0.5034]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/12546 [00:10<8:44:40,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.0434, -0.3458]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/12546 [00:13<9:13:05,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-1.1902,  0.8427]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/12546 [00:18<12:21:25,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.8433, -1.4177]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/12546 [00:20<10:08:38,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.4764, -1.5382]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/12546 [00:21<8:02:49,  2.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.2600, -0.7214]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/12546 [00:22<6:55:08,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.6116, -0.1456]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/12546 [00:24<6:10:51,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 2.1974, -2.0701]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/12546 [00:25<5:34:49,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 2.3078, -2.4600]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/12546 [00:26<5:14:46,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.9369, -0.9817]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/12546 [00:27<4:42:52,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.3688, -0.8425]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/12546 [00:28<4:26:53,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 2.1483, -2.1280]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/12546 [00:29<4:15:59,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 3.7258, -3.8336]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/12546 [00:31<4:14:06,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.6277, -0.4663]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/12546 [00:32<4:06:38,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.3886,  0.6661]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/12546 [00:33<4:26:15,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.7426,  0.6735]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/12546 [00:34<4:10:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.0155, -0.1980]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/12546 [00:36<4:41:09,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-1.6190,  1.6832]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/12546 [00:37<4:43:59,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.5935, -1.5733]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/12546 [00:38<4:34:47,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 4.4069, -4.2766]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/12546 [00:40<4:26:49,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.2966, -1.0754]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/12546 [00:41<4:22:33,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.1084,  0.4031]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/12546 [00:42<4:18:43,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 3.0551, -2.9220]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/12546 [00:43<4:22:28,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.6238, -1.7210]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/12546 [00:45<4:24:48,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 2.4421, -2.6440]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/12546 [00:46<4:38:31,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[0.0844, 0.1283]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/12546 [00:47<4:17:44,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.0735, -1.2047]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/12546 [00:48<4:21:56,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.8101, -1.0646]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/12546 [00:50<4:18:28,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 4.1417, -3.6845]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/12546 [00:52<5:25:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.1431, -1.3727]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/12546 [00:53<4:56:10,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 2.3934, -2.2555]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/12546 [00:54<4:29:47,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.3741, -1.4557]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/12546 [00:55<4:36:49,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-1.6378,  1.9177]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/12546 [00:57<4:59:25,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.8334, -2.4273]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/12546 [00:58<4:32:39,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.8727, -0.5921]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 38/12546 [01:00<5:16:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 2.9368, -3.1556]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/12546 [01:02<5:08:24,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 2.3122, -1.8568]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/12546 [01:03<4:44:35,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.2615,  0.3970]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/12546 [01:04<4:34:30,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.4970, -1.2929]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 42/12546 [01:06<5:41:25,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 1.7709, -1.6454]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 43/12546 [01:08<5:45:15,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 2.2464, -1.9900]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 44/12546 [01:13<9:01:37,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-1.0964,  0.9258]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/12546 [01:16<10:11:07,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-1.6309,  1.7456]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/12546 [01:17<5:58:22,  1.72s/it] \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(path_testset)\n",
    "max_length = model.max_string_length\n",
    "classes = model.classes\n",
    "tokenizer = model.tokenizer\n",
    "\n",
    "prepared_set = Prepare(dataset, tokenizer, max_length, classes)\n",
    "params_dataloader = {\n",
    "    'batch_size': 1,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "}\n",
    "data_loader = DataLoader(prepared_set, **params_dataloader)\n",
    "y_hats_all = []\n",
    "y_true_all = []\n",
    "ids_top3 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(data_loader):\n",
    "#         ids_top3.append(data['ids'].cpu().numpy()[0][:3])\n",
    "        input_ids = data['ids'].to(device)\n",
    "        attention_mask = data['mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "#         print(outputs)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        y_hats_all.append(preds.cpu().numpy()[0])\n",
    "        y_true_all.append(data['targets'][0])\n",
    "    # end\n",
    "# end\n",
    "\n",
    "print('accuracy_score: {}'.format(accuracy_score(y_true_all, y_hats_all)))\n",
    "print('precision_score: {}'.format(precision_score(y_true_all, y_hats_all, zero_division=1)))\n",
    "print('recall_score: {}'.format(recall_score(y_true_all, y_hats_all, zero_division=1)))\n",
    "print('f1_score: {}'.format(f1_score(y_true_all, y_hats_all, zero_division=1)))\n",
    "# print(ids_top3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31b660-d014-4326-b7ce-aaf8221aeb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_hats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da22ae9-e276-4c5f-b32a-1af5befcd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('y_hats_all.txt', 'w+') as file:\n",
    "#     file.write(json.dumps([int(x) for x in y_hats_all]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1a755-bf68-44f8-94db-21e252e9783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('y_true_all.txt', 'w+') as file:\n",
    "#     file.write(json.dumps([int(x) for x in y_true_all]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d18938-2a77-479c-a7c3-8d080df51190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('accuracy_score: {}'.format(accuracy_score(y_true_all, y_hats_all)))\n",
    "# print('precision_score: {}'.format(precision_score(y_true_all, y_hats_all, zero_division=1, average='macro')))\n",
    "# print('recall_score: {}'.format(recall_score(y_true_all, y_hats_all, zero_division=1, average='macro')))\n",
    "# print('f1_score: {}'.format(f1_score(y_true_all, y_hats_all, zero_division=1, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975025e-8087-4805-9cfc-4cd29957f785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
