{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46bc3c6c-dd1a-4c8d-b420-72021ebe075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import IntTensor\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, EarlyStoppingCallback\n",
    "\n",
    "\n",
    "# DEVICE = 'cuda'\n",
    "DEVICE = 'cpu'\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "MAX_LENGTH = 512\n",
    "TOKEN_SEP = 102\n",
    "TOKEN_CLS = 101\n",
    "\n",
    "\n",
    "model_name = MODEL_NAME\n",
    "max_length = MAX_LENGTH\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
    "\n",
    "sample_test = 'permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask'\n",
    "\n",
    "# tokenizer.encode_plus(sample_test, padding=True, max_length=max_length, return_tensors='pt', truncation=True)\n",
    "# dict_sample = tokenizer.encode_plus(sample_test, return_tensors='pt')\n",
    "dict_sample = tokenizer.encode_plus(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b3cf3a6-1659-49cc-ad67-053287f52b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 6656, 2015, 2006, 1996, 4539, 14176, 5136, 5278, 1996, 6556, 1056, 8737, 4130, 1999, 2019, 19307, 9563, 2000, 1037, 4130, 15685, 1999, 1056, 8737, 2005, 2062, 7561, 2592, 2224, 1058, 1058, 1058, 3478, 3094, 2001, 1057, 7308, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca36fe49-59f0-405b-b34e-cbeb7ceeffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_sample = list(set(dict_sample['input_ids'][1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4021fdb1-8c87-41a4-94e7-781351abf101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-44e3f816c5a4>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  list_masks_attention = np.array([ [1 for i in range(len(tokens_sample))] for tokens_sample in list_tokens_sample])\n"
     ]
    }
   ],
   "source": [
    "list_tokens_sample = [[token] for token in tokens_sample]\n",
    "list_tokens_sample.insert(0, tokens_sample)\n",
    "\n",
    "for tokens_sample in list_tokens_sample:\n",
    "    tokens_sample.insert(0, TOKEN_CLS)\n",
    "    tokens_sample.append(TOKEN_SEP)\n",
    "# end\n",
    "\n",
    "list_masks_attention = np.array([ [1 for i in range(len(tokens_sample))] for tokens_sample in list_tokens_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55d9360a-10b0-4ea7-bc0a-30fbd12d70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_info_input = [{'input_ids': torch.IntTensor([tokens_sample]), 'attention_mask': torch.IntTensor([masks_sample])} for tokens_sample, masks_sample in zip(list_tokens_sample, list_masks_attention)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aa6cd59-a83a-4aaf-bac8-37f7a48665f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "725ca293-6feb-4067-bdc5-c13e67c87fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(sentence_origin, tokenizer):\n",
    "    dict_sample = tokenizer.encode_plus(sentence_origin)\n",
    "    \n",
    "    tokens_sample = dict_sample['input_ids'][1:-1]\n",
    "    tokens_sample_unique = list(set(dict_sample['input_ids'][1:-1]))\n",
    "\n",
    "    list_tokens_sample = [[token] for token in tokens_sample_unique]\n",
    "    list_tokens_sample.insert(0, tokens_sample)\n",
    "\n",
    "    for tokens_sample in list_tokens_sample:\n",
    "        tokens_sample.insert(0, TOKEN_CLS)\n",
    "        tokens_sample.append(TOKEN_SEP)\n",
    "    # end\n",
    "\n",
    "    list_masks_attention = np.array([ [1 for i in range(len(tokens_sample))] for tokens_sample in list_tokens_sample])\n",
    "    list_info_input = [{'input_ids': torch.IntTensor([tokens_sample]), 'attention_mask': torch.IntTensor([masks_sample]), 'is_main': False} for tokens_sample, masks_sample in zip(list_tokens_sample, list_masks_attention)]\n",
    "    list_info_input[0]['is_main'] = True\n",
    "    \n",
    "    return list_info_input\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "937fe08c-d3b8-4a96-a7fe-a3aa5835b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_output(input_model, out_model, tokenizer):\n",
    "    dict_info = {}\n",
    "    \n",
    "    tokens = input_model['input_ids'].tolist()[0]\n",
    "    sentence = tokenizer.decode(tokens[1:-1])\n",
    "    \n",
    "    hidden_states = out_model.hidden_states\n",
    "    h2 = hidden_states[-1].squeeze(0) # [24, 762]\n",
    "    h2 = h2.to('cpu')\n",
    "    \n",
    "    is_main = input_model['is_main']\n",
    "    \n",
    "    if not is_main:\n",
    "        # dict_info[sentence] = h2[0,:]   # get the cls of this token\n",
    "        dict_info[sentence] = h2[1,:]   # get the token of this token\n",
    "        return dict_info\n",
    "    # end\n",
    "    \n",
    "    list_word = [tokenizer.decode(token) for token in tokens]\n",
    "    list_result = []\n",
    "    \n",
    "    for i in range(len(list_word)):\n",
    "        list_result.append([list_word[i], h2[i,:]])\n",
    "    # end\n",
    "    \n",
    "    dict_info[sentence] = list_result\n",
    "    \n",
    "    return dict_info\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92cfb1c1-f173-45fb-bc18-90923209d6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-3c9e8eb8d73d>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  list_masks_attention = np.array([ [1 for i in range(len(tokens_sample))] for tokens_sample in list_tokens_sample])\n"
     ]
    }
   ],
   "source": [
    "list_input = prepare_input(sample_test, tokenizer)\n",
    "list_result = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_current in list_input:\n",
    "        out = model(input_ids=input_current['input_ids'].to(DEVICE), attention_mask=input_current['attention_mask'].to(DEVICE), output_attentions=True, output_hidden_states=True)\n",
    "        result = parse_model_output(input_current, out, tokenizer)\n",
    "        list_result.append(result)\n",
    "    # end for\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e815b7bf-846a-444f-b7bf-85cd43f1400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_states = out.hidden_states\n",
    "# h2 = hidden_states[-1].squeeze(0) # [24, 762]\n",
    "# h2 = h2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "05d7e418-be19-4299-8451-e777d310c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(list_info_input[0]['input_ids'].tolist()[0][1:-1])\n",
    "# [tokenizer.decode(token) for token in list_info_input[0]['input_ids'].tolist()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2fafb02a-abee-48b1-b145-71f6aee0c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate token in sentence vs token short\n",
    "\n",
    "dict_single = {k:v for result in list_result[1:] for k, v in result.items()}\n",
    "list_origin = list(list_result[0].values())[0]\n",
    "list_sim = []\n",
    "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "\n",
    "for item_origin in list_origin[1:-1]:\n",
    "    embedding_origin = item_origin[1]\n",
    "    embedding_single = dict_single[token_origin]\n",
    "    \n",
    "    result_cos = cos(embedding_origin, embedding_single).tolist()\n",
    "    list_sim.append((token_origin, result_cos))\n",
    "# end\n",
    "    token_origin = item_origin[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "157ac748-7bfa-4527-84ac-e0883a9b7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate token in sentence vs cls in sentence\n",
    "cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "list_sim = []\n",
    "\n",
    "for item_origin in list_origin[1:-1]:\n",
    "    token_origin = item_origin[0]\n",
    "    \n",
    "    embedding_origin = item_origin[1]\n",
    "    embedding_cls = list_origin[0][1]\n",
    "\n",
    "    result_cos = cos(embedding_origin, embedding_cls).tolist()\n",
    "    list_sim.append((token_origin, result_cos))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0eaeec4a-2270-499b-8532-1a786c7e167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [att for att in model.__dir__() if att[0] != '_' and callable(getattr(model, att))]\n",
    "\n",
    "# target = model.distilbert.transformer.layer[-1].attention\n",
    "# [att for att in target.__dir__() if att[0] != '_' and callable(getattr(target, att))]\n",
    "# target.forward.__code__\n",
    "# out.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f549601f-4e07-40ef-aa3a-0a0679cd5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://github.com/huggingface/transformers/blob/main/src/transformers/models/distilbert/modeling_distilbert.py\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "from types import MethodType\n",
    "import math\n",
    "from torch import nn\n",
    "\n",
    "def forward_version_jinyuj(\n",
    "    self,\n",
    "    query: torch.Tensor,\n",
    "    key: torch.Tensor,\n",
    "    value: torch.Tensor,\n",
    "    mask: torch.Tensor,\n",
    "    head_mask: Optional[torch.Tensor] = None,\n",
    "    output_attentions: bool = False,\n",
    ") -> Tuple[torch.Tensor, ...]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        query: torch.tensor(bs, seq_length, dim)\n",
    "        key: torch.tensor(bs, seq_length, dim)\n",
    "        value: torch.tensor(bs, seq_length, dim)\n",
    "        mask: torch.tensor(bs, seq_length)\n",
    "\n",
    "    Returns:\n",
    "        weights: torch.tensor(bs, n_heads, seq_length, seq_length) Attention weights context: torch.tensor(bs,\n",
    "        seq_length, dim) Contextualized layer. Optional: only if `output_attentions=True`\n",
    "    \"\"\"\n",
    "    \n",
    "    print('[ jinyuj] run jinyuj version of forward')\n",
    "    bs, q_length, dim = query.size()\n",
    "    k_length = key.size(1)\n",
    "    # assert dim == self.dim, f'Dimensions do not match: {dim} input vs {self.dim} configured'\n",
    "    # assert key.size() == value.size()\n",
    "\n",
    "    dim_per_head = self.dim // self.n_heads\n",
    "\n",
    "    mask_reshp = (bs, 1, 1, k_length)\n",
    "\n",
    "    def shape(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"separate heads\"\"\"\n",
    "        return x.view(bs, -1, self.n_heads, dim_per_head).transpose(1, 2)\n",
    "\n",
    "    def unshape(x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"group heads\"\"\"\n",
    "        return x.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * dim_per_head)\n",
    "\n",
    "    q = shape(self.q_lin(query))  # (bs, n_heads, q_length, dim_per_head)\n",
    "    k = shape(self.k_lin(key))  # (bs, n_heads, k_length, dim_per_head)\n",
    "    v = shape(self.v_lin(value))  # (bs, n_heads, k_length, dim_per_head)\n",
    "\n",
    "    q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\n",
    "    scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)\n",
    "    mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)\n",
    "    scores = scores.masked_fill(\n",
    "        mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
    "    )  # (bs, n_heads, q_length, k_length)\n",
    "\n",
    "    weights = nn.functional.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)\n",
    "    weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)\n",
    "\n",
    "    # Mask heads if we want to\n",
    "    if head_mask is not None:\n",
    "        weights = weights * head_mask\n",
    "\n",
    "    context = torch.matmul(weights, v)  # (bs, n_heads, q_length, dim_per_head)\n",
    "    context = unshape(context)  # (bs, q_length, dim)\n",
    "    \n",
    "    v_unshape = unshape(v)\n",
    "    self.v_last = v_unshape\n",
    "    self.z_last = context\n",
    "    \n",
    "    context = self.out_lin(context)  # (bs, q_length, dim)\n",
    "\n",
    "    if output_attentions:\n",
    "        return (context, weights)\n",
    "    else:\n",
    "        return (context,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "063bc050-f686-42d6-ba28-365d6256c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.distilbert.transformer.layer[-2].attention.forward.__code__\n",
    "target = model.distilbert.transformer.layer[-1].attention\n",
    "target.forward = MethodType(forward_version_jinyuj, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c3483594-788b-4e99-9cb8-6803bcf16444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ jinyuj] run jinyuj version of forward\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model(input_ids=input_current['input_ids'].to(DEVICE), attention_mask=input_current['attention_mask'].to(DEVICE), output_attentions=True, output_hidden_states=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f68d6ea7-ef87-4a8e-9020-cd398ba87923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 768])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.z_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d4595f1a-8923-4a91-aa8e-2058739f020a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.distilbert.transformer.layer[-1]\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
