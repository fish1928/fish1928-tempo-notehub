{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a36c05-aa20-4909-a5e9-a172529e22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from os.path import exists\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad, one_hot\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import json\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "### utils.py ###\n",
    "\n",
    "class Dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "    def __iadd__(self, other):\n",
    "        for k, v in self.items():\n",
    "            if k in other and other[k]:\n",
    "                self[k] += other[k]\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        return self\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "# Takes the file paths as arguments\n",
    "def parse_csv_file_to_json(path_file_csv):\n",
    "    # create a dictionary\n",
    "    elements = []\n",
    "\n",
    "    # Open a csv reader called DictReader\n",
    "    with open(path_file_csv, encoding='utf-8') as file_csv:\n",
    "    #with open(path_file_csv) as file_csv:\n",
    "        reader_csv = csv.DictReader(file_csv, delimiter=\"\\t\")\n",
    "\n",
    "        # Convert each row into a dictionary\n",
    "        # and add it to data\n",
    "        for dict_head_value in reader_csv:\n",
    "            element = {}\n",
    "\n",
    "            for head, value in dict_head_value.items():\n",
    "                #print(value)\n",
    "                if value and (value[0] in [\"[\", \"{\"]):\n",
    "                    #element[head] = eval(value)\n",
    "                    element[head] = value\n",
    "                else:\n",
    "                    element[head] = value\n",
    "\n",
    "            elements.append(element)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    return elements\n",
    "# end\n",
    "\n",
    "### utils.py ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### core.py ###\n",
    "\n",
    "\"Produce N identical layers.\"\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "\n",
    "    \"Take in model size and number of heads.\"\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    # end\n",
    "\n",
    "\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    def attention(self, query, key, value, mask=None, dropout=None):\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            # print('jinyuj: scores: {}, mask: {}'.format(scores.shape, mask.shape))\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        # end\n",
    "        p_attn = scores.softmax(dim=-1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        # end\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "    # end\n",
    "\n",
    "\n",
    "    \"Implements Figure 2\"\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = self.attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (\n",
    "            x.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)\n",
    "    # end\n",
    "# end class\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A residual connection followed by a layer norm.\n",
    "Note for code simplicity the norm is first as opposed to last.\n",
    "\"\"\"\n",
    "class ResidualLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, size, dropout=0.1, eps=1e-6):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.norm = torch.nn.LayerNorm(size, eps)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    # end\n",
    "\n",
    "    \"Apply residual connection to any sublayer with the same size.\"\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    # end\n",
    "# end class\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleIDEmbeddings(nn.Module):\n",
    "    def __init__(self, size_vocab, dim_hidden, id_pad):\n",
    "        super(SimpleIDEmbeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(size_vocab, dim_hidden, padding_idx=id_pad)\n",
    "        self.dim_hidden = dim_hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.lut(x)\n",
    "        return result * math.sqrt(self.dim_hidden)\n",
    "    # end\n",
    "\n",
    "    def get_shape(self):\n",
    "        return (self.lut.num_embeddings, self.lut.embedding_dim)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\"Implement the PE function.\"\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_positional, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.dim_positional = dim_positional\n",
    "        pe = torch.zeros(max_len, dim_positional)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, dim_positional, 2) * -(math.log(10000.0) / dim_positional)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).to('cuda')\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return x\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleEmbedder(nn.Module):    # no segment embedder as we do not need that\n",
    "    def __init__(self, size_vocab=None, dim_hidden=128, dropout=0.1, id_pad=0):\n",
    "        super(SimpleEmbedder, self).__init__()\n",
    "        self.size_vocab = size_vocab\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.id_pad = id_pad\n",
    "\n",
    "        self.embedder = nn.Sequential(\n",
    "            SimpleIDEmbeddings(size_vocab, dim_hidden, id_pad),\n",
    "            PositionalEncoding(dim_hidden),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    def forward(self, ids_input):   # (batch, seqs_with_padding)\n",
    "        return self.embedder(ids_input)\n",
    "    # end\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.size_vocab\n",
    "    # end\n",
    "# end\n",
    "\n",
    "### core.py ###\n",
    "\n",
    "\n",
    "\n",
    "class SimpleEncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, dim_feedforward, n_head, dropout=0.1):\n",
    "        super(SimpleEncoderLayer, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.layer_attention = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_feedforward = PositionwiseFeedForward(dim_hidden, dim_feedforward, dropout)\n",
    "        self.layers_residual = clones(ResidualLayer(dim_hidden, dropout), 2)\n",
    "    # end\n",
    "\n",
    "    def forward(self, embeddings, masks, *args):\n",
    "        embeddings = self.layers_residual[0](embeddings, lambda embeddings: self.layer_attention(embeddings, embeddings, embeddings, masks))\n",
    "        return self.layers_residual[1](embeddings, self.layer_feedforward)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class SimpleDecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, dim_feedforward, n_head, dropout=0.1):\n",
    "        super(SimpleDecoderLayer, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.layer_attention_decoder = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_attention_encoder = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_feedforward = PositionwiseFeedForward(dim_hidden, dim_feedforward, dropout)\n",
    "        self.layers_residual = clones(ResidualLayer(dim_hidden, dropout), 3)\n",
    "\n",
    "    def forward(self, embeddings, masks_encoder, output_encoder, masks_decoder, *args):\n",
    "        embeddings = self.layers_residual[0](embeddings, lambda embeddings: self.layer_attention_decoder(embeddings, embeddings, embeddings, masks_decoder))\n",
    "        embeddings = self.layers_residual[1](embeddings, lambda embeddings: self.layer_attention_encoder(embeddings, output_encoder, output_encoder, masks_encoder))\n",
    "        return self.layers_residual[2](embeddings, self.layer_feedforward)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleTransformerStack(nn.Module):\n",
    "\n",
    "    def __init__(self, obj_layer, n_layers):\n",
    "        super(SimpleTransformerStack, self).__init__()\n",
    "        self.layers = clones(obj_layer, n_layers)\n",
    "\n",
    "        self.norm = torch.nn.LayerNorm(obj_layer.dim_hidden)\n",
    "        self.keys_cache = ['output']\n",
    "        self.cache = Dotdict({\n",
    "            'output': None\n",
    "        })\n",
    "    # end\n",
    "\n",
    "    def forward(self, embedding_encoder=None, masks_encoder=None, output_encoder=None, embedding_decoder=None, masks_decoder=None ,noncache=False, **kwargs):  # input -> (batch, len_seq, vocab)\n",
    "\n",
    "        if output_encoder is not None and embedding_decoder is not None and masks_decoder is not None:\n",
    "            embeddings = embedding_decoder\n",
    "        else:\n",
    "            embeddings = embedding_encoder\n",
    "        # end\n",
    "\n",
    "        for layer in self.layers:\n",
    "            embeddings = layer(embeddings, masks_encoder, output_encoder, masks_decoder)\n",
    "        # end\n",
    "\n",
    "        output = self.norm(embeddings)\n",
    "\n",
    "        if not noncache:\n",
    "            self.cache.output = output\n",
    "        # end\n",
    "\n",
    "        return output\n",
    "    # end\n",
    "\n",
    "    # def get_vocab_size(self):\n",
    "    #     return self.embedder.embedder_token.shape[-1]\n",
    "    # # end\n",
    "\n",
    "    def clear_cache(self):\n",
    "        for key_cache in self.keys_cache:\n",
    "            self.cache[key_cache] = None\n",
    "        # end\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleEncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embedder_encoder, embedder_decoder, pooling=False):\n",
    "        super(SimpleEncoderDecoder, self).__init__()\n",
    "\n",
    "        self.pooling = pooling\n",
    "        \n",
    "        self.embedder_encoder = embedder_encoder\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.embedder_decoder = embedder_decoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        self.keys_cache = ['output_encoder_pooled']\n",
    "        self.cache = Dotdict({\n",
    "            'output_encoder_pooled': None\n",
    "        })\n",
    "    # end\n",
    "\n",
    "    def forward(self, ids_encoder=None, masks_encoder=None, ids_decoder=None, masks_decoder=None, nocache=False, **kwargs):\n",
    "        \n",
    "        output_encoder = self.embed_and_encode(ids_encoder=ids_encoder, masks_encoder=masks_encoder, nocache=nocache)\n",
    "        output = output_encoder\n",
    "        \n",
    "        if self.pooling:\n",
    "            output_encoder_refilled = output_encoder.masked_fill(masks_encoder.transpose(-1,-2)==False, 0)\n",
    "            output_encoder_pooled = torch.mean(output_encoder_refilled, dim=-2)\n",
    "            self.cache.output_encoder_pooled = output_encoder_pooled\n",
    "            \n",
    "            output_encoder_pooled_expanded = output_encoder_pooled.unsqueeze(-2).expand(output_encoder.shape)\n",
    "            output = output_encoder_pooled_expanded\n",
    "        # end\n",
    "        \n",
    "        if self.embedder_decoder and self.decoder:\n",
    "            output_decoder = self.embed_and_decode(ids_decoder=ids_decoder, masks_encoder=masks_encoder, output_encoder=output, masks_decoder=masks_decoder, nocache=nocache)\n",
    "            output = output_decoder\n",
    "        # end if\n",
    "        \n",
    "        return output\n",
    "    # end\n",
    "    \n",
    "    def embed_and_encode(self, ids_encoder=None, masks_encoder=None, nocache=False, **kwargs):\n",
    "        self.encoder.clear_cache()\n",
    "        \n",
    "        embedding_encoder = self.embedder_encoder(ids_encoder)\n",
    "        output_encoder = self.encoder(\n",
    "            embedding_encoder=embedding_encoder,\n",
    "            masks_encoder=masks_encoder,\n",
    "            nocache=nocache\n",
    "        )\n",
    "        \n",
    "        return output_encoder\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def embed_and_decode(self, ids_decoder=None, masks_encoder=None, output_encoder=None, masks_decoder=None, nocache=False, **kwargs):\n",
    "        self.decoder.clear_cache()\n",
    "        \n",
    "        embedding_decoder = self.embedder_decoder(ids_decoder)\n",
    "        output_decoder = self.decoder(\n",
    "            masks_encoder=masks_encoder,\n",
    "            output_encoder=output_encoder,    #(len_seq, dim_hidden) -> (1, dim_hidden)\n",
    "            embedding_decoder=embedding_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            nocache=nocache\n",
    "        )\n",
    "\n",
    "        return output_decoder\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def clear_cache(self):\n",
    "        self.encoder.clear_cache()\n",
    "        \n",
    "        for key_cache in self.keys_cache:\n",
    "            self.cache[key_cache] = None\n",
    "        # end\n",
    "        \n",
    "        if self.decoder:\n",
    "            self.decoder.clear_cache()\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def get_vocab_size(self, name_embedder):\n",
    "        embedder = getattr(self, f'embedder_{name_embedder}')\n",
    "        return embedder.get_vocab_size()\n",
    "    # end\n",
    "\n",
    "# end\n",
    "\n",
    "class LinearAndNorm(nn.Module):\n",
    "    def __init__(self, dim_in = None, dim_out = None, eps_norm=1e-12):\n",
    "        super(LinearAndNorm, self).__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(dim_in, dim_out)\n",
    "        self.norm = torch.nn.LayerNorm(dim_out, eps_norm)\n",
    "    # end\n",
    "\n",
    "    def forward(self, seqs_in):\n",
    "        return self.norm(self.linear(seqs_in).relu())\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, vocab, splitter):\n",
    "        self.splitter = splitter\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.id_pad = len(vocab)\n",
    "        self.id_cls = len(vocab) + 1\n",
    "        self.id_sep = len(vocab) + 2\n",
    "        self.id_mask = len(vocab) + 3\n",
    "        \n",
    "        self.size_vocab = len(vocab) + 4\n",
    "        self.vocab_size = self.size_vocab\n",
    "\n",
    "        self.token_pad = '[P@D]'\n",
    "        self.token_cls = '[CL$]'\n",
    "        self.token_sep = '[$EP]'\n",
    "        self.token_mask = '[M@$K]'\n",
    "           \n",
    "        self.index_id_token_special = {\n",
    "            self.id_pad: self.token_pad,\n",
    "            self.id_cls: self.token_cls,\n",
    "            self.id_sep: self.token_sep,\n",
    "            self.id_mask: self.token_mask\n",
    "        }\n",
    "        \n",
    "    # end\n",
    "\n",
    "    def encode(self, line):\n",
    "        return self.vocab([doc.text.lower() for doc in self.splitter(line)])\n",
    "    # end\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        words = []\n",
    "        for token in tokens:\n",
    "            token = int(token)\n",
    "            \n",
    "            if token in self.index_id_token_special:\n",
    "                word_target = self.index_id_token_special[token]\n",
    "            else:\n",
    "                try:\n",
    "                    word_target = vocab.lookup_token(token)\n",
    "                except:\n",
    "                    word_target = '[ERROR_LOOKUP_{}]'.format(token)\n",
    "                # end\n",
    "            # end\n",
    "            \n",
    "            words.append(word_target)\n",
    "        # end\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        for k, v in kwargs.items():\n",
    "            if v is not None and type(v) is not bool:\n",
    "                self.kwargs[k] = v.to(Batch.DEVICE)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.kwargs\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class Collator_S2S:\n",
    "\n",
    "    def __init__(self, tokenizer, size_seq_max, need_masked=0.3):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size_seq_max = size_seq_max\n",
    "        self.need_masked = need_masked\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def __call__(self, list_corpus_source):\n",
    "\n",
    "        tokens_input_encoder = []\n",
    "        tokens_input_decoder = []\n",
    "        tokens_label_decoder = []\n",
    "        labels_similarity = []\n",
    "\n",
    "        for corpus_source in list_corpus_source: # (line0, line1, sim), output of zip remove single case\n",
    "            if len(corpus_source) == 3:\n",
    "                corpus_line = [corpus_source[0], corpus_source[1]]\n",
    "                labels_similarity.append(corpus_source[2])\n",
    "            else:\n",
    "                corpus_line = [corpus_source[1]]\n",
    "            # end\n",
    "            \n",
    "            for line in corpus_line:\n",
    "                tokens = self.tokenizer.encode(line)\n",
    "\n",
    "                # TODO: check edge\n",
    "                if len(tokens) > self.size_seq_max - 2:\n",
    "                    tokens = tokens[:self.size_seq_max-2]\n",
    "                # end\n",
    "\n",
    "                tokens_input_encoder.append([self.tokenizer.id_cls] + tokens + [self.tokenizer.id_sep])\n",
    "                tokens_input_decoder.append([self.tokenizer.id_cls] + tokens)\n",
    "                tokens_label_decoder.append(tokens + [self.tokenizer.id_sep])\n",
    "            # end\n",
    "            \n",
    "\n",
    "        # end\n",
    "\n",
    "        inputs_encoder, masks_encoder, segments_encoder, labels_encoder = self.pad_sequences(tokens_input_encoder, self.size_seq_max, need_masked=self.need_masked)\n",
    "        inputs_decoder, masks_decoder, segments_decoder, _ = self.pad_sequences(tokens_input_decoder, self.size_seq_max, need_diagonal=True)\n",
    "        labels_decoder, masks_label, segments_label, _ = self.pad_sequences(tokens_label_decoder, self.size_seq_max)\n",
    "        # labels_similarity = torch.Tensor(labels_similarity).unsqueeze(0).transpose(0,1)\n",
    "        labels_similarity = torch.Tensor(labels_similarity)\n",
    "\n",
    "        return Batch(\n",
    "            ids_encoder=inputs_encoder,  # contains [mask]s\n",
    "            masks_encoder=masks_encoder,\n",
    "            labels_encoder=labels_encoder,  # doesn't contain [mask]\n",
    "            segments_encoder=segments_encoder,\n",
    "            ids_decoder=inputs_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            labels_decoder=labels_decoder,\n",
    "            segments_label=segments_label,\n",
    "            labels_similarity=labels_similarity\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    \n",
    "    # return masks_attention?, return masks_segment?\n",
    "    def pad_sequences(self, sequences, size_seq_max, need_diagonal=False, need_masked=0): # need_diagonal and need_masked cannot both set, one for bert seq one for s2s seq\n",
    "        id_pad = self.tokenizer.id_pad\n",
    "        id_mask = self.tokenizer.id_mask\n",
    "\n",
    "        sequences_padded = []\n",
    "        sequences_masked_padded = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            len_seq = len(sequence)\n",
    "\n",
    "            count_pad = size_seq_max - len_seq\n",
    "\n",
    "            sequence = torch.LongTensor(sequence)\n",
    "            sequence_padded = torch.cat((sequence, torch.LongTensor([id_pad] * count_pad)))\n",
    "            sequences_padded.append(sequence_padded)\n",
    "\n",
    "            if need_masked:\n",
    "                index_masked = list(range(1, len_seq-1))\n",
    "                random.shuffle(index_masked)\n",
    "                index_masked = torch.LongTensor(index_masked[:int(need_masked * (len_seq-2))])\n",
    "\n",
    "                sequence_masked = sequence.detach().clone()\n",
    "                sequence_masked.index_fill_(0, index_masked, id_mask)\n",
    "                sequence_masked_padded = torch.cat((sequence_masked, torch.LongTensor([id_pad] * count_pad)))\n",
    "                \n",
    "                sequences_masked_padded.append(sequence_masked_padded)\n",
    "            # end\n",
    "    #   # end for\n",
    "\n",
    "        inputs = torch.stack(sequences_padded)  # (batch, size_seq_max)\n",
    "        if need_masked:\n",
    "            inputs_masked_padded = torch.stack(sequences_masked_padded)\n",
    "        # end\n",
    "\n",
    "        masks_segment = (inputs != self.tokenizer.id_pad).unsqueeze(-2)    #(nbatch, 1, seq)\n",
    "        masks_attention = self.make_std_mask(inputs, self.tokenizer.id_pad) if need_diagonal else masks_segment\n",
    "\n",
    "        if need_masked:\n",
    "            masks_masked = (inputs_masked_padded != id_mask).unsqueeze(-2)\n",
    "            masks_attention = masks_attention & masks_masked\n",
    "            return inputs_masked_padded, masks_attention, masks_segment, inputs # (inputs, masks_attention, masks_segment, labels)\n",
    "        else:\n",
    "            return inputs, masks_attention, masks_segment, None\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def subsequent_mask(self, size):\n",
    "        \"Mask out subsequent positions.\"\n",
    "        attn_shape = (1, size, size)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        return subsequent_mask == 0\n",
    "\n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & self.subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class Collator_BERT:\n",
    "    def __init__(self, tokenizer, size_seq_max, need_masked=0.3):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size_seq_max = size_seq_max\n",
    "        self.need_masked = need_masked\n",
    "        \n",
    "        index_special_token_2_id = {k:v for k,v in zip(tokenizer.all_special_tokens,tokenizer.all_special_ids)}\n",
    "        \n",
    "        self.id_pad = index_special_token_2_id['[PAD]']\n",
    "        self.id_mask = index_special_token_2_id['[MASK]']\n",
    "        self.id_cls = index_special_token_2_id['[CLS]']\n",
    "        self.id_sep = index_special_token_2_id['[SEP]']\n",
    "        self.id_unk = index_special_token_2_id['[UNK]']\n",
    "        \n",
    "        self.regex_special_token = re.compile(r'\\[(PAD|MASK|CLS|SEP|EOL|UNK)\\]')\n",
    "    # end\n",
    "    \n",
    "    def _preprocess(self, line):\n",
    "        line = re.sub(self.regex_special_token, r'<\\1>', line)\n",
    "        line = re.sub(r'''('|\"|`){2}''', '', line)\n",
    "        line = re.sub(r'\\.{2,3}', '', line)\n",
    "        line = re.sub(r' {2,}', ' ', line)\n",
    "        line = line.lstrip().rstrip()\n",
    "        return line\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def __call__(self, list_sequence_batch):\n",
    "        list_sequence_batch = [self._preprocess(sequence) for sequence in list_sequence_batch]   # remove special tokens\n",
    "        \n",
    "        list_sequence_tokenized = self.tokenizer.batch_encode_plus(list_sequence_batch, add_special_tokens=False)['input_ids']\n",
    "        \n",
    "        # Process I. \n",
    "        list_list_tokenized = []\n",
    "        \n",
    "        # batch initialized condition\n",
    "        list_tokenized_cache = []\n",
    "        len_tokenized_accumulated = 2 # add cls and sep\n",
    "        \n",
    "        while list_sequence_tokenized:\n",
    "            tokenized_poped = list_sequence_tokenized.pop(0)\n",
    "            len_tokenized_current = len(tokenized_poped)\n",
    "            \n",
    "            if len_tokenized_accumulated + len_tokenized_current > self.size_seq_max:\n",
    "                if list_tokenized_cache:\n",
    "                    list_list_tokenized.append(list_tokenized_cache)\n",
    "                \n",
    "                    # clear\n",
    "                    list_tokenized_cache = []\n",
    "                    len_tokenized_accumulated = 2\n",
    "                # end\n",
    "            # end\n",
    "\n",
    "            list_tokenized_cache.append(tokenized_poped)\n",
    "            len_tokenized_accumulated += len_tokenized_current\n",
    "        # end\n",
    "        \n",
    "        list_list_tokenized.append(list_tokenized_cache)\n",
    "        \n",
    "        \n",
    "        # Process II. Merge list_tokenized\n",
    "        list_tokenized_merged = []\n",
    "        \n",
    "        for list_tokenized in list_list_tokenized:\n",
    "            # tokenized_merged = [token for tokenized_padded in [tokenized + [self.id_eol] for tokenized in list_tokenized] for token in tokenized_padded]\n",
    "            tokenized_merged = [token for tokenized in list_tokenized for token in tokenized][:self.size_seq_max-2]\n",
    "            list_tokenized_merged.append(tokenized_merged)\n",
    "        # end\n",
    "        \n",
    "        \n",
    "        # Process III. Add begin and stop special token, same as jinyuj_transformers_quora.ipynb\n",
    "        tokens_input_encoder = []\n",
    "        tokens_input_decoder = []\n",
    "        tokens_label_decoder = []\n",
    "        \n",
    "        for tokenized_merged in list_tokenized_merged:\n",
    "            tokens_input_encoder.append([self.id_cls] + tokenized_merged + [self.id_sep])\n",
    "            tokens_input_decoder.append([self.id_cls] + tokenized_merged)\n",
    "            tokens_label_decoder.append(tokenized_merged + [self.id_sep])\n",
    "        # end\n",
    "        \n",
    "        inputs_encoder, masks_encoder, segments_encoder, labels_encoder = self.pad_sequences(tokens_input_encoder, self.size_seq_max, need_masked=self.need_masked)\n",
    "        inputs_decoder, masks_decoder, segments_decoder, _ = self.pad_sequences(tokens_input_decoder, self.size_seq_max, need_diagonal=True)\n",
    "        labels_decoder, masks_label, segments_label, _ = self.pad_sequences(tokens_label_decoder, self.size_seq_max)\n",
    "        \n",
    "        return Batch(\n",
    "            ids_encoder=inputs_encoder,  # contains [mask]s\n",
    "            masks_encoder=masks_encoder,\n",
    "            labels_encoder=labels_encoder,  # doesn't contain [mask]\n",
    "            segments_encoder=segments_encoder,\n",
    "            ids_decoder=inputs_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            labels_decoder=labels_decoder,\n",
    "            segments_label=segments_label\n",
    "        )\n",
    "    # end\n",
    "\n",
    "\n",
    "    # return masks_attention?, return masks_segment?\n",
    "    def pad_sequences(self, sequences, size_seq_max, need_diagonal=False, need_masked=0): # need_diagonal and need_masked cannot both set, one for bert seq one for s2s seq\n",
    "        id_pad = self.id_pad\n",
    "        id_mask = self.id_mask\n",
    "\n",
    "        sequences_padded = []\n",
    "        sequences_masked_padded = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            len_seq = len(sequence)\n",
    "\n",
    "            count_pad = size_seq_max - len_seq\n",
    "\n",
    "            sequence = torch.LongTensor(sequence)\n",
    "            sequence_padded = torch.cat((sequence, torch.LongTensor([id_pad] * count_pad)))\n",
    "            # print(sequence_padded.shape)\n",
    "            sequences_padded.append(sequence_padded)\n",
    "\n",
    "            if need_masked:\n",
    "                index_masked = list(range(1, len_seq-1))\n",
    "                random.shuffle(index_masked)\n",
    "                index_masked = torch.LongTensor(index_masked[:int(need_masked * (len_seq-2))])\n",
    "\n",
    "                sequence_masked = sequence.detach().clone()\n",
    "                sequence_masked.index_fill_(0, index_masked, id_mask)\n",
    "                sequence_masked_padded = torch.cat((sequence_masked, torch.LongTensor([id_pad] * count_pad)))\n",
    "                \n",
    "                sequences_masked_padded.append(sequence_masked_padded)\n",
    "            # end\n",
    "    #   # end for\n",
    "\n",
    "        inputs = torch.stack(sequences_padded)  # (batch, size_seq_max)\n",
    "        if need_masked:\n",
    "            inputs_masked_padded = torch.stack(sequences_masked_padded)\n",
    "        # end\n",
    "\n",
    "        masks_segment = (inputs != self.id_pad).unsqueeze(-2)    #(nbatch, 1, seq)\n",
    "        masks_attention = self.make_std_mask(inputs, self.id_pad) if need_diagonal else masks_segment\n",
    "\n",
    "        if need_masked:\n",
    "            masks_masked = (inputs_masked_padded != id_mask).unsqueeze(-2)\n",
    "            masks_attention = masks_attention & masks_masked\n",
    "            return inputs_masked_padded, masks_attention, masks_segment, inputs # (inputs, masks_attention, masks_segment, labels)\n",
    "        else:\n",
    "            return inputs, masks_attention, masks_segment, None\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def subsequent_mask(self, size):\n",
    "        \"Mask out subsequent positions.\"\n",
    "        attn_shape = (1, size, size)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        return subsequent_mask == 0\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & self.subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51933c37-2474-4ea8-8819-d67e8061c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "def Multi30k(language_pair=None):\n",
    "    corpus_lines_train = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/train.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_train.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_train = list(zip(*corpus_lines_train))\n",
    "\n",
    "    corpus_lines_eval = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/val.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_eval.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_eval = list(zip(*corpus_lines_eval))\n",
    "\n",
    "    return corpus_train, corpus_eval, None\n",
    "# end\n",
    "\n",
    "\n",
    "def Quora(split=0.05):\n",
    "    filename_quora = 'quora_duplicate_questions.tsv'\n",
    "    \n",
    "    contents_quora = parse_csv_file_to_json(filename_quora)\n",
    "    list_corpus_quora = []\n",
    "    for c in contents_quora:\n",
    "        label = int(c['is_duplicate'])\n",
    "        score = 1.0 if label else 0.5\n",
    "        corpus_quora = (c['question1'], c['question2'], score)\n",
    "        list_corpus_quora.append(corpus_quora)\n",
    "    # end\n",
    "    \n",
    "    indexs_all = list(range(len(list_corpus_quora)))\n",
    "    random.shuffle(indexs_all)\n",
    "    \n",
    "    index_split = int(split * len(list_corpus_quora))\n",
    "    \n",
    "    indexs_eval = indexs_all[:index_split]\n",
    "    indexs_train = indexs_all[index_split:]\n",
    "    \n",
    "    list_corpus_eval = [list_corpus_quora[i_e] for i_e in indexs_eval]\n",
    "    list_corpus_train = [list_corpus_quora[i_t] for i_t in indexs_train]\n",
    "    \n",
    "    return list_corpus_train, list_corpus_eval, None\n",
    "# end\n",
    "\n",
    "def BookCorpus2000(split=0.1):\n",
    "    filename = 'bookcorpus_2000.json'\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        list_corpus = json.load(file)\n",
    "    # end\n",
    "    \n",
    "    indexs_all = list(range(len(list_corpus)))\n",
    "    random.shuffle(indexs_all)\n",
    "    \n",
    "    index_split = int(split * len(list_corpus))\n",
    "    \n",
    "    indexs_eval = indexs_all[:index_split]\n",
    "    indexs_train = indexs_all[index_split:]\n",
    "    \n",
    "    list_corpus_eval = [list_corpus[i_e] for i_e in indexs_eval]\n",
    "    list_corpus_train = [list_corpus[i_t] for i_t in indexs_train]\n",
    "    \n",
    "    return list_corpus_train, list_corpus_eval, None\n",
    "# end\n",
    "\n",
    "\n",
    "def BookCorpus(split=0.0001, used=-1):\n",
    "    import datasets\n",
    "    \n",
    "    list_corpus = datasets.load_dataset('bookcorpus')['train']['text'][:used]   # 70,000,000, 70 Million\n",
    "    \n",
    "    indexs_all = list(range(len(list_corpus)))\n",
    "    random.shuffle(indexs_all)\n",
    "    \n",
    "    index_split = int(split * len(list_corpus))\n",
    "    \n",
    "    indexs_eval = indexs_all[:index_split]\n",
    "    indexs_train = indexs_all[index_split:]\n",
    "    \n",
    "    list_corpus_eval = [list_corpus[i_e] for i_e in indexs_eval]\n",
    "    list_corpus_train = [list_corpus[i_t] for i_t in indexs_train]\n",
    "    \n",
    "    return list_corpus_train, list_corpus_eval, None\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_vocab(filename_vocab):\n",
    "    vocab_tgt = torch.load(filename_vocab)\n",
    "    return vocab_tgt\n",
    "# end\n",
    "\n",
    "def load_spacy():\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_en\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c03c357-ab7a-4589-a7a0-b87c2a3572b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoderHead_MLM(nn.Module):\n",
    "\n",
    "    @classmethod\n",
    "    def get_info_accuracy_template(cls):\n",
    "        return Dotdict({\n",
    "            'corrects_segmented': 0,\n",
    "            'corrects_masked': 0,\n",
    "            'num_segmented': 0,\n",
    "            'num_masked': 0 \n",
    "        })\n",
    "    # end\n",
    "    \n",
    "    def __init__(self, model, size_vocab, dim_hidden=128):\n",
    "        super(SimpleEncoderHead_MLM, self).__init__()\n",
    "        \n",
    "        self.ffn = LinearAndNorm(dim_in=dim_hidden, dim_out=dim_hidden)\n",
    "        self.extractor = torch.nn.Linear(dim_hidden, size_vocab, bias=False)\n",
    "        self.extractor.weight = nn.Parameter(model.embedder_encoder.embedder[0].lut.weight)\n",
    "        \n",
    "        self.keys_cache = ['labels_mlm', 'masks_encoder', 'segments_encoder', 'output']\n",
    "        self.cache = Dotdict({\n",
    "            'labels_mlm': None,\n",
    "            'masks_encoder': None,\n",
    "            'segments_encoder': None,\n",
    "            'output': None\n",
    "        })\n",
    "        \n",
    "        self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "    # end\n",
    "\n",
    "\n",
    "    def forward(self, model, labels_encoder=None, segments_encoder=None, masks_encoder=None, nocache=False, **kwargs):   # labels_input -> (batch, seq, labels)\n",
    "        output_encoder = model.encoder.cache.output\n",
    "        output_ffn = self.ffn(output_encoder)\n",
    "        output_mlm = self.extractor(output_ffn) # output_mlm = prediction_logits\n",
    "\n",
    "        if not nocache:\n",
    "            self.cache.labels_mlm = labels_encoder\n",
    "            self.cache.masks_encoder = masks_encoder\n",
    "            self.cache.segments_encoder = segments_encoder\n",
    "            self.cache.output = output_mlm\n",
    "        # end\n",
    "\n",
    "        return output_mlm\n",
    "    # end\n",
    "    \n",
    "    def get_loss(self):\n",
    "        \n",
    "        labels_mlm = self.cache.labels_mlm\n",
    "        masks_encoder = self.cache.masks_encoder\n",
    "        segments_encoder = self.cache.segments_encoder\n",
    "        output_mlm = self.cache.output\n",
    "        \n",
    "        info_acc = SimpleEncoderHead_MLM.get_info_accuracy_template()\n",
    "        \n",
    "        segments_encoder_2d = segments_encoder.transpose(-1,-2)[:,:,0]\n",
    "        hidden_mlm_segmented = output_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, output_mlm.shape[-1]) # should be (segmented_all_batchs, size_vocab)\n",
    "        \n",
    "        loss_segments = self.func_loss(hidden_mlm_segmented, labels_mlm.masked_select(segments_encoder_2d))\n",
    "        info_acc.corrects_segmented = torch.sum(hidden_mlm_segmented.argmax(-1) == labels_mlm.masked_select(segments_encoder_2d)).cpu().item()\n",
    "        info_acc.num_segmented = hidden_mlm_segmented.shape[0]\n",
    "        \n",
    "        masks_masked = torch.logical_xor(masks_encoder, segments_encoder) & segments_encoder # True is masked\n",
    "        masks_masked_perbatch = masks_masked[:,0,:]\n",
    "        hidden_mlm_masked = output_mlm.masked_select(masks_masked_perbatch.unsqueeze(-1)).reshape(-1, output_mlm.shape[-1])\n",
    "        \n",
    "        loss_masked = self.func_loss(hidden_mlm_masked, labels_mlm.masked_select(masks_masked_perbatch))       \n",
    "        info_acc.corrects_masked = torch.sum(hidden_mlm_masked.argmax(-1) == labels_mlm.masked_select(masks_masked_perbatch)).cpu().item()\n",
    "        info_acc.num_masked = hidden_mlm_masked.shape[0]\n",
    "        \n",
    "        loss_mlm = loss_segments + loss_masked * 3\n",
    "        \n",
    "        return loss_mlm, info_acc\n",
    "    # end\n",
    "    \n",
    "    \n",
    "    def clear_cache(self):\n",
    "        for key_cache in self.keys_cache:\n",
    "            self.cache[key_cache] = None\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b941e33c-9c6a-495b-8978-cc8b54e13120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoderHead_S2S(nn.Module):\n",
    "\n",
    "    @classmethod\n",
    "    def get_info_accuracy_template(cls):\n",
    "        return Dotdict({\n",
    "            'corrects_segmented': 0,\n",
    "            'num_segmented': 0 \n",
    "        })\n",
    "    # end\n",
    "    \n",
    "    \n",
    "    def __init__(self, model, size_vocab, dim_hidden=128):\n",
    "        super(SimpleDecoderHead_S2S, self).__init__()\n",
    "        \n",
    "        self.ffn = LinearAndNorm(dim_in=dim_hidden, dim_out=dim_hidden)\n",
    "        self.extractor = torch.nn.Linear(dim_hidden, size_vocab, bias=False)\n",
    "        self.extractor.weight = nn.Parameter(model.embedder_decoder.embedder[0].lut.weight)\n",
    "\n",
    "        self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.keys_cache = ['output', 'labels_s2s', 'segments_decoder']\n",
    "        self.cache = Dotdict({\n",
    "            'output': None,\n",
    "            'labels_s2s': None,\n",
    "            'segments_decoder': None\n",
    "        })\n",
    "\n",
    "    # end\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, model, labels_decoder=None, segments_label=None, nocache=False, **kwargs):   # labels_input -> (batch, seq, labels)\n",
    "        output_decoder = model.decoder.cache.output\n",
    "        output_ffn = self.ffn(output_decoder)\n",
    "        output_s2s = self.extractor(output_ffn)   # output_mlm = prediction_logits\n",
    "        \n",
    "        if not nocache:\n",
    "            self.cache.segments_label = segments_label\n",
    "            self.cache.labels_s2s =  labels_decoder\n",
    "            self.cache.output = output_s2s\n",
    "        # end\n",
    "\n",
    "        return output_s2s\n",
    "    # end\n",
    "\n",
    "\n",
    "    def get_loss(self):\n",
    "        labels_s2s = self.cache.labels_s2s\n",
    "        output_s2s = self.cache.output\n",
    "        info_acc = SimpleDecoderHead_S2S.get_info_accuracy_template()\n",
    "        \n",
    "        segments_label = self.cache.segments_label\n",
    "        segments_label_2d = segments_label.transpose(-1,-2)[:,:,0]\n",
    "        hidden_s2s_segmented = output_s2s.masked_select(segments_label_2d.unsqueeze(-1)).reshape(-1, output_s2s.shape[-1])\n",
    "\n",
    "        loss_segments = self.func_loss(hidden_s2s_segmented, labels_s2s.masked_select(segments_label_2d))\n",
    "        info_acc.corrects_segmented = torch.sum(hidden_s2s_segmented.argmax(-1) == labels_s2s.masked_select(segments_label_2d)).cpu().item()\n",
    "        info_acc.num_segmented = hidden_s2s_segmented.shape[0]\n",
    "        \n",
    "        return loss_segments * 4, info_acc\n",
    "    # end\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        pass\n",
    "    # end\n",
    "\n",
    "\n",
    "    def clear_cache(self):\n",
    "        for key_cache in self.keys_cache:\n",
    "            self.cache[key_cache] = None\n",
    "        # end\n",
    "    # end\n",
    "# end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9f43f1-b7b1-4d54-91bc-947cdc6e4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoderHead_Similarity(nn.Module):\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def get_info_accuracy_template(cls):\n",
    "        return Dotdict({\n",
    "            'meansquares': []\n",
    "        })\n",
    "    # end    \n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleEncoderHead_Similarity, self).__init__()\n",
    "\n",
    "        self.func_loss = torch.nn.MSELoss()\n",
    "        self.cos_score_transformation = torch.nn.Identity()\n",
    "        self.keys_cache = ['labels_sim', 'output']\n",
    "        self.cache = Dotdict({\n",
    "            'labels_sim': None,\n",
    "            'output': None\n",
    "        })\n",
    "    # end\n",
    "\n",
    "    def forward(self, model, labels_similarity=None, nocache=False, **kwargs):  # labels_sim (batch/2, 1)   for every two sentences, we have a label\n",
    "\n",
    "        output_encoder_pooled = model.cache.output_encoder_pooled\n",
    "        size_batch, dim_hidden = output_encoder_pooled.shape\n",
    "\n",
    "        if size_batch % 2 != 0:\n",
    "            raise Exception('sim calculation is not prepared as size_batch % 2 != 0')\n",
    "        # end\n",
    "\n",
    "        # pooling (batch, pair, dim_hidden)\n",
    "        output_pooling = output_encoder_pooled.squeeze(1).view(-1, 2, dim_hidden)   # might cls + sep, but abandon now (as it's not easy to get sep for every batch, different location)\n",
    "        output_pooling_x1 = output_pooling[:, 0, :]\n",
    "        output_pooling_x2 = output_pooling[:, 1, :]\n",
    "        sims = self.cos_score_transformation(torch.cosine_similarity(output_pooling_x1, output_pooling_x2))  # -> (batch, scores)\n",
    "\n",
    "        if not nocache:\n",
    "            self.cache.output = sims\n",
    "            self.cache.labels_sim = labels_similarity\n",
    "        # end\n",
    "\n",
    "        return sims\n",
    "    # end\n",
    "\n",
    "    def get_loss(self):\n",
    "        sims = self.cache.output\n",
    "        labels_sim = self.cache.labels_sim\n",
    "        info_acc = SimpleEncoderHead_Similarity.get_info_accuracy_template()\n",
    "\n",
    "        loss_sim = self.func_loss(sims, labels_sim)\n",
    "        info_acc.meansquares.append((torch.mean((sims - labels_sim) ** 2)).cpu().item())\n",
    "        return loss_sim * 64, info_acc\n",
    "    # end\n",
    "\n",
    "    def clear_cache(self):\n",
    "        for key_cache in self.keys_cache:\n",
    "            self.cache[key_cache] = None\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def evaluate(self):\n",
    "        pass\n",
    "    # end\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4c3e2f-17aa-44ad-aa98-43ed56627067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadManager(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HeadManager, self).__init__()\n",
    "        self.index_name_head = set()\n",
    "    # end\n",
    "\n",
    "    def register(self, head):\n",
    "        name_head = head.__class__.__name__\n",
    "        setattr(self, name_head, head)\n",
    "        self.index_name_head.add(name_head)\n",
    "        return self\n",
    "    # end\n",
    "\n",
    "    def forward(self, model, **kwargs):\n",
    "        for name in self.index_name_head:\n",
    "            head = getattr(self, name)\n",
    "            head.forward(model, **kwargs)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def get_head(self, klass):\n",
    "        return getattr(self, klass.__name__)\n",
    "    # end\n",
    "\n",
    "    def clear_cache(self):\n",
    "        for name_head in self.index_name_head:\n",
    "            getattr(self, name_head).clear_cache()\n",
    "        # end\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class Trainer(nn.Module):\n",
    "    def __init__(self, model=None, manager=None):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.model = model\n",
    "        self.manager = manager\n",
    "    # end\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        self.clear_cache()\n",
    "        \n",
    "        self.model.forward(**kwargs)\n",
    "        self.manager.forward(self.model, **kwargs)\n",
    "    # end\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        self.model.clear_cache() if self.model else None\n",
    "        self.manager.clear_cache() if self.manager else None\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SaverAndLoader:\n",
    "    def __init__(self, path_checkpoints='./checkpoints'):\n",
    "        self.dict_name_item = {}\n",
    "        self.path_checkpoints = path_checkpoints\n",
    "    # end\n",
    "    \n",
    "    def add_item(self, item, name=None):\n",
    "        if not name:\n",
    "            name = item.__class__.__name__\n",
    "        # end\n",
    "        \n",
    "        self.dict_name_item[name] = item\n",
    "        return self\n",
    "    # end\n",
    "    \n",
    "    \n",
    "    def update_checkpoint(self, name_checkpoint, name_checkpoint_previous=None):  # epoch_n\n",
    "        if name_checkpoint_previous:\n",
    "            result = self._delete_checkpoint_folder(name_checkpoint_previous)\n",
    "            if result:\n",
    "                print(f'[INFO] {name_checkpoint_previous} is cleared.')\n",
    "            else:\n",
    "                print(f'[ALERT] {name_checkpoint_previous} fail to be cleared.')\n",
    "            # end\n",
    "        # end\n",
    "        \n",
    "        folder_checkpoint = self._create_checkpoint_folder(name_checkpoint)\n",
    "        for name_item, item in self.dict_name_item.items():\n",
    "            path_checkpoint_item = os.path.join(folder_checkpoint, f'{name_item}.pt')\n",
    "            torch.save(item.state_dict(), path_checkpoint_item)\n",
    "            \n",
    "            size_file_saved_MB = os.path.getsize(path_checkpoint_item) / 1024 / 1024\n",
    "            print(f'[INFO] {name_item} is saved, {size_file_saved_MB} MB')\n",
    "        # end\n",
    "        \n",
    "        print(f'[INFO] {name_checkpoint} is saved')\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def load_item_state(self, name_checkpoint, instance_item, name_item=None):\n",
    "        if not name_item:\n",
    "            name_item = instance_item.__class__.__name__\n",
    "        # end\n",
    "        \n",
    "        path_checkpoint_item = os.path.join(self.path_checkpoints, name_checkpoint, f'{name_item}.pt')\n",
    "        if not os.path.exists(path_checkpoint_item):\n",
    "            print(f'[ERROR] {path_checkpoint_item} not exists')\n",
    "            return None\n",
    "        # end\n",
    "        if issubclass(instance_item.__class__, torch.nn.Module):\n",
    "            instance_item.load_state_dict(torch.load(path_checkpoint_item), strict=False)\n",
    "        else:\n",
    "            instance_item.load_state_dict(torch.load(path_checkpoint_item))\n",
    "        # end\n",
    "        \n",
    "        print(f'[INFO] {name_item} loaded for {name_checkpoint}.')\n",
    "        return instance_item\n",
    "    # end\n",
    "    \n",
    "    \n",
    "    def list_items(self):\n",
    "        return list(self.dict_name_item.keys())\n",
    "    # end\n",
    "    \n",
    "    def _create_checkpoint_folder(self, name_checkpoint):\n",
    "        path_folder_target = os.path.join(self.path_checkpoints, name_checkpoint)\n",
    "        Path(path_folder_target).mkdir(parents=True, exist_ok=True)\n",
    "        return path_folder_target\n",
    "    # end\n",
    "    \n",
    "    def _delete_checkpoint_folder(self, name_checkpoint_previous):\n",
    "        path_folder_target = os.path.join(self.path_checkpoints, name_checkpoint_previous)\n",
    "        if os.path.exists(path_folder_target):\n",
    "            shutil.rmtree(path_folder_target, ignore_errors=True)\n",
    "        # end\n",
    "        return (not os.path.exists(path_folder_target))\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947695c3-1322-4748-8174-a1f1003cc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Builder:\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_mlm_v2(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, None, embedder_encoder, None)\n",
    "        head_mlm = SimpleEncoderHead_MLM(model, size_vocab, dim_hidden)\n",
    "\n",
    "        manager = HeadManager().register(head_mlm)\n",
    "        trainer = Trainer(model=model, manager=manager)\n",
    "\n",
    "        return trainer\n",
    "    # end\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_s2s_v2(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "        \n",
    "        embedder_decoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_decoder = SimpleDecoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        decoderstack = SimpleTransformerStack(sample_decoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, decoderstack, embedder_encoder, embedder_decoder, pooling=True)\n",
    "        head_s2s = SimpleDecoderHead_S2S(model, size_vocab, dim_hidden)\n",
    "        \n",
    "        manager = HeadManager().register(head_s2s)\n",
    "        trainer = Trainer(model=model, manager=manager)\n",
    "\n",
    "        return trainer\n",
    "    # end\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_2heads(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "        \n",
    "        embedder_decoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_decoder = SimpleDecoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        decoderstack = SimpleTransformerStack(sample_decoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, decoderstack, embedder_encoder, embedder_decoder, pooling=True)\n",
    "        head_s2s = SimpleDecoderHead_S2S(model, size_vocab, dim_hidden)\n",
    "        head_mlm = SimpleEncoderHead_MLM(model, size_vocab, dim_hidden)\n",
    "        \n",
    "        manager = HeadManager().register(head_s2s).register(head_mlm)\n",
    "        trainer = Trainer(model=model, manager=manager)\n",
    "\n",
    "        return trainer\n",
    "    # end\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model_with_2heads(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer, saver, name_checkpoint):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "        \n",
    "        embedder_decoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_decoder = SimpleDecoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        decoderstack = SimpleTransformerStack(sample_decoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, decoderstack, embedder_encoder, embedder_decoder, pooling=True)\n",
    "        head_s2s = SimpleDecoderHead_S2S(model, size_vocab, dim_hidden)\n",
    "        head_mlm = SimpleEncoderHead_MLM(model, size_vocab, dim_hidden)\n",
    "        \n",
    "        loader.load_item_state(name_checkpoint, model)\n",
    "        loader.load_item_state(name_checkpoint, head_s2s)\n",
    "        loader.load_item_state(name_checkpoint, head_mlm)\n",
    "        \n",
    "        manager = HeadManager().register(head_s2s).register(head_mlm)\n",
    "        trainer = Trainer(model=model, manager=manager)\n",
    "\n",
    "        return trainer\n",
    "    # end\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_sim_v2(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, None, embedder_encoder, None, pooling=True)\n",
    "        head_sim = SimpleEncoderHead_Similarity()\n",
    "\n",
    "        manager = HeadManager().register(head_sim)\n",
    "        trainer = Trainer(model=model, manager=manager)\n",
    "\n",
    "        return trainer\n",
    "    # end\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def build_model_with_3heads(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "        \n",
    "        embedder_decoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_decoder = SimpleDecoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        decoderstack = SimpleTransformerStack(sample_decoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, decoderstack, embedder_encoder, embedder_decoder, pooling=True)\n",
    "        head_s2s = SimpleDecoderHead_S2S(model, size_vocab, dim_hidden)\n",
    "        head_mlm = SimpleEncoderHead_MLM(model, size_vocab, dim_hidden)\n",
    "        head_sim = SimpleEncoderHead_Similarity()\n",
    "        \n",
    "        manager = HeadManager().register(head_s2s).register(head_mlm).register(head_sim)\n",
    "        trainer = Trainer(model=model, manager=manager)\n",
    "\n",
    "        return trainer\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6929fc-2f8f-4edb-aa57-fd9aa5b8610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "gpu = 0\n",
    "torch.cuda.set_device(gpu)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "# source\n",
    "seq_max = 128\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# model & head\n",
    "dim_hidden = 512\n",
    "dim_feedforward = 512\n",
    "n_head = 8\n",
    "n_layer = 8\n",
    "\n",
    "# optimizer\n",
    "lr_base_optimizer = 1e-4\n",
    "betas_optimizer = (0.9, 0.999)\n",
    "eps_optimizer = 1e-9\n",
    "\n",
    "# scheduler\n",
    "warmup = 200\n",
    "\n",
    "### for bookcorpus 2 heads ###\n",
    "train_source, valid_source, _ = BookCorpus(split=0.001, used=100000)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "collator = Collator_BERT(tokenizer, seq_max)\n",
    "###########\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(train_source, batch_size, shuffle=False, collate_fn=collator)\n",
    "dataloader_eval = DataLoader(valid_source, 1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "# trainer= Builder.load_model_with_2heads(tokenizer.vocab_size, dim_hidden, dim_feedforward, n_head, n_layer, loader, 'epoch1')\n",
    "trainer = Builder.build_model_with_2heads(tokenizer.vocab_size, dim_hidden, dim_feedforward, n_head, n_layer)\n",
    "\n",
    "for p in trainer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "trainer = trainer.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.Adam(trainer.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "decayRate = 0.96\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "\n",
    "# optimizer = loader.load_item_state('epoch1', optimizer)\n",
    "# lr_scheduler = loader.load_item_state('epoch1', lr_scheduler)\n",
    "\n",
    "loader = SaverAndLoader('checkpoints_0')\n",
    "loader.add_item(trainer.model)\n",
    "loader.add_item(trainer.manager.get_head(SimpleEncoderHead_MLM))\n",
    "loader.add_item(trainer.manager.get_head(SimpleDecoderHead_S2S))\n",
    "loader.add_item(optimizer)\n",
    "loader.add_item(lr_scheduler)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab31751-de7d-44b3-9814-1e0ed6da008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_a_batch(batch, trainer, optimizer=None, scheduler=None):\n",
    "    trainer.train()\n",
    "    trainer.forward(**batch())\n",
    "    \n",
    "    \n",
    "    loss_s2s, info_acc_s2s = trainer.manager.get_head(SimpleDecoderHead_S2S).get_loss()\n",
    "    loss_mlm, info_acc_mlm = trainer.manager.get_head(SimpleEncoderHead_MLM).get_loss()\n",
    "    # loss_sim, info_acc_sim = trainer.manager.get_head(SimpleEncoderHead_Similarity).get_loss()\n",
    "\n",
    "    # crossentropy loss\n",
    "    \n",
    "    # loss_all = loss_s2s * 5\n",
    "    # loss_all = loss_mlm\n",
    "    # loss_all = loss_sim\n",
    "    loss_all = (loss_s2s + loss_mlm) / 2\n",
    "    # loss_all = (loss_s2s + loss_mlm + loss_sim) / 3\n",
    "    # loss_all = (loss_s2s + loss_mlm + loss_sim)\n",
    "    loss_all_value = loss_all.item()\n",
    "    \n",
    "    # print(loss_all)\n",
    "    loss_all.backward()\n",
    "\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    # end\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    # end\n",
    "    \n",
    "    trainer.clear_cache()\n",
    "    return loss_all_value, Dotdict({'mlm': info_acc_mlm, 's2s': info_acc_s2s})\n",
    "    # return loss_all_value, Dotdict({'mlm': info_acc_mlm, 's2s': info_acc_s2s, 'sim': info_acc_sim})\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ff65d6-c08e-4f95-885d-0d688713deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_a_batch(batch, trainer, *args, **kwargs):\n",
    "    trainer.eval()\n",
    "    with torch.no_grad():\n",
    "        trainer.forward(**batch())\n",
    "    # end\n",
    "    \n",
    "    loss_s2s, info_acc_s2s = trainer.manager.get_head(SimpleDecoderHead_S2S).get_loss()\n",
    "    loss_mlm, info_acc_mlm = trainer.manager.get_head(SimpleEncoderHead_MLM).get_loss()\n",
    "\n",
    "    # crossentropy loss\n",
    "    \n",
    "    # loss_all = loss_s2s * 5\n",
    "    # loss_all = loss_mlm\n",
    "    # loss_all = loss_sim\n",
    "    loss_all = (loss_s2s + loss_mlm) / 2\n",
    "    # loss_all = (loss_s2s + loss_mlm + loss_sim) / 3\n",
    "    # loss_all = (loss_s2s + loss_mlm + loss_sim)\n",
    "    loss_all_value = loss_all.item()\n",
    "    \n",
    "    trainer.clear_cache()\n",
    "    return loss_all_value, Dotdict({'mlm': info_acc_mlm, 's2s': info_acc_s2s})\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fcf19d1-b502-4a47-99dc-66bf2b071347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1561 [01:06<11:54:34, 27.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 0, loss: 41.342159271240234, rate: 0.0001, acc_mlm: 0.0, acc_s2s: 0.0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 102/1561 [01:20<03:20,  7.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 100, loss: 27.255756378173828, rate: 0.0001, acc_mlm: 0.05514705882352941, acc_s2s: 0.059203444564047365\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 202/1561 [01:33<02:50,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 200, loss: 25.891868591308594, rate: 0.0001, acc_mlm: 0.0627062706270627, acc_s2s: 0.04961089494163424\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 302/1561 [01:47<02:50,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 300, loss: 24.867835998535156, rate: 0.0001, acc_mlm: 0.05653710247349823, acc_s2s: 0.11431513903192585\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 402/1561 [02:01<02:27,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 400, loss: 24.38874053955078, rate: 0.0001, acc_mlm: 0.06578947368421052, acc_s2s: 0.11923076923076924\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 502/1561 [02:14<02:21,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 500, loss: 23.752307891845703, rate: 0.0001, acc_mlm: 0.042483660130718956, acc_s2s: 0.15479582146248813\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 602/1561 [02:28<02:07,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 600, loss: 23.078828811645508, rate: 0.0001, acc_mlm: 0.06885245901639345, acc_s2s: 0.15784408084696824\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 702/1561 [02:41<01:51,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 700, loss: 22.693668365478516, rate: 0.0001, acc_mlm: 0.08664259927797834, acc_s2s: 0.16382978723404254\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|    | 802/1561 [02:54<01:42,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 800, loss: 23.112232208251953, rate: 0.0001, acc_mlm: 0.052805280528052806, acc_s2s: 0.15272373540856032\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 902/1561 [03:07<01:31,  7.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 900, loss: 22.144081115722656, rate: 0.0001, acc_mlm: 0.06382978723404255, acc_s2s: 0.16666666666666666\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 1002/1561 [03:21<01:17,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 1000, loss: 21.730398178100586, rate: 0.0001, acc_mlm: 0.04391891891891892, acc_s2s: 0.16122650840751732\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1102/1561 [03:34<01:02,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 1100, loss: 21.985755920410156, rate: 0.0001, acc_mlm: 0.05263157894736842, acc_s2s: 0.1723076923076923\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1202/1561 [03:48<00:49,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 1200, loss: 21.946741104125977, rate: 0.0001, acc_mlm: 0.05639097744360902, acc_s2s: 0.17672886937431395\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 1302/1561 [04:02<00:35,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 1300, loss: 22.588062286376953, rate: 0.0001, acc_mlm: 0.0672782874617737, acc_s2s: 0.1693548387096774\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 1402/1561 [04:15<00:21,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 1400, loss: 22.26475715637207, rate: 0.0001, acc_mlm: 0.08865248226950355, acc_s2s: 0.178125\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 1502/1561 [04:29<00:07,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 1500, loss: 22.573814392089844, rate: 0.0001, acc_mlm: 0.06741573033707865, acc_s2s: 0.16575192096597147\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1561/1561 [04:37<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-29 11:06:52.081279] Epoch: 0 training ends. Status: Average loss: 23.931120262170435, Average MLM accuracy: 0.05945389255244097, Average S2S accuracy: 0.1419955644668053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1561/1561 [01:26<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-29 11:08:18.462823] Epoch: 0 Evalutation ends. Status: Average loss: 22.03921740212401, Average MLM accuracy: 0.06133217188524349, Average S2S accuracy: 0.1746098964510416\n",
      "[INFO] SimpleEncoderDecoder is saved, 249.78036785125732 MB\n",
      "[INFO] SimpleEncoderHead_MLM is saved, 60.62121295928955 MB\n",
      "[INFO] SimpleDecoderHead_S2S is saved, 60.62121295928955 MB\n",
      "[INFO] Adam is saved, 737.990008354187 MB\n",
      "[INFO] ExponentialLR is saved, 0.0005445480346679688 MB\n",
      "[INFO] epoch_0 is saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1561 [00:00<03:56,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 0, loss: 22.64373207092285, rate: 9.6e-05, acc_mlm: 0.05128205128205128, acc_s2s: 0.17418546365914786\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 102/1561 [00:14<03:15,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 100, loss: 22.654911041259766, rate: 9.6e-05, acc_mlm: 0.05514705882352941, acc_s2s: 0.17115177610333693\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 202/1561 [00:27<02:55,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 200, loss: 21.91657829284668, rate: 9.6e-05, acc_mlm: 0.052805280528052806, acc_s2s: 0.16245136186770429\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 302/1561 [00:41<02:43,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 300, loss: 21.64832878112793, rate: 9.6e-05, acc_mlm: 0.045936395759717315, acc_s2s: 0.164778578784758\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 402/1561 [00:54<02:37,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 400, loss: 22.04288101196289, rate: 9.6e-05, acc_mlm: 0.05263157894736842, acc_s2s: 0.15096153846153845\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 502/1561 [01:07<02:19,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 500, loss: 21.985258102416992, rate: 9.6e-05, acc_mlm: 0.049019607843137254, acc_s2s: 0.1785375118708452\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 602/1561 [01:21<02:04,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 600, loss: 22.03728485107422, rate: 9.6e-05, acc_mlm: 0.05573770491803279, acc_s2s: 0.17709335899903753\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 702/1561 [01:34<01:51,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 700, loss: 21.441957473754883, rate: 9.6e-05, acc_mlm: 0.05054151624548736, acc_s2s: 0.1595744680851064\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|    | 802/1561 [01:47<01:39,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 800, loss: 21.92365837097168, rate: 9.6e-05, acc_mlm: 0.07590759075907591, acc_s2s: 0.17704280155642024\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 902/1561 [02:00<01:24,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 900, loss: 21.715312957763672, rate: 9.6e-05, acc_mlm: 0.07801418439716312, acc_s2s: 0.18229166666666666\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 1002/1561 [02:13<01:17,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1000, loss: 21.17093276977539, rate: 9.6e-05, acc_mlm: 0.033783783783783786, acc_s2s: 0.17012858555885263\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1102/1561 [02:27<01:00,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1100, loss: 21.971891403198242, rate: 9.6e-05, acc_mlm: 0.05964912280701754, acc_s2s: 0.18051282051282053\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1202/1561 [02:41<00:47,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1200, loss: 21.082435607910156, rate: 9.6e-05, acc_mlm: 0.08270676691729323, acc_s2s: 0.18660812294182216\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 1302/1561 [02:54<00:34,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1300, loss: 22.20851707458496, rate: 9.6e-05, acc_mlm: 0.04281345565749235, acc_s2s: 0.17293906810035842\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 1402/1561 [03:08<00:20,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1400, loss: 22.034414291381836, rate: 9.6e-05, acc_mlm: 0.07092198581560284, acc_s2s: 0.18229166666666666\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 1502/1561 [03:21<00:07,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1500, loss: 22.425548553466797, rate: 9.6e-05, acc_mlm: 0.04868913857677903, acc_s2s: 0.16794731064763996\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1561/1561 [03:29<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-29 11:12:15.133408] Epoch: 1 training ends. Status: Average loss: 22.02207019373364, Average MLM accuracy: 0.06064483053519619, Average S2S accuracy: 0.17379152993984906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1561/1561 [01:26<00:00, 18.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-29 11:13:41.408403] Epoch: 1 Evalutation ends. Status: Average loss: 21.8013455954826, Average MLM accuracy: 0.06187660067736016, Average S2S accuracy: 0.1799449015300994\n",
      "[INFO] epoch_0 is cleared.\n",
      "[INFO] SimpleEncoderDecoder is saved, 249.78036785125732 MB\n",
      "[INFO] SimpleEncoderHead_MLM is saved, 60.62121295928955 MB\n",
      "[INFO] SimpleDecoderHead_S2S is saved, 60.62121295928955 MB\n",
      "[INFO] Adam is saved, 737.990008354187 MB\n",
      "[INFO] ExponentialLR is saved, 0.0005445480346679688 MB\n",
      "[INFO] epoch_1 is saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1561 [00:00<03:19,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 0, loss: 22.15630340576172, rate: 9.6e-05, acc_mlm: 0.08974358974358974, acc_s2s: 0.18796992481203006\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 102/1561 [00:13<03:09,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 100, loss: 22.27186393737793, rate: 9.6e-05, acc_mlm: 0.0625, acc_s2s: 0.17007534983853606\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 202/1561 [00:27<02:54,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 200, loss: 21.770280838012695, rate: 9.6e-05, acc_mlm: 0.0429042904290429, acc_s2s: 0.16828793774319067\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 302/1561 [00:41<02:47,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 300, loss: 21.187597274780273, rate: 9.6e-05, acc_mlm: 0.0706713780918728, acc_s2s: 0.17507723995880536\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 402/1561 [00:54<02:40,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 400, loss: 22.005496978759766, rate: 9.6e-05, acc_mlm: 0.04276315789473684, acc_s2s: 0.15\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 502/1561 [01:07<02:22,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 500, loss: 22.020832061767578, rate: 9.6e-05, acc_mlm: 0.06209150326797386, acc_s2s: 0.1842355175688509\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 602/1561 [01:21<02:12,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 600, loss: 22.051027297973633, rate: 9.6e-05, acc_mlm: 0.05573770491803279, acc_s2s: 0.17998075072184794\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 702/1561 [01:34<01:59,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 700, loss: 22.011154174804688, rate: 9.6e-05, acc_mlm: 0.05415162454873646, acc_s2s: 0.1723404255319149\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|    | 802/1561 [01:48<01:37,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 800, loss: 22.026836395263672, rate: 9.6e-05, acc_mlm: 0.0429042904290429, acc_s2s: 0.17898832684824903\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 902/1561 [02:01<01:32,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 900, loss: 21.534942626953125, rate: 9.6e-05, acc_mlm: 0.06028368794326241, acc_s2s: 0.18854166666666666\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 1002/1561 [02:15<01:16,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 1000, loss: 20.9748477935791, rate: 9.6e-05, acc_mlm: 0.07094594594594594, acc_s2s: 0.17309594460929772\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 1102/1561 [02:28<01:00,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 1100, loss: 21.47995376586914, rate: 9.6e-05, acc_mlm: 0.07017543859649122, acc_s2s: 0.18153846153846154\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 1202/1561 [02:42<00:49,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 1200, loss: 21.380634307861328, rate: 9.6e-05, acc_mlm: 0.04887218045112782, acc_s2s: 0.19099890230515917\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 1302/1561 [02:55<00:34,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 1300, loss: 21.920467376708984, rate: 9.6e-05, acc_mlm: 0.0764525993883792, acc_s2s: 0.17831541218637992\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 1402/1561 [03:09<00:21,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 1400, loss: 21.82544708251953, rate: 9.6e-05, acc_mlm: 0.0673758865248227, acc_s2s: 0.190625\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 1502/1561 [03:23<00:08,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Batch: 1500, loss: 21.802059173583984, rate: 9.6e-05, acc_mlm: 0.08614232209737828, acc_s2s: 0.16575192096597147\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1561/1561 [03:31<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-29 11:17:38.819180] Epoch: 2 training ends. Status: Average loss: 21.908296596079893, Average MLM accuracy: 0.060229703581207224, Average S2S accuracy: 0.1770776271492924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1561/1561 [01:26<00:00, 18.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-29 11:19:05.080765] Epoch: 2 Evalutation ends. Status: Average loss: 21.734466985278523, Average MLM accuracy: 0.06152952732238578, Average S2S accuracy: 0.18240332505438048\n",
      "[INFO] epoch_1 is cleared.\n",
      "[INFO] SimpleEncoderDecoder is saved, 249.78036785125732 MB\n",
      "[INFO] SimpleEncoderHead_MLM is saved, 60.62121295928955 MB\n",
      "[INFO] SimpleDecoderHead_S2S is saved, 60.62121295928955 MB\n",
      "[INFO] Adam is saved, 737.990008354187 MB\n",
      "[INFO] ExponentialLR is saved, 0.0005445480346679688 MB\n",
      "[INFO] epoch_2 is saved\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "name_checkpoint_current = None\n",
    "name_checkpoint_last = None\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    info_acc_heads_train = Dotdict({\n",
    "        'mlm': SimpleEncoderHead_MLM.get_info_accuracy_template(),\n",
    "        's2s': SimpleDecoderHead_S2S.get_info_accuracy_template(),\n",
    "        # 'sim': SimpleEncoderHead_Similarity.get_info_accuracy_template()\n",
    "    })\n",
    "\n",
    "\n",
    "    info_acc_heads_eval = Dotdict({\n",
    "        'mlm': SimpleEncoderHead_MLM.get_info_accuracy_template(),\n",
    "        's2s': SimpleDecoderHead_S2S.get_info_accuracy_template(),\n",
    "        # 'sim': SimpleEncoderHead_Similarity.get_info_accuracy_template()\n",
    "    })\n",
    "    \n",
    "    # train phase\n",
    "    losss_per_e = []\n",
    "    for i, batch in enumerate(tqdm(dataloader_train)):\n",
    "        loss_current, info_acc_heads_batch = train_a_batch(batch, trainer, optimizer, None)\n",
    "        info_acc_heads_train += info_acc_heads_batch\n",
    "        \n",
    "        losss_per_e.append(loss_current)\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} Batch: {}, loss: {}, rate: {}, acc_mlm: {}, acc_s2s: {}'.format(\n",
    "                e, i, loss_current, optimizer.param_groups[0]['lr'],\n",
    "                info_acc_heads_batch.mlm.corrects_masked / info_acc_heads_batch.mlm.num_masked,\n",
    "                info_acc_heads_batch.s2s.corrects_segmented / info_acc_heads_batch.s2s.num_segmented,\n",
    "                # sum(info_acc_heads_batch.sim.meansquares) / len(info_acc_heads_batch.sim.meansquares)\n",
    "            ), end='\\r')\n",
    "        # end\n",
    "    # end\n",
    "    \n",
    "    loss_average_per_e = sum(losss_per_e) / len(losss_per_e)\n",
    "    print('[{}] Epoch: {} training ends. Status: Average loss: {}, Average MLM accuracy: {}, Average S2S accuracy: {}'.format(\n",
    "        datetime.utcnow(), e, loss_average_per_e,\n",
    "        info_acc_heads_train.mlm.corrects_masked / info_acc_heads_train.mlm.num_masked,\n",
    "        info_acc_heads_train.s2s.corrects_segmented / info_acc_heads_train.s2s.num_segmented,\n",
    "        # sum(info_acc_heads_train.sim.meansquares) / len(info_acc_heads_train.sim.meansquares)\n",
    "    ))\n",
    "    \n",
    "    if e % 2 == 0:\n",
    "        lr_scheduler.step() # schedule per 2 epoch\n",
    "    # end\n",
    "\n",
    "    \n",
    "    # eval phase\n",
    "    losss_per_e = []\n",
    "    for i, batch in enumerate(tqdm(dataloader_train)):\n",
    "        loss_current, info_acc_heads_batch = evaluate_a_batch(batch, trainer)\n",
    "        info_acc_heads_eval += info_acc_heads_batch\n",
    "        \n",
    "        losss_per_e.append(loss_current)\n",
    "    # end\n",
    "    \n",
    "    loss_average_per_e = sum(losss_per_e) / len(losss_per_e)\n",
    "    print('[{}] Epoch: {} Evalutation ends. Status: Average loss: {}, Average MLM accuracy: {}, Average S2S accuracy: {}'.format(\n",
    "        datetime.utcnow(), e, loss_average_per_e,\n",
    "        info_acc_heads_eval.mlm.corrects_masked / info_acc_heads_eval.mlm.num_masked,\n",
    "        info_acc_heads_eval.s2s.corrects_segmented / info_acc_heads_eval.s2s.num_segmented,\n",
    "        # sum(info_acc_heads_eval.sim.meansquares) / len(info_acc_heads_eval.sim.meansquares)\n",
    "    ))\n",
    "    \n",
    "    name_checkpoint_current = f'epoch_{e}'\n",
    "    loader.update_checkpoint(name_checkpoint_current, name_checkpoint_last)\n",
    "    name_checkpoint_last = name_checkpoint_current\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec99c1ef-60c6-42ad-b979-3092495d3d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df05c45-ed31-4d3f-ab04-ed182c182027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: he probably wasn't even attracted to her. [SEP]\n",
      "target: [CLS] she wasn't have to the other, she wasn't have to the other. she't have to the other. i't have to the other. i't have to the other. she wasn't have to the other. i't have to the other. i't have to the other. i't have to the other. she wasn't have to the other.\n",
      "\n",
      "\n",
      "source: yes. [SEP]\n",
      "target: [CLS] she wasn't have to the other, she wasn't have to the other. i't have to the other. i't have to the other. i't have to the other. i't have to the other. i't have to the other. i't have to the other. i't have to the other. she wasn't have to the other.\n",
      "\n",
      "\n",
      "source: he got back into his truck and drove the rest of the way to his cabin seething with anger. [SEP]\n",
      "target: [CLS] she wasn't have to the other, she wasn't have to the other. she't have to the other. she't have to the other. she't have to the other. she wasn't have to the other. she't have to the other. she't have to the other. she't have to the other. she wasn't have to the other. she't have to the other.\n",
      "\n",
      "\n",
      "source: don't move! [SEP]\n",
      "target: [CLS] she wasn't have to the other, she wasn't have to the other. i't have to the other. i't have to the other. i't have to the other. i't have to the other. i't have to the other. i't have to the other. i't have to the other. she wasn't have to the other.\n",
      "\n",
      "\n",
      "source: if she was worried about others in the palace gossiping, he'd have to be a bit more subtle, but he was damned if he was going to give her up. [SEP]\n",
      "target: [CLS] she wasn't have to the other, she wasn't have to the other. she't have to the other. she't have to the other. she't have to the other. she wasn't have to the other. she't have to the other. she't have to the other. she't have to the other. she wasn't have to the other. she't have to the other.\n",
      "\n",
      "\n",
      "source: like i was about to get everything i'd ever dreamed of. [SEP]\n",
      "target: [CLS] she wasn't have to the other, she wasn't have to the other. she't have to the other. i't have to the other. i't have to the other. she wasn't have to the other. i't have to the other. i't have to the other. she't have to the other. she wasn't have to the other. she't have to the other.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For s2s head\n",
    "def greedy_generate(model, head, tokenizer, collator, **kwargs):\n",
    "    id_start = tokenizer.id_cls if hasattr(tokenizer, 'id_cls') else collator.id_cls\n",
    "    id_end = tokenizer.id_sep if hasattr(tokenizer, 'id_sep') else collator.id_sep\n",
    "    id_pad = tokenizer.id_pad if hasattr(tokenizer, 'id_pad') else collator.id_pad\n",
    "    size_seq_max = collator.size_seq_max\n",
    "\n",
    "    ids_encoder_twin = kwargs['ids_encoder']\n",
    "    masks_encoder_twin = kwargs['masks_encoder']\n",
    "    \n",
    "    ids_decoder_all = []\n",
    "    \n",
    "    for j in range(ids_encoder_twin.shape[0]):\n",
    "        ids_encoder = ids_encoder_twin[j,].unsqueeze(0)\n",
    "        masks_encoder = masks_encoder_twin[j,].unsqueeze(0)\n",
    "\n",
    "        output_encoder = model.embed_and_encode(ids_encoder=ids_encoder, masks_encoder=masks_encoder)\n",
    "        ids_decoder = torch.zeros(1, 1).fill_(id_start).type_as(ids_encoder.data)\n",
    "\n",
    "        for i in range(size_seq_max - 1):\n",
    "            masks_decoder = collator.subsequent_mask(ids_decoder.size(1)).type_as(ids_encoder.data)\n",
    "            output_decoder = model.embed_and_decode(ids_decoder=ids_decoder, masks_encoder=masks_encoder, output_encoder=output_encoder, masks_decoder=masks_decoder)\n",
    "\n",
    "            output_ffn = head.ffn(output_decoder)\n",
    "            output_s2s = head.extractor(output_ffn)   # output_mlm = prediction_logits\n",
    "\n",
    "            logits_nextword = torch.softmax(output_s2s[:, -1], dim=-1)  # mynote: select dim2=-1, remain=all; last is the next\n",
    "\n",
    "            id_nextword = torch.argmax(logits_nextword, dim=-1)\n",
    "            id_nextword = id_nextword.data[0]\n",
    "\n",
    "            if id_nextword == id_end:\n",
    "                break\n",
    "            # end\n",
    "\n",
    "            ids_decoder = torch.cat([ids_decoder, torch.zeros(1, 1).type_as(ids_encoder.data).fill_(id_nextword)], dim=1)\n",
    "        # end\n",
    "        \n",
    "        ids_pad = torch.full((1, size_seq_max - ids_decoder.shape[-1]), id_pad).type_as(ids_decoder.data)\n",
    "        \n",
    "        ids_decoder_all.append(torch.cat([ids_decoder, ids_pad], dim=-1).squeeze(0))\n",
    "    # end for \n",
    "\n",
    "    return torch.stack(ids_decoder_all)\n",
    "# end\n",
    "\n",
    "# eval_source = to_map_style_dataset(valid_iter)\n",
    "dataloader_eval = DataLoader(valid_source, 1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "for i, batch in enumerate(dataloader_eval):\n",
    "    info_batch = batch()\n",
    "    result = greedy_generate(trainer.model, trainer.manager.get_head(SimpleDecoderHead_S2S), tokenizer, collator, **info_batch)\n",
    "    \n",
    "    \n",
    "    result_cpu_list = result.cpu().tolist()\n",
    "    labels_decoder_cpu_list = info_batch['labels_decoder'].cpu().tolist()\n",
    "    \n",
    "    for result_cpu, labels_decoder in zip(result_cpu_list, labels_decoder_cpu_list):\n",
    "    \n",
    "        sentence_predicted = tokenizer.decode(result_cpu).split(' [PAD]')[0]\n",
    "        sentence_origin = tokenizer.decode(labels_decoder).split(' [PAD]')[0]\n",
    "        \n",
    "        print('source: {}\\ntarget: {}\\n\\n'.format(sentence_origin, sentence_predicted))\n",
    "    # end\n",
    "    \n",
    "    if i >= 5:\n",
    "        break\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68df3a99-6f6a-4fee-8e7a-c9ffc168e9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 17.235618591308594, acc: 0.3333333432674408\n",
      "source: probably to.\n",
      "input: [MASK] [MASK] [MASK]\n",
      "predict: he,.\n",
      "\n",
      "\n",
      "loss: nan, acc: nan\n",
      "source: \n",
      "input: \n",
      "predict: \n",
      "\n",
      "\n",
      "loss: 23.20349884033203, acc: 0.1666666716337204\n",
      "source: he truck and rest of cabin\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: he,,,..\n",
      "\n",
      "\n",
      "loss: 15.194304466247559, acc: 0.0\n",
      "source: t\n",
      "input: [MASK]\n",
      "predict: ,\n",
      "\n",
      "\n",
      "loss: 22.411466598510742, acc: 0.0\n",
      "source: others gossip d have to a bit more but up\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: ,,........\n",
      "\n",
      "\n",
      "loss: 19.523229598999023, acc: 0.0\n",
      "source: i about everything d\n",
      "input: [MASK] [MASK] [MASK] [MASK]\n",
      "predict: he,,,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_output(out_mlm, masks_masked_prebatch, labels_mlm, ids_encoder, tokenizer):\n",
    "    # print segments\n",
    "    # sentence_predicts = tokenizer.decode(out_mlm.softmax(dim=-1).argmax(dim=-1).masked_select(segments_encoder[:, 0, :]).numpy().tolist())\n",
    "    # sentence_labels = tokenizer.decode(labels_mlm.masked_select(segments_encoder[:, 0, :]).numpy().tolist())\n",
    "    # sentence_inputs = tokenizer.decode(ids_encoder.masked_select(segments_encoder[:, 0, :]).numpy().tolist())\n",
    "\n",
    "    # print masks\n",
    "    sentence_predicts = tokenizer.decode(out_mlm.softmax(dim=-1).argmax(dim=-1).masked_select(masks_masked_perbatch).numpy().tolist())\n",
    "    sentence_labels = tokenizer.decode(labels_mlm.masked_select(masks_masked_perbatch).numpy().tolist())\n",
    "    sentence_inputs = tokenizer.decode(ids_encoder.masked_select(masks_masked_perbatch).numpy().tolist())\n",
    "\n",
    "\n",
    "#     sentence_predicts = tokenizer.decode(out_mlm.softmax(dim=-1).argmax(dim=-1).numpy().tolist()[0])\n",
    "#     sentence_labels = tokenizer.decode(labels_mlm.numpy().tolist()[0])\n",
    "#     sentence_inputs = tokenizer.decode(ids_encoder.numpy().tolist()[0])\n",
    "\n",
    "    predicts_masked = out_mlm.softmax(dim=-1).argmax(dim=-1).masked_select(masks_masked_perbatch)\n",
    "    labels_masked = labels_mlm.masked_select(masks_masked_perbatch)\n",
    "\n",
    "    acc = torch.count_nonzero(predicts_masked == labels_masked) / labels_masked.shape[0]\n",
    "    # acc = torch.count_nonzero(out_mlm.softmax(dim=-1).argmax(dim=-1).view(-1) == labels_mlm.view(-1)) / labels_mlm.view(-1).shape[0]\n",
    "    return acc, sentence_labels, sentence_inputs, sentence_predicts\n",
    "# end\n",
    "\n",
    "\n",
    "# eval_source = to_map_style_dataset(valid_iter)\n",
    "dataloader_eval = DataLoader(valid_source, 1, shuffle=False, collate_fn=collator)\n",
    "# dataloader_eval = DataLoader(train_source, 1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "for i, batch in enumerate(dataloader_eval):\n",
    "    info_batch = batch()\n",
    "    trainer.forward(**info_batch)\n",
    "    \n",
    "    head = trainer.manager.get_head(SimpleEncoderHead_MLM)\n",
    "    out_mlm = head.cache.output\n",
    "    loss_mlm, _ = head.get_loss()\n",
    "    \n",
    "    out_mlm = out_mlm.cpu().detach()\n",
    "    loss_mlm = loss_mlm.cpu().detach()\n",
    "    labels_mlm = info_batch['labels_encoder'].cpu().detach()\n",
    "    masks_encoder = info_batch['masks_encoder'].cpu().detach()\n",
    "    segments_encoder = info_batch['segments_encoder'].cpu().detach()\n",
    "    ids_encoder = info_batch['ids_encoder'].cpu().detach()\n",
    "    \n",
    "    \n",
    "    masks_masked = torch.logical_xor(masks_encoder, segments_encoder) & segments_encoder # True is masked\n",
    "    masks_masked_perbatch = masks_masked[:,0,:]\n",
    "    \n",
    "    for j in range(masks_masked_perbatch.shape[0]):\n",
    "        acc, sentence_labels, sentence_inputs, sentence_predicts = decode_output(out_mlm[j,].unsqueeze(0), masks_masked_perbatch[j,].unsqueeze(0), labels_mlm[j,].unsqueeze(0), ids_encoder[j,].unsqueeze(0), tokenizer)\n",
    "        print('loss: {}, acc: {}\\nsource: {}\\ninput: {}\\npredict: {}\\n\\n'.format(loss_mlm.item(), acc, sentence_labels, sentence_inputs, sentence_predicts))\n",
    "    \n",
    "    if i >= 5:\n",
    "        break\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcc3bec-6f6c-4dfc-bb43-78bf90d4ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06a264-833b-4170-a4dc-d1f767e12ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6527dc2e-31f2-4eea-9e24-314d419c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = SaverAndLoader('./checkpoints')\n",
    "# loader.add_item(trainer.model)\n",
    "# loader.add_item(trainer.manager.get_head(SimpleEncoderHead_MLM))\n",
    "# loader.add_item(trainer.manager.get_head(SimpleDecoderHead_S2S))\n",
    "# loader.add_item(optimizer)\n",
    "# loader.add_item(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "497a66fe-34b5-4fa4-9857-6dcdb4e1398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader.update_checkpoint('epoch1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
