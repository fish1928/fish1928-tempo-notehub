{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708ce0aa-3617-4b3c-b735-6c289cde796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from spacy.lang.en.examples import sentences\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# import torchtext.datasets as datasets\n",
    "# from multi30k import Multi30k\n",
    "import re\n",
    "\n",
    "def load_tokenizers():\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_en\n",
    "# end\n",
    "\n",
    "def tokenize(text, tokenizer):\n",
    "    # text = re.sub(r'\\d+', ' ', text)\n",
    "    return [tok.text.lower() for tok in tokenizer.tokenizer(text)]\n",
    "# end\n",
    "\n",
    "\n",
    "def yield_tokens(data_iter, tokenizer):\n",
    "    for line in data_iter:\n",
    "        yield tokenizer(line)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "def build_vocabulary(spacy_en, source):\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return tokenize(text, spacy_en)\n",
    "\n",
    "    print(\"Building English Vocabulary ...\")\n",
    "\n",
    "    vocab_tgt = build_vocab_from_iterator(\n",
    "        yield_tokens(source, tokenize_en),\n",
    "        min_freq=20,\n",
    "        specials=[\"<s>\", \"</s>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    vocab_tgt.set_default_index(vocab_tgt[\"<unk>\"])\n",
    "\n",
    "    return vocab_tgt\n",
    "# end\n",
    "\n",
    "\n",
    "def load_vocab(spacy_en, source):\n",
    "    if not os.path.exists(\"vocab_quora.pt\"):\n",
    "        vocab_tgt = build_vocabulary(spacy_en, source)\n",
    "        torch.save(vocab_tgt, \"vocab_quora.pt\")\n",
    "    else:\n",
    "        vocab_tgt = torch.load(\"vocab_quora.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes:\")\n",
    "    print(len(vocab_tgt))\n",
    "    return vocab_tgt\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3cef976-34bf-40ce-bad2-4ee54a54db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: /Users/jinyuj/Workspace/PythonProjects/FirstPython/src/Tests/csv2json\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Function to convert a CSV to JSON\n",
    "# Takes the file paths as arguments\n",
    "def parse_csv_file_to_json(path_file_csv):\n",
    "    # create a dictionary\n",
    "    elements = []\n",
    "\n",
    "    # Open a csv reader called DictReader\n",
    "    with open(path_file_csv, encoding='utf-8') as file_csv:\n",
    "    #with open(path_file_csv) as file_csv:\n",
    "        reader_csv = csv.DictReader(file_csv, delimiter=\"\\t\")\n",
    "\n",
    "        # Convert each row into a dictionary\n",
    "        # and add it to data\n",
    "        for dict_head_value in reader_csv:\n",
    "            element = {}\n",
    "\n",
    "            for head, value in dict_head_value.items():\n",
    "                #print(value)\n",
    "                if value and (value[0] in [\"[\", \"{\"]):\n",
    "                    #element[head] = eval(value)\n",
    "                    element[head] = value\n",
    "                else:\n",
    "                    element[head] = value\n",
    "\n",
    "            elements.append(element)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    return elements\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a1ee68-5cc2-4aaf-bba0-a0484b819063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537362\n"
     ]
    }
   ],
   "source": [
    "contents_quora = parse_csv_file_to_json('quora_duplicate_questions.tsv')\n",
    "set_line_quora = set()\n",
    "for content_quora in contents_quora:\n",
    "    set_line_quora.add(content_quora['question1'])\n",
    "    set_line_quora.add(content_quora['question2'])\n",
    "# end\n",
    "print(len(set_line_quora))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f3de92-835f-4892-af0e-26af99023dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English Vocabulary ...\n",
      "Finished.\n",
      "Vocabulary sizes:\n",
      "12804\n"
     ]
    }
   ],
   "source": [
    "spacy_en = load_tokenizers()\n",
    "vocab_new = load_vocab(spacy_en, set_line_quora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84741cac-4cd4-4a2c-9f51-4afe2dcd9b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_new(['-1111223'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
