{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765f49a7-271e-4995-9006-3b01ac9bd17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "\n",
    "def Multi30k(language_pair=None):\n",
    "    corpus_lines_train = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/train.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_train.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_train = list(zip(*corpus_lines_train))\n",
    "\n",
    "    corpus_lines_eval = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/val.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_eval.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_eval = list(zip(*corpus_lines_eval))\n",
    "\n",
    "    return corpus_train, corpus_eval, None\n",
    "# end\n",
    "\n",
    "\n",
    "def load_vocab(spacy_en):\n",
    "    if not os.path.exists(\"vocab.pt\"):\n",
    "        vocab_tgt = build_vocabulary(spacy_en)\n",
    "        torch.save(vocab_tgt, \"vocab.pt\")\n",
    "    else:\n",
    "        vocab_tgt = torch.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes: {}\".format(len(vocab_tgt)))\n",
    "    return vocab_tgt\n",
    "# end\n",
    "\n",
    "def load_spacy():\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_en\n",
    "# end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7164e586-738a-44ca-85be-db4a2a1ccb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " PyTorch DistilBERT model adapted in part from Facebook, Inc XLM model (https://github.com/facebookresearch/XLM) and in\n",
    " part from HuggingFace PyTorch version of Google AI Bert model (https://github.com/google-research/bert)\n",
    "\"\"\"\n",
    "\n",
    "def is_deepspeed_zero3_enabled():\n",
    "    return False\n",
    "\n",
    "def get_activation(klass_activation):\n",
    "    return klass_activation()\n",
    "# end\n",
    "\n",
    "class PretrainedConfig(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "# end\n",
    "\n",
    "\n",
    "class BaseModelOutput:\n",
    "    def __init__(self, last_hidden_state=None, hidden_states=None, attentions=None):\n",
    "        self.last_hidden_state = hidden_state\n",
    "        self.hidden_states = all_hidden_states\n",
    "        self.attentions = all_attentions\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class MaskedLMOutput:\n",
    "    def __init__(self, mlm_loss=None, prediction_logits=None, dlbrt_output=None):\n",
    "        self.loss=mlm_loss,\n",
    "        self.logits=prediction_logits,\n",
    "        self.hidden_states=dlbrt_output.hidden_states,\n",
    "        self.attentions=dlbrt_output.attentions,\n",
    "# end\n",
    "\n",
    "import math\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "from pytorch_utils import apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
    "\n",
    "import json\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "\n",
    "def create_sinusoidal_embeddings(n_pos: int, dim: int, out: torch.Tensor):\n",
    "    if is_deepspeed_zero3_enabled():\n",
    "        import deepspeed\n",
    "\n",
    "        with deepspeed.zero.GatheredParameters(out, modifier_rank=0):\n",
    "            if torch.distributed.get_rank() == 0:\n",
    "                _create_sinusoidal_embeddings(n_pos=n_pos, dim=dim, out=out)\n",
    "    else:\n",
    "        _create_sinusoidal_embeddings(n_pos=n_pos, dim=dim, out=out)\n",
    "\n",
    "\n",
    "def _create_sinusoidal_embeddings(n_pos: int, dim: int, out: torch.Tensor):\n",
    "    position_enc = np.array([[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)])\n",
    "    out.requires_grad = False\n",
    "    out[:, 0::2] = torch.FloatTensor(np.sin(position_enc[:, 0::2]))\n",
    "    out[:, 1::2] = torch.FloatTensor(np.cos(position_enc[:, 1::2]))\n",
    "    out.detach_()\n",
    "\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.dim, padding_idx=config.pad_token_id)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.dim)\n",
    "        if config.sinusoidal_pos_embds:\n",
    "            create_sinusoidal_embeddings(\n",
    "                n_pos=config.max_position_embeddings, dim=config.dim, out=self.position_embeddings.weight\n",
    "            )\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.register_buffer(\n",
    "            \"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)), persistent=False\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, input_embeds: Optional[torch.Tensor] = None):\n",
    "\n",
    "        if input_ids is not None:\n",
    "            input_embeds = self.word_embeddings(input_ids)  # (bs, max_seq_length, dim)\n",
    "\n",
    "        seq_length = input_embeds.size(1)\n",
    "\n",
    "        if hasattr(self, \"position_ids\"):\n",
    "            position_ids = self.position_ids[:, :seq_length]\n",
    "        else: \n",
    "            position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)  # (max_seq_length)\n",
    "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # (bs, max_seq_length)\n",
    "\n",
    "        position_embeddings = self.position_embeddings(position_ids)  # (bs, max_seq_length, dim)\n",
    "\n",
    "        embeddings = input_embeds + position_embeddings  # (bs, max_seq_length, dim)\n",
    "        embeddings = self.LayerNorm(embeddings)  # (bs, max_seq_length, dim)\n",
    "        embeddings = self.dropout(embeddings)  # (bs, max_seq_length, dim)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.n_heads = config.n_heads\n",
    "        self.dim = config.dim\n",
    "        self.dropout = nn.Dropout(p=config.attention_dropout)\n",
    "        self.is_causal = False\n",
    "\n",
    "        # Have an even number of multi heads that divide the dimensions\n",
    "        if self.dim % self.n_heads != 0:\n",
    "            # Raise value errors for even multi-head attention nodes\n",
    "            raise ValueError(f\"self.n_heads: {self.n_heads} must divide self.dim: {self.dim} evenly\")\n",
    "\n",
    "        self.q_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.k_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.v_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "        self.out_lin = nn.Linear(in_features=config.dim, out_features=config.dim)\n",
    "\n",
    "        self.pruned_heads: Set[int] = set()\n",
    "        self.attention_head_size = self.dim // self.n_heads\n",
    "\n",
    "    def prune_heads(self, heads: List[int]):\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        heads, index = find_pruneable_heads_and_indices(\n",
    "            heads, self.n_heads, self.attention_head_size, self.pruned_heads\n",
    "        )\n",
    "        # Prune linear layers\n",
    "        self.q_lin = prune_linear_layer(self.q_lin, index)\n",
    "        self.k_lin = prune_linear_layer(self.k_lin, index)\n",
    "        self.v_lin = prune_linear_layer(self.v_lin, index)\n",
    "        self.out_lin = prune_linear_layer(self.out_lin, index, dim=1)\n",
    "        # Update hyper params\n",
    "        self.n_heads = self.n_heads - len(heads)\n",
    "        self.dim = self.attention_head_size * self.n_heads\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        query: torch.Tensor,\n",
    "        key: torch.Tensor,\n",
    "        value: torch.Tensor,\n",
    "        mask: torch.Tensor,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        output_attentions: bool = False,\n",
    "    ):\n",
    "\n",
    "        bs, q_length, dim = query.size()\n",
    "        k_length = key.size(1)\n",
    "\n",
    "        dim_per_head = self.dim // self.n_heads\n",
    "\n",
    "        mask_reshp = (bs, 1, 1, k_length)\n",
    "\n",
    "        def shape(x: torch.Tensor) -> torch.Tensor:\n",
    "            return x.view(bs, -1, self.n_heads, dim_per_head).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor) -> torch.Tensor:\n",
    "            return x.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * dim_per_head)\n",
    "\n",
    "        q = shape(self.q_lin(query))  # (bs, n_heads, q_length, dim_per_head)\n",
    "        k = shape(self.k_lin(key))  # (bs, n_heads, k_length, dim_per_head)\n",
    "        v = shape(self.v_lin(value))  # (bs, n_heads, k_length, dim_per_head)\n",
    "\n",
    "        q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\n",
    "        scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)\n",
    "        mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)\n",
    "        scores = scores.masked_fill(\n",
    "            mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
    "        )  # (bs, n_heads, q_length, k_length)\n",
    "\n",
    "        weights = nn.functional.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)\n",
    "        weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            weights = weights * head_mask\n",
    "\n",
    "        context = torch.matmul(weights, v)  # (bs, n_heads, q_length, dim_per_head)\n",
    "        context = unshape(context)  # (bs, q_length, dim)\n",
    "        context = self.out_lin(context)  # (bs, q_length, dim)\n",
    "\n",
    "        if output_attentions:\n",
    "            return (context, weights)\n",
    "        else:\n",
    "            return (context,)\n",
    "\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=config.dropout)\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.lin1 = nn.Linear(in_features=config.dim, out_features=config.hidden_dim)\n",
    "        self.lin2 = nn.Linear(in_features=config.hidden_dim, out_features=config.dim)\n",
    "        self.activation = get_activation(config.activation)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return apply_chunking_to_forward(self.ff_chunk, self.chunk_size_feed_forward, self.seq_len_dim, input)\n",
    "\n",
    "    def ff_chunk(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.lin1(input)\n",
    "        x = self.activation(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        # Have an even number of Configure multi-heads\n",
    "        if config.dim % config.n_heads != 0:\n",
    "            raise ValueError(f\"config.n_heads {config.n_heads} must divide config.dim {config.dim} evenly\")\n",
    "\n",
    "        self.attention = (\n",
    "            MultiHeadSelfAttention(config)\n",
    "            if not getattr(config, \"_flash_attn_2_enabled\", False)\n",
    "            else DistilBertFlashAttention2(config)\n",
    "        )\n",
    "        self.sa_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=1e-12)\n",
    "\n",
    "        self.ffn = FFN(config)\n",
    "        self.output_layer_norm = nn.LayerNorm(normalized_shape=config.dim, eps=1e-12)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        attn_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        output_attentions: bool = False,\n",
    "    ):\n",
    "        # Self-Attention\n",
    "        sa_output = self.attention(\n",
    "            query=x,\n",
    "            key=x,\n",
    "            value=x,\n",
    "            mask=attn_mask,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        if output_attentions:\n",
    "            sa_output, sa_weights = sa_output  # (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\n",
    "        else:  # To handle these `output_attentions` or `output_hidden_states` cases returning tuples\n",
    "            if type(sa_output) != tuple:\n",
    "                raise TypeError(f\"sa_output must be a tuple but it is {type(sa_output)} type\")\n",
    "\n",
    "            sa_output = sa_output[0]\n",
    "        sa_output = self.sa_layer_norm(sa_output + x)  # (bs, seq_length, dim)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.ffn(sa_output)  # (bs, seq_length, dim)\n",
    "        ffn_output: torch.Tensor = self.output_layer_norm(ffn_output + sa_output)  # (bs, seq_length, dim)\n",
    "\n",
    "        output = (ffn_output,)\n",
    "        if output_attentions:\n",
    "            output = (sa_weights,) + output\n",
    "        return output\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.n_layers = config.n_layers\n",
    "        self.layer = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        attn_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        output_attentions: bool = False,\n",
    "        output_hidden_states: bool = False,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_attentions = () if output_attentions else None\n",
    "\n",
    "        hidden_state = x\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_state,)\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "                layer_outputs = self._gradient_checkpointing_func(\n",
    "                    layer_module.__call__,\n",
    "                    hidden_state,\n",
    "                    attn_mask,\n",
    "                    head_mask[i],\n",
    "                    output_attentions,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_state,\n",
    "                    attn_mask,\n",
    "                    head_mask[i],\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_state = layer_outputs[-1]\n",
    "\n",
    "            if output_attentions:\n",
    "                if len(layer_outputs) != 2:\n",
    "                    raise ValueError(f\"The length of the layer_outputs should be 2, but it is {len(layer_outputs)}\")\n",
    "\n",
    "                attentions = layer_outputs[0]\n",
    "                all_attentions = all_attentions + (attentions,)\n",
    "            else:\n",
    "                if len(layer_outputs) != 1:\n",
    "                    raise ValueError(f\"The length of the layer_outputs should be 1, but it is {len(layer_outputs)}\")\n",
    "\n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_state,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(v for v in [hidden_state, all_hidden_states, all_attentions] if v is not None)\n",
    "        return BaseModelOutput(\n",
    "            last_hidden_state=hidden_state, hidden_states=all_hidden_states, attentions=all_attentions\n",
    "        )\n",
    "\n",
    "\n",
    "# INTERFACE FOR ENCODER AND TASK SPECIFIC MODEL #\n",
    "class DistilBertPreTrainedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "    # end\n",
    "\n",
    "    config_class = PretrainedConfig\n",
    "    load_tf_weights = None\n",
    "    base_model_prefix = \"distilbert\"\n",
    "    supports_gradient_checkpointing = True\n",
    "    _supports_flash_attn_2 = False\n",
    "\n",
    "    def _init_weights(self, module: nn.Module):\n",
    "        \"\"\"Initialize the weights.\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    # end\n",
    "    \n",
    "    def post_init(self):\n",
    "        pass\n",
    "    # end\n",
    "\n",
    "\n",
    "\n",
    "class DistilBertModel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.embeddings = Embeddings(config)  # Embeddings\n",
    "        self.transformer = Transformer(config)  # Encoder\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "    # end\n",
    "    \n",
    "    def post_init(self):\n",
    "        pass\n",
    "    # end\n",
    "\n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        \"\"\"\n",
    "        Returns the position embeddings\n",
    "        \"\"\"\n",
    "        return self.embeddings.position_embeddings\n",
    "\n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "\n",
    "        num_position_embeds_diff = new_num_position_embeddings - self.config.max_position_embeddings\n",
    "\n",
    "        # no resizing needs to be done if the length stays the same\n",
    "        if num_position_embeds_diff == 0:\n",
    "            return\n",
    "\n",
    "        logger.info(f\"Setting `config.max_position_embeddings={new_num_position_embeddings}`...\")\n",
    "        self.config.max_position_embeddings = new_num_position_embeddings\n",
    "\n",
    "        old_position_embeddings_weight = self.embeddings.position_embeddings.weight.clone()\n",
    "\n",
    "        self.embeddings.position_embeddings = nn.Embedding(self.config.max_position_embeddings, self.config.dim)\n",
    "\n",
    "        if self.config.sinusoidal_pos_embds:\n",
    "            create_sinusoidal_embeddings(\n",
    "                n_pos=self.config.max_position_embeddings, dim=self.config.dim, out=self.position_embeddings.weight\n",
    "            )\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                if num_position_embeds_diff > 0:\n",
    "                    self.embeddings.position_embeddings.weight[:-num_position_embeds_diff] = nn.Parameter(\n",
    "                        old_position_embeddings_weight\n",
    "                    )\n",
    "                else:\n",
    "                    self.embeddings.position_embeddings.weight = nn.Parameter(\n",
    "                        old_position_embeddings_weight[:num_position_embeds_diff]\n",
    "                    )\n",
    "        # move position_embeddings to correct device\n",
    "        self.embeddings.position_embeddings.to(self.device)\n",
    "\n",
    "    def get_input_embeddings(self) -> nn.Embedding:\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, new_embeddings: nn.Embedding):\n",
    "        self.embeddings.word_embeddings = new_embeddings\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune: Dict[int, List[List[int]]]):\n",
    "\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.transformer.layer[layer].attention.prune_heads(heads)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            # self.warn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "        head_mask = [None for _ in range(config.n_heads)]\n",
    "\n",
    "        embeddings = self.embeddings(input_ids, inputs_embeds)  # (bs, seq_length, dim)\n",
    "\n",
    "        if getattr(self.config, \"_flash_attn_2_enabled\", False):\n",
    "            attention_mask = attention_mask if (attention_mask is not None and 0 in attention_mask) else None\n",
    "        else:\n",
    "            if attention_mask is None:\n",
    "                attention_mask = torch.ones(input_shape, device=device)  # (bs, seq_length)\n",
    "\n",
    "        return self.transformer(\n",
    "            x=embeddings,\n",
    "            attn_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class DistilBertForMaskedLM(DistilBertPreTrainedModel):\n",
    "    _tied_weights_keys = [\"vocab_projector.weight\"]\n",
    "\n",
    "    def __init__(self, config: PretrainedConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.activation = get_activation(config.activation)\n",
    "\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        self.vocab_transform = nn.Linear(config.dim, config.dim)\n",
    "        self.vocab_layer_norm = nn.LayerNorm(config.dim, eps=1e-12)\n",
    "        self.vocab_projector = nn.Linear(config.dim, config.vocab_size)\n",
    "\n",
    "        self.post_init()\n",
    "\n",
    "        self.mlm_loss_fct = nn.CrossEntropyLoss()\n",
    "    # end\n",
    "    \n",
    "    def post_init(self):\n",
    "        pass\n",
    "    # end\n",
    "\n",
    "    def get_position_embeddings(self) -> nn.Embedding:\n",
    "        return self.distilbert.get_position_embeddings()\n",
    "\n",
    "    def resize_position_embeddings(self, new_num_position_embeddings: int):\n",
    "        self.distilbert.resize_position_embeddings(new_num_position_embeddings)\n",
    "\n",
    "    def get_output_embeddings(self) -> nn.Module:\n",
    "        return self.vocab_projector\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings: nn.Module):\n",
    "        self.vocab_projector = new_embeddings\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        dlbrt_output = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = dlbrt_output[0]  # (bs, seq_length, dim)\n",
    "        prediction_logits = self.vocab_transform(hidden_states)  # (bs, seq_length, dim)\n",
    "        prediction_logits = self.activation(prediction_logits)  # (bs, seq_length, dim)\n",
    "        prediction_logits = self.vocab_layer_norm(prediction_logits)  # (bs, seq_length, dim)\n",
    "        prediction_logits = self.vocab_projector(prediction_logits)  # (bs, seq_length, vocab_size)\n",
    "\n",
    "        mlm_loss = None\n",
    "        if labels is not None:\n",
    "            mlm_loss = self.mlm_loss_fct(prediction_logits.view(-1, prediction_logits.size(-1)), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_logits,) + dlbrt_output[1:]\n",
    "            return ((mlm_loss,) + output) if mlm_loss is not None else output\n",
    "\n",
    "        return MaskedLMOutput(\n",
    "            loss=mlm_loss,\n",
    "            logits=prediction_logits,\n",
    "            hidden_states=dlbrt_output.hidden_states,\n",
    "            attentions=dlbrt_output.attentions,\n",
    "        )\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aaeb091-725e-4182-8b18-3ee9d049328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, vocab, splitter):\n",
    "        self.splitter = splitter\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.id_pad = len(vocab)\n",
    "        self.id_cls = len(vocab) + 1\n",
    "        self.id_sep = len(vocab) + 2\n",
    "        self.id_mask = len(vocab) + 3\n",
    "        \n",
    "        self.size_vocab = len(vocab) + 4\n",
    "\n",
    "        self.token_pad = '[PAD]'\n",
    "        self.token_cls = '[CLS]'\n",
    "        self.token_sep = '[SEP]'\n",
    "        self.token_mask = '[MASK]'\n",
    "           \n",
    "        self.index_id_token_special = {\n",
    "            self.id_pad: self.token_pad,\n",
    "            self.id_cls: self.token_cls,\n",
    "            self.id_sep: self.token_sep,\n",
    "            self.id_mask: self.token_mask\n",
    "        }\n",
    "        \n",
    "    # end\n",
    "\n",
    "    def encode(self, line):\n",
    "        return self.vocab([doc.text for doc in self.splitter(line)])\n",
    "    # end\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        words = []\n",
    "        for token in tokens:\n",
    "            token = int(token)\n",
    "            \n",
    "            if token in self.index_id_token_special:\n",
    "                word_target = self.index_id_token_special[token]\n",
    "            else:\n",
    "                try:\n",
    "                    word_target = vocab.lookup_token(token)\n",
    "                except:\n",
    "                    word_target = '[ERROR_LOOKUP_{}]'.format(token)\n",
    "                # end\n",
    "            # end\n",
    "            \n",
    "            words.append(word_target)\n",
    "        # end\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "class Batch:\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        for k, v in kwargs.items():\n",
    "            if v is not None and type(v) is not bool:\n",
    "                self.kwargs[k] = v.to(Batch.DEVICE)\n",
    "            # end\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.kwargs\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class Collator_S2S:\n",
    "\n",
    "    def __init__(self, tokenizer, size_seq_max):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size_seq_max = size_seq_max\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def __call__(self, list_corpus_source):\n",
    "\n",
    "        tokens_input_encoder = []\n",
    "        tokens_input_decoder = []\n",
    "        tokens_label_decoder = []\n",
    "        labels_similarity = []\n",
    "\n",
    "        for corpus_source in list_corpus_source: # (line0, line1, sim), output of zip remove single case\n",
    "            if len(corpus_source) == 3:\n",
    "                corpus_line = [courpus_source[0], corpus_source[1]]\n",
    "                labels_similarity.append(corpus_line[2])\n",
    "            else:\n",
    "                corpus_line = [corpus_source[1]]\n",
    "            # end\n",
    "            \n",
    "            for line in corpus_line:\n",
    "                tokens = self.tokenizer.encode(line)\n",
    "\n",
    "                # TODO: check edge\n",
    "                if len(tokens) > self.size_seq_max - 2:\n",
    "                    tokens = tokens[:self.size_seq_max-2]\n",
    "                # end\n",
    "\n",
    "                tokens_input_encoder.append([self.tokenizer.id_cls] + tokens + [self.tokenizer.id_sep])\n",
    "                tokens_input_decoder.append([self.tokenizer.id_cls] + tokens)\n",
    "                tokens_label_decoder.append(tokens + [self.tokenizer.id_sep])\n",
    "            # end\n",
    "            \n",
    "\n",
    "        # end\n",
    "\n",
    "        inputs_encoder, masks_encoder, segments_encoder, labels_encoder = self.pad_sequences(tokens_input_encoder, self.size_seq_max, need_masked=0.3)\n",
    "\n",
    "    \n",
    "        return Batch(\n",
    "            input_ids=inputs_encoder,\n",
    "            attention_mask=masks_encoder,\n",
    "            labels=labels_encoder,\n",
    "            inputs_embeds=None,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=False\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    \n",
    "    # return masks_attention?, return masks_segment?\n",
    "    def pad_sequences(self, sequences, size_seq_max, need_diagonal=False, need_masked=0): # need_diagonal and need_masked cannot both set, one for bert seq one for s2s seq\n",
    "        id_pad = self.tokenizer.id_pad\n",
    "        id_mask = self.tokenizer.id_mask\n",
    "\n",
    "        sequences_padded = []\n",
    "        sequences_masked_padded = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            len_seq = len(sequence)\n",
    "\n",
    "            count_pad = size_seq_max - len_seq\n",
    "\n",
    "            sequence = torch.LongTensor(sequence)\n",
    "            sequence_padded = torch.cat((sequence, torch.LongTensor([id_pad] * count_pad)))\n",
    "            sequences_padded.append(sequence_padded)\n",
    "\n",
    "            if need_masked:\n",
    "                index_masked = list(range(1, len_seq-1))\n",
    "                random.shuffle(index_masked)\n",
    "                index_masked = torch.LongTensor(index_masked[:int(need_masked * (len_seq-2))])\n",
    "\n",
    "                sequence_masked = sequence.detach().clone()\n",
    "                sequence_masked.index_fill_(0, index_masked, id_mask)\n",
    "                sequence_masked_padded = torch.cat((sequence_masked, torch.LongTensor([id_pad] * count_pad)))\n",
    "                \n",
    "                sequences_masked_padded.append(sequence_masked_padded)\n",
    "            # end\n",
    "    #   # end for\n",
    "\n",
    "        inputs = torch.stack(sequences_padded)  # (batch, size_seq_max)\n",
    "        if need_masked:\n",
    "            inputs_masked_padded = torch.stack(sequences_masked_padded)\n",
    "        # end\n",
    "\n",
    "        masks_segment = (inputs != self.tokenizer.id_pad) #(nbatch, , seq)\n",
    "        masks_attention = self.make_std_mask(inputs, self.tokenizer.id_pad) if need_diagonal else masks_segment\n",
    "\n",
    "        if need_masked:\n",
    "            masks_masked = (inputs_masked_padded != id_mask)\n",
    "            masks_attention = masks_attention & masks_masked\n",
    "            return inputs_masked_padded, masks_attention, masks_segment, inputs # (inputs, masks_attention, masks_segment, labels)\n",
    "        else:\n",
    "            return inputs, masks_attention, masks_segment\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def subsequent_mask(self, size):\n",
    "        \"Mask out subsequent positions.\"\n",
    "        attn_shape = (1, size, size)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        return subsequent_mask == 0\n",
    "\n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & self.subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "    # end\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c2c169-42a0-455e-ac22-d70e95101862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: weight tied not enabled\n",
    "\n",
    "# train config\n",
    "seq_max = 16\n",
    "batch_size = 16\n",
    "epochs=80\n",
    "\n",
    "# model config\n",
    "config = PretrainedConfig()\n",
    "config._flash_attn_2_enabled=False\n",
    "config.activation=torch.nn.ReLU\n",
    "config.dim = 512\n",
    "config.hidden_dim=512\n",
    "config.vocab_size = 6195\n",
    "config.pad_token_id = 6194\n",
    "config.max_position_embeddings = 512\n",
    "config.sinusoidal_pos_embds = True\n",
    "config.n_layers = 4\n",
    "config.n_heads = 8\n",
    "config.attention_dropout = 0.1\n",
    "config.dropout=0.1\n",
    "config.use_return_dict=False\n",
    "config.chunk_size_feed_forward=False\n",
    "\n",
    "head = DistilBertForMaskedLM(config)\n",
    "head = head.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.Adam(head.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "decayRate = 0.96\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e2704e-6554-45aa-9f4d-e216bbc14291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes: 6191\n"
     ]
    }
   ],
   "source": [
    "spacy_en = load_spacy()\n",
    "vocab = load_vocab(spacy_en)\n",
    "tokenizer = TokenizerWrapper(vocab, spacy_en)\n",
    "\n",
    "train_iter, valid_iter, _ = Multi30k(language_pair=(\"de\", \"en\"))\n",
    "train_source = to_map_style_dataset(train_iter)\n",
    "\n",
    "collator = Collator_S2S(tokenizer, seq_max)\n",
    "dataloader_train = DataLoader(train_source, batch_size, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "971f24b7-7a68-46fd-bf90-83b8561c7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_a_batch(batch, head, optimizer=None, scheduler=None):\n",
    "    loss_mlm, out_mlm = head.forward(**batch())    # save to cache\n",
    "\n",
    "    # crossentropy loss\n",
    "    \n",
    "    loss_all = loss_mlm\n",
    "    loss_all_value = loss_all.item()\n",
    "    \n",
    "    # print(loss_all)\n",
    "    loss_all.backward()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    # end\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    # end\n",
    "    # manager.clear_cache()\n",
    "    return loss_all_value\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4c7d429-3344-4ce1-bcc9-f9925c36b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 0, loss: 8.986350059509277, rate: 0.0001\n",
      "Epoch: 0 Batch: 50, loss: 3.800835371017456, rate: 0.0001\n",
      "Epoch: 0 Batch: 100, loss: 3.3727011680603027, rate: 0.0001\n",
      "Epoch: 0 Batch: 150, loss: 2.8725202083587646, rate: 0.0001\n",
      "Epoch: 0 Batch: 200, loss: 2.929250478744507, rate: 0.0001\n",
      "Epoch: 0 Batch: 250, loss: 2.6574900150299072, rate: 0.0001\n",
      "Epoch: 0 Batch: 300, loss: 1.9307184219360352, rate: 0.0001\n",
      "Epoch: 0 Batch: 350, loss: 2.2226295471191406, rate: 0.0001\n",
      "Epoch: 0 Batch: 400, loss: 2.0516533851623535, rate: 0.0001\n",
      "Epoch: 0 Batch: 450, loss: 2.1807262897491455, rate: 0.0001\n",
      "Epoch: 0 Batch: 500, loss: 2.574434757232666, rate: 0.0001\n",
      "Epoch: 0 Batch: 550, loss: 2.3924269676208496, rate: 0.0001\n",
      "Epoch: 0 Batch: 600, loss: 1.8914878368377686, rate: 0.0001\n",
      "Epoch: 0 Batch: 650, loss: 1.9782049655914307, rate: 0.0001\n",
      "Epoch: 0 Batch: 700, loss: 2.2591726779937744, rate: 0.0001\n",
      "Epoch: 0 Batch: 750, loss: 1.9410871267318726, rate: 0.0001\n",
      "Epoch: 0 Batch: 800, loss: 2.0861685276031494, rate: 0.0001\n",
      "Epoch: 0 Batch: 850, loss: 2.0492732524871826, rate: 0.0001\n",
      "Epoch: 0 Batch: 900, loss: 2.274721384048462, rate: 0.0001\n",
      "Epoch: 0 Batch: 950, loss: 2.1121633052825928, rate: 0.0001\n",
      "Epoch: 0 Batch: 1000, loss: 2.245547294616699, rate: 0.0001\n",
      "Epoch: 0 Batch: 1050, loss: 1.909204363822937, rate: 0.0001\n",
      "Epoch: 0 Batch: 1100, loss: 2.020474672317505, rate: 0.0001\n",
      "Epoch: 0 Batch: 1150, loss: 2.019258975982666, rate: 0.0001\n",
      "Epoch: 0 Batch: 1200, loss: 1.9887347221374512, rate: 0.0001\n",
      "Epoch: 0 Batch: 1250, loss: 1.8781518936157227, rate: 0.0001\n",
      "Epoch: 0 Batch: 1300, loss: 1.6843794584274292, rate: 0.0001\n",
      "Epoch: 0 Batch: 1350, loss: 1.9893709421157837, rate: 0.0001\n",
      "Epoch: 0 Batch: 1400, loss: 1.8390675783157349, rate: 0.0001\n",
      "Epoch: 0 Batch: 1450, loss: 2.2602930068969727, rate: 0.0001\n",
      "Epoch: 0 Batch: 1500, loss: 2.2367305755615234, rate: 0.0001\n",
      "Epoch: 0 Batch: 1550, loss: 2.1338539123535156, rate: 0.0001\n",
      "Epoch: 0 Batch: 1600, loss: 2.3559694290161133, rate: 0.0001\n",
      "Epoch: 0 Batch: 1650, loss: 2.352835178375244, rate: 0.0001\n",
      "Epoch: 0 Batch: 1700, loss: 2.425116777420044, rate: 0.0001\n",
      "Epoch: 0 Batch: 1750, loss: 2.0202441215515137, rate: 0.0001\n",
      "Epoch: 0 Batch: 1800, loss: 1.9714114665985107, rate: 0.0001\n",
      "[2023-11-13 09:27:57.465822] Epoch: 0 ends. Average loss: 2.2836863840080004\n",
      "Epoch: 1 Batch: 0, loss: 2.00227952003479, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 50, loss: 1.8172607421875, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 100, loss: 2.1281330585479736, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 150, loss: 1.9399605989456177, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 200, loss: 2.179689884185791, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 250, loss: 2.03275728225708, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 300, loss: 1.4752908945083618, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 350, loss: 1.9818062782287598, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 400, loss: 1.7564024925231934, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 450, loss: 2.0285239219665527, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 500, loss: 2.394707202911377, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 550, loss: 2.2035045623779297, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 600, loss: 1.6825008392333984, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 650, loss: 1.9072599411010742, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 700, loss: 2.1871817111968994, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 750, loss: 1.863983392715454, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 800, loss: 2.095237970352173, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 850, loss: 1.894717812538147, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 900, loss: 2.066080093383789, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 950, loss: 2.1480226516723633, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1000, loss: 2.246189832687378, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1050, loss: 1.9808584451675415, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1100, loss: 2.1892521381378174, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1150, loss: 2.0769598484039307, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1200, loss: 2.0158135890960693, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1250, loss: 1.8519153594970703, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1300, loss: 1.7715773582458496, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1350, loss: 2.0863587856292725, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1400, loss: 1.8373950719833374, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1450, loss: 2.2194736003875732, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1500, loss: 2.226750373840332, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1550, loss: 2.1870346069335938, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1600, loss: 2.3891921043395996, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1650, loss: 2.397596836090088, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1700, loss: 2.498248815536499, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1750, loss: 2.108206033706665, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1800, loss: 1.9877479076385498, rate: 9.6e-05\n",
      "[2023-11-13 09:31:43.017686] Epoch: 1 ends. Average loss: 2.0357784168271813\n",
      "Epoch: 2 Batch: 0, loss: 2.0058062076568604, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 50, loss: 1.961806058883667, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 100, loss: 2.197248935699463, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 150, loss: 2.0996105670928955, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 200, loss: 2.3154683113098145, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 250, loss: 2.165978193283081, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 300, loss: 1.5282979011535645, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 350, loss: 2.0585832595825195, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 400, loss: 1.9237875938415527, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 450, loss: 2.1417019367218018, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 500, loss: 2.461782217025757, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 550, loss: 2.321713447570801, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 600, loss: 1.788896083831787, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 650, loss: 2.020432949066162, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 700, loss: 2.265096664428711, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 750, loss: 2.001460313796997, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 800, loss: 2.100504159927368, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 850, loss: 2.035212278366089, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 900, loss: 2.309191942214966, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 950, loss: 2.264758348464966, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1000, loss: 2.4171764850616455, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1050, loss: 2.1178340911865234, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1100, loss: 2.1958107948303223, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1150, loss: 2.1751821041107178, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1200, loss: 2.2625675201416016, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1250, loss: 1.9840123653411865, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1300, loss: 1.9343725442886353, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1350, loss: 2.208325147628784, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1400, loss: 1.9932118654251099, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1450, loss: 2.3567466735839844, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1500, loss: 2.392106056213379, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1550, loss: 2.3479697704315186, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1600, loss: 2.489328384399414, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1650, loss: 2.5576171875, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1700, loss: 2.6460633277893066, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1750, loss: 2.2420430183410645, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1800, loss: 2.2477641105651855, rate: 9.216e-05\n",
      "[2023-11-13 09:35:30.060849] Epoch: 2 ends. Average loss: 2.1530445633313304\n",
      "Epoch: 3 Batch: 0, loss: 2.100940227508545, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 50, loss: 2.0050010681152344, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 100, loss: 2.298856258392334, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 150, loss: 2.19878888130188, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 200, loss: 2.457892656326294, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 250, loss: 2.266084909439087, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 300, loss: 1.6422775983810425, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 350, loss: 2.0347843170166016, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 400, loss: 1.9968122243881226, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 450, loss: 2.153628349304199, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 500, loss: 2.5680654048919678, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 550, loss: 2.4180965423583984, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 600, loss: 1.9044623374938965, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 650, loss: 2.089893341064453, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 700, loss: 2.4298040866851807, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 750, loss: 2.1245102882385254, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 800, loss: 2.3252434730529785, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 850, loss: 2.0905728340148926, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 900, loss: 2.424405813217163, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 950, loss: 2.3768975734710693, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1000, loss: 2.4310567378997803, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1050, loss: 2.2071163654327393, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1100, loss: 2.2638275623321533, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1150, loss: 2.3940389156341553, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1200, loss: 2.3573789596557617, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1250, loss: 2.1159121990203857, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1300, loss: 2.024991512298584, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1350, loss: 2.240098237991333, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1400, loss: 1.9958401918411255, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1450, loss: 2.5288355350494385, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1500, loss: 2.562986373901367, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1550, loss: 2.384408950805664, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1600, loss: 2.6196107864379883, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1650, loss: 2.6580755710601807, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1700, loss: 2.7891793251037598, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1750, loss: 2.3439688682556152, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1800, loss: 2.3738350868225098, rate: 8.847359999999999e-05\n",
      "[2023-11-13 09:39:16.497829] Epoch: 3 ends. Average loss: 2.2701730847161445\n",
      "Epoch: 4 Batch: 0, loss: 2.205493927001953, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 50, loss: 2.1105337142944336, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 100, loss: 2.418104648590088, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 150, loss: 2.259505271911621, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 200, loss: 2.52485728263855, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 250, loss: 2.3908791542053223, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 300, loss: 1.7359563112258911, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 350, loss: 2.1969194412231445, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 400, loss: 2.0520851612091064, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 450, loss: 2.2562241554260254, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 500, loss: 2.6483068466186523, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 550, loss: 2.4999351501464844, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 600, loss: 1.8685805797576904, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 650, loss: 2.182767152786255, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 700, loss: 2.4499759674072266, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 750, loss: 2.0789217948913574, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 800, loss: 2.284189224243164, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 850, loss: 2.2209558486938477, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 900, loss: 2.4960391521453857, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 950, loss: 2.3652615547180176, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1000, loss: 2.534008264541626, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1050, loss: 2.1994168758392334, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1100, loss: 2.2807633876800537, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1150, loss: 2.25801157951355, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1200, loss: 2.3576858043670654, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1250, loss: 2.109567165374756, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1300, loss: 1.890307903289795, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1350, loss: 2.16247296333313, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1400, loss: 2.0257456302642822, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1450, loss: 2.3862006664276123, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1500, loss: 2.410008668899536, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1550, loss: 2.2665882110595703, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1600, loss: 2.5482141971588135, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1650, loss: 2.574160575866699, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1700, loss: 2.6971850395202637, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1750, loss: 2.23437762260437, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1800, loss: 2.2191224098205566, rate: 8.493465599999999e-05\n",
      "[2023-11-13 09:43:03.789133] Epoch: 4 ends. Average loss: 2.2789460092503524\n",
      "Epoch: 5 Batch: 0, loss: 2.1950416564941406, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 50, loss: 2.0531656742095947, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 100, loss: 2.3462133407592773, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 150, loss: 2.1578478813171387, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 200, loss: 2.402418375015259, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 250, loss: 2.237093210220337, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 300, loss: 1.6273859739303589, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 350, loss: 2.0783114433288574, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 400, loss: 1.9111939668655396, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 450, loss: 2.1529109477996826, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 500, loss: 2.5390517711639404, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 550, loss: 2.4021236896514893, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 600, loss: 1.7427252531051636, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 650, loss: 2.06144380569458, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 700, loss: 2.2040951251983643, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 750, loss: 1.9442102909088135, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 800, loss: 2.1463935375213623, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 850, loss: 2.0274789333343506, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 900, loss: 2.259211540222168, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 950, loss: 2.204740047454834, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1000, loss: 2.2905752658843994, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1050, loss: 1.9584271907806396, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1100, loss: 2.0972747802734375, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1150, loss: 2.1317203044891357, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1200, loss: 2.1857383251190186, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1250, loss: 1.8434523344039917, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1300, loss: 1.8087331056594849, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1350, loss: 2.0081045627593994, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1400, loss: 1.9139864444732666, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1450, loss: 2.223512887954712, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1500, loss: 2.170083522796631, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1550, loss: 2.0899393558502197, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1600, loss: 2.315858840942383, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1650, loss: 2.4243359565734863, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1700, loss: 2.547935962677002, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1750, loss: 2.067187547683716, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1800, loss: 1.997721552848816, rate: 8.153726975999998e-05\n",
      "[2023-11-13 09:46:48.732745] Epoch: 5 ends. Average loss: 2.1109810992623324\n",
      "Epoch: 6 Batch: 0, loss: 2.00229811668396, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 50, loss: 1.9204339981079102, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 100, loss: 2.134505271911621, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 150, loss: 2.017852783203125, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 200, loss: 2.240527868270874, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 250, loss: 1.978926420211792, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 300, loss: 1.3889451026916504, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 350, loss: 1.9380642175674438, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 400, loss: 1.7596461772918701, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 450, loss: 1.9948015213012695, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 500, loss: 2.3357186317443848, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 550, loss: 2.209463596343994, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 600, loss: 1.6218910217285156, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 650, loss: 1.8829270601272583, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 700, loss: 2.1522598266601562, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 750, loss: 1.7162717580795288, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 800, loss: 2.0206964015960693, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 850, loss: 1.902214527130127, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 900, loss: 2.1043460369110107, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 950, loss: 2.0668187141418457, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1000, loss: 2.1590576171875, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1050, loss: 1.8576284646987915, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1100, loss: 1.9871991872787476, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1150, loss: 1.9571682214736938, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1200, loss: 1.9999750852584839, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1250, loss: 1.7903711795806885, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1300, loss: 1.6413499116897583, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1350, loss: 1.8601709604263306, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1400, loss: 1.7385622262954712, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1450, loss: 2.176623821258545, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1500, loss: 2.091153860092163, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1550, loss: 2.1176633834838867, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1600, loss: 2.242204427719116, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1650, loss: 2.265965700149536, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1700, loss: 2.351504325866699, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1750, loss: 1.9153658151626587, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1800, loss: 1.9060786962509155, rate: 7.827577896959998e-05\n",
      "[2023-11-13 09:50:36.517381] Epoch: 6 ends. Average loss: 1.9695390541120845\n",
      "Epoch: 7 Batch: 0, loss: 1.9453530311584473, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 50, loss: 1.801800012588501, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 100, loss: 2.034390926361084, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 150, loss: 1.8580161333084106, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 200, loss: 2.1212615966796875, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 250, loss: 1.9650161266326904, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 300, loss: 1.3641704320907593, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 350, loss: 1.795732855796814, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 400, loss: 1.5929973125457764, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 450, loss: 1.8847014904022217, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 500, loss: 2.2833919525146484, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 550, loss: 2.0276308059692383, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 600, loss: 1.487500548362732, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 650, loss: 1.8135894536972046, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 700, loss: 1.9499483108520508, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 750, loss: 1.8235725164413452, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 800, loss: 1.8681062459945679, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 850, loss: 1.766763687133789, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 900, loss: 1.9770653247833252, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 950, loss: 2.0143473148345947, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1000, loss: 2.0356454849243164, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1050, loss: 1.7940051555633545, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1100, loss: 1.9097694158554077, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1150, loss: 1.8691372871398926, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1200, loss: 1.9300057888031006, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1250, loss: 1.7889689207077026, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1300, loss: 1.5833983421325684, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1350, loss: 1.813101053237915, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1400, loss: 1.645789384841919, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1450, loss: 2.1279447078704834, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1500, loss: 2.103742837905884, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1550, loss: 1.9885443449020386, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1600, loss: 2.089832067489624, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1650, loss: 2.2231762409210205, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1700, loss: 2.2509751319885254, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1750, loss: 1.7789160013198853, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1800, loss: 1.7835562229156494, rate: 7.514474781081598e-05\n",
      "[2023-11-13 09:54:26.709852] Epoch: 7 ends. Average loss: 1.8831023594587466\n",
      "Epoch: 8 Batch: 0, loss: 1.846996545791626, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 50, loss: 1.7984157800674438, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 100, loss: 1.9423552751541138, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 150, loss: 1.8016055822372437, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 200, loss: 2.0543808937072754, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 250, loss: 1.832732915878296, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 300, loss: 1.1561776399612427, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 350, loss: 1.735357403755188, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 400, loss: 1.5934269428253174, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 450, loss: 1.7506296634674072, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 500, loss: 2.105024814605713, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 550, loss: 1.9748833179473877, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 600, loss: 1.5386937856674194, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 650, loss: 1.7318519353866577, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 700, loss: 1.9411059617996216, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 750, loss: 1.7229416370391846, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 800, loss: 1.8987212181091309, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 850, loss: 1.7670917510986328, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 900, loss: 1.9219015836715698, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 950, loss: 1.9033197164535522, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1000, loss: 2.0258898735046387, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1050, loss: 1.6976656913757324, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1100, loss: 1.8485372066497803, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1150, loss: 1.847041130065918, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1200, loss: 1.8283284902572632, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1250, loss: 1.629043698310852, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1300, loss: 1.496286392211914, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1350, loss: 1.793177843093872, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1400, loss: 1.6508978605270386, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1450, loss: 1.9810829162597656, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1500, loss: 2.006868600845337, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1550, loss: 1.8763686418533325, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1600, loss: 2.047078847885132, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1650, loss: 2.192037343978882, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1700, loss: 2.301948308944702, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1750, loss: 1.8166040182113647, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1800, loss: 1.7895164489746094, rate: 7.213895789838334e-05\n",
      "[2023-11-13 09:58:15.843121] Epoch: 8 ends. Average loss: 1.8210153644806892\n",
      "Epoch: 9 Batch: 0, loss: 1.8051961660385132, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 50, loss: 1.6420866250991821, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 100, loss: 1.9835138320922852, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 150, loss: 1.7359696626663208, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 200, loss: 2.0398993492126465, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 250, loss: 1.7924137115478516, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 300, loss: 1.2445143461227417, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 350, loss: 1.6262574195861816, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 400, loss: 1.6342321634292603, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 450, loss: 1.8644187450408936, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 500, loss: 2.212698459625244, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 550, loss: 1.9624651670455933, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 600, loss: 1.3544191122055054, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 650, loss: 1.705464243888855, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 700, loss: 1.8847230672836304, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 750, loss: 1.7064622640609741, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 800, loss: 1.7775828838348389, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 850, loss: 1.671599268913269, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 900, loss: 1.8513942956924438, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 950, loss: 1.9302927255630493, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1000, loss: 1.9650858640670776, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1050, loss: 1.655523419380188, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1100, loss: 1.8962191343307495, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1150, loss: 1.7748631238937378, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1200, loss: 1.835134744644165, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1250, loss: 1.5534353256225586, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1300, loss: 1.4375606775283813, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1350, loss: 1.6100271940231323, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1400, loss: 1.6613216400146484, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1450, loss: 1.981569766998291, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1500, loss: 1.9839634895324707, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1550, loss: 1.8723775148391724, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1600, loss: 1.9950262308120728, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1650, loss: 2.2271246910095215, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1700, loss: 2.270622491836548, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1750, loss: 1.7036347389221191, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1800, loss: 1.7518901824951172, rate: 6.9253399582448e-05\n",
      "[2023-11-13 10:02:05.059668] Epoch: 9 ends. Average loss: 1.777494536995296\n",
      "Epoch: 10 Batch: 0, loss: 1.8241053819656372, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 50, loss: 1.7300655841827393, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 100, loss: 1.8365342617034912, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 150, loss: 1.7646565437316895, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 200, loss: 1.9626646041870117, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 250, loss: 1.758346676826477, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 300, loss: 1.1950808763504028, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 350, loss: 1.5548545122146606, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 400, loss: 1.5358891487121582, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 450, loss: 1.7296473979949951, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 500, loss: 2.0602657794952393, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 550, loss: 1.8559881448745728, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 600, loss: 1.4113454818725586, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 650, loss: 1.6994127035140991, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 700, loss: 1.9208438396453857, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 750, loss: 1.5981959104537964, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 800, loss: 1.7631257772445679, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 850, loss: 1.7161362171173096, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 900, loss: 1.7607953548431396, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 950, loss: 1.8185436725616455, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1000, loss: 1.9784455299377441, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1050, loss: 1.7077564001083374, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1100, loss: 1.8448930978775024, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1150, loss: 1.8155040740966797, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1200, loss: 1.853872537612915, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1250, loss: 1.579895257949829, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1300, loss: 1.3692368268966675, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1350, loss: 1.6491926908493042, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1400, loss: 1.5776249170303345, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1450, loss: 1.8736481666564941, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1500, loss: 1.9168986082077026, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1550, loss: 1.8629719018936157, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1600, loss: 1.860120415687561, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1650, loss: 2.1532211303710938, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1700, loss: 2.210542678833008, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1750, loss: 1.690777063369751, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1800, loss: 1.7722065448760986, rate: 6.648326359915008e-05\n",
      "[2023-11-13 10:05:53.413659] Epoch: 10 ends. Average loss: 1.7462883255985384\n",
      "Epoch: 11 Batch: 0, loss: 1.706860065460205, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 50, loss: 1.620784878730774, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 100, loss: 1.8277620077133179, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 150, loss: 1.7381104230880737, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 200, loss: 2.0306854248046875, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 250, loss: 1.671829342842102, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 300, loss: 1.1910251379013062, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 350, loss: 1.5997698307037354, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 400, loss: 1.5167295932769775, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 450, loss: 1.6883913278579712, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 500, loss: 2.0171494483947754, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 550, loss: 1.8839815855026245, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 600, loss: 1.3884769678115845, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 650, loss: 1.5306583642959595, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 700, loss: 1.784945011138916, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 750, loss: 1.695892333984375, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 800, loss: 1.7131446599960327, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 850, loss: 1.6018178462982178, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 900, loss: 1.7733118534088135, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 950, loss: 1.858070969581604, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1000, loss: 1.8649280071258545, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1050, loss: 1.6422370672225952, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1100, loss: 1.7792770862579346, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1150, loss: 1.6593221426010132, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1200, loss: 1.7829062938690186, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1250, loss: 1.5427151918411255, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1300, loss: 1.3595914840698242, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1350, loss: 1.6726993322372437, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1400, loss: 1.6375716924667358, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1450, loss: 1.9145452976226807, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1500, loss: 1.8974608182907104, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1550, loss: 1.9039572477340698, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1600, loss: 1.9923239946365356, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1650, loss: 2.005871295928955, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1700, loss: 2.202219009399414, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1750, loss: 1.7299550771713257, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1800, loss: 1.675307273864746, rate: 6.382393305518408e-05\n",
      "[2023-11-13 10:09:39.943347] Epoch: 11 ends. Average loss: 1.724067725269951\n",
      "Epoch: 12 Batch: 0, loss: 1.711094856262207, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 50, loss: 1.5807024240493774, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 100, loss: 1.7640738487243652, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 150, loss: 1.7475974559783936, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 200, loss: 1.9611492156982422, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 250, loss: 1.7239896059036255, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 300, loss: 1.1811935901641846, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 350, loss: 1.5552154779434204, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 400, loss: 1.5065373182296753, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 450, loss: 1.7238274812698364, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 500, loss: 1.9985328912734985, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 550, loss: 1.8327784538269043, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 600, loss: 1.426525354385376, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 650, loss: 1.5408740043640137, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 700, loss: 1.8565620183944702, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 750, loss: 1.6279851198196411, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 800, loss: 1.7465258836746216, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 850, loss: 1.693069338798523, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 900, loss: 1.7686439752578735, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 950, loss: 1.6873387098312378, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1000, loss: 1.8347349166870117, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1050, loss: 1.554114580154419, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1100, loss: 1.877272367477417, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1150, loss: 1.7103785276412964, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1200, loss: 1.719881534576416, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1250, loss: 1.5761322975158691, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1300, loss: 1.3969470262527466, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1350, loss: 1.615551471710205, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1400, loss: 1.5537241697311401, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1450, loss: 1.8449349403381348, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1500, loss: 1.9316673278808594, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1550, loss: 1.8225449323654175, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1600, loss: 1.9337050914764404, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1650, loss: 2.037471055984497, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1700, loss: 2.133174180984497, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1750, loss: 1.7025965452194214, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1800, loss: 1.8591123819351196, rate: 6.127097573297672e-05\n",
      "[2023-11-13 10:13:26.036582] Epoch: 12 ends. Average loss: 1.7102447208356146\n",
      "Epoch: 13 Batch: 0, loss: 1.6827495098114014, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 50, loss: 1.4734039306640625, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 100, loss: 1.8240398168563843, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 150, loss: 1.7330670356750488, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 200, loss: 1.9707071781158447, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 250, loss: 1.6671357154846191, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 300, loss: 1.2286041975021362, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 350, loss: 1.5840020179748535, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 400, loss: 1.4966537952423096, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 450, loss: 1.6528935432434082, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 500, loss: 1.9946255683898926, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 550, loss: 1.7932556867599487, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 600, loss: 1.3212623596191406, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 650, loss: 1.586923599243164, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 700, loss: 1.778761386871338, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 750, loss: 1.6251213550567627, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 800, loss: 1.717829704284668, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 850, loss: 1.656602144241333, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 900, loss: 1.6720768213272095, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 950, loss: 1.7105265855789185, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1000, loss: 1.972910761833191, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1050, loss: 1.5699788331985474, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1100, loss: 1.7276148796081543, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1150, loss: 1.7063896656036377, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1200, loss: 1.773276925086975, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1250, loss: 1.5776450634002686, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1300, loss: 1.3709189891815186, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1350, loss: 1.653260350227356, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1400, loss: 1.64714515209198, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1450, loss: 1.8620672225952148, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1500, loss: 1.8570175170898438, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1550, loss: 1.8619983196258545, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1600, loss: 1.9137133359909058, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1650, loss: 2.068789482116699, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1700, loss: 2.186384916305542, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1750, loss: 1.6431221961975098, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1800, loss: 1.719868540763855, rate: 5.882013670365765e-05\n",
      "[2023-11-13 10:17:11.925570] Epoch: 13 ends. Average loss: 1.6962793930025306\n",
      "Epoch: 14 Batch: 0, loss: 1.7040175199508667, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 50, loss: 1.5236095190048218, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 100, loss: 1.8559644222259521, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 150, loss: 1.6679677963256836, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 200, loss: 1.9149497747421265, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 250, loss: 1.7079591751098633, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 300, loss: 1.2290661334991455, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 350, loss: 1.4698163270950317, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 400, loss: 1.4704352617263794, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 450, loss: 1.740401268005371, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 500, loss: 1.9641952514648438, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 550, loss: 1.7609734535217285, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 600, loss: 1.4808646440505981, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 650, loss: 1.5661569833755493, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 700, loss: 1.7685729265213013, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 750, loss: 1.6338183879852295, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 800, loss: 1.835269570350647, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 850, loss: 1.5457825660705566, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 900, loss: 1.7251877784729004, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 950, loss: 1.8275067806243896, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1000, loss: 1.9064030647277832, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1050, loss: 1.456744909286499, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1100, loss: 1.6833652257919312, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1150, loss: 1.6928839683532715, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1200, loss: 1.8006036281585693, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1250, loss: 1.614235520362854, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1300, loss: 1.3729352951049805, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1350, loss: 1.5654345750808716, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1400, loss: 1.594284176826477, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1450, loss: 1.8538286685943604, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1500, loss: 1.8785167932510376, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1550, loss: 1.8329830169677734, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1600, loss: 1.8806363344192505, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1650, loss: 2.021244525909424, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1700, loss: 2.100675106048584, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1750, loss: 1.6446658372879028, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1800, loss: 1.725817322731018, rate: 5.6467331235511337e-05\n",
      "[2023-11-13 10:20:57.603385] Epoch: 14 ends. Average loss: 1.6883406913944587\n",
      "Epoch: 15 Batch: 0, loss: 1.7054318189620972, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 50, loss: 1.5230717658996582, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 100, loss: 1.7805317640304565, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 150, loss: 1.7675914764404297, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 200, loss: 1.9173203706741333, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 250, loss: 1.657659888267517, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 300, loss: 1.1710853576660156, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 350, loss: 1.4398928880691528, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 400, loss: 1.4782581329345703, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 450, loss: 1.687351942062378, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 500, loss: 1.9945958852767944, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 550, loss: 1.7718963623046875, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 600, loss: 1.391725778579712, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 650, loss: 1.5576651096343994, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 700, loss: 1.821315050125122, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 750, loss: 1.6016207933425903, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 800, loss: 1.6440969705581665, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 850, loss: 1.5711472034454346, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 900, loss: 1.659810185432434, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 950, loss: 1.761054515838623, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1000, loss: 1.9957976341247559, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1050, loss: 1.4498379230499268, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1100, loss: 1.651798963546753, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1150, loss: 1.7047431468963623, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1200, loss: 1.8150850534439087, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1250, loss: 1.5931687355041504, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1300, loss: 1.296453833580017, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1350, loss: 1.5594321489334106, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1400, loss: 1.574144721031189, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1450, loss: 1.8615689277648926, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1500, loss: 1.9087762832641602, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1550, loss: 1.8485217094421387, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1600, loss: 1.862879753112793, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1650, loss: 2.053683280944824, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1700, loss: 2.127147674560547, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1750, loss: 1.7218413352966309, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1800, loss: 1.686248779296875, rate: 5.4208637986090884e-05\n",
      "[2023-11-13 10:24:43.385226] Epoch: 15 ends. Average loss: 1.68060974757841\n",
      "Epoch: 16 Batch: 0, loss: 1.701135277748108, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 50, loss: 1.63774573802948, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 100, loss: 1.7621549367904663, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 150, loss: 1.6696308851242065, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 200, loss: 1.8201919794082642, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 250, loss: 1.7576991319656372, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 300, loss: 1.1682583093643188, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 350, loss: 1.528743028640747, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 400, loss: 1.5420063734054565, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 450, loss: 1.6917577981948853, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 500, loss: 1.9856548309326172, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 550, loss: 1.8852964639663696, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 600, loss: 1.3592649698257446, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 650, loss: 1.5220625400543213, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 700, loss: 1.7097147703170776, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 750, loss: 1.7271087169647217, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 800, loss: 1.7564969062805176, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 850, loss: 1.6779183149337769, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 900, loss: 1.5872889757156372, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 950, loss: 1.716161847114563, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1000, loss: 1.8433709144592285, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1050, loss: 1.5122119188308716, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1100, loss: 1.844725489616394, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1150, loss: 1.6499245166778564, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1200, loss: 1.670086145401001, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1250, loss: 1.5843689441680908, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1300, loss: 1.3673723936080933, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1350, loss: 1.5728248357772827, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1400, loss: 1.5794858932495117, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1450, loss: 1.8900507688522339, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1500, loss: 1.936131238937378, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1550, loss: 1.8645994663238525, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1600, loss: 1.8654953241348267, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1650, loss: 2.0474181175231934, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1700, loss: 2.183053493499756, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1750, loss: 1.6464625597000122, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1800, loss: 1.6586040258407593, rate: 5.2040292466647244e-05\n",
      "[2023-11-13 10:28:31.248456] Epoch: 16 ends. Average loss: 1.6788370205563072\n",
      "Epoch: 17 Batch: 0, loss: 1.6702133417129517, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 50, loss: 1.5648167133331299, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 100, loss: 1.696413516998291, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 150, loss: 1.647996187210083, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 200, loss: 1.7992119789123535, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 250, loss: 1.634214162826538, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 300, loss: 1.1820056438446045, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 350, loss: 1.5344330072402954, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 400, loss: 1.4379868507385254, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 450, loss: 1.5689117908477783, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 500, loss: 1.9732613563537598, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 550, loss: 1.7933026552200317, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 600, loss: 1.308227777481079, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 650, loss: 1.5869858264923096, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 700, loss: 1.778753399848938, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 750, loss: 1.70066499710083, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 800, loss: 1.7687643766403198, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 850, loss: 1.6232967376708984, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 900, loss: 1.7139792442321777, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 950, loss: 1.7392311096191406, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1000, loss: 1.8101775646209717, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1050, loss: 1.4949241876602173, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1100, loss: 1.8386855125427246, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1150, loss: 1.642975926399231, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1200, loss: 1.686437726020813, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1250, loss: 1.5187104940414429, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1300, loss: 1.3247126340866089, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1350, loss: 1.5574660301208496, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1400, loss: 1.5827512741088867, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1450, loss: 1.87510085105896, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1500, loss: 1.9356236457824707, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1550, loss: 1.8621729612350464, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1600, loss: 1.8750412464141846, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1650, loss: 2.042436122894287, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1700, loss: 2.1569535732269287, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1750, loss: 1.626140832901001, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1800, loss: 1.7311270236968994, rate: 4.995868076798135e-05\n",
      "[2023-11-13 10:32:17.023249] Epoch: 17 ends. Average loss: 1.6748249069538421\n",
      "Epoch: 18 Batch: 0, loss: 1.6942952871322632, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 50, loss: 1.5223054885864258, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 100, loss: 1.7377219200134277, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 150, loss: 1.6561710834503174, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 200, loss: 1.8863219022750854, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 250, loss: 1.6796892881393433, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 300, loss: 1.1406487226486206, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 350, loss: 1.4724878072738647, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 400, loss: 1.4921817779541016, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 450, loss: 1.6519334316253662, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 500, loss: 2.0535318851470947, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 550, loss: 1.7648401260375977, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 600, loss: 1.3758254051208496, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 650, loss: 1.43864905834198, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 700, loss: 1.679054856300354, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 750, loss: 1.567783236503601, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 800, loss: 1.7380731105804443, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 850, loss: 1.4888070821762085, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 900, loss: 1.6906182765960693, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 950, loss: 1.8374557495117188, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1000, loss: 1.818916916847229, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1050, loss: 1.4900517463684082, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1100, loss: 1.7527574300765991, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1150, loss: 1.5688506364822388, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1200, loss: 1.7163926362991333, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1250, loss: 1.4562084674835205, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1300, loss: 1.3885198831558228, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1350, loss: 1.5398341417312622, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1400, loss: 1.5111849308013916, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1450, loss: 1.8640824556350708, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1500, loss: 1.9110262393951416, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1550, loss: 1.8732810020446777, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1600, loss: 1.8084594011306763, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1650, loss: 2.093263626098633, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1700, loss: 2.231255531311035, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1750, loss: 1.68806791305542, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1800, loss: 1.6675137281417847, rate: 4.7960333537262095e-05\n",
      "[2023-11-13 10:36:03.062780] Epoch: 18 ends. Average loss: 1.6640512816036728\n",
      "Epoch: 19 Batch: 0, loss: 1.6802911758422852, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 50, loss: 1.49617338180542, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 100, loss: 1.7517549991607666, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 150, loss: 1.5989606380462646, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 200, loss: 1.8956818580627441, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 250, loss: 1.6888540983200073, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 300, loss: 1.1926121711730957, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 350, loss: 1.491763710975647, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 400, loss: 1.515062689781189, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 450, loss: 1.6886279582977295, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 500, loss: 1.9709824323654175, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 550, loss: 1.7227365970611572, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 600, loss: 1.3708456754684448, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 650, loss: 1.5900884866714478, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 700, loss: 1.6447696685791016, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 750, loss: 1.6858431100845337, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 800, loss: 1.7516465187072754, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 850, loss: 1.572802186012268, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 900, loss: 1.684430480003357, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 950, loss: 1.7154016494750977, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1000, loss: 1.9033350944519043, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1050, loss: 1.490134835243225, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1100, loss: 1.6973596811294556, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1150, loss: 1.7285780906677246, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1200, loss: 1.782759428024292, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1250, loss: 1.4992038011550903, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1300, loss: 1.2512691020965576, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1350, loss: 1.5184111595153809, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1400, loss: 1.536967396736145, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1450, loss: 1.8107421398162842, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1500, loss: 1.902518630027771, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1550, loss: 1.7577277421951294, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1600, loss: 1.8515353202819824, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1650, loss: 1.948613166809082, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1700, loss: 2.010155439376831, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1750, loss: 1.6649454832077026, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1800, loss: 1.6807129383087158, rate: 4.6041920195771606e-05\n",
      "[2023-11-13 10:39:50.401361] Epoch: 19 ends. Average loss: 1.6546460651785908\n",
      "Epoch: 20 Batch: 0, loss: 1.649101972579956, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 50, loss: 1.4815706014633179, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 100, loss: 1.7307357788085938, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 150, loss: 1.6490403413772583, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 200, loss: 1.798997163772583, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 250, loss: 1.5991820096969604, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 300, loss: 1.1981815099716187, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 350, loss: 1.5365585088729858, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 400, loss: 1.5320357084274292, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 450, loss: 1.717793345451355, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 500, loss: 1.8861366510391235, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 550, loss: 1.8085598945617676, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 600, loss: 1.3132401704788208, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 650, loss: 1.5282741785049438, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 700, loss: 1.6941033601760864, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 750, loss: 1.5844144821166992, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 800, loss: 1.6800572872161865, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 850, loss: 1.6307262182235718, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 900, loss: 1.6413813829421997, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 950, loss: 1.6872224807739258, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1000, loss: 1.8521836996078491, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1050, loss: 1.5733438730239868, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1100, loss: 1.7856374979019165, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1150, loss: 1.6533223390579224, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1200, loss: 1.6139116287231445, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1250, loss: 1.4020873308181763, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1300, loss: 1.3754922151565552, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1350, loss: 1.6427667140960693, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1400, loss: 1.5517433881759644, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1450, loss: 1.769553303718567, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1500, loss: 1.8366882801055908, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1550, loss: 1.7893517017364502, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1600, loss: 1.8207635879516602, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1650, loss: 1.992504596710205, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1700, loss: 2.098578453063965, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1750, loss: 1.635249137878418, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1800, loss: 1.6264419555664062, rate: 4.420024338794074e-05\n",
      "[2023-11-13 10:43:41.856856] Epoch: 20 ends. Average loss: 1.6399225618914222\n",
      "Epoch: 21 Batch: 0, loss: 1.6754804849624634, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 50, loss: 1.4748913049697876, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 100, loss: 1.757028579711914, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 150, loss: 1.6568361520767212, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 200, loss: 1.8406440019607544, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 250, loss: 1.59614098072052, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 300, loss: 1.1281652450561523, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 350, loss: 1.4270557165145874, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 400, loss: 1.4112865924835205, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 450, loss: 1.5619016885757446, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 500, loss: 1.9313299655914307, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 550, loss: 1.7478772401809692, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 600, loss: 1.2599945068359375, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 650, loss: 1.452865481376648, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 700, loss: 1.6354461908340454, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 750, loss: 1.5112621784210205, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 800, loss: 1.6333189010620117, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 850, loss: 1.5723559856414795, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 900, loss: 1.635554552078247, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 950, loss: 1.72089421749115, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1000, loss: 1.788681983947754, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1050, loss: 1.4324113130569458, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1100, loss: 1.6909724473953247, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1150, loss: 1.6645206212997437, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1200, loss: 1.7218468189239502, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1250, loss: 1.5598047971725464, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1300, loss: 1.351528286933899, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1350, loss: 1.5662742853164673, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1400, loss: 1.4566045999526978, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1450, loss: 1.7744919061660767, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1500, loss: 1.7438637018203735, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1550, loss: 1.721861481666565, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1600, loss: 1.8132312297821045, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1650, loss: 1.9916421175003052, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1700, loss: 2.182497501373291, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1750, loss: 1.561116099357605, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1800, loss: 1.623308539390564, rate: 4.243223365242311e-05\n",
      "[2023-11-13 10:47:33.655852] Epoch: 21 ends. Average loss: 1.6286139167347995\n",
      "Epoch: 22 Batch: 0, loss: 1.6549322605133057, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 50, loss: 1.4903836250305176, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 100, loss: 1.7614421844482422, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 150, loss: 1.597078561782837, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 200, loss: 1.8004295825958252, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 250, loss: 1.7132511138916016, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 300, loss: 1.1554077863693237, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 350, loss: 1.4018754959106445, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 400, loss: 1.3948673009872437, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 450, loss: 1.5809118747711182, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 500, loss: 1.9112541675567627, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 550, loss: 1.8206723928451538, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 600, loss: 1.3344992399215698, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 650, loss: 1.534079909324646, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 700, loss: 1.6621389389038086, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 750, loss: 1.5776759386062622, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 800, loss: 1.691339135169983, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 850, loss: 1.4899828433990479, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 900, loss: 1.64682137966156, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 950, loss: 1.685528039932251, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1000, loss: 1.828931450843811, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1050, loss: 1.4629565477371216, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1100, loss: 1.6249793767929077, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1150, loss: 1.593466877937317, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1200, loss: 1.659805417060852, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1250, loss: 1.4416712522506714, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1300, loss: 1.3352919816970825, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1350, loss: 1.5223495960235596, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1400, loss: 1.5242561101913452, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1450, loss: 1.857983112335205, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1500, loss: 1.8464622497558594, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1550, loss: 1.7818361520767212, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1600, loss: 1.7898023128509521, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1650, loss: 1.913586139678955, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1700, loss: 2.064497709274292, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1750, loss: 1.6353572607040405, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1800, loss: 1.655914306640625, rate: 4.073494430632618e-05\n",
      "[2023-11-13 10:51:24.429012] Epoch: 22 ends. Average loss: 1.6177670403008164\n",
      "Epoch: 23 Batch: 0, loss: 1.6283934116363525, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 50, loss: 1.4369951486587524, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 100, loss: 1.757054090499878, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 150, loss: 1.5690077543258667, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 200, loss: 1.8543494939804077, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 250, loss: 1.635636568069458, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 300, loss: 1.1229413747787476, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 350, loss: 1.4199424982070923, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 400, loss: 1.4054863452911377, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 450, loss: 1.5615861415863037, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 500, loss: 1.8741048574447632, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 550, loss: 1.8067007064819336, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 600, loss: 1.2181140184402466, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 650, loss: 1.476789116859436, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 700, loss: 1.6213488578796387, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 750, loss: 1.578950047492981, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 800, loss: 1.6838117837905884, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 850, loss: 1.568421483039856, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 900, loss: 1.5997081995010376, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 950, loss: 1.6571028232574463, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1000, loss: 1.7354657649993896, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1050, loss: 1.4031652212142944, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1100, loss: 1.6627792119979858, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1150, loss: 1.7164264917373657, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1200, loss: 1.6311038732528687, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1250, loss: 1.3619091510772705, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1300, loss: 1.3602685928344727, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1350, loss: 1.4664158821105957, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1400, loss: 1.4940804243087769, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1450, loss: 1.758594274520874, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1500, loss: 1.7786040306091309, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1550, loss: 1.7044814825057983, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1600, loss: 1.897591471672058, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1650, loss: 1.9282279014587402, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1700, loss: 2.039016008377075, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1750, loss: 1.574265718460083, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1800, loss: 1.5737979412078857, rate: 3.910554653407313e-05\n",
      "[2023-11-13 10:55:14.906176] Epoch: 23 ends. Average loss: 1.606151521205902\n",
      "Epoch: 24 Batch: 0, loss: 1.6482385396957397, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 50, loss: 1.3872699737548828, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 100, loss: 1.6777585744857788, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 150, loss: 1.5667941570281982, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 200, loss: 1.8416544198989868, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 250, loss: 1.6718555688858032, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 300, loss: 1.15687894821167, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 350, loss: 1.4187991619110107, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 400, loss: 1.369767427444458, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 450, loss: 1.560384750366211, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 500, loss: 1.953034520149231, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 550, loss: 1.7590312957763672, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 600, loss: 1.3695706129074097, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 650, loss: 1.4894108772277832, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 700, loss: 1.6696064472198486, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 750, loss: 1.5562957525253296, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 800, loss: 1.5839922428131104, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 850, loss: 1.5033639669418335, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 900, loss: 1.5786898136138916, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 950, loss: 1.6862175464630127, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1000, loss: 1.729372501373291, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1050, loss: 1.4500133991241455, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1100, loss: 1.727083444595337, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1150, loss: 1.5639771223068237, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1200, loss: 1.6571049690246582, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1250, loss: 1.486480951309204, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1300, loss: 1.2705965042114258, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1350, loss: 1.5182147026062012, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1400, loss: 1.4680747985839844, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1450, loss: 1.71792471408844, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1500, loss: 1.872511386871338, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1550, loss: 1.8177568912506104, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1600, loss: 1.8839133977890015, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1650, loss: 1.960676908493042, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1700, loss: 2.099904775619507, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1750, loss: 1.5794086456298828, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1800, loss: 1.6194475889205933, rate: 3.7541324672710204e-05\n",
      "[2023-11-13 10:59:05.968819] Epoch: 24 ends. Average loss: 1.5993365470835732\n",
      "Epoch: 25 Batch: 0, loss: 1.632980465888977, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 50, loss: 1.4949125051498413, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 100, loss: 1.7687816619873047, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 150, loss: 1.567039132118225, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 200, loss: 1.7633675336837769, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 250, loss: 1.6238223314285278, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 300, loss: 1.025192379951477, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 350, loss: 1.418498158454895, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 400, loss: 1.4392930269241333, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 450, loss: 1.5666910409927368, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 500, loss: 1.8811137676239014, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 550, loss: 1.7643346786499023, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 600, loss: 1.2449625730514526, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 650, loss: 1.5390686988830566, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 700, loss: 1.6160789728164673, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 750, loss: 1.5217907428741455, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 800, loss: 1.641289234161377, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 850, loss: 1.517448902130127, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 900, loss: 1.566128134727478, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 950, loss: 1.7071295976638794, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1000, loss: 1.8025259971618652, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1050, loss: 1.4204392433166504, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1100, loss: 1.6690208911895752, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1150, loss: 1.6550768613815308, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1200, loss: 1.6118502616882324, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1250, loss: 1.4272552728652954, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1300, loss: 1.279983639717102, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1350, loss: 1.5864564180374146, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1400, loss: 1.4933762550354004, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1450, loss: 1.6914775371551514, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1500, loss: 1.7527527809143066, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1550, loss: 1.772421956062317, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1600, loss: 1.8632396459579468, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1650, loss: 1.9396178722381592, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1700, loss: 2.179779291152954, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1750, loss: 1.530552864074707, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1800, loss: 1.5797446966171265, rate: 3.603967168580179e-05\n",
      "[2023-11-13 11:02:58.180199] Epoch: 25 ends. Average loss: 1.5915707944179858\n",
      "Epoch: 26 Batch: 0, loss: 1.5785073041915894, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 50, loss: 1.4626115560531616, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 100, loss: 1.724530577659607, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 150, loss: 1.5412778854370117, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 200, loss: 1.7862086296081543, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 250, loss: 1.5811054706573486, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 300, loss: 1.0573159456253052, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 350, loss: 1.3994805812835693, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 400, loss: 1.4298006296157837, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 450, loss: 1.553018569946289, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 500, loss: 1.8187233209609985, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 550, loss: 1.7038483619689941, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 600, loss: 1.2024731636047363, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 650, loss: 1.5715234279632568, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 700, loss: 1.5682024955749512, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 750, loss: 1.6434779167175293, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 800, loss: 1.449522852897644, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 850, loss: 1.5023446083068848, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 900, loss: 1.5619823932647705, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 950, loss: 1.7729073762893677, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1000, loss: 1.7703276872634888, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1050, loss: 1.3736690282821655, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1100, loss: 1.624422550201416, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1150, loss: 1.6931878328323364, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1200, loss: 1.6344411373138428, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1250, loss: 1.4494304656982422, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1300, loss: 1.274112343788147, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1350, loss: 1.3697510957717896, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1400, loss: 1.5248943567276, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1450, loss: 1.7124007940292358, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1500, loss: 1.7527706623077393, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1550, loss: 1.7718087434768677, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1600, loss: 1.7316814661026, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1650, loss: 1.9078683853149414, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1700, loss: 2.1045687198638916, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1750, loss: 1.5418082475662231, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1800, loss: 1.5742406845092773, rate: 3.459808481836972e-05\n",
      "[2023-11-13 11:06:48.809544] Epoch: 26 ends. Average loss: 1.5856548812398579\n",
      "Epoch: 27 Batch: 0, loss: 1.65642511844635, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 50, loss: 1.3488998413085938, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 100, loss: 1.6799511909484863, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 150, loss: 1.5706889629364014, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 200, loss: 1.8127820491790771, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 250, loss: 1.4917383193969727, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 300, loss: 1.072172999382019, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 350, loss: 1.4710743427276611, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 400, loss: 1.4295679330825806, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 450, loss: 1.5031014680862427, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 500, loss: 1.91206693649292, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 550, loss: 1.68423330783844, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 600, loss: 1.2946035861968994, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 650, loss: 1.5000540018081665, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 700, loss: 1.5878242254257202, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 750, loss: 1.6166082620620728, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 800, loss: 1.6911859512329102, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 850, loss: 1.524619698524475, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 900, loss: 1.6011369228363037, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 950, loss: 1.6685452461242676, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1000, loss: 1.7614550590515137, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1050, loss: 1.4136253595352173, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1100, loss: 1.7961715459823608, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1150, loss: 1.6318379640579224, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1200, loss: 1.6578012704849243, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1250, loss: 1.4089442491531372, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1300, loss: 1.3593318462371826, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1350, loss: 1.3994654417037964, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1400, loss: 1.4423844814300537, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1450, loss: 1.7973500490188599, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1500, loss: 1.8545130491256714, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1550, loss: 1.7054444551467896, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1600, loss: 1.7664941549301147, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1650, loss: 1.9288207292556763, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1700, loss: 1.9918009042739868, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1750, loss: 1.5391203165054321, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1800, loss: 1.5738235712051392, rate: 3.321416142563493e-05\n",
      "[2023-11-13 11:10:39.137080] Epoch: 27 ends. Average loss: 1.580257233045276\n",
      "Epoch: 28 Batch: 0, loss: 1.5867782831192017, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 50, loss: 1.420130729675293, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 100, loss: 1.793373942375183, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 150, loss: 1.649246096611023, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 200, loss: 1.8068403005599976, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 250, loss: 1.6198426485061646, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 300, loss: 1.0446999073028564, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 350, loss: 1.3662270307540894, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 400, loss: 1.427276611328125, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 450, loss: 1.5438148975372314, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 500, loss: 1.8904762268066406, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 550, loss: 1.644955039024353, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 600, loss: 1.267187237739563, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 650, loss: 1.4321386814117432, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 700, loss: 1.6368780136108398, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 750, loss: 1.578468680381775, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 800, loss: 1.6834050416946411, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 850, loss: 1.4898123741149902, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 900, loss: 1.5576317310333252, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 950, loss: 1.6764194965362549, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1000, loss: 1.7655417919158936, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1050, loss: 1.4193716049194336, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1100, loss: 1.5987615585327148, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1150, loss: 1.583403468132019, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1200, loss: 1.5989457368850708, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1250, loss: 1.5531034469604492, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1300, loss: 1.2152070999145508, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1350, loss: 1.5235133171081543, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1400, loss: 1.5399607419967651, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1450, loss: 1.6815437078475952, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1500, loss: 1.7448898553848267, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1550, loss: 1.7050777673721313, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1600, loss: 1.813795804977417, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1650, loss: 2.0141537189483643, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1700, loss: 1.9924120903015137, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1750, loss: 1.5354779958724976, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1800, loss: 1.5366374254226685, rate: 3.188559496860953e-05\n",
      "[2023-11-13 11:14:28.923967] Epoch: 28 ends. Average loss: 1.5752566126059644\n",
      "Epoch: 29 Batch: 0, loss: 1.5457977056503296, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 50, loss: 1.441956877708435, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 100, loss: 1.5898818969726562, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 150, loss: 1.6304980516433716, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 200, loss: 1.7397879362106323, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 250, loss: 1.59649658203125, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 300, loss: 1.001320242881775, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 350, loss: 1.4857358932495117, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 400, loss: 1.3930151462554932, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 450, loss: 1.5583962202072144, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 500, loss: 1.8064050674438477, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 550, loss: 1.69948410987854, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 600, loss: 1.2387114763259888, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 650, loss: 1.4618051052093506, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 700, loss: 1.5251325368881226, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 750, loss: 1.5824650526046753, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 800, loss: 1.6856763362884521, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 850, loss: 1.5320180654525757, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 900, loss: 1.6201651096343994, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 950, loss: 1.7154597043991089, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1000, loss: 1.8119920492172241, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1050, loss: 1.4192442893981934, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1100, loss: 1.566483974456787, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1150, loss: 1.5572783946990967, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1200, loss: 1.6348015069961548, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1250, loss: 1.4058188199996948, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1300, loss: 1.302584171295166, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1350, loss: 1.4927934408187866, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1400, loss: 1.496188998222351, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1450, loss: 1.7776908874511719, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1500, loss: 1.7103979587554932, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1550, loss: 1.68313729763031, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1600, loss: 1.7639744281768799, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1650, loss: 1.8767783641815186, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1700, loss: 2.132284641265869, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1750, loss: 1.5108031034469604, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1800, loss: 1.6072546243667603, rate: 3.0610171169865154e-05\n",
      "[2023-11-13 11:18:18.975598] Epoch: 29 ends. Average loss: 1.5696176429249868\n",
      "Epoch: 30 Batch: 0, loss: 1.515612244606018, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 50, loss: 1.3530889749526978, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 100, loss: 1.6435139179229736, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 150, loss: 1.4635196924209595, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 200, loss: 1.8065601587295532, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 250, loss: 1.5212805271148682, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 300, loss: 1.1010797023773193, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 350, loss: 1.3243753910064697, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 400, loss: 1.4396809339523315, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 450, loss: 1.5739336013793945, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 500, loss: 1.8810770511627197, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 550, loss: 1.5704647302627563, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 600, loss: 1.2003859281539917, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 650, loss: 1.44022536277771, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 700, loss: 1.6196867227554321, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 750, loss: 1.522194504737854, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 800, loss: 1.4969183206558228, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 850, loss: 1.3570743799209595, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 900, loss: 1.5837098360061646, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 950, loss: 1.605611801147461, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1000, loss: 1.6351433992385864, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1050, loss: 1.4663726091384888, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1100, loss: 1.6753820180892944, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1150, loss: 1.6217451095581055, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1200, loss: 1.5735658407211304, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1250, loss: 1.4540762901306152, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1300, loss: 1.3167438507080078, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1350, loss: 1.473496913909912, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1400, loss: 1.404808521270752, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1450, loss: 1.756850242614746, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1500, loss: 1.6872276067733765, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1550, loss: 1.7009341716766357, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1600, loss: 1.713842749595642, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1650, loss: 1.8474647998809814, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1700, loss: 2.105260133743286, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1750, loss: 1.559921145439148, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1800, loss: 1.5744175910949707, rate: 2.9385764323070547e-05\n",
      "[2023-11-13 11:22:10.538324] Epoch: 30 ends. Average loss: 1.5645893441335443\n",
      "Epoch: 31 Batch: 0, loss: 1.6382770538330078, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 50, loss: 1.4650726318359375, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 100, loss: 1.729235291481018, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 150, loss: 1.5307327508926392, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 200, loss: 1.6935900449752808, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 250, loss: 1.5782387256622314, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 300, loss: 1.0514127016067505, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 350, loss: 1.3328380584716797, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 400, loss: 1.3934019804000854, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 450, loss: 1.5824631452560425, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 500, loss: 1.8732188940048218, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 550, loss: 1.6877659559249878, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 600, loss: 1.233199119567871, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 650, loss: 1.438753604888916, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 700, loss: 1.5950061082839966, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 750, loss: 1.4767049551010132, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 800, loss: 1.5760421752929688, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 850, loss: 1.5512791872024536, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 900, loss: 1.5826081037521362, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 950, loss: 1.7468754053115845, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1000, loss: 1.7471250295639038, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1050, loss: 1.3552277088165283, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1100, loss: 1.676987648010254, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1150, loss: 1.6694300174713135, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1200, loss: 1.5989867448806763, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1250, loss: 1.381210446357727, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1300, loss: 1.2258223295211792, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1350, loss: 1.5348665714263916, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1400, loss: 1.3822675943374634, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1450, loss: 1.673774242401123, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1500, loss: 1.7577317953109741, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1550, loss: 1.7332700490951538, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1600, loss: 1.7869367599487305, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1650, loss: 1.8679276704788208, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1700, loss: 2.0622611045837402, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1750, loss: 1.5091594457626343, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1800, loss: 1.5898295640945435, rate: 2.8210333750147723e-05\n",
      "[2023-11-13 11:25:55.806438] Epoch: 31 ends. Average loss: 1.5605867049408695\n",
      "Epoch: 32 Batch: 0, loss: 1.485735535621643, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 50, loss: 1.408675193786621, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 100, loss: 1.641190767288208, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 150, loss: 1.620824933052063, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 200, loss: 1.7659075260162354, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 250, loss: 1.5772422552108765, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 300, loss: 1.1251295804977417, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 350, loss: 1.3954193592071533, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 400, loss: 1.367193579673767, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 450, loss: 1.524747371673584, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 500, loss: 1.9682413339614868, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 550, loss: 1.5907328128814697, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 600, loss: 1.3461703062057495, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 650, loss: 1.4824150800704956, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 700, loss: 1.6283870935440063, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 750, loss: 1.4986824989318848, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 800, loss: 1.411667823791504, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 850, loss: 1.4654567241668701, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 900, loss: 1.5526561737060547, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 950, loss: 1.6040520668029785, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1000, loss: 1.7144775390625, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1050, loss: 1.4567490816116333, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1100, loss: 1.5949419736862183, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1150, loss: 1.5473078489303589, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1200, loss: 1.611838459968567, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1250, loss: 1.467474102973938, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1300, loss: 1.2785382270812988, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1350, loss: 1.328658103942871, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1400, loss: 1.4767587184906006, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1450, loss: 1.7880260944366455, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1500, loss: 1.7453382015228271, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1550, loss: 1.6400765180587769, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1600, loss: 1.7210479974746704, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1650, loss: 1.9395664930343628, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1700, loss: 2.022118330001831, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1750, loss: 1.5397114753723145, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1800, loss: 1.6158503293991089, rate: 2.7081920400141814e-05\n",
      "[2023-11-13 11:29:42.164550] Epoch: 32 ends. Average loss: 1.5582238066216167\n",
      "Epoch: 33 Batch: 0, loss: 1.5536994934082031, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 50, loss: 1.3763004541397095, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 100, loss: 1.6043832302093506, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 150, loss: 1.5865641832351685, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 200, loss: 1.706235408782959, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 250, loss: 1.5847563743591309, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 300, loss: 1.1187639236450195, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 350, loss: 1.3274281024932861, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 400, loss: 1.3635660409927368, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 450, loss: 1.5890419483184814, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 500, loss: 1.8352409601211548, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 550, loss: 1.6617217063903809, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 600, loss: 1.2365747690200806, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 650, loss: 1.4589426517486572, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 700, loss: 1.5231229066848755, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 750, loss: 1.5405192375183105, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 800, loss: 1.6217656135559082, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 850, loss: 1.4621326923370361, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 900, loss: 1.5143641233444214, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 950, loss: 1.6051585674285889, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1000, loss: 1.775040864944458, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1050, loss: 1.371325135231018, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1100, loss: 1.6520326137542725, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1150, loss: 1.6766304969787598, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1200, loss: 1.6260592937469482, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1250, loss: 1.4739079475402832, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1300, loss: 1.250344157218933, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1350, loss: 1.5112130641937256, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1400, loss: 1.4341131448745728, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1450, loss: 1.6645479202270508, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1500, loss: 1.697367787361145, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1550, loss: 1.69451105594635, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1600, loss: 1.7246531248092651, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1650, loss: 1.870948314666748, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1700, loss: 2.040548324584961, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1750, loss: 1.5003271102905273, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1800, loss: 1.53151273727417, rate: 2.599864358413614e-05\n",
      "[2023-11-13 11:33:30.496594] Epoch: 33 ends. Average loss: 1.5550705119515411\n",
      "Epoch: 34 Batch: 0, loss: 1.466576099395752, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 50, loss: 1.4635859727859497, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 100, loss: 1.5850670337677002, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 150, loss: 1.60090172290802, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 200, loss: 1.7382495403289795, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 250, loss: 1.5847032070159912, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 300, loss: 1.0234633684158325, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 350, loss: 1.3502607345581055, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 400, loss: 1.3972336053848267, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 450, loss: 1.5018759965896606, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 500, loss: 1.8626575469970703, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 550, loss: 1.5633816719055176, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 600, loss: 1.2528036832809448, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 650, loss: 1.4751251935958862, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 700, loss: 1.573464035987854, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 750, loss: 1.5632741451263428, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 800, loss: 1.6138719320297241, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 850, loss: 1.5270963907241821, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 900, loss: 1.4887540340423584, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 950, loss: 1.6836931705474854, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1000, loss: 1.6751426458358765, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1050, loss: 1.3744568824768066, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1100, loss: 1.6763105392456055, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1150, loss: 1.5578677654266357, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1200, loss: 1.4448862075805664, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1250, loss: 1.5046241283416748, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1300, loss: 1.2621369361877441, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1350, loss: 1.5891683101654053, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1400, loss: 1.513447880744934, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1450, loss: 1.6622445583343506, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1500, loss: 1.778212070465088, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1550, loss: 1.6871205568313599, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1600, loss: 1.623638391494751, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1650, loss: 1.890459418296814, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1700, loss: 1.9862658977508545, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1750, loss: 1.4806511402130127, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1800, loss: 1.5805070400238037, rate: 2.4958697840770694e-05\n",
      "[2023-11-13 11:37:19.905473] Epoch: 34 ends. Average loss: 1.5496617973475448\n",
      "Epoch: 35 Batch: 0, loss: 1.6028445959091187, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 50, loss: 1.4755133390426636, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 100, loss: 1.6654024124145508, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 150, loss: 1.5977336168289185, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 200, loss: 1.8152797222137451, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 250, loss: 1.5299755334854126, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 300, loss: 1.0747737884521484, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 350, loss: 1.3359622955322266, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 400, loss: 1.2172555923461914, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 450, loss: 1.6208380460739136, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 500, loss: 1.8583848476409912, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 550, loss: 1.6011112928390503, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 600, loss: 1.3202719688415527, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 650, loss: 1.5040768384933472, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 700, loss: 1.6317431926727295, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 750, loss: 1.525590419769287, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 800, loss: 1.6308856010437012, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 850, loss: 1.4039303064346313, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 900, loss: 1.5353553295135498, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 950, loss: 1.636214017868042, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1000, loss: 1.7496095895767212, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1050, loss: 1.3446327447891235, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1100, loss: 1.7202098369598389, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1150, loss: 1.5769129991531372, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1200, loss: 1.6789696216583252, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1250, loss: 1.4390571117401123, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1300, loss: 1.28211510181427, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1350, loss: 1.454121470451355, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1400, loss: 1.4635472297668457, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1450, loss: 1.7717844247817993, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1500, loss: 1.7965443134307861, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1550, loss: 1.6410572528839111, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1600, loss: 1.7580209970474243, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1650, loss: 1.9053406715393066, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1700, loss: 2.052347421646118, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1750, loss: 1.4706156253814697, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1800, loss: 1.5671610832214355, rate: 2.3960349927139864e-05\n",
      "[2023-11-13 11:41:09.064299] Epoch: 35 ends. Average loss: 1.5482501093682437\n",
      "Epoch: 36 Batch: 0, loss: 1.5780785083770752, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 50, loss: 1.372848629951477, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 100, loss: 1.7517430782318115, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 150, loss: 1.5095208883285522, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 200, loss: 1.7835267782211304, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 250, loss: 1.481839895248413, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 300, loss: 1.089820384979248, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 350, loss: 1.4034754037857056, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 400, loss: 1.3591976165771484, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 450, loss: 1.6209917068481445, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 500, loss: 1.9040727615356445, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 550, loss: 1.6846133470535278, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 600, loss: 1.2391290664672852, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 650, loss: 1.4538933038711548, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 700, loss: 1.5366791486740112, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 750, loss: 1.5429952144622803, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 800, loss: 1.6388102769851685, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 850, loss: 1.49239182472229, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 900, loss: 1.5781054496765137, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 950, loss: 1.6579225063323975, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1000, loss: 1.605372428894043, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1050, loss: 1.2826542854309082, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1100, loss: 1.5688157081604004, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1150, loss: 1.6097067594528198, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1200, loss: 1.6181339025497437, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1250, loss: 1.4313328266143799, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1300, loss: 1.197186827659607, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1350, loss: 1.5138291120529175, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1400, loss: 1.4557639360427856, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1450, loss: 1.6881376504898071, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1500, loss: 1.6925300359725952, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1550, loss: 1.6696611642837524, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1600, loss: 1.7447212934494019, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1650, loss: 1.8332277536392212, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1700, loss: 2.0028128623962402, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1750, loss: 1.5371359586715698, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1800, loss: 1.5215378999710083, rate: 2.3001935930054268e-05\n",
      "[2023-11-13 11:44:57.617136] Epoch: 36 ends. Average loss: 1.5447429454070194\n",
      "Epoch: 37 Batch: 0, loss: 1.5330380201339722, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 50, loss: 1.4226531982421875, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 100, loss: 1.6579340696334839, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 150, loss: 1.460443139076233, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 200, loss: 1.7099792957305908, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 250, loss: 1.5255025625228882, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 300, loss: 1.0829733610153198, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 350, loss: 1.4058154821395874, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 400, loss: 1.3920586109161377, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 450, loss: 1.5384124517440796, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 500, loss: 1.929223895072937, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 550, loss: 1.5194934606552124, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 600, loss: 1.2568535804748535, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 650, loss: 1.4124407768249512, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 700, loss: 1.6676442623138428, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 750, loss: 1.5051859617233276, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 800, loss: 1.592010259628296, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 850, loss: 1.5442018508911133, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 900, loss: 1.539594292640686, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 950, loss: 1.6752212047576904, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1000, loss: 1.6807862520217896, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1050, loss: 1.4218252897262573, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1100, loss: 1.5991449356079102, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1150, loss: 1.5041528940200806, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1200, loss: 1.6354795694351196, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1250, loss: 1.318122148513794, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1300, loss: 1.371562123298645, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1350, loss: 1.4133155345916748, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1400, loss: 1.5303716659545898, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1450, loss: 1.5867129564285278, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1500, loss: 1.8286694288253784, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1550, loss: 1.7461782693862915, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1600, loss: 1.8351339101791382, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1650, loss: 1.8195310831069946, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1700, loss: 2.0600554943084717, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1750, loss: 1.4821759462356567, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1800, loss: 1.5745192766189575, rate: 2.2081858492852098e-05\n",
      "[2023-11-13 11:48:45.059523] Epoch: 37 ends. Average loss: 1.5427466214393557\n",
      "Epoch: 38 Batch: 0, loss: 1.6010003089904785, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 50, loss: 1.3262178897857666, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 100, loss: 1.659900188446045, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 150, loss: 1.5640971660614014, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 200, loss: 1.734850525856018, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 250, loss: 1.6082097291946411, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 300, loss: 1.13323974609375, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 350, loss: 1.2891924381256104, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 400, loss: 1.4276063442230225, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 450, loss: 1.5633491277694702, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 500, loss: 1.8268572092056274, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 550, loss: 1.669931411743164, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 600, loss: 1.3080899715423584, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 650, loss: 1.5026792287826538, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 700, loss: 1.53013014793396, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 750, loss: 1.4822176694869995, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 800, loss: 1.5239050388336182, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 850, loss: 1.5235158205032349, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 900, loss: 1.5398916006088257, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 950, loss: 1.7294681072235107, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1000, loss: 1.6709905862808228, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1050, loss: 1.3861063718795776, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1100, loss: 1.6374719142913818, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1150, loss: 1.551783561706543, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1200, loss: 1.6458826065063477, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1250, loss: 1.4848809242248535, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1300, loss: 1.1998798847198486, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1350, loss: 1.3898688554763794, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1400, loss: 1.4324146509170532, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1450, loss: 1.7275513410568237, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1500, loss: 1.8443593978881836, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1550, loss: 1.6450315713882446, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1600, loss: 1.733094334602356, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1650, loss: 1.8554807901382446, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1700, loss: 2.0524284839630127, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1750, loss: 1.561403751373291, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1800, loss: 1.6022549867630005, rate: 2.1198584153138014e-05\n",
      "[2023-11-13 11:52:32.509807] Epoch: 38 ends. Average loss: 1.5376053812157957\n",
      "Epoch: 39 Batch: 0, loss: 1.583341360092163, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 50, loss: 1.3467159271240234, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 100, loss: 1.7667410373687744, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 150, loss: 1.5122545957565308, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 200, loss: 1.6007803678512573, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 250, loss: 1.545267105102539, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 300, loss: 1.0353902578353882, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 350, loss: 1.1865049600601196, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 400, loss: 1.4492604732513428, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 450, loss: 1.4937963485717773, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 500, loss: 1.759842872619629, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 550, loss: 1.676865577697754, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 600, loss: 1.2539194822311401, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 650, loss: 1.3759827613830566, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 700, loss: 1.4642014503479004, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 750, loss: 1.4334735870361328, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 800, loss: 1.540189266204834, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 850, loss: 1.424776315689087, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 900, loss: 1.5453523397445679, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 950, loss: 1.669090747833252, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1000, loss: 1.6042060852050781, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1050, loss: 1.3907769918441772, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1100, loss: 1.6117804050445557, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1150, loss: 1.588881492614746, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1200, loss: 1.5150747299194336, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1250, loss: 1.4554871320724487, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1300, loss: 1.2963414192199707, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1350, loss: 1.4265135526657104, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1400, loss: 1.5096256732940674, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1450, loss: 1.7242680788040161, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1500, loss: 1.6740211248397827, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1550, loss: 1.6641086339950562, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1600, loss: 1.6375163793563843, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1650, loss: 1.8219414949417114, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1700, loss: 2.0790836811065674, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1750, loss: 1.4238636493682861, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1800, loss: 1.4693421125411987, rate: 2.035064078701249e-05\n",
      "[2023-11-13 11:56:19.310072] Epoch: 39 ends. Average loss: 1.533886128213612\n",
      "Epoch: 40 Batch: 0, loss: 1.5870802402496338, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 50, loss: 1.3291009664535522, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 100, loss: 1.6427003145217896, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 150, loss: 1.583997130393982, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 200, loss: 1.734025001525879, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 250, loss: 1.502057671546936, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 300, loss: 1.1189993619918823, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 350, loss: 1.3111238479614258, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 400, loss: 1.376871109008789, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 450, loss: 1.5054353475570679, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 500, loss: 1.9370585680007935, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 550, loss: 1.5543075799942017, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 600, loss: 1.1894093751907349, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 650, loss: 1.4883532524108887, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 700, loss: 1.5994093418121338, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 750, loss: 1.4266799688339233, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 800, loss: 1.455897331237793, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 850, loss: 1.4254906177520752, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 900, loss: 1.514396071434021, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 950, loss: 1.7092392444610596, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1000, loss: 1.758129596710205, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1050, loss: 1.3097302913665771, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1100, loss: 1.593132734298706, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1150, loss: 1.522865891456604, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1200, loss: 1.5935323238372803, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1250, loss: 1.4771978855133057, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1300, loss: 1.3192585706710815, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1350, loss: 1.4037644863128662, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1400, loss: 1.3918614387512207, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1450, loss: 1.6360464096069336, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1500, loss: 1.7789463996887207, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1550, loss: 1.6191105842590332, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1600, loss: 1.686547040939331, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1650, loss: 1.8489470481872559, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1700, loss: 2.0841760635375977, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1750, loss: 1.5142078399658203, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1800, loss: 1.6032443046569824, rate: 1.953661515553199e-05\n",
      "[2023-11-13 12:00:06.039287] Epoch: 40 ends. Average loss: 1.5336294774514696\n",
      "Epoch: 41 Batch: 0, loss: 1.574464201927185, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 50, loss: 1.372469425201416, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 100, loss: 1.6897410154342651, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 150, loss: 1.5330182313919067, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 200, loss: 1.7501261234283447, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 250, loss: 1.6502916812896729, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 300, loss: 1.0597742795944214, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 350, loss: 1.3381236791610718, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 400, loss: 1.4706120491027832, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 450, loss: 1.514399528503418, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 500, loss: 1.869524359703064, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 550, loss: 1.591881513595581, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 600, loss: 1.2563674449920654, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 650, loss: 1.3738186359405518, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 700, loss: 1.577255129814148, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 750, loss: 1.4161940813064575, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 800, loss: 1.659443974494934, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 850, loss: 1.40554678440094, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 900, loss: 1.4270471334457397, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 950, loss: 1.5976542234420776, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1000, loss: 1.6249415874481201, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1050, loss: 1.3601667881011963, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1100, loss: 1.6098741292953491, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1150, loss: 1.5824432373046875, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1200, loss: 1.5610579252243042, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1250, loss: 1.4103494882583618, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1300, loss: 1.2251017093658447, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1350, loss: 1.3434358835220337, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1400, loss: 1.4343690872192383, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1450, loss: 1.6778260469436646, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1500, loss: 1.717513918876648, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1550, loss: 1.743764877319336, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1600, loss: 1.7240005731582642, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1650, loss: 1.9400087594985962, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1700, loss: 2.1098549365997314, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1750, loss: 1.524132490158081, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1800, loss: 1.6311248540878296, rate: 1.8755150549310708e-05\n",
      "[2023-11-13 12:03:53.059646] Epoch: 41 ends. Average loss: 1.5303056950866354\n",
      "Epoch: 42 Batch: 0, loss: 1.5569764375686646, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 50, loss: 1.36273193359375, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 100, loss: 1.6725900173187256, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 150, loss: 1.5259735584259033, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 200, loss: 1.7204676866531372, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 250, loss: 1.5518184900283813, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 300, loss: 1.0055886507034302, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 350, loss: 1.268646001815796, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 400, loss: 1.394504427909851, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 450, loss: 1.5608526468276978, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 500, loss: 1.8364232778549194, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 550, loss: 1.670925498008728, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 600, loss: 1.2705328464508057, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 650, loss: 1.4362053871154785, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 700, loss: 1.6312843561172485, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 750, loss: 1.5351735353469849, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 800, loss: 1.580033540725708, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 850, loss: 1.4457626342773438, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 900, loss: 1.482505440711975, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 950, loss: 1.6330173015594482, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1000, loss: 1.6050686836242676, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1050, loss: 1.2813769578933716, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1100, loss: 1.5392725467681885, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1150, loss: 1.5229151248931885, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1200, loss: 1.6247894763946533, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1250, loss: 1.4614402055740356, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1300, loss: 1.2700068950653076, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1350, loss: 1.428002953529358, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1400, loss: 1.4764920473098755, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1450, loss: 1.7253400087356567, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1500, loss: 1.7006235122680664, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1550, loss: 1.6369918584823608, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1600, loss: 1.7724130153656006, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1650, loss: 1.8772177696228027, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1700, loss: 1.994850754737854, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1750, loss: 1.4589122533798218, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1800, loss: 1.5391449928283691, rate: 1.800494452733828e-05\n",
      "[2023-11-13 12:07:41.079679] Epoch: 42 ends. Average loss: 1.5291226312920854\n",
      "Epoch: 43 Batch: 0, loss: 1.5881973505020142, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 50, loss: 1.437423825263977, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 100, loss: 1.6102147102355957, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 150, loss: 1.5559502840042114, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 200, loss: 1.6895346641540527, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 250, loss: 1.5666654109954834, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 300, loss: 1.0636494159698486, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 350, loss: 1.3437193632125854, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 400, loss: 1.3696309328079224, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 450, loss: 1.489275574684143, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 500, loss: 1.8154033422470093, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 550, loss: 1.6745139360427856, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 600, loss: 1.2249547243118286, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 650, loss: 1.4680328369140625, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 700, loss: 1.5271791219711304, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 750, loss: 1.5815000534057617, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 800, loss: 1.4574495553970337, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 850, loss: 1.4668183326721191, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 900, loss: 1.5262564420700073, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 950, loss: 1.5841326713562012, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1000, loss: 1.7413551807403564, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1050, loss: 1.401607871055603, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1100, loss: 1.6385704278945923, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1150, loss: 1.5520401000976562, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1200, loss: 1.5864983797073364, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1250, loss: 1.428729772567749, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1300, loss: 1.2110759019851685, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1350, loss: 1.41058349609375, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1400, loss: 1.5060038566589355, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1450, loss: 1.659427285194397, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1500, loss: 1.7890182733535767, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1550, loss: 1.6720530986785889, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1600, loss: 1.7208850383758545, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1650, loss: 1.846220850944519, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1700, loss: 2.0974409580230713, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1750, loss: 1.5159900188446045, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1800, loss: 1.625977635383606, rate: 1.7284746746244747e-05\n",
      "[2023-11-13 12:11:31.862347] Epoch: 43 ends. Average loss: 1.5261583705995205\n",
      "Epoch: 44 Batch: 0, loss: 1.5684477090835571, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 50, loss: 1.4043936729431152, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 100, loss: 1.6381564140319824, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 150, loss: 1.566320776939392, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 200, loss: 1.7312122583389282, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 250, loss: 1.5450193881988525, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 300, loss: 1.1047801971435547, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 350, loss: 1.4114959239959717, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 400, loss: 1.2709919214248657, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 450, loss: 1.535093903541565, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 500, loss: 1.8781954050064087, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 550, loss: 1.5931684970855713, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 600, loss: 1.3023759126663208, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 650, loss: 1.461323857307434, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 700, loss: 1.549277424812317, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 750, loss: 1.484682559967041, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 800, loss: 1.6346588134765625, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 850, loss: 1.4016891717910767, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 900, loss: 1.4697911739349365, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 950, loss: 1.6658068895339966, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1000, loss: 1.6048314571380615, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1050, loss: 1.345835566520691, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1100, loss: 1.5668765306472778, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1150, loss: 1.5047130584716797, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1200, loss: 1.5525974035263062, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1250, loss: 1.3535246849060059, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1300, loss: 1.2301523685455322, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1350, loss: 1.4190006256103516, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1400, loss: 1.386959195137024, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1450, loss: 1.6978260278701782, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1500, loss: 1.8504079580307007, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1550, loss: 1.693343997001648, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1600, loss: 1.603238821029663, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1650, loss: 1.8753727674484253, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1700, loss: 2.0121893882751465, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1750, loss: 1.5709505081176758, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1800, loss: 1.509421467781067, rate: 1.6593356876394957e-05\n",
      "[2023-11-13 12:15:24.518262] Epoch: 44 ends. Average loss: 1.5266244900995898\n",
      "Epoch: 45 Batch: 0, loss: 1.5084037780761719, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 50, loss: 1.3725218772888184, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 100, loss: 1.658281683921814, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 150, loss: 1.5369887351989746, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 200, loss: 1.7020800113677979, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 250, loss: 1.5370653867721558, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 300, loss: 1.0458418130874634, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 350, loss: 1.32279634475708, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 400, loss: 1.4222958087921143, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 450, loss: 1.5437638759613037, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 500, loss: 1.8069950342178345, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 550, loss: 1.6460585594177246, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 600, loss: 1.1768430471420288, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 650, loss: 1.3010380268096924, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 700, loss: 1.4732054471969604, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 750, loss: 1.4964678287506104, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 800, loss: 1.6238205432891846, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 850, loss: 1.3831462860107422, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 900, loss: 1.5493141412734985, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 950, loss: 1.7040871381759644, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1000, loss: 1.7027417421340942, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1050, loss: 1.4126018285751343, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1100, loss: 1.6318517923355103, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1150, loss: 1.5117679834365845, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1200, loss: 1.63343346118927, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1250, loss: 1.34675931930542, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1300, loss: 1.2484843730926514, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1350, loss: 1.3511029481887817, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1400, loss: 1.4438296556472778, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1450, loss: 1.6888635158538818, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1500, loss: 1.7315369844436646, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1550, loss: 1.639298677444458, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1600, loss: 1.730492115020752, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1650, loss: 1.8132014274597168, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1700, loss: 2.0054430961608887, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1750, loss: 1.532015323638916, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1800, loss: 1.5010930299758911, rate: 1.592962260133916e-05\n",
      "[2023-11-13 12:19:14.706384] Epoch: 45 ends. Average loss: 1.5260553766664589\n",
      "Epoch: 46 Batch: 0, loss: 1.4820095300674438, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 50, loss: 1.3082116842269897, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 100, loss: 1.636682152748108, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 150, loss: 1.4208978414535522, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 200, loss: 1.6178914308547974, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 250, loss: 1.5033631324768066, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 300, loss: 1.0916428565979004, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 350, loss: 1.3233392238616943, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 400, loss: 1.3717116117477417, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 450, loss: 1.4576886892318726, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 500, loss: 1.8956549167633057, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 550, loss: 1.6082626581192017, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 600, loss: 1.230183482170105, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 650, loss: 1.414018988609314, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 700, loss: 1.5075733661651611, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 750, loss: 1.4690965414047241, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 800, loss: 1.5549745559692383, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 850, loss: 1.4137154817581177, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 900, loss: 1.5225389003753662, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 950, loss: 1.6398370265960693, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1000, loss: 1.7224823236465454, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1050, loss: 1.397912859916687, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1100, loss: 1.6186859607696533, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1150, loss: 1.5100986957550049, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1200, loss: 1.5204803943634033, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1250, loss: 1.4364289045333862, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1300, loss: 1.2188019752502441, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1350, loss: 1.4076412916183472, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1400, loss: 1.4405245780944824, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1450, loss: 1.7762134075164795, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1500, loss: 1.6990541219711304, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1550, loss: 1.7027629613876343, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1600, loss: 1.6462262868881226, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1650, loss: 1.8569774627685547, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1700, loss: 2.0046534538269043, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1750, loss: 1.4501760005950928, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1800, loss: 1.5268365144729614, rate: 1.5292437697285593e-05\n",
      "[2023-11-13 12:23:07.397956] Epoch: 46 ends. Average loss: 1.5226733997521713\n",
      "Epoch: 47 Batch: 0, loss: 1.4050172567367554, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 50, loss: 1.4771368503570557, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 100, loss: 1.5413552522659302, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 150, loss: 1.550596833229065, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 200, loss: 1.767606258392334, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 250, loss: 1.5061970949172974, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 300, loss: 1.0705910921096802, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 350, loss: 1.3552697896957397, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 400, loss: 1.3083726167678833, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 450, loss: 1.4684703350067139, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 500, loss: 1.8078211545944214, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 550, loss: 1.608330249786377, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 600, loss: 1.2754658460617065, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 650, loss: 1.3759320974349976, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 700, loss: 1.646437644958496, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 750, loss: 1.471681833267212, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 800, loss: 1.5428569316864014, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 850, loss: 1.4021697044372559, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 900, loss: 1.4938411712646484, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 950, loss: 1.5763782262802124, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1000, loss: 1.5714390277862549, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1050, loss: 1.3101005554199219, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1100, loss: 1.572188138961792, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1150, loss: 1.64415442943573, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1200, loss: 1.632135033607483, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1250, loss: 1.3959949016571045, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1300, loss: 1.2772830724716187, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1350, loss: 1.2747195959091187, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1400, loss: 1.416202187538147, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1450, loss: 1.7160158157348633, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1500, loss: 1.7725276947021484, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1550, loss: 1.6411267518997192, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1600, loss: 1.676558494567871, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1650, loss: 1.8114991188049316, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1700, loss: 1.9208109378814697, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1750, loss: 1.5187196731567383, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1800, loss: 1.3999006748199463, rate: 1.468074018939417e-05\n",
      "[2023-11-13 12:26:59.743727] Epoch: 47 ends. Average loss: 1.5220564661338982\n",
      "Epoch: 48 Batch: 0, loss: 1.5273610353469849, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 50, loss: 1.4338597059249878, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 100, loss: 1.707757830619812, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 150, loss: 1.5230827331542969, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 200, loss: 1.7048718929290771, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 250, loss: 1.666843056678772, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 300, loss: 1.0460755825042725, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 350, loss: 1.2781553268432617, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 400, loss: 1.3385255336761475, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 450, loss: 1.478458285331726, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 500, loss: 1.7760716676712036, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 550, loss: 1.5578125715255737, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 600, loss: 1.2608286142349243, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 650, loss: 1.3314872980117798, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 700, loss: 1.612800121307373, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 750, loss: 1.5750466585159302, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 800, loss: 1.5963720083236694, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 850, loss: 1.409080147743225, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 900, loss: 1.578037977218628, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 950, loss: 1.5862926244735718, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1000, loss: 1.741990089416504, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1050, loss: 1.306660771369934, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1100, loss: 1.630220890045166, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1150, loss: 1.5367733240127563, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1200, loss: 1.5216838121414185, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1250, loss: 1.3844802379608154, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1300, loss: 1.186509609222412, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1350, loss: 1.4596048593521118, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1400, loss: 1.382973313331604, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1450, loss: 1.7115453481674194, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1500, loss: 1.681752324104309, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1550, loss: 1.7408831119537354, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1600, loss: 1.5766929388046265, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1650, loss: 1.8336632251739502, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1700, loss: 2.0606322288513184, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1750, loss: 1.450903296470642, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1800, loss: 1.6041288375854492, rate: 1.4093510581818402e-05\n",
      "[2023-11-13 12:30:50.618788] Epoch: 48 ends. Average loss: 1.520102919890482\n",
      "Epoch: 49 Batch: 0, loss: 1.5126934051513672, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 50, loss: 1.3718935251235962, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 100, loss: 1.6293082237243652, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 150, loss: 1.486903429031372, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 200, loss: 1.7100640535354614, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 250, loss: 1.521338939666748, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 300, loss: 1.1188932657241821, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 350, loss: 1.331968903541565, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 400, loss: 1.3618087768554688, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 450, loss: 1.476189374923706, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 500, loss: 1.7369056940078735, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 550, loss: 1.5910298824310303, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 600, loss: 1.2617652416229248, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 650, loss: 1.4283417463302612, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 700, loss: 1.600252628326416, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 750, loss: 1.475522756576538, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 800, loss: 1.5413627624511719, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 850, loss: 1.4460195302963257, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 900, loss: 1.490227460861206, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 950, loss: 1.754872441291809, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1000, loss: 1.614352822303772, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1050, loss: 1.3686602115631104, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1100, loss: 1.6548839807510376, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1150, loss: 1.5653692483901978, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1200, loss: 1.6137638092041016, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1250, loss: 1.3837283849716187, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1300, loss: 1.1823384761810303, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1350, loss: 1.519591212272644, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1400, loss: 1.4743705987930298, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1450, loss: 1.5880206823349, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1500, loss: 1.7433815002441406, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1550, loss: 1.7328094244003296, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1600, loss: 1.6771036386489868, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1650, loss: 1.8417898416519165, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1700, loss: 2.023715019226074, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1750, loss: 1.56208074092865, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1800, loss: 1.5000230073928833, rate: 1.3529770158545665e-05\n",
      "[2023-11-13 12:34:37.107760] Epoch: 49 ends. Average loss: 1.5186167953754748\n",
      "Epoch: 50 Batch: 0, loss: 1.5071319341659546, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 50, loss: 1.3321863412857056, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 100, loss: 1.5554194450378418, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 150, loss: 1.4920635223388672, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 200, loss: 1.7151918411254883, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 250, loss: 1.515867829322815, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 300, loss: 1.0785961151123047, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 350, loss: 1.2923580408096313, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 400, loss: 1.392065167427063, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 450, loss: 1.5110167264938354, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 500, loss: 1.8910486698150635, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 550, loss: 1.5434473752975464, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 600, loss: 1.2161858081817627, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 650, loss: 1.355398416519165, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 700, loss: 1.6217405796051025, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 750, loss: 1.495452642440796, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 800, loss: 1.6269268989562988, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 850, loss: 1.3888156414031982, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 900, loss: 1.630092978477478, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 950, loss: 1.6833007335662842, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1000, loss: 1.717461109161377, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1050, loss: 1.3166884183883667, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1100, loss: 1.625349760055542, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1150, loss: 1.552424669265747, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1200, loss: 1.6042499542236328, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1250, loss: 1.3033461570739746, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1300, loss: 1.3009388446807861, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1350, loss: 1.438866138458252, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1400, loss: 1.4221179485321045, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1450, loss: 1.710638165473938, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1500, loss: 1.7333183288574219, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1550, loss: 1.6677265167236328, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1600, loss: 1.7280532121658325, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1650, loss: 1.901466727256775, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1700, loss: 1.970291256904602, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1750, loss: 1.4922659397125244, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1800, loss: 1.4869464635849, rate: 1.2988579352203839e-05\n",
      "[2023-11-13 12:38:24.122783] Epoch: 50 ends. Average loss: 1.5174458902709338\n",
      "Epoch: 51 Batch: 0, loss: 1.535728931427002, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 50, loss: 1.3766977787017822, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 100, loss: 1.715111494064331, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 150, loss: 1.5483609437942505, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 200, loss: 1.6782422065734863, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 250, loss: 1.559828519821167, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 300, loss: 1.0317981243133545, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 350, loss: 1.2574574947357178, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 400, loss: 1.2945754528045654, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 450, loss: 1.5288277864456177, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 500, loss: 1.8856147527694702, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 550, loss: 1.6037558317184448, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 600, loss: 1.193224549293518, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 650, loss: 1.3651317358016968, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 700, loss: 1.5253803730010986, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 750, loss: 1.4586657285690308, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 800, loss: 1.5786455869674683, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 850, loss: 1.4544535875320435, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 900, loss: 1.5196024179458618, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 950, loss: 1.5933109521865845, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1000, loss: 1.687673568725586, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1050, loss: 1.336342453956604, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1100, loss: 1.5434727668762207, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1150, loss: 1.5533676147460938, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1200, loss: 1.520943522453308, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1250, loss: 1.4513810873031616, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1300, loss: 1.3201297521591187, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1350, loss: 1.396599531173706, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1400, loss: 1.3545273542404175, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1450, loss: 1.7990226745605469, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1500, loss: 1.8313077688217163, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1550, loss: 1.694750428199768, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1600, loss: 1.6339994668960571, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1650, loss: 1.8022828102111816, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1700, loss: 1.9448308944702148, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1750, loss: 1.4305344820022583, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1800, loss: 1.5866754055023193, rate: 1.2469036178115684e-05\n",
      "[2023-11-13 12:42:11.848836] Epoch: 51 ends. Average loss: 1.51468700722838\n",
      "Epoch: 52 Batch: 0, loss: 1.497239351272583, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 50, loss: 1.4345009326934814, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 100, loss: 1.5697638988494873, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 150, loss: 1.614084243774414, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 200, loss: 1.6544649600982666, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 250, loss: 1.498741626739502, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 300, loss: 1.0394704341888428, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 350, loss: 1.4360414743423462, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 400, loss: 1.3111567497253418, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 450, loss: 1.5482150316238403, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 500, loss: 1.8126978874206543, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 550, loss: 1.6707971096038818, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 600, loss: 1.3330838680267334, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 650, loss: 1.423277735710144, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 700, loss: 1.5085711479187012, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 750, loss: 1.4293291568756104, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 800, loss: 1.585132360458374, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 850, loss: 1.4302701950073242, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 900, loss: 1.5411854982376099, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 950, loss: 1.5627070665359497, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1000, loss: 1.6941261291503906, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1050, loss: 1.4023081064224243, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1100, loss: 1.5268486738204956, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1150, loss: 1.4926042556762695, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1200, loss: 1.5717281103134155, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1250, loss: 1.3984943628311157, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1300, loss: 1.2007859945297241, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1350, loss: 1.428956389427185, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1400, loss: 1.4028040170669556, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1450, loss: 1.712917447090149, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1500, loss: 1.7136094570159912, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1550, loss: 1.585286021232605, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1600, loss: 1.6186128854751587, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1650, loss: 1.74735426902771, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1700, loss: 1.9307842254638672, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1750, loss: 1.4692593812942505, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1800, loss: 1.462314248085022, rate: 1.1970274730991057e-05\n",
      "[2023-11-13 12:45:59.722143] Epoch: 52 ends. Average loss: 1.515149548641569\n",
      "Epoch: 53 Batch: 0, loss: 1.5305328369140625, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 50, loss: 1.2802859544754028, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 100, loss: 1.6386009454727173, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 150, loss: 1.6286907196044922, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 200, loss: 1.6709232330322266, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 250, loss: 1.543318748474121, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 300, loss: 1.0082658529281616, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 350, loss: 1.2935899496078491, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 400, loss: 1.293560266494751, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 450, loss: 1.4922631978988647, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 500, loss: 1.845292091369629, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 550, loss: 1.6862009763717651, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 600, loss: 1.22586190700531, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 650, loss: 1.418079137802124, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 700, loss: 1.6296402215957642, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 750, loss: 1.5662568807601929, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 800, loss: 1.5003690719604492, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 850, loss: 1.5626804828643799, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 900, loss: 1.4726961851119995, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 950, loss: 1.602154016494751, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1000, loss: 1.6109473705291748, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1050, loss: 1.3199737071990967, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1100, loss: 1.6863445043563843, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1150, loss: 1.496801495552063, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1200, loss: 1.6098875999450684, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1250, loss: 1.3138548135757446, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1300, loss: 1.295583963394165, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1350, loss: 1.5311100482940674, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1400, loss: 1.3390331268310547, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1450, loss: 1.6889194250106812, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1500, loss: 1.6287697553634644, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1550, loss: 1.6134930849075317, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1600, loss: 1.6595643758773804, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1650, loss: 1.7999038696289062, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1700, loss: 2.009324789047241, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1750, loss: 1.4343181848526, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1800, loss: 1.5128098726272583, rate: 1.1491463741751414e-05\n",
      "[2023-11-13 12:49:47.033155] Epoch: 53 ends. Average loss: 1.5166547782041062\n",
      "Epoch: 54 Batch: 0, loss: 1.5060079097747803, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 50, loss: 1.3610472679138184, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 100, loss: 1.6634085178375244, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 150, loss: 1.5155121088027954, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 200, loss: 1.7155531644821167, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 250, loss: 1.4810079336166382, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 300, loss: 0.9942388534545898, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 350, loss: 1.3420288562774658, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 400, loss: 1.2926034927368164, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 450, loss: 1.478346824645996, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 500, loss: 1.8086291551589966, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 550, loss: 1.5908854007720947, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 600, loss: 1.2492929697036743, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 650, loss: 1.5177456140518188, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 700, loss: 1.5219181776046753, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 750, loss: 1.5192716121673584, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 800, loss: 1.559983730316162, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 850, loss: 1.3638279438018799, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 900, loss: 1.495353102684021, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 950, loss: 1.5780694484710693, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1000, loss: 1.7021645307540894, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1050, loss: 1.4235297441482544, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1100, loss: 1.5309228897094727, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1150, loss: 1.5587295293807983, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1200, loss: 1.6136810779571533, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1250, loss: 1.306637167930603, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1300, loss: 1.288214921951294, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1350, loss: 1.4187747240066528, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1400, loss: 1.43294358253479, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1450, loss: 1.7635037899017334, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1500, loss: 1.7806087732315063, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1550, loss: 1.7256990671157837, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1600, loss: 1.719053030014038, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1650, loss: 1.7775821685791016, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1700, loss: 2.0396881103515625, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1750, loss: 1.4967422485351562, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1800, loss: 1.5508992671966553, rate: 1.1031805192081357e-05\n",
      "[2023-11-13 12:53:33.351649] Epoch: 54 ends. Average loss: 1.5114751394716863\n",
      "Epoch: 55 Batch: 0, loss: 1.58175790309906, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 50, loss: 1.430663824081421, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 100, loss: 1.6304430961608887, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 150, loss: 1.5529738664627075, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 200, loss: 1.6334593296051025, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 250, loss: 1.5475131273269653, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 300, loss: 0.9827879667282104, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 350, loss: 1.4074819087982178, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 400, loss: 1.2402446269989014, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 450, loss: 1.4700716733932495, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 500, loss: 1.7973941564559937, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 550, loss: 1.6359626054763794, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 600, loss: 1.3196884393692017, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 650, loss: 1.4738134145736694, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 700, loss: 1.5100195407867432, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 750, loss: 1.5151100158691406, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 800, loss: 1.6139353513717651, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 850, loss: 1.434140920639038, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 900, loss: 1.6404789686203003, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 950, loss: 1.6459423303604126, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1000, loss: 1.6079119443893433, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1050, loss: 1.3680466413497925, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1100, loss: 1.582598090171814, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1150, loss: 1.519561529159546, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1200, loss: 1.598244071006775, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1250, loss: 1.3539570569992065, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1300, loss: 1.3110840320587158, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1350, loss: 1.3814043998718262, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1400, loss: 1.3844932317733765, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1450, loss: 1.5417940616607666, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1500, loss: 1.6561857461929321, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1550, loss: 1.6990618705749512, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1600, loss: 1.6606218814849854, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1650, loss: 1.705383539199829, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1700, loss: 2.0560905933380127, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1750, loss: 1.4321556091308594, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1800, loss: 1.4578237533569336, rate: 1.0590532984398102e-05\n",
      "[2023-11-13 12:57:20.241693] Epoch: 55 ends. Average loss: 1.5135496127888175\n",
      "Epoch: 56 Batch: 0, loss: 1.5667248964309692, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 50, loss: 1.4008653163909912, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 100, loss: 1.618483543395996, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 150, loss: 1.5078184604644775, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 200, loss: 1.7906769514083862, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 250, loss: 1.5100222826004028, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 300, loss: 1.0067129135131836, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 350, loss: 1.4729477167129517, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 400, loss: 1.3234288692474365, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 450, loss: 1.4682625532150269, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 500, loss: 1.7947906255722046, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 550, loss: 1.5708683729171753, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 600, loss: 1.1715874671936035, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 650, loss: 1.481801986694336, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 700, loss: 1.5269391536712646, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 750, loss: 1.421510100364685, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 800, loss: 1.5784633159637451, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 850, loss: 1.3308651447296143, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 900, loss: 1.5819343328475952, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 950, loss: 1.6159484386444092, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1000, loss: 1.6915031671524048, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1050, loss: 1.3594112396240234, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1100, loss: 1.5556660890579224, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1150, loss: 1.5302375555038452, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1200, loss: 1.6167938709259033, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1250, loss: 1.43733811378479, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1300, loss: 1.2001268863677979, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1350, loss: 1.4644262790679932, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1400, loss: 1.3113150596618652, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1450, loss: 1.744794487953186, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1500, loss: 1.726637840270996, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1550, loss: 1.7037162780761719, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1600, loss: 1.6665948629379272, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1650, loss: 1.7654666900634766, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1700, loss: 1.9522202014923096, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1750, loss: 1.4843419790267944, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1800, loss: 1.638365626335144, rate: 1.0166911665022178e-05\n",
      "[2023-11-13 13:01:07.598072] Epoch: 56 ends. Average loss: 1.5105533698482272\n",
      "Epoch: 57 Batch: 0, loss: 1.545301914215088, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 50, loss: 1.3534460067749023, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 100, loss: 1.6588534116744995, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 150, loss: 1.546104073524475, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 200, loss: 1.7749115228652954, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 250, loss: 1.5109736919403076, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 300, loss: 1.0722168684005737, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 350, loss: 1.3487001657485962, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 400, loss: 1.3414698839187622, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 450, loss: 1.5607752799987793, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 500, loss: 1.7811990976333618, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 550, loss: 1.50171959400177, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 600, loss: 1.2726958990097046, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 650, loss: 1.3669639825820923, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 700, loss: 1.4707651138305664, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 750, loss: 1.4646828174591064, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 800, loss: 1.5115694999694824, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 850, loss: 1.4043545722961426, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 900, loss: 1.497828483581543, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 950, loss: 1.7180414199829102, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1000, loss: 1.614383578300476, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1050, loss: 1.4226046800613403, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1100, loss: 1.6700842380523682, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1150, loss: 1.5385202169418335, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1200, loss: 1.4668141603469849, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1250, loss: 1.4547154903411865, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1300, loss: 1.2842878103256226, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1350, loss: 1.4019666910171509, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1400, loss: 1.4965444803237915, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1450, loss: 1.5986665487289429, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1500, loss: 1.6845321655273438, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1550, loss: 1.5987077951431274, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1600, loss: 1.656435489654541, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1650, loss: 1.8667289018630981, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1700, loss: 1.9610004425048828, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1750, loss: 1.468449592590332, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1800, loss: 1.4809449911117554, rate: 9.76023519842129e-06\n",
      "[2023-11-13 13:04:53.146387] Epoch: 57 ends. Average loss: 1.5081181261859016\n",
      "Epoch: 58 Batch: 0, loss: 1.4908417463302612, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 50, loss: 1.305930495262146, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 100, loss: 1.4956161975860596, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 150, loss: 1.4493590593338013, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 200, loss: 1.7745357751846313, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 250, loss: 1.5645184516906738, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 300, loss: 1.0316218137741089, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 350, loss: 1.4111473560333252, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 400, loss: 1.4327999353408813, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 450, loss: 1.4867205619812012, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 500, loss: 1.8458976745605469, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 550, loss: 1.5186762809753418, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 600, loss: 1.2637488842010498, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 650, loss: 1.4023464918136597, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 700, loss: 1.5203197002410889, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 750, loss: 1.475027084350586, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 800, loss: 1.6340422630310059, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 850, loss: 1.4280550479888916, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 900, loss: 1.4752494096755981, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 950, loss: 1.5315099954605103, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1000, loss: 1.5013718605041504, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1050, loss: 1.4221227169036865, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1100, loss: 1.5514225959777832, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1150, loss: 1.507279396057129, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1200, loss: 1.586402416229248, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1250, loss: 1.3836405277252197, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1300, loss: 1.1441943645477295, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1350, loss: 1.3986389636993408, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1400, loss: 1.3964124917984009, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1450, loss: 1.7244800329208374, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1500, loss: 1.711209774017334, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1550, loss: 1.6357269287109375, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1600, loss: 1.735191822052002, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1650, loss: 1.8663609027862549, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1700, loss: 1.92383873462677, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1750, loss: 1.3975698947906494, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1800, loss: 1.5888335704803467, rate: 9.369825790484438e-06\n",
      "[2023-11-13 13:08:42.608578] Epoch: 58 ends. Average loss: 1.5078605859567629\n",
      "Epoch: 59 Batch: 0, loss: 1.5287960767745972, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 50, loss: 1.316800594329834, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 100, loss: 1.6576833724975586, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 150, loss: 1.4715262651443481, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 200, loss: 1.7744531631469727, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 250, loss: 1.4726762771606445, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 300, loss: 0.9165281653404236, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 350, loss: 1.2186518907546997, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 400, loss: 1.298370122909546, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 450, loss: 1.4690934419631958, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 500, loss: 1.8198233842849731, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 550, loss: 1.5962616205215454, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 600, loss: 1.3191512823104858, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 650, loss: 1.3726072311401367, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 700, loss: 1.5086811780929565, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 750, loss: 1.4882872104644775, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 800, loss: 1.5858197212219238, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 850, loss: 1.3530691862106323, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 900, loss: 1.4617135524749756, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 950, loss: 1.610891342163086, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1000, loss: 1.7042778730392456, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1050, loss: 1.4048771858215332, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1100, loss: 1.5753718614578247, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1150, loss: 1.567030429840088, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1200, loss: 1.5636523962020874, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1250, loss: 1.4514861106872559, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1300, loss: 1.2349132299423218, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1350, loss: 1.50459623336792, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1400, loss: 1.4422359466552734, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1450, loss: 1.653483510017395, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1500, loss: 1.785786747932434, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1550, loss: 1.6517341136932373, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1600, loss: 1.6473324298858643, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1650, loss: 1.9007474184036255, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1700, loss: 2.016237735748291, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1750, loss: 1.504563570022583, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1800, loss: 1.5293365716934204, rate: 8.99503275886506e-06\n",
      "[2023-11-13 13:12:34.382149] Epoch: 59 ends. Average loss: 1.5077118590531662\n",
      "Epoch: 60 Batch: 0, loss: 1.5259050130844116, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 50, loss: 1.3696123361587524, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 100, loss: 1.6436922550201416, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 150, loss: 1.5843908786773682, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 200, loss: 1.7576911449432373, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 250, loss: 1.5526254177093506, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 300, loss: 1.0649731159210205, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 350, loss: 1.2762888669967651, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 400, loss: 1.3330845832824707, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 450, loss: 1.3562266826629639, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 500, loss: 1.8009188175201416, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 550, loss: 1.5862834453582764, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 600, loss: 1.210950493812561, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 650, loss: 1.532557725906372, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 700, loss: 1.5192307233810425, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 750, loss: 1.4943431615829468, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 800, loss: 1.518131136894226, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 850, loss: 1.3083277940750122, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 900, loss: 1.582364559173584, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 950, loss: 1.6362355947494507, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1000, loss: 1.7151380777359009, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1050, loss: 1.296897053718567, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1100, loss: 1.5761945247650146, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1150, loss: 1.469391107559204, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1200, loss: 1.5437195301055908, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1250, loss: 1.4605820178985596, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1300, loss: 1.200966477394104, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1350, loss: 1.4676251411437988, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1400, loss: 1.2838350534439087, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1450, loss: 1.710797667503357, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1500, loss: 1.7825539112091064, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1550, loss: 1.7408829927444458, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1600, loss: 1.6190730333328247, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1650, loss: 1.714768886566162, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1700, loss: 2.002248764038086, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1750, loss: 1.5413261651992798, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1800, loss: 1.494594693183899, rate: 8.635231448510457e-06\n",
      "[2023-11-13 13:16:24.020139] Epoch: 60 ends. Average loss: 1.5102637556134437\n",
      "Epoch: 61 Batch: 0, loss: 1.5011311769485474, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 50, loss: 1.355270266532898, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 100, loss: 1.4675379991531372, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 150, loss: 1.434277892112732, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 200, loss: 1.719070553779602, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 250, loss: 1.4958401918411255, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 300, loss: 1.0264177322387695, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 350, loss: 1.3130590915679932, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 400, loss: 1.398618221282959, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 450, loss: 1.4313139915466309, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 500, loss: 1.816877841949463, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 550, loss: 1.5704830884933472, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 600, loss: 1.2697842121124268, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 650, loss: 1.4335412979125977, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 700, loss: 1.40361487865448, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 750, loss: 1.4971774816513062, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 800, loss: 1.4678815603256226, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 850, loss: 1.4042377471923828, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 900, loss: 1.546786904335022, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 950, loss: 1.6582149267196655, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1000, loss: 1.5782296657562256, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1050, loss: 1.3802963495254517, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1100, loss: 1.5814036130905151, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1150, loss: 1.4001270532608032, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1200, loss: 1.5718616247177124, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1250, loss: 1.3993369340896606, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1300, loss: 1.179618239402771, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1350, loss: 1.3355143070220947, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1400, loss: 1.397566556930542, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1450, loss: 1.613499402999878, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1500, loss: 1.8039313554763794, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1550, loss: 1.6984318494796753, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1600, loss: 1.805499792098999, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1650, loss: 1.8092405796051025, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1700, loss: 2.0646395683288574, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1750, loss: 1.5343161821365356, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1800, loss: 1.5223795175552368, rate: 8.289822190570038e-06\n",
      "[2023-11-13 13:20:12.587074] Epoch: 61 ends. Average loss: 1.5077954798328632\n",
      "Epoch: 62 Batch: 0, loss: 1.4555219411849976, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 50, loss: 1.3599867820739746, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 100, loss: 1.6216754913330078, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 150, loss: 1.6065912246704102, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 200, loss: 1.682749629020691, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 250, loss: 1.561777949333191, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 300, loss: 1.102591633796692, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 350, loss: 1.392227292060852, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 400, loss: 1.371786117553711, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 450, loss: 1.5679229497909546, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 500, loss: 1.8274405002593994, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 550, loss: 1.5872752666473389, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 600, loss: 1.2513291835784912, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 650, loss: 1.2866575717926025, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 700, loss: 1.6102397441864014, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 750, loss: 1.5407577753067017, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 800, loss: 1.5344350337982178, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 850, loss: 1.4656455516815186, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 900, loss: 1.4668766260147095, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 950, loss: 1.5920588970184326, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1000, loss: 1.7053649425506592, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1050, loss: 1.3682529926300049, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1100, loss: 1.6265071630477905, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1150, loss: 1.4489022493362427, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1200, loss: 1.6262892484664917, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1250, loss: 1.3600342273712158, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1300, loss: 1.223641276359558, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1350, loss: 1.4854459762573242, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1400, loss: 1.3695898056030273, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1450, loss: 1.686296820640564, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1500, loss: 1.6638991832733154, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1550, loss: 1.6813818216323853, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1600, loss: 1.6716265678405762, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1650, loss: 1.868719458580017, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1700, loss: 1.970001459121704, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1750, loss: 1.454328179359436, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1800, loss: 1.495790958404541, rate: 7.958229302947236e-06\n",
      "[2023-11-13 13:23:58.531270] Epoch: 62 ends. Average loss: 1.5065586395639776\n",
      "Epoch: 63 Batch: 0, loss: 1.5434937477111816, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 50, loss: 1.324713945388794, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 100, loss: 1.6389234066009521, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 150, loss: 1.4603359699249268, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 200, loss: 1.762511134147644, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 250, loss: 1.5676779747009277, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 300, loss: 1.053896427154541, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 350, loss: 1.3683627843856812, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 400, loss: 1.2842607498168945, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 450, loss: 1.5304452180862427, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 500, loss: 1.813126802444458, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 550, loss: 1.5818941593170166, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 600, loss: 1.208918571472168, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 650, loss: 1.421301007270813, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 700, loss: 1.4745502471923828, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 750, loss: 1.3614338636398315, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 800, loss: 1.4893934726715088, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 850, loss: 1.3857022523880005, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 900, loss: 1.5634042024612427, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 950, loss: 1.5422804355621338, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1000, loss: 1.6446179151535034, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1050, loss: 1.3032547235488892, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1100, loss: 1.5675545930862427, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1150, loss: 1.5055385828018188, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1200, loss: 1.473699927330017, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1250, loss: 1.4118120670318604, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1300, loss: 1.2211061716079712, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1350, loss: 1.4619648456573486, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1400, loss: 1.4069769382476807, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1450, loss: 1.6736807823181152, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1500, loss: 1.672928810119629, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1550, loss: 1.637987494468689, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1600, loss: 1.740976095199585, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1650, loss: 1.7949700355529785, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1700, loss: 1.9924410581588745, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1750, loss: 1.4454325437545776, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1800, loss: 1.535643458366394, rate: 7.639900130829346e-06\n",
      "[2023-11-13 13:27:45.173761] Epoch: 63 ends. Average loss: 1.5052141514326811\n",
      "Epoch: 64 Batch: 0, loss: 1.572828769683838, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 50, loss: 1.2995121479034424, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 100, loss: 1.5786322355270386, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 150, loss: 1.5316426753997803, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 200, loss: 1.6760298013687134, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 250, loss: 1.4684501886367798, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 300, loss: 1.027854084968567, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 350, loss: 1.4123926162719727, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 400, loss: 1.3785042762756348, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 450, loss: 1.6029666662216187, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 500, loss: 1.81636643409729, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 550, loss: 1.6320276260375977, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 600, loss: 1.2641533613204956, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 650, loss: 1.339709997177124, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 700, loss: 1.6001348495483398, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 750, loss: 1.5346243381500244, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 800, loss: 1.5740174055099487, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 850, loss: 1.3351932764053345, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 900, loss: 1.5129759311676025, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 950, loss: 1.7498881816864014, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1000, loss: 1.6726219654083252, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1050, loss: 1.3532127141952515, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1100, loss: 1.517588496208191, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1150, loss: 1.539461612701416, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1200, loss: 1.4838706254959106, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1250, loss: 1.3047016859054565, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1300, loss: 1.1956309080123901, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1350, loss: 1.3392174243927002, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1400, loss: 1.347693681716919, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1450, loss: 1.6645957231521606, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1500, loss: 1.6732784509658813, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1550, loss: 1.6819158792495728, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1600, loss: 1.5943578481674194, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1650, loss: 1.8107541799545288, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1700, loss: 2.028308153152466, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1750, loss: 1.5949598550796509, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1800, loss: 1.567554235458374, rate: 7.334304125596171e-06\n",
      "[2023-11-13 13:31:31.756164] Epoch: 64 ends. Average loss: 1.5041026650905873\n",
      "Epoch: 65 Batch: 0, loss: 1.5152093172073364, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 50, loss: 1.3778702020645142, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 100, loss: 1.554966926574707, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 150, loss: 1.5467309951782227, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 200, loss: 1.7429275512695312, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 250, loss: 1.4612513780593872, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 300, loss: 1.134262204170227, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 350, loss: 1.257924199104309, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 400, loss: 1.288543462753296, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 450, loss: 1.4495364427566528, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 500, loss: 1.7379963397979736, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 550, loss: 1.5859770774841309, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 600, loss: 1.2444466352462769, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 650, loss: 1.5065383911132812, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 700, loss: 1.4688764810562134, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 750, loss: 1.4503934383392334, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 800, loss: 1.4909507036209106, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 850, loss: 1.46869695186615, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 900, loss: 1.432508945465088, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 950, loss: 1.570045828819275, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1000, loss: 1.6302942037582397, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1050, loss: 1.373208999633789, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1100, loss: 1.5663772821426392, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1150, loss: 1.4554654359817505, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1200, loss: 1.6019905805587769, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1250, loss: 1.530116319656372, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1300, loss: 1.2500098943710327, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1350, loss: 1.3823128938674927, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1400, loss: 1.4746531248092651, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1450, loss: 1.6690278053283691, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1500, loss: 1.6589001417160034, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1550, loss: 1.6212384700775146, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1600, loss: 1.5761265754699707, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1650, loss: 1.8248330354690552, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1700, loss: 2.0411415100097656, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1750, loss: 1.497550368309021, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1800, loss: 1.5457404851913452, rate: 7.040931960572324e-06\n",
      "[2023-11-13 13:35:18.681565] Epoch: 65 ends. Average loss: 1.5051013810557026\n",
      "Epoch: 66 Batch: 0, loss: 1.5817850828170776, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 50, loss: 1.3254221677780151, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 100, loss: 1.6014642715454102, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 150, loss: 1.4956592321395874, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 200, loss: 1.6536014080047607, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 250, loss: 1.5014710426330566, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 300, loss: 1.080966830253601, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 350, loss: 1.302376389503479, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 400, loss: 1.4222286939620972, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 450, loss: 1.4827512502670288, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 500, loss: 1.8303117752075195, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 550, loss: 1.5864450931549072, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 600, loss: 1.1933892965316772, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 650, loss: 1.4125770330429077, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 700, loss: 1.5084105730056763, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 750, loss: 1.4996157884597778, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 800, loss: 1.5766781568527222, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 850, loss: 1.3469717502593994, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 900, loss: 1.4254478216171265, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 950, loss: 1.6312897205352783, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1000, loss: 1.6124701499938965, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1050, loss: 1.3018866777420044, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1100, loss: 1.469130277633667, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1150, loss: 1.4939242601394653, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1200, loss: 1.6022542715072632, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1250, loss: 1.2911657094955444, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1300, loss: 1.1478387117385864, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1350, loss: 1.3557721376419067, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1400, loss: 1.405228614807129, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1450, loss: 1.6169040203094482, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1500, loss: 1.6010334491729736, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1550, loss: 1.6823490858078003, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1600, loss: 1.6795496940612793, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1650, loss: 1.8386735916137695, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1700, loss: 1.9860655069351196, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1750, loss: 1.4384472370147705, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1800, loss: 1.5420609712600708, rate: 6.759294682149431e-06\n",
      "[2023-11-13 13:39:07.007645] Epoch: 66 ends. Average loss: 1.5060310698121013\n",
      "Epoch: 67 Batch: 0, loss: 1.5887328386306763, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 50, loss: 1.2966244220733643, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 100, loss: 1.5983167886734009, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 150, loss: 1.4836703538894653, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 200, loss: 1.762768268585205, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 250, loss: 1.4869920015335083, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 300, loss: 1.1235487461090088, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 350, loss: 1.379982590675354, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 400, loss: 1.2714160680770874, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 450, loss: 1.4502214193344116, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 500, loss: 1.7867101430892944, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 550, loss: 1.5222687721252441, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 600, loss: 1.2078871726989746, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 650, loss: 1.3508119583129883, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 700, loss: 1.4577189683914185, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 750, loss: 1.5684268474578857, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 800, loss: 1.5125163793563843, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 850, loss: 1.4336295127868652, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 900, loss: 1.5316510200500488, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 950, loss: 1.5962461233139038, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1000, loss: 1.540906548500061, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1050, loss: 1.2792017459869385, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1100, loss: 1.5525856018066406, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1150, loss: 1.4754173755645752, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1200, loss: 1.5290957689285278, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1250, loss: 1.4500746726989746, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1300, loss: 1.2151274681091309, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1350, loss: 1.3572146892547607, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1400, loss: 1.394172191619873, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1450, loss: 1.6148924827575684, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1500, loss: 1.7070286273956299, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1550, loss: 1.5000404119491577, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1600, loss: 1.6374809741973877, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1650, loss: 1.847204327583313, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1700, loss: 2.0269992351531982, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1750, loss: 1.460211157798767, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1800, loss: 1.5561089515686035, rate: 6.488922894863454e-06\n",
      "[2023-11-13 13:42:56.088372] Epoch: 67 ends. Average loss: 1.5025670402824582\n",
      "Epoch: 68 Batch: 0, loss: 1.4942798614501953, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 50, loss: 1.3327792882919312, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 100, loss: 1.558964729309082, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 150, loss: 1.5574400424957275, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 200, loss: 1.6596968173980713, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 250, loss: 1.5090432167053223, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 300, loss: 1.0033994913101196, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 350, loss: 1.2791178226470947, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 400, loss: 1.388193964958191, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 450, loss: 1.4908050298690796, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 500, loss: 1.8319728374481201, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 550, loss: 1.6347291469573975, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 600, loss: 1.1668715476989746, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 650, loss: 1.3613375425338745, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 700, loss: 1.5227632522583008, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 750, loss: 1.4271217584609985, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 800, loss: 1.5499273538589478, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 850, loss: 1.483028769493103, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 900, loss: 1.5412019491195679, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 950, loss: 1.675584316253662, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1000, loss: 1.5894967317581177, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1050, loss: 1.349422812461853, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1100, loss: 1.7388733625411987, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1150, loss: 1.5566825866699219, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1200, loss: 1.5927833318710327, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1250, loss: 1.3210209608078003, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1300, loss: 1.282720685005188, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1350, loss: 1.4506607055664062, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1400, loss: 1.4313082695007324, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1450, loss: 1.724859356880188, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1500, loss: 1.7877178192138672, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1550, loss: 1.6427918672561646, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1600, loss: 1.5844578742980957, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1650, loss: 1.827133059501648, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1700, loss: 1.995642900466919, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1750, loss: 1.4681172370910645, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1800, loss: 1.5270520448684692, rate: 6.229365979068915e-06\n",
      "[2023-11-13 13:46:48.487458] Epoch: 68 ends. Average loss: 1.5063653654047486\n",
      "Epoch: 69 Batch: 0, loss: 1.5528994798660278, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 50, loss: 1.2892277240753174, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 100, loss: 1.6141972541809082, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 150, loss: 1.505155086517334, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 200, loss: 1.6870619058609009, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 250, loss: 1.5953342914581299, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 300, loss: 1.0879215002059937, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 350, loss: 1.3337444067001343, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 400, loss: 1.350611925125122, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 450, loss: 1.4506385326385498, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 500, loss: 1.8218846321105957, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 550, loss: 1.4720183610916138, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 600, loss: 1.1838815212249756, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 650, loss: 1.430458664894104, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 700, loss: 1.5969903469085693, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 750, loss: 1.3754936456680298, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 800, loss: 1.5867304801940918, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 850, loss: 1.4747408628463745, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 900, loss: 1.4494417905807495, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 950, loss: 1.597647786140442, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1000, loss: 1.6755479574203491, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1050, loss: 1.4025967121124268, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1100, loss: 1.6237519979476929, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1150, loss: 1.4958821535110474, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1200, loss: 1.5178600549697876, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1250, loss: 1.3918923139572144, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1300, loss: 1.1968220472335815, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1350, loss: 1.4236572980880737, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1400, loss: 1.5157277584075928, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1450, loss: 1.6023757457733154, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1500, loss: 1.6240801811218262, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1550, loss: 1.6048030853271484, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1600, loss: 1.6816867589950562, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1650, loss: 1.8291798830032349, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1700, loss: 2.060831308364868, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1750, loss: 1.4660723209381104, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1800, loss: 1.5105869770050049, rate: 5.980191339906158e-06\n",
      "[2023-11-13 13:50:40.097210] Epoch: 69 ends. Average loss: 1.5036086245787716\n",
      "Epoch: 70 Batch: 0, loss: 1.5042908191680908, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 50, loss: 1.2930593490600586, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 100, loss: 1.598737359046936, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 150, loss: 1.4857025146484375, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 200, loss: 1.7261409759521484, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 250, loss: 1.4416453838348389, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 300, loss: 1.024466872215271, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 350, loss: 1.4345422983169556, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 400, loss: 1.372293472290039, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 450, loss: 1.5095889568328857, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 500, loss: 1.7737988233566284, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 550, loss: 1.5173944234848022, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 600, loss: 1.2037814855575562, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 650, loss: 1.4502716064453125, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 700, loss: 1.6656190156936646, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 750, loss: 1.4110933542251587, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 800, loss: 1.516864538192749, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 850, loss: 1.3445476293563843, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 900, loss: 1.3996522426605225, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 950, loss: 1.6327579021453857, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1000, loss: 1.6884167194366455, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1050, loss: 1.368373990058899, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1100, loss: 1.547987461090088, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1150, loss: 1.3994492292404175, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1200, loss: 1.5136289596557617, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1250, loss: 1.4331706762313843, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1300, loss: 1.2171437740325928, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1350, loss: 1.430982232093811, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1400, loss: 1.4509848356246948, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1450, loss: 1.679979681968689, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1500, loss: 1.7531921863555908, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1550, loss: 1.729982852935791, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1600, loss: 1.7004064321517944, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1650, loss: 1.8070611953735352, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1700, loss: 2.0443618297576904, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1750, loss: 1.4302632808685303, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1800, loss: 1.668656587600708, rate: 5.740983686309912e-06\n",
      "[2023-11-13 13:54:31.536054] Epoch: 70 ends. Average loss: 1.5017766532027386\n",
      "Epoch: 71 Batch: 0, loss: 1.4944015741348267, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 50, loss: 1.3308525085449219, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 100, loss: 1.493467926979065, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 150, loss: 1.4510794878005981, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 200, loss: 1.7514406442642212, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 250, loss: 1.5830416679382324, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 300, loss: 1.039476990699768, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 350, loss: 1.2996997833251953, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 400, loss: 1.2974997758865356, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 450, loss: 1.4975740909576416, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 500, loss: 1.9358221292495728, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 550, loss: 1.5584238767623901, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 600, loss: 1.148364782333374, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 650, loss: 1.385520339012146, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 700, loss: 1.5452425479888916, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 750, loss: 1.4486275911331177, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 800, loss: 1.5198451280593872, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 850, loss: 1.4350913763046265, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 900, loss: 1.42521333694458, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 950, loss: 1.625853419303894, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1000, loss: 1.693569302558899, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1050, loss: 1.3654600381851196, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1100, loss: 1.5540457963943481, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1150, loss: 1.5543780326843262, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1200, loss: 1.5915101766586304, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1250, loss: 1.361096739768982, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1300, loss: 1.2360814809799194, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1350, loss: 1.4041962623596191, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1400, loss: 1.4194310903549194, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1450, loss: 1.6121160984039307, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1500, loss: 1.737426519393921, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1550, loss: 1.5994433164596558, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1600, loss: 1.725501537322998, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1650, loss: 1.855785846710205, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1700, loss: 2.0402793884277344, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1750, loss: 1.4207561016082764, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1800, loss: 1.584301233291626, rate: 5.511344338857515e-06\n",
      "[2023-11-13 13:58:22.392731] Epoch: 71 ends. Average loss: 1.5031554046679254\n",
      "Epoch: 72 Batch: 0, loss: 1.456020474433899, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 50, loss: 1.3726168870925903, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 100, loss: 1.463331699371338, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 150, loss: 1.435670018196106, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 200, loss: 1.6475141048431396, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 250, loss: 1.4765154123306274, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 300, loss: 1.0275707244873047, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 350, loss: 1.1699477434158325, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 400, loss: 1.4798989295959473, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 450, loss: 1.4591326713562012, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 500, loss: 1.8092013597488403, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 550, loss: 1.5574958324432373, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 600, loss: 1.2150620222091675, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 650, loss: 1.4556052684783936, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 700, loss: 1.5069621801376343, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 750, loss: 1.451175332069397, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 800, loss: 1.566858172416687, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 850, loss: 1.2978181838989258, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 900, loss: 1.6172971725463867, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 950, loss: 1.668885350227356, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1000, loss: 1.655475378036499, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1050, loss: 1.222439169883728, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1100, loss: 1.5514127016067505, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1150, loss: 1.6276130676269531, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1200, loss: 1.559069037437439, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1250, loss: 1.2437553405761719, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1300, loss: 1.246639370918274, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1350, loss: 1.4333082437515259, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1400, loss: 1.4945240020751953, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1450, loss: 1.705931544303894, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1500, loss: 1.6721466779708862, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1550, loss: 1.6176252365112305, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1600, loss: 1.6818379163742065, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1650, loss: 1.819775938987732, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1700, loss: 1.9752103090286255, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1750, loss: 1.4369369745254517, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1800, loss: 1.4541850090026855, rate: 5.290890565303214e-06\n",
      "[2023-11-13 14:02:13.566973] Epoch: 72 ends. Average loss: 1.5024136345950663\n",
      "Epoch: 73 Batch: 0, loss: 1.6358706951141357, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 50, loss: 1.2978557348251343, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 100, loss: 1.6022692918777466, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 150, loss: 1.4917759895324707, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 200, loss: 1.670356035232544, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 250, loss: 1.4765715599060059, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 300, loss: 1.0253512859344482, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 350, loss: 1.374166488647461, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 400, loss: 1.4105761051177979, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 450, loss: 1.549530267715454, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 500, loss: 1.7623662948608398, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 550, loss: 1.558945655822754, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 600, loss: 1.2124409675598145, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 650, loss: 1.3650444746017456, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 700, loss: 1.5374647378921509, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 750, loss: 1.4116545915603638, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 800, loss: 1.6336586475372314, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 850, loss: 1.4467860460281372, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 900, loss: 1.5013808012008667, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 950, loss: 1.5409642457962036, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1000, loss: 1.6550341844558716, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1050, loss: 1.3515874147415161, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1100, loss: 1.561215877532959, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1150, loss: 1.446634292602539, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1200, loss: 1.6006438732147217, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1250, loss: 1.383571982383728, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1300, loss: 1.2740272283554077, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1350, loss: 1.34487783908844, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1400, loss: 1.4481102228164673, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1450, loss: 1.6300885677337646, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1500, loss: 1.6530705690383911, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1550, loss: 1.673284649848938, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1600, loss: 1.5044150352478027, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1650, loss: 1.8107733726501465, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1700, loss: 2.1168317794799805, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1750, loss: 1.4700899124145508, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1800, loss: 1.5256397724151611, rate: 5.079254942691085e-06\n",
      "[2023-11-13 14:06:03.860636] Epoch: 73 ends. Average loss: 1.4997712559484344\n",
      "Epoch: 74 Batch: 0, loss: 1.577866792678833, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 50, loss: 1.4008147716522217, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 100, loss: 1.6055891513824463, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 150, loss: 1.5205754041671753, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 200, loss: 1.7394529581069946, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 250, loss: 1.6124294996261597, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 300, loss: 1.0588102340698242, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 350, loss: 1.4007176160812378, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 400, loss: 1.3134074211120605, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 450, loss: 1.41958487033844, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 500, loss: 1.8175427913665771, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 550, loss: 1.6880073547363281, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 600, loss: 1.2897123098373413, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 650, loss: 1.3869284391403198, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 700, loss: 1.5209417343139648, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 750, loss: 1.4777915477752686, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 800, loss: 1.569736361503601, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 850, loss: 1.4811443090438843, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 900, loss: 1.4758244752883911, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 950, loss: 1.611057162284851, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1000, loss: 1.590216875076294, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1050, loss: 1.366923213005066, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1100, loss: 1.5636123418807983, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1150, loss: 1.4651323556900024, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1200, loss: 1.6564234495162964, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1250, loss: 1.3602309226989746, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1300, loss: 1.2405749559402466, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1350, loss: 1.3712519407272339, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1400, loss: 1.3731495141983032, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1450, loss: 1.710009217262268, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1500, loss: 1.72993004322052, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1550, loss: 1.6311742067337036, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1600, loss: 1.6674076318740845, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1650, loss: 1.740100383758545, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1700, loss: 1.946632981300354, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1750, loss: 1.4497140645980835, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1800, loss: 1.58066987991333, rate: 4.876084744983441e-06\n",
      "[2023-11-13 14:09:55.676538] Epoch: 74 ends. Average loss: 1.5000652224072026\n",
      "Epoch: 75 Batch: 0, loss: 1.5393567085266113, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 50, loss: 1.3493822813034058, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 100, loss: 1.7125704288482666, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 150, loss: 1.4568350315093994, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 200, loss: 1.6613537073135376, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 250, loss: 1.523779273033142, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 300, loss: 0.983566164970398, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 350, loss: 1.2711979150772095, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 400, loss: 1.3691461086273193, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 450, loss: 1.3960789442062378, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 500, loss: 1.7633084058761597, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 550, loss: 1.5868157148361206, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 600, loss: 1.2185988426208496, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 650, loss: 1.4606133699417114, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 700, loss: 1.5876213312149048, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 750, loss: 1.4603586196899414, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 800, loss: 1.5120999813079834, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 850, loss: 1.3886189460754395, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 900, loss: 1.5999125242233276, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 950, loss: 1.6034245491027832, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1000, loss: 1.6805698871612549, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1050, loss: 1.310571551322937, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1100, loss: 1.5333447456359863, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1150, loss: 1.5383883714675903, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1200, loss: 1.6006113290786743, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1250, loss: 1.3853205442428589, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1300, loss: 1.2115799188613892, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1350, loss: 1.376103401184082, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1400, loss: 1.3896992206573486, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1450, loss: 1.7099096775054932, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1500, loss: 1.7115815877914429, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1550, loss: 1.6298660039901733, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1600, loss: 1.7215474843978882, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1650, loss: 1.840768575668335, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1700, loss: 2.0440542697906494, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1750, loss: 1.3924696445465088, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1800, loss: 1.5712313652038574, rate: 4.681041355184103e-06\n",
      "[2023-11-13 14:13:46.508223] Epoch: 75 ends. Average loss: 1.4984606516604522\n",
      "Epoch: 76 Batch: 0, loss: 1.5255056619644165, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 50, loss: 1.367211103439331, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 100, loss: 1.5914946794509888, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 150, loss: 1.497085690498352, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 200, loss: 1.6940712928771973, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 250, loss: 1.4821715354919434, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 300, loss: 1.0812273025512695, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 350, loss: 1.4576163291931152, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 400, loss: 1.3425476551055908, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 450, loss: 1.5242195129394531, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 500, loss: 1.8692514896392822, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 550, loss: 1.5660117864608765, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 600, loss: 1.2629414796829224, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 650, loss: 1.4303295612335205, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 700, loss: 1.5168527364730835, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 750, loss: 1.4638370275497437, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 800, loss: 1.4743541479110718, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 850, loss: 1.4776995182037354, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 900, loss: 1.4895153045654297, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 950, loss: 1.5814433097839355, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1000, loss: 1.676017165184021, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1050, loss: 1.3873846530914307, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1100, loss: 1.5406261682510376, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1150, loss: 1.6055761575698853, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1200, loss: 1.5884102582931519, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1250, loss: 1.336734652519226, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1300, loss: 1.162828803062439, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1350, loss: 1.4272260665893555, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1400, loss: 1.386132836341858, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1450, loss: 1.6491929292678833, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1500, loss: 1.7294442653656006, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1550, loss: 1.6027551889419556, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1600, loss: 1.7739211320877075, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1650, loss: 1.8022842407226562, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1700, loss: 1.9236661195755005, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1750, loss: 1.5136080980300903, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1800, loss: 1.5463217496871948, rate: 4.493799700976739e-06\n",
      "[2023-11-13 14:17:37.064980] Epoch: 76 ends. Average loss: 1.501330070908531\n",
      "Epoch: 77 Batch: 0, loss: 1.5502294301986694, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 50, loss: 1.3372124433517456, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 100, loss: 1.5759345293045044, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 150, loss: 1.5830588340759277, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 200, loss: 1.6829607486724854, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 250, loss: 1.4119782447814941, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 300, loss: 1.023727536201477, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 350, loss: 1.3129041194915771, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 400, loss: 1.3499735593795776, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 450, loss: 1.575217843055725, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 500, loss: 1.7811040878295898, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 550, loss: 1.5300902128219604, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 600, loss: 1.2607669830322266, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 650, loss: 1.4068471193313599, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 700, loss: 1.4853127002716064, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 750, loss: 1.4470325708389282, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 800, loss: 1.533650279045105, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 850, loss: 1.3931578397750854, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 900, loss: 1.4482265710830688, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 950, loss: 1.5691523551940918, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1000, loss: 1.5804975032806396, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1050, loss: 1.3647849559783936, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1100, loss: 1.465836524963379, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1150, loss: 1.6038936376571655, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1200, loss: 1.572746992111206, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1250, loss: 1.4049383401870728, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1300, loss: 1.2776410579681396, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1350, loss: 1.3971221446990967, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1400, loss: 1.3794338703155518, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1450, loss: 1.6301441192626953, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1500, loss: 1.6037976741790771, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1550, loss: 1.6774345636367798, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1600, loss: 1.6501353979110718, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1650, loss: 1.7927833795547485, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1700, loss: 1.9944593906402588, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1750, loss: 1.464925765991211, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1800, loss: 1.4892263412475586, rate: 4.31404771293767e-06\n",
      "[2023-11-13 14:21:28.188853] Epoch: 77 ends. Average loss: 1.4993524203560855\n",
      "Epoch: 78 Batch: 0, loss: 1.510381817817688, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 50, loss: 1.2606652975082397, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 100, loss: 1.5830552577972412, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 150, loss: 1.5362462997436523, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 200, loss: 1.6832270622253418, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 250, loss: 1.61963951587677, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 300, loss: 1.0678448677062988, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 350, loss: 1.3316010236740112, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 400, loss: 1.2810791730880737, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 450, loss: 1.4775607585906982, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 500, loss: 1.89094078540802, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 550, loss: 1.5800468921661377, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 600, loss: 1.2479385137557983, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 650, loss: 1.4187264442443848, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 700, loss: 1.6719141006469727, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 750, loss: 1.4172377586364746, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 800, loss: 1.5426169633865356, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 850, loss: 1.3839441537857056, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 900, loss: 1.532590389251709, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 950, loss: 1.5695611238479614, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1000, loss: 1.5724512338638306, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1050, loss: 1.3982279300689697, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1100, loss: 1.541373372077942, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1150, loss: 1.5870416164398193, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1200, loss: 1.5298209190368652, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1250, loss: 1.3523591756820679, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1300, loss: 1.2112245559692383, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1350, loss: 1.3792327642440796, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1400, loss: 1.4957777261734009, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1450, loss: 1.6216061115264893, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1500, loss: 1.7729700803756714, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1550, loss: 1.6338207721710205, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1650, loss: 1.8086268901824951, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1700, loss: 2.004514694213867, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1750, loss: 1.4933704137802124, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1800, loss: 1.4822423458099365, rate: 4.141485804420163e-06\n",
      "[2023-11-13 14:25:18.886638] Epoch: 78 ends. Average loss: 1.4995338836889271\n",
      "Epoch: 79 Batch: 0, loss: 1.492629885673523, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 50, loss: 1.2933470010757446, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 100, loss: 1.5686198472976685, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 150, loss: 1.417459487915039, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 200, loss: 1.670379400253296, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 250, loss: 1.4596049785614014, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 300, loss: 1.0547820329666138, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 350, loss: 1.315853238105774, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 400, loss: 1.361143708229065, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 450, loss: 1.495491623878479, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 500, loss: 1.8153434991836548, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 550, loss: 1.5381579399108887, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 600, loss: 1.2978862524032593, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 650, loss: 1.4458075761795044, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 700, loss: 1.4617280960083008, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 750, loss: 1.4662952423095703, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 800, loss: 1.4796220064163208, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 850, loss: 1.436366319656372, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 900, loss: 1.4956504106521606, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 950, loss: 1.5625014305114746, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1000, loss: 1.6958993673324585, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1050, loss: 1.242643117904663, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1100, loss: 1.5221152305603027, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1150, loss: 1.4770995378494263, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1200, loss: 1.5721772909164429, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1250, loss: 1.3487751483917236, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1300, loss: 1.1950465440750122, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1350, loss: 1.4651985168457031, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1400, loss: 1.34804368019104, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1450, loss: 1.6522822380065918, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1500, loss: 1.7771542072296143, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1550, loss: 1.5957584381103516, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1600, loss: 1.5962247848510742, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1650, loss: 1.8002299070358276, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1700, loss: 2.030639171600342, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1750, loss: 1.493641972541809, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1800, loss: 1.515283465385437, rate: 3.9758263722433564e-06\n",
      "[2023-11-13 14:29:05.847253] Epoch: 79 ends. Average loss: 1.5011296958076448\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "head.train()\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    losss_per_e = []\n",
    "    for i, batch in enumerate(dataloader_train):\n",
    "        loss_current = train_a_batch(batch, head, optimizer, None)\n",
    "        losss_per_e.append(loss_current)\n",
    "        if i % 50 == 0:\n",
    "            print('Epoch: {} Batch: {}, loss: {}, rate: {}'.format(e, i, loss_current, optimizer.param_groups[0]['lr']))\n",
    "        # end\n",
    "\n",
    "        # if i > 1000:\n",
    "        #     break\n",
    "        # # end\n",
    "    # end\n",
    "    \n",
    "    loss_average_per_e = sum(losss_per_e) / len(losss_per_e)\n",
    "    print('[{}] Epoch: {} ends. Average loss: {}'.format(datetime.utcnow(), e, loss_average_per_e))\n",
    "    \n",
    "    # if loss_average_per_e < 10:\n",
    "    #     break\n",
    "    # # end\n",
    "    \n",
    "    lr_scheduler.step() # schedule per epoch\n",
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
