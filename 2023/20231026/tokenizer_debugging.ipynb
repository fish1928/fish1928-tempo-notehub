{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7ebb15-4b5e-4fc9-8a5e-5399ffab8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "\n",
    "def Multi30k(language_pair=None):\n",
    "    corpus_lines_train = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/train.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_train.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_train = list(zip(*corpus_lines_train))\n",
    "\n",
    "    corpus_lines_eval = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/val.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_eval.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_eval = list(zip(*corpus_lines_eval))\n",
    "\n",
    "    return corpus_train, corpus_eval, None\n",
    "# end\n",
    "\n",
    "\n",
    "def load_vocab(spacy_en):\n",
    "    if not os.path.exists(\"vocab.pt\"):\n",
    "        vocab_tgt = build_vocabulary(spacy_en)\n",
    "        torch.save(vocab_tgt, \"vocab.pt\")\n",
    "    else:\n",
    "        vocab_tgt = torch.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes: {}\".format(len(vocab_tgt)))\n",
    "    return vocab_tgt\n",
    "# end\n",
    "\n",
    "def load_spacy():\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_en\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb8c312-f19a-4d31-b9ee-c88c7ef4aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, vocab, splitter):\n",
    "        self.splitter = splitter\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.id_pad = len(vocab)\n",
    "        self.id_cls = len(vocab) + 1\n",
    "        self.id_sep = len(vocab) + 2\n",
    "        self.id_mask = len(vocab) + 3\n",
    "        \n",
    "        self.size_vocab = len(vocab) + 4\n",
    "\n",
    "        self.token_pad = '[PAD]'\n",
    "        self.token_cls = '[CLS]'\n",
    "        self.token_sep = '[SEP]'\n",
    "        self.token_mask = '[MASK]'\n",
    "        \n",
    "    # end\n",
    "\n",
    "    def encode(self, line):\n",
    "        return self.vocab([doc.text for doc in self.splitter(line)])\n",
    "    # end\n",
    "\n",
    "    def decode(self):\n",
    "        pass\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        for k, v in kwargs.items():\n",
    "            self.kwargs[k] = v.to(Batch.DEVICE)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.kwargs\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class Collator_S2S:\n",
    "\n",
    "    def __init__(self, tokenizer, size_seq_max):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size_seq_max = size_seq_max\n",
    "    # end\n",
    "\n",
    "    def __call__(self, list_corpus_source):\n",
    "\n",
    "        tokens_input_encoder = []\n",
    "        tokens_input_decoder = []\n",
    "        tokens_label_decoder = []\n",
    "        labels_similarity = []\n",
    "\n",
    "        for corpus_source in list_corpus_source: # (line0, line1, sim), output of zip remove single case\n",
    "            if corpus_source == 3:\n",
    "                corpus_line = [courpus_source[0], corpus_source[1]]\n",
    "                labels_similarity.append(corpus_line[2])\n",
    "            else:\n",
    "                corpus_line = [corpus_source[1]]\n",
    "            # end\n",
    "            \n",
    "            for line in corpus_line:\n",
    "                tokens = self.tokenizer.encode(line)\n",
    "\n",
    "                # TODO: check edge\n",
    "                if len(tokens) > self.size_seq_max - 2:\n",
    "                    tokens = tokens[:self.size_seq_max-2]\n",
    "                # end\n",
    "\n",
    "                tokens_input_encoder.append([self.tokenizer.id_cls] + tokens + [self.tokenizer.id_sep])\n",
    "                tokens_input_decoder.append([self.tokenizer.id_cls] + tokens)\n",
    "                tokens_label_decoder.append(tokens + [self.tokenizer.id_sep])\n",
    "            # end\n",
    "            \n",
    "\n",
    "        # end\n",
    "\n",
    "        inputs_encoder, masks_encoder, segments_encoder, labels_encoder = self.pad_sequences(tokens_input_encoder, self.size_seq_max, need_masked=0.3)\n",
    "        inputs_decoder, masks_decoder, segments_decoder = self.pad_sequences(tokens_input_decoder, self.size_seq_max, need_diagonal=True)\n",
    "        labels_decoder, masks_label, segments_label = self.pad_sequences(tokens_label_decoder, self.size_seq_max)\n",
    "        # labels_similarity = torch.Tensor(labels_similarity).unsqueeze(0).transpose(0,1)\n",
    "        labels_similarity = torch.Tensor(labels_similarity)\n",
    "\n",
    "        return Batch(\n",
    "            ids_encoder=inputs_encoder,  # contains [mask]s\n",
    "            masks_encoder=masks_encoder,\n",
    "            labels_encoder=labels_encoder,  # doesn't contain [mask]\n",
    "            ids_decoder=inputs_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            labels_decoder=labels_decoder,\n",
    "            segments_label=segments_label,\n",
    "            labels_similarity=labels_similarity\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    \n",
    "    # return masks_attention?, return masks_segment?\n",
    "    def pad_sequences(self, sequences, size_seq_max, need_diagonal=False, need_masked=0): # need_diagonal and need_masked cannot both set, one for bert seq one for s2s seq\n",
    "        id_pad = self.tokenizer.id_pad\n",
    "        id_mask = self.tokenizer.id_mask\n",
    "\n",
    "        sequences_padded = []\n",
    "        sequences_masked_padded = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            len_seq = len(sequence)\n",
    "\n",
    "            count_pad = size_seq_max - len_seq\n",
    "\n",
    "            sequence = torch.LongTensor(sequence)\n",
    "            sequence_padded = torch.cat((sequence, torch.LongTensor([id_pad] * count_pad)))\n",
    "            sequences_padded.append(sequence_padded)\n",
    "\n",
    "            if need_masked:\n",
    "                index_masked = list(range(1, len_seq-1))\n",
    "                random.shuffle(index_masked)\n",
    "                index_masked = torch.LongTensor(index_masked[:int(need_masked * (len_seq-2))])\n",
    "                print(index_masked)\n",
    "\n",
    "                sequence_masked = sequence.detach().clone()\n",
    "                sequence_masked.index_fill_(0, index_masked, id_mask)\n",
    "                sequence_masked_padded = torch.cat((sequence_masked, torch.LongTensor([id_pad] * count_pad)))\n",
    "                \n",
    "                sequences_masked_padded.append(sequence_masked_padded)\n",
    "            # end\n",
    "    #   # end for\n",
    "\n",
    "        inputs = torch.stack(sequences_padded)  # (batch, size_seq_max)\n",
    "        if need_masked:\n",
    "            inputs_masked_padded = torch.stack(sequences_masked_padded)\n",
    "        # end\n",
    "\n",
    "        masks_segment = (inputs != self.tokenizer.id_pad).unsqueeze(-2).expand(inputs.shape[0], inputs.shape[-1], inputs.shape[-1]) #(nbatch, seq, seq)\n",
    "        masks_attention = self.make_std_mask(inputs, self.tokenizer.id_pad) if need_diagonal else masks_segment\n",
    "\n",
    "        if need_masked:\n",
    "            masks_masked = (inputs_masked_padded != id_mask).unsqueeze(-2).expand(inputs.shape[0], inputs.shape[-1], inputs.shape[-1])\n",
    "            masks_attention = masks_attention & masks_masked\n",
    "            return inputs_masked_padded, masks_attention, masks_segment, inputs # (inputs, masks_attention, masks_segment, labels)\n",
    "        else:\n",
    "            return inputs, masks_attention, masks_segment\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def subsequent_mask(self, size):\n",
    "        \"Mask out subsequent positions.\"\n",
    "        attn_shape = (1, size, size)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        return subsequent_mask == 0\n",
    "\n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & self.subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df77194-a5ba-4df4-90d7-db62f55378df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes: 6191\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "\n",
    "seq_max = 16\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "\n",
    "spacy_en = load_spacy()\n",
    "vocab = load_vocab(spacy_en)\n",
    "tokenizer = TokenizerWrapper(vocab, spacy_en)\n",
    "\n",
    "train_iter, valid_iter, _ = Multi30k(language_pair=(\"de\", \"en\"))\n",
    "\n",
    "train_source = to_map_style_dataset(train_iter)\n",
    "\n",
    "\n",
    "collator = Collator_S2S(tokenizer, seq_max)\n",
    "dataloader_train = DataLoader(train_source, batch_size, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eafd211-1d8e-43c9-9e3f-d0838e24ac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7, 10,  3])\n",
      "tensor([12,  8,  7])\n",
      "ids_encoder\n",
      "tensor([[6192,   19,   25, 6194, 1169,  808,   17, 6194,   84,  336, 6194,    5,\n",
      "         6193, 6191, 6191, 6191],\n",
      "        [6192,  164,   36,    7,  333,  286,   17, 6194, 6194,  744, 3732, 2678,\n",
      "         6194, 6193, 6191, 6191]])\n",
      "\n",
      "\n",
      "labels_encoder\n",
      "tensor([[6192,   19,   25,   15, 1169,  808,   17,   57,   84,  336, 1339,    5,\n",
      "         6193, 6191, 6191, 6191],\n",
      "        [6192,  164,   36,    7,  333,  286,   17, 1191,    4,  744, 3732, 2678,\n",
      "            5, 6193, 6191, 6191]])\n",
      "\n",
      "\n",
      "masks_encoder\n",
      "tensor([[[ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False],\n",
      "         [ True,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
      "          False,  True,  True, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
      "           True,  True, False,  True, False, False]]])\n",
      "\n",
      "\n",
      "ids_decoder\n",
      "tensor([[6192,   19,   25,   15, 1169,  808,   17,   57,   84,  336, 1339,    5,\n",
      "         6191, 6191, 6191, 6191],\n",
      "        [6192,  164,   36,    7,  333,  286,   17, 1191,    4,  744, 3732, 2678,\n",
      "            5, 6191, 6191, 6191]])\n",
      "\n",
      "\n",
      "labels_decoder\n",
      "tensor([[  19,   25,   15, 1169,  808,   17,   57,   84,  336, 1339,    5, 6193,\n",
      "         6191, 6191, 6191, 6191],\n",
      "        [ 164,   36,    7,  333,  286,   17, 1191,    4,  744, 3732, 2678,    5,\n",
      "         6193, 6191, 6191, 6191]])\n",
      "\n",
      "\n",
      "masks_decoder\n",
      "tensor([[[ True, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False]],\n",
      "\n",
      "        [[ True, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False]]])\n",
      "\n",
      "\n",
      "segments_label\n",
      "tensor([[[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True, False, False, False]]])\n",
      "tensor([8, 3])\n",
      "tensor([12, 14,  3,  5])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader_train):\n",
    "    if i >= 1:\n",
    "        break\n",
    "    # end\n",
    "    \n",
    "    info_batch = batch()\n",
    "    print('ids_encoder')\n",
    "    print(info_batch['ids_encoder'])\n",
    "    print('\\n\\nlabels_encoder')\n",
    "    print(info_batch['labels_encoder'])\n",
    "    print('\\n\\nmasks_encoder')\n",
    "    print(info_batch['masks_encoder'])\n",
    "    print('\\n\\nids_decoder')\n",
    "    print(info_batch['ids_decoder'])\n",
    "    print('\\n\\nlabels_decoder')\n",
    "    print(info_batch['labels_decoder'])\n",
    "    print('\\n\\nmasks_decoder')\n",
    "    print(info_batch['masks_decoder'])    \n",
    "    print('\\n\\nsegments_label')\n",
    "    print(info_batch['segments_label'])\n",
    "    \n",
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
