{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a0b152-7fa4-497b-a465-af0a373b80e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-26T09:56:07] start main_train_and_evaluate with data/202205240000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 1171\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-26T09:56:15] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1617' max='2940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1617/2940 05:58 < 04:54, 4.50 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.248500</td>\n",
       "      <td>0.579775</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.886217</td>\n",
       "      <td>0.856725</td>\n",
       "      <td>0.833816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.215666</td>\n",
       "      <td>0.946565</td>\n",
       "      <td>0.946578</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.945013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.152964</td>\n",
       "      <td>0.969466</td>\n",
       "      <td>0.970635</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.969299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.161289</td>\n",
       "      <td>0.969466</td>\n",
       "      <td>0.970635</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.969299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.099191</td>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.984962</td>\n",
       "      <td>0.984759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.140543</td>\n",
       "      <td>0.969466</td>\n",
       "      <td>0.970635</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.969299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.108569</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.977021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.153244</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>0.978195</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.977026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.148472</td>\n",
       "      <td>0.969466</td>\n",
       "      <td>0.969841</td>\n",
       "      <td>0.969925</td>\n",
       "      <td>0.969315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.134805</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>0.978195</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.977026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.152270</td>\n",
       "      <td>0.977099</td>\n",
       "      <td>0.978195</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.977026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-147\n",
      "Configuration saved in results/checkpoint-147/config.json\n",
      "Model weights saved in results/checkpoint-147/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-735] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-294\n",
      "Configuration saved in results/checkpoint-294/config.json\n",
      "Model weights saved in results/checkpoint-294/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1029] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-441\n",
      "Configuration saved in results/checkpoint-441/config.json\n",
      "Model weights saved in results/checkpoint-441/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1176] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-588\n",
      "Configuration saved in results/checkpoint-588/config.json\n",
      "Model weights saved in results/checkpoint-588/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1323] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-735\n",
      "Configuration saved in results/checkpoint-735/config.json\n",
      "Model weights saved in results/checkpoint-735/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1470] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-882\n",
      "Configuration saved in results/checkpoint-882/config.json\n",
      "Model weights saved in results/checkpoint-882/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1617] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-1029\n",
      "Configuration saved in results/checkpoint-1029/config.json\n",
      "Model weights saved in results/checkpoint-1029/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-147] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-1176\n",
      "Configuration saved in results/checkpoint-1176/config.json\n",
      "Model weights saved in results/checkpoint-1176/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-294] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-1323\n",
      "Configuration saved in results/checkpoint-1323/config.json\n",
      "Model weights saved in results/checkpoint-1323/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-441] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-1470\n",
      "Configuration saved in results/checkpoint-1470/config.json\n",
      "Model weights saved in results/checkpoint-1470/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-588] due to args.save_total_limit\n",
      "<ipython-input-1-7f1de6c70702>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 131\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to results/checkpoint-1617\n",
      "Configuration saved in results/checkpoint-1617/config.json\n",
      "Model weights saved in results/checkpoint-1617/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-882] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-735 (score: 0.984759195285511).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import BoolTensor\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, EarlyStoppingCallback\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "DEVICE_DEFAULT = 'cuda'\n",
    "\n",
    "\n",
    "def get_ts():\n",
    "    return datetime.utcnow().replace(microsecond=0).isoformat()\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    # end\n",
    "\n",
    "\n",
    "# end\n",
    "\n",
    "def read_passages(path_data, path_label, test_size=0):\n",
    "    df = pd.read_csv(path_data)\n",
    "\n",
    "    documents = df['processed'].to_list()\n",
    "    labels_str = df['target'].to_list()\n",
    "\n",
    "    samples = documents\n",
    "\n",
    "    with open(path_label, 'r') as file:\n",
    "        labels_list = sorted(json.load(file))\n",
    "    # end\n",
    "\n",
    "    labels_all = {l: idx for idx, l in enumerate(labels_list)}\n",
    "\n",
    "    labels = [labels_all[label_str] for label_str in labels_str]\n",
    "\n",
    "    if test_size > 0:\n",
    "        return train_test_split(samples, labels, test_size=test_size, stratify=labels, random_state=234), labels_list\n",
    "    else:\n",
    "        return (samples, samples, labels, labels), labels_list\n",
    "    # end\n",
    "\n",
    "\n",
    "# end\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.reshape(-1)\n",
    "    preds = pred.predictions.argmax(-1).reshape(-1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    precision = precision_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "\n",
    "# end\n",
    "\n",
    "def predict_plus(input_tokenized, model):\n",
    "    masks_sample = input_tokenized.attention_mask\n",
    "\n",
    "    indicates_sample = BoolTensor(masks_sample == 1)\n",
    "    indicates_sample = indicates_sample.to(DEVICE_DEFAULT)\n",
    "\n",
    "    out = model(**input_tokenized.to(DEVICE_DEFAULT), output_attentions=True)\n",
    "\n",
    "    logits = out.logits.cpu()\n",
    "    attentions = out.attentions[-1].cpu()\n",
    "\n",
    "    attentions_sum = torch.masked_select((torch.sum(attentions[:, :, 0, :], 1) / attentions.shape[1])[0],\n",
    "                                         indicates_sample).tolist()[1:-1]\n",
    "\n",
    "    return logits, attentions_sum\n",
    "\n",
    "\n",
    "# end\n",
    "\n",
    "def main_train(path_train, path_label, model_name, max_length, output_dir):\n",
    "    print('[{}] start main_train_and_evaluate with {}'.format(get_ts(), path_train))\n",
    "\n",
    "    (train_samples, valid_samples, train_labels, valid_labels), target_names = read_passages(path_train, path_label, 0.1)\n",
    "\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
    "    train_encodings = tokenizer.batch_encode_plus(train_samples, truncation=True, padding=True, max_length=max_length,\n",
    "                                                  return_tensors='pt')\n",
    "    valid_encodings = tokenizer.batch_encode_plus(valid_samples, truncation=True, padding=True, max_length=max_length,\n",
    "                                                  return_tensors='pt')\n",
    "\n",
    "    train_dataset = SimpleDataset(train_encodings, train_labels)\n",
    "    valid_dataset = SimpleDataset(valid_encodings, valid_labels)\n",
    "\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names))\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,  # output directory\n",
    "        num_train_epochs=20,  # total number of training epochs\n",
    "        per_device_train_batch_size=8,  # batch size per device during training\n",
    "        per_device_eval_batch_size=8,  # batch size for evaluation\n",
    "        warmup_steps=0,  # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,  # strength of weight decay\n",
    "        logging_dir='./logs',  # directory for storing logs\n",
    "        load_best_model_at_end=True,\n",
    "        # load the best model when finished training (default metric is loss)    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "        logging_steps=1,  # log & save weights each logging_steps\n",
    "        evaluation_strategy=\"epoch\",  # evaluate each `logging_steps`\n",
    "        learning_rate=2e-5,\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=6,\n",
    "        metric_for_best_model='f1'\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,  # the instantiated Transformers model to be trained\n",
    "        args=training_args,  # training arguments, defined above\n",
    "        train_dataset=train_dataset,  # training dataset\n",
    "        eval_dataset=valid_dataset,  # evaluation dataset\n",
    "        compute_metrics=compute_metrics,  # the callback that computes metrics of interest\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=6)]\n",
    "    )\n",
    "\n",
    "    print('[{}] start training...'.format(get_ts()))\n",
    "    trainer.train()\n",
    "\n",
    "    return model, tokenizer\n",
    "# end\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "max_length = 512\n",
    "\n",
    "folder_data = 'data'\n",
    "filename_data = '202205240000.csv'\n",
    "filename_label = 'labels.json'\n",
    "output_dir = 'results'\n",
    "\n",
    "path_file_data = os.path.join(folder_data, filename_data)\n",
    "path_file_label = os.path.join(folder_data, filename_label)\n",
    "\n",
    "model, tokenizer = main_train(path_file_data, path_file_label, model_name, max_length, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd20bbf-6b4b-4406-bde4-c602709981f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, Tuple\n",
    "from types import MethodType\n",
    "import math\n",
    "from torch import nn\n",
    "from torch import BoolTensor\n",
    "\n",
    "\n",
    "def replace_model_function(model):\n",
    "\n",
    "    def forward_version_jinyuj(\n",
    "            self,\n",
    "            query: torch.Tensor,\n",
    "            key: torch.Tensor,\n",
    "            value: torch.Tensor,\n",
    "            mask: torch.Tensor,\n",
    "            head_mask: Optional[torch.Tensor] = None,\n",
    "            output_attentions: bool = False,\n",
    "    ) -> Tuple[torch.Tensor, ...]:\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            query: torch.tensor(bs, seq_length, dim)\n",
    "            key: torch.tensor(bs, seq_length, dim)\n",
    "            value: torch.tensor(bs, seq_length, dim)\n",
    "            mask: torch.tensor(bs, seq_length)\n",
    "\n",
    "        Returns:\n",
    "            weights: torch.tensor(bs, n_heads, seq_length, seq_length) Attention weights context: torch.tensor(bs,\n",
    "            seq_length, dim) Contextualized layer. Optional: only if `output_attentions=True`\n",
    "        \"\"\"\n",
    "\n",
    "        # print('[ jinyuj] run jinyuj version of forward')\n",
    "        bs, q_length, dim = query.size()\n",
    "        k_length = key.size(1)\n",
    "        # assert dim == self.dim, f'Dimensions do not match: {dim} input vs {self.dim} configured'\n",
    "        # assert key.size() == value.size()\n",
    "\n",
    "        dim_per_head = self.dim // self.n_heads\n",
    "\n",
    "        mask_reshp = (bs, 1, 1, k_length)\n",
    "\n",
    "        def shape(x: torch.Tensor) -> torch.Tensor:\n",
    "            \"\"\"separate heads\"\"\"\n",
    "            return x.view(bs, -1, self.n_heads, dim_per_head).transpose(1, 2)\n",
    "\n",
    "        def unshape(x: torch.Tensor) -> torch.Tensor:\n",
    "            \"\"\"group heads\"\"\"\n",
    "            return x.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * dim_per_head)\n",
    "\n",
    "        q = shape(self.q_lin(query))  # (bs, n_heads, q_length, dim_per_head)\n",
    "        k = shape(self.k_lin(key))  # (bs, n_heads, k_length, dim_per_head)\n",
    "        v = shape(self.v_lin(value))  # (bs, n_heads, k_length, dim_per_head)\n",
    "\n",
    "        q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\n",
    "        scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)\n",
    "        mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)\n",
    "        scores = scores.masked_fill(\n",
    "            mask, torch.tensor(torch.finfo(scores.dtype).min)\n",
    "        )  # (bs, n_heads, q_length, k_length)\n",
    "\n",
    "        weights = nn.functional.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)\n",
    "        # weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            weights = weights * head_mask\n",
    "\n",
    "        context = torch.matmul(weights, v)  # (bs, n_heads, q_length, dim_per_head)\n",
    "        context = unshape(context)  # (bs, q_length, dim)\n",
    "\n",
    "        context = self.out_lin(context)  # (bs, q_length, dim)\n",
    "        \n",
    "        self.my_param = {'w_pt': weights, 'v_pt': v, 'n_heads': self.n_heads, 'dim_hidden': dim_per_head, 'bs': bs, 'x_pt': query, 'out_pt': context}\n",
    "        \n",
    "\n",
    "        if output_attentions:\n",
    "            return (context, weights)\n",
    "        else:\n",
    "            return (context,)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    target = model.distilbert.transformer.layer[-1].attention\n",
    "    target.forward = MethodType(forward_version_jinyuj, target)\n",
    "    return target\n",
    "# end\n",
    "\n",
    "def predict_plus(sample_test, tokenizer, model, target, max_length=512):\n",
    "    input_tokenized = tokenizer.encode_plus(sample_test, padding=True, truncation=True, max_length=max_length,\n",
    "                                        return_tensors='pt')\n",
    "\n",
    "    masks_sample = input_tokenized.attention_mask\n",
    "    indicates_sample = BoolTensor(masks_sample == 1)\n",
    "    indicates_sample = indicates_sample.to(DEVICE_DEFAULT)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(**input_tokenized.to(DEVICE_DEFAULT), output_attentions=True)\n",
    "    # end\n",
    "\n",
    "    logits = out.logits.cpu()\n",
    "    attentions = out.attentions[-1].cpu()\n",
    "\n",
    "    attentions_sum = torch.masked_select((torch.sum(attentions[:, :, 0, :], 1) / attentions.shape[1])[0],\n",
    "                        indicates_sample).tolist()\n",
    "\n",
    "    my_param = target.my_param\n",
    "\n",
    "    return my_param, logits, attentions_sum()\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d968c9c-69b4-4dda-863d-a76b2c8a7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine(v_1, v_2):\n",
    "    return np.dot(v_1, v_2) / (norm(v_1) * norm(v_2))\n",
    "# end\n",
    "\n",
    "def unshape(x, n_heads, dim_hidden, bs):\n",
    "    return x.transpose(0, 2, 1, 3).reshape(bs, -1, n_heads * dim_hidden)\n",
    "# end\n",
    "\n",
    "def unshape_pt(x, n_heads, dim_hidden, bs):\n",
    "    return x.transpose(1, 2).contiguous().view(bs, -1, n_heads * dim_hidden)\n",
    "# end\n",
    "\n",
    "def investigation(w_pt=None, v_pt=None, n_heads=None, dim_hidden=None, bs=None, **kwargs):    # w=(bs, n_heads, seq_q, seq_k), v=(bs, n_heads, seq_k, dim_hidden)\n",
    "    \n",
    "    w = w_pt.detach().clone().cpu().numpy()\n",
    "    v = v_pt.detach().clone().cpu().numpy()\n",
    "    \n",
    "    embedding_cls = np.matmul(w[:,:,0,:], v)    # (bs, n_head, 1, dim_hidden)\n",
    "\n",
    "    embedding_cls_unshape = unshape(embedding_cls, n_heads, dim_hidden, bs) # (bs, 1, dim)\n",
    "    v_unshape = unshape(v, n_heads, dim_hidden, bs) # (bs, seq_k, dim*n_heads)\n",
    "\n",
    "    # calculate original cosine\n",
    "    list_cosine_cls_v = []\n",
    "    for i_bs in range(bs):\n",
    "        bs_cosine_cls_v = []\n",
    "\n",
    "        for i in range(v_unshape.shape[1]):\n",
    "            bs_cosine_cls_v.append(cosine(embedding_cls_unshape[i_bs, 0, :], v_unshape[i_bs, i, :]))\n",
    "        # end\n",
    "\n",
    "        list_cosine_cls_v.append(bs_cosine_cls_v)\n",
    "    # end\n",
    "\n",
    "\n",
    "    # calculate impact cosine\n",
    "    list_cosine_cls_cls_delta = []\n",
    "    list_cls_delta_unshape = []\n",
    "\n",
    "    for i in range(v.shape[2]):\n",
    "        v_current = v.copy()\n",
    "        v_current[:,:,i,:] = 0\n",
    "        embedding_cls_delta = np.matmul(w[:, :, 0, :], v_current)    # (bs, n_heads, 1, seq_k) x (bs, n_head, seq_k, dim_hidden)\n",
    "        embedding_cls_delta_unshape = unshape(embedding_cls_delta, n_heads, dim_hidden, bs)    # (bs, 1, dim*n_heads)\n",
    "\n",
    "        bs_cosine_cls_cls_delta = []\n",
    "        for i_bs in range(bs):\n",
    "            bs_cosine_cls_cls_delta.append(cosine(embedding_cls_unshape[i_bs, 0, :], embedding_cls_delta_unshape[i_bs, 0, :]))\n",
    "            list_cls_delta_unshape.append(embedding_cls_delta_unshape[i_bs, 0, :])\n",
    "        # end\n",
    "\n",
    "        list_cosine_cls_cls_delta.append(bs_cosine_cls_cls_delta)\n",
    "    # end\n",
    "\n",
    "    return list_cosine_cls_v, list_cosine_cls_cls_delta, embedding_cls_unshape[i_bs, 0, :], list_cls_delta_unshape\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd3797d7-7145-4064-a4c3-d36f476d0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "labels = [\"product\", \"testcase\", \"testbed\", \"usererror\", \"targetvm\", \"nimbus\", \"infra\"]\n",
    "# sample_test = 'timestamp failed at play check os full name timestamp task verify guest full name in guest info is expected fatal localhost failed guest full name in guest info microsoft windows server number number b it is not the same as expected one'\n",
    "sample_test = 'failed guest full name'\n",
    "sample_tokenized = tokenizer.encode_plus(sample_test, padding=True, truncation=True, max_length=max_length,\n",
    "                                        return_tensors='pt')\n",
    "\n",
    "target = replace_model_function(model)\n",
    "out = model(**sample_tokenized.to(DEVICE_DEFAULT))\n",
    "preds = softmax(out.logits.detach().cpu().numpy().squeeze(0))\n",
    "my_param = target.my_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71ee03aa-74c4-4382-b868-3ad2954f23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cosine_cls_v, list_cosine_cls_cls_delta, embedding_cls_unshape, list_cls_delta_unshape = investigation(**my_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9bcb2cb9-4dcb-4ccc-a11d-0c4862bb3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer.decode(i) for i in sample_tokenized.input_ids[0]]\n",
    "attention = my_param['w_pt'].clone().detach().cpu().numpy().mean(1).squeeze(0)[0,:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5328582f-e381-4cc1-be25-654e08ad94f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('product', 0.02952733),\n",
       " ('testcase', 0.04065845),\n",
       " ('testbed', 0.09369221),\n",
       " ('usererror', 0.12102889),\n",
       " ('targetvm', 0.024749966),\n",
       " ('nimbus', 0.6562893),\n",
       " ('infra', 0.034053694)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(a,b) for a,b in zip(labels, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e2f059eb-b3d8-4aea-92f3-cf5933dc2e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 0.97704524, 0.05038498342037201, 0.64797926),\n",
       " ('failed', 0.9008743, 0.30575433373451233, 0.85002106),\n",
       " ('guest', 0.98406416, 0.09968140721321106, 0.8043557),\n",
       " ('full', 0.9987719, 0.04141746088862419, 0.69122773),\n",
       " ('name', 0.9926224, 0.09466409683227539, 0.7638469),\n",
       " ('[SEP]', 0.99575186, 0.4080977439880371, 0.39237162)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted([(a, b[0], c,d) for a, b, c,d in zip(tokens, list_cosine_cls_cls_delta, attention, list_cosine_cls_v[0])], key=lambda item: -item[1])\n",
    "# [(a, b[0], c, d, c * d) for a, b, c,d in zip(tokens, list_cosine_cls_cls_delta, attention, list_cosine_cls_v[0])]\n",
    "[(a, b[0], c, d) for a, b, c,d in zip(tokens, list_cosine_cls_cls_delta, attention, list_cosine_cls_v[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6a779a90-df03-429d-a36e-19c9cf789a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_cls_unshape - list_cls_delta_unshape[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53c4bcab-3ab8-4558-a702-ff1470f87823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_cls_unshape - embedding_cls_unshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1e2d8c9-482b-4c1a-a991-5c760a1a0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myforward(model, x_pt, out_pt):\n",
    "    x_pt = x_pt.detach().clone()\n",
    "    out_pt = out_pt.detach().clone()\n",
    "    \n",
    "    a = model.distilbert.transformer.layer[-1]\n",
    "    a_attention = a.attention\n",
    "    a_norm = a.sa_layer_norm\n",
    "    a_ffn = a.ffn\n",
    "    a_out = a.output_layer_norm\n",
    "\n",
    "    b = model.pre_classifier\n",
    "    c = model.dropout\n",
    "    d = model.classifier\n",
    "\n",
    "    sa_output = a_norm(out_pt + x_pt)\n",
    "    ffn_output = a_ffn(sa_output)\n",
    "    ffn_output = a_out(ffn_output + sa_output)\n",
    "    out_a = ffn_output\n",
    "    pooled_output = out_a[:,0]\n",
    "    logits_jinyuj = d(c(nn.ReLU()(b(pooled_output))))\n",
    "    preds_jinyuj = softmax(logits_jinyuj.detach().cpu().numpy().squeeze(0))\n",
    "\n",
    "    return preds_jinyuj\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d149de14-75f6-4d08-8569-3f7fb8c0e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_outpt(target, w_pt, v_pt, n_heads, dim_hidden, bs, index_v_tuning=None):\n",
    "    w_pt = w_pt.detach().clone()    # (bs, n_heads, q_length, k_length)\n",
    "    v_pt = v_pt.detach().clone()    # (bs, n_hreads, k_length, dim_hidden)\n",
    "\n",
    "    if index_v_tuning:\n",
    "        v_pt[:,:,index_v_tuning,:] = 0\n",
    "    # end\n",
    "\n",
    "    z_pt = torch.matmul(w_pt, v_pt)  # (bs, n_heads, q_length, dim_hidden)\n",
    "    z_pt_unshape = unshape_pt(z_pt, n_heads, dim_hidden, bs)  # (bs, q_length, dim_hidden * n_heads)\n",
    "\n",
    "    out_pt = target.out_lin(z_pt_unshape)  # (bs, q_length, dim)\n",
    "    return out_pt\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "79b4cb32-52a2-43f7-bcb8-8104d85c7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "impacts = []\n",
    "diffs = []\n",
    "\n",
    "# myout_pt = my_outpt(target, my_param['w_pt'], my_param['v_pt'], my_param['n_heads'], my_param['dim_hidden'], my_param['bs'])\n",
    "for i in range(my_param['v_pt'].shape[2]):\n",
    "    myout_pt = my_outpt(target, my_param['w_pt'], my_param['v_pt'], my_param['n_heads'], my_param['dim_hidden'], my_param['bs'], i)\n",
    "    preds_jinyuj = myforward(model, my_param['x_pt'], myout_pt)\n",
    "    impacts.append(np.mean(abs(preds_jinyuj - preds)))\n",
    "    diffs.append((preds - preds_jinyuj).tolist())\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "61b1568a-f6e0-4064-9bff-e65d918c61c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['product', 'testcase', 'testbed', 'usererror', 'targetvm', 'nimbus', 'infra']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f41171cb-0d8f-4548-8e48-a48507b42d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#0: [CLS] <0.00000000,0.00000000,0.00000000,0.00000000,0.00000000,0.00000000,0.00000000>',\n",
       " '#1: failed <-0.05385577,-0.04783045,-0.07102384,-0.03167168,-0.06064560,0.29308793,-0.02806073>',\n",
       " '#2: guest <-0.01016757,-0.01674532,-0.02724136,0.00564633,-0.01159035,0.06952024,-0.00942210>',\n",
       " '#3: full <-0.00424204,-0.00539367,-0.01261340,0.00117198,-0.00368822,0.02828062,-0.00351550>',\n",
       " '#4: name <-0.00781824,-0.01307989,-0.01972469,-0.00422693,-0.01221539,0.06655574,-0.00949069>',\n",
       " '#5: [SEP] <-0.00242660,-0.00338863,-0.00767665,0.00192922,-0.00222145,0.01385921,-0.00007525>']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [('id', 'token', 'delta', 'impact', 'attention', 'cosine')] + [(i, a, b[0], c, d, e) for i, a, b, c,d, e in zip(range(len(tokens)), tokens, list_cosine_cls_cls_delta, impacts, attention, list_cosine_cls_v[0])]\n",
    "# sorted([(i, a, b[0], c, d, e) for i, a, b, c,d, e in zip(range(len(tokens)), tokens, list_cosine_cls_cls_delta, impacts, attention, list_cosine_cls_v[0])], key=lambda item: -item[3])\n",
    "\n",
    "diffs_str = []\n",
    "for diff in diffs:\n",
    "    diffs_str.append(['{:.8f}'.format(i) for i in diff])\n",
    "# end\n",
    "\n",
    "['#{}: {} <{}>'.format(a,b,','.join(c)) for a,b,c in zip(range(len(tokens)), tokens, diffs_str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f1f529de-9c85-48c6-9d3c-fca13551fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def predict_and_investigate_logits(sample_test, tokenizer, model):\n",
    "    elements_sample_test = sample_test.split()\n",
    "    preds_all = []\n",
    "    tokens_removed = []\n",
    "    \n",
    "    for i in range(len(elements_sample_test)):\n",
    "        sample_current = copy(elements_sample_test)\n",
    "        tokens_removed.append(sample_current.pop(i))\n",
    "        \n",
    "        # print(' '.join(sample_current))\n",
    "        input_tokenized = tokenizer.encode_plus(' '.join(sample_current), padding=True, truncation=True, max_length=max_length,\n",
    "                                        return_tensors='pt')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(**input_tokenized.to(DEVICE_DEFAULT), output_attentions=True)\n",
    "        # end\n",
    "\n",
    "        logits = out.logits.cpu()\n",
    "        preds = softmax(logits.numpy().squeeze(0))\n",
    "        preds_all.append(preds)\n",
    "    # end\n",
    "    \n",
    "    return preds_all, tokens_removed\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "70af5f1d-5bdd-4e81-9fda-fdf7c149f12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('failed', 5, 0.42458412),\n",
       " ('guest', 5, 0.48809105),\n",
       " ('full', 5, 0.58696437),\n",
       " ('name', 5, 0.73717934)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_test = 'timestamp failed at play check quiesce snapshot timestamp task check specified file status until it exists in windows guest fatal localhost ip address failed'\n",
    "sample_test = 'failed guest full name'\n",
    "preds_all ,tokens_removed = predict_and_investigate_logits(sample_test, tokenizer, model)\n",
    "results = [np.argmax(pred_all) for pred_all in preds_all]\n",
    "confidences = [pred_all[np.argmax(pred_all)] for pred_all in preds_all]\n",
    "[(a,b,c) for a,b,c in zip(tokens_removed, results, confidences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6997d09c-4694-4cdf-81c9-af72708e0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_train = 'data/202205240000.csv'\n",
    "# path_label = 'data/labels.json'\n",
    "# (train_samples, _, train_labels, _), target_names = read_passages(path_train, path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c85caf7d-5d48-41aa-88da-2591c1bc582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_weird = []\n",
    "\n",
    "# for train_sample in train_samples:\n",
    "#     preds_all, tokens_removed = predict_and_investigate_logits(train_sample, tokenizer, model)\n",
    "#     results = [np.argmax(pred_all) for pred_all in preds_all]\n",
    "#     if len(set(results)) > 1:\n",
    "#         samples_weird.append(train_sample)\n",
    "#     # end\n",
    "# # end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c628fc5-ddf8-4b60-8201-492825ea72d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp failed at play check quiesce snapshot timestamp task check specified file status until it exists in windows guest fatal localhost ip address failed',\n",
       " 'timestamp failed at play para virtual v hba device ops timestamp task run io zone test on new added disk fatal localhost ip address failed non zero return code',\n",
       " 'timestamp failed at play check os full name timestamp task verify guest full name in guest info is expected fatal localhost failed guest full name in guest info microsoft windows server number number b it is not the same as expected one',\n",
       " 'timestamp failed at play deploy vm bios nvme timestamp task set vm boot options fatal localhost failed efi secure boot can not be enabled when boot firmware bios vm s boot firmware currently set to bios timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme e number e',\n",
       " 'timestamp failed at play environment setup timestamp task enable guest ip hack on esxi host ip address fatal localhost un reachable failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo vmfs volumes data store number mkdir echo vmfs volumes data store number ansible tmp hex id number timestamp echo ansible tmp hex id number timestamp echo vmfs volumes data store number ansible tmp hex id number timestamp exited with result number',\n",
       " 'timestamp failed at play environment setup timestamp task enable guest ip hack on esxi host ip address fatal localhost un reachable failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo vmfs volumes data store number mkdir echo vmfs volumes data store number ansible tmp hex id number number timestamp echo ansible tmp hex id number number timestamp echo vmfs volumes data store number ansible tmp hex id number number timestamp exited with result number',\n",
       " 'timestamp failed at play go sc cloud init static ip timestamp task get default gateway fatal localhost failed non zero return code when cat',\n",
       " 'timestamp failed at play go sc sanity static ip timestamp task execute powershell command in windows guest fatal localhost ip address failed non zero return code when remove appx provisioned package timestamp task fetch file c windows temp vmware imc guest cust log from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed guest file c windows temp vmware imc guest cust log does not exist file c windows temp vmware imc guest cust log was not found',\n",
       " 'timestamp failed at play ovt verify install timestamp task collect filtered guest information for ip address fatal localhost un reachable failed to connect to the host via ssh warning permanently added ip address to the list of known hosts root ip address permission denied public key gss api k eye x gss api with mic',\n",
       " 'timestamp failed at play environment setup timestamp task check super shell fatal localhost un reachable failed to connect to the host via ssh root ip address permission denied public key keyboard interactive',\n",
       " 'timestamp failed at play environment setup timestamp task get shell executable on esxi server fatal localhost un reachable failed to connect to the host via ssh root ip address permission denied public key keyboard interactive',\n",
       " 'timestamp failed at play deploy vm efi para virtual timestamp task configure vm cdrom to client exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number 110 connection timed out timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed',\n",
       " 'timestamp failed at play environment setup timestamp task check super shell fatal localhost un reachable failed to connect to the host via ssh root ip address permission denied public key keyboard interactive',\n",
       " 'timestamp failed at play ovt verify install timestamp task collect filtered guest information for ip address fatal localhost un reachable failed to connect to the host via ssh warning permanently added ip address to the list of known hosts root ip address permission denied public key gss api k eye x gss api with mic',\n",
       " 'timestamp failed at play environment setup timestamp task get shell executable on esxi server fatal localhost un reachable failed to connect to the host via ssh root ip address permission denied public key keyboard interactive',\n",
       " 'timestamp failed at play deploy vm efi para virtual timestamp task configure vm cdrom to client exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number 110 connection timed out timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed',\n",
       " 'timestamp failed at play ovt verify install timestamp task create snapshot base snapshot on test vm fatal localhost failed unable to retrieve the current working directory number input output error check if the directory has been deleted or un mounted',\n",
       " 'timestamp failed at play ovt verify install timestamp task collect filtered guest information for ip address fatal localhost un reachable failed to connect to the host via ssh warning permanently added ip address to the list of known hosts root ip address permission denied public key',\n",
       " 'timestamp failed at play sata v hba device ops timestamp task run io zone test on new added disk fatal localhost ip address failed non zero return code']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_weird"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
