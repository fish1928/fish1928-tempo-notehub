{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f80016b-c9bb-4700-bde6-2086a1458a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from torch import BoolTensor\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, EarlyStoppingCallback\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import json\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "DEVICE_DEFAULT = 'cuda'\n",
    "seed_val = 234\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "def get_ts():\n",
    "    return datetime.utcnow().replace(microsecond=0).isoformat()\n",
    "# end\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "def read_passages(path_data, labels_origin, test_size=0):\n",
    "    df = pd.read_csv(path_data)\n",
    "\n",
    "    documents = df['processed'].to_list()\n",
    "    labels_str = df['target'].to_list()\n",
    "\n",
    "    samples = documents\n",
    "\n",
    "    labels_list = sorted(labels_origin)\n",
    "\n",
    "    labels_all = {l: idx for idx, l in enumerate(labels_list)}\n",
    "\n",
    "    labels = [labels_all[label_str] for label_str in labels_str]\n",
    "\n",
    "    if test_size > 0:\n",
    "        return train_test_split(samples, labels, test_size=test_size, stratify=labels, random_state=234), labels_list\n",
    "    else:\n",
    "        return (samples, samples, labels, labels), labels_list\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.reshape(-1)\n",
    "    preds = pred.predictions.argmax(-1).reshape(-1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    precision = precision_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "# end\n",
    "\n",
    "def predict_plus(input_tokenized, model):\n",
    "    masks_sample = input_tokenized.attention_mask\n",
    "\n",
    "    indicates_sample = BoolTensor(masks_sample == 1)\n",
    "    indicates_sample = indicates_sample.to(DEVICE_DEFAULT)\n",
    "\n",
    "    out = model(**input_tokenized.to(DEVICE_DEFAULT), output_attentions=True)\n",
    "\n",
    "    logits = out.logits.cpu()\n",
    "    # attentions = out.attentions[-1].cpu()\n",
    "\n",
    "    # attentions_sum = torch.masked_select((torch.sum(attentions[:, :, 0, :], 1) / attentions.shape[1])[0],\n",
    "                                         # indicates_sample).tolist()[1:-1]\n",
    "\n",
    "    # return logits, attentions_sum\n",
    "    return logits, None\n",
    "# end\n",
    "\n",
    "\n",
    "class TrainingEnvironment:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    # end\n",
    "\n",
    "    def add_label(self, labels):\n",
    "        self.labels = labels\n",
    "        return self\n",
    "    # end\n",
    "\n",
    "# end\n",
    "\n",
    "class ModelFramework_SequenceClassification:\n",
    "    FILENAME_CONFIG_FRAMEWORK = 'framework.json'\n",
    "    FILENAME_CHECKSUM = 'checksum.md5'\n",
    "    FOLDER_DATA = 'data'\n",
    "    FOLDER_OUTPUT = 'output'\n",
    "\n",
    "    CONFIG_FRAMEWORK_TEMPLATE = {   # model_full_name = '{model_name}-{model_version}'\n",
    "        'folder_structure': {\n",
    "            FOLDER_DATA: '# folder for train/eval data',\n",
    "            FILENAME_CONFIG_FRAMEWORK: '# jsonfile for framework configuration',\n",
    "            FILENAME_CHECKSUM: '# framework config checksum',\n",
    "            FOLDER_OUTPUT: '# folder for output'\n",
    "        },\n",
    "        'defaults': {\n",
    "            'model_name': 'distilbert-base-uncased',\n",
    "            'model': 'DistilBertForSequenceClassification',\n",
    "            'tokenizer': 'DistilBertTokenizerFast',\n",
    "            'tokenizer_name': 'distilbert-base-uncased',\n",
    "        },\n",
    "        'model': {\n",
    "            'model_name': '',\n",
    "            'model': '',\n",
    "            'tokenizer': '',\n",
    "            'labels': [],\n",
    "            'model_version': '',\n",
    "            'historical_datasets': []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self, path_folder_base):\n",
    "        self.path_folder_base = path_folder_base\n",
    "        self.config_framework = None\n",
    "\n",
    "        path_file_config_framework = os.path.join(path_folder_base, ModelFramework_SequenceClassification.FILENAME_CONFIG_FRAMEWORK)\n",
    "        if os.path.exists(path_file_config_framework):\n",
    "            with open(path_file_config_framework, 'r') as file:\n",
    "                self.config_framework = json.load(file)\n",
    "            # end\n",
    "\n",
    "            print('[INFO] config {} loaded'.format(path_file_config_framework))\n",
    "        else:\n",
    "            print('[WARN] please run ModelFramework_SequenceClassification.generate_default_config first.')\n",
    "        # end\n",
    "\n",
    "    # end\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def generate_default_config(cls, path_folder_base):\n",
    "        os.makedirs(path_folder_base, exist_ok=True)\n",
    "\n",
    "        path_file_config_framework = os.path.join(path_folder_base, cls.FILENAME_CONFIG_FRAMEWORK)\n",
    "\n",
    "        with open(path_file_config_framework, 'w+') as file:\n",
    "            file.write(json.dumps(ModelFramework_SequenceClassification.CONFIG_FRAMEWORK_TEMPLATE))\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def load_training_environment(self):\n",
    "        if not self.config_framework:\n",
    "            print('[ERROR] initialize failed, config_framework is not loaded')\n",
    "            return None\n",
    "        # end\n",
    "\n",
    "        config_model = self.config_framework['model']\n",
    "\n",
    "        if not config_model['labels']:\n",
    "            print('[ERROR] please add labels into framework.config')\n",
    "            return None\n",
    "        # end\n",
    "\n",
    "        if not config_model['model']:\n",
    "            for k, v in self.config_framework['defaults'].items():  # fill model config by defaults\n",
    "                config_model[k] = v\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        model_name = config_model['model_name']\n",
    "        model_version = config_model['model_version']\n",
    "        labels = config_model['labels']\n",
    "\n",
    "        module_transformers = importlib.import_module('transformers')\n",
    "        klass_model = getattr(module_transformers, config_model['model'])\n",
    "        klass_tokenizer = getattr(module_transformers, config_model['tokenizer'])\n",
    "\n",
    "\n",
    "        name_model_full = f\"{model_name}-{model_version}\" if model_version else model_name\n",
    "        print('[INFO] loading model: {}'.format(name_model_full))\n",
    "        model = klass_model.from_pretrained(name_model_full, num_labels=len(labels))\n",
    "        # model = model.to('cpu')\n",
    "        \n",
    "        tokenizer_name = config_model.get('tokenizer_name', model_name)\n",
    "        print('[INFO] loading tokenizer: {}'.format(tokenizer_name))\n",
    "        tokenizer = klass_tokenizer.from_pretrained(tokenizer_name, do_lower_case=True)\n",
    "\n",
    "        env_training = TrainingEnvironment(model, tokenizer).add_label(labels)\n",
    "        return env_training\n",
    "    # end\n",
    "\n",
    "    # update config and save model\n",
    "    def save_training_environment(self, env_training, version_current):\n",
    "        model = env_training.model\n",
    "        config_model = self.config_framework['model']\n",
    "\n",
    "        name_model = config_model['model_name']\n",
    "        version_model = config_model['model_version']\n",
    "        name_model_full = f'{name_model}-{version_model}'\n",
    "        path_model = os.path.join(self.path_folder_base, name_model_full)\n",
    "        \n",
    "        if version_model:\n",
    "            subprocess.run('rm -rf {}'.format(path_model), shell=True)\n",
    "            print('[INFO] model {} cleared'.format(name_model_full))\n",
    "        # end\n",
    "\n",
    "        name_model_full_current = f'{name_model}-{version_current}'\n",
    "        path_model_current = os.path.join(self.path_folder_base, name_model_full_current)\n",
    "        print('[INFO] start to save {}'.format(path_model_current))\n",
    "        model.save_pretrained(path_model_current)\n",
    "        print('[INFO] model {} saved'.format(path_model_current))\n",
    "\n",
    "        config_model['model_version'] = version_current\n",
    "        config_model['historical_datasets'].append(version_model)\n",
    "\n",
    "        path_config_framework = os.path.join(self.path_folder_base, ModelFramework_SequenceClassification.FILENAME_CONFIG_FRAMEWORK)\n",
    "        with open(path_config_framework, 'w+') as file:\n",
    "            file.write(json.dumps(self.config_framework, indent=4))\n",
    "        # end\n",
    "        print('[INFO] config updated to {}'.format(version_current))\n",
    "    # end\n",
    "\n",
    "    def train_and_evaluate(self, env_training, path_train, path_test, path_output, path_checkpoint_model):\n",
    "        print('[INFO] [{}] start main_train_and_evaluate with {} {}'.format(get_ts(), path_train, path_test))\n",
    "\n",
    "        output_dir = path_checkpoint_model\n",
    "        labels = env_training.labels\n",
    "        (train_samples, valid_samples, train_labels, valid_labels), target_names = read_passages(path_train, labels, 0.1)\n",
    "\n",
    "        tokenizer = env_training.tokenizer\n",
    "        train_encodings = tokenizer.batch_encode_plus(train_samples, truncation=True, padding=True,\n",
    "                                                      max_length=MAX_LENGTH,\n",
    "                                                      return_tensors='pt')\n",
    "        valid_encodings = tokenizer.batch_encode_plus(valid_samples, truncation=True, padding=True,\n",
    "                                                      max_length=MAX_LENGTH,\n",
    "                                                      return_tensors='pt')\n",
    "\n",
    "        train_dataset = SimpleDataset(train_encodings, train_labels)\n",
    "        valid_dataset = SimpleDataset(valid_encodings, valid_labels)\n",
    "\n",
    "        model = env_training.model\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,  # output directory\n",
    "            num_train_epochs=8,  # total number of training epochs\n",
    "            per_device_train_batch_size=16,  # batch size per device during training\n",
    "            per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "            warmup_steps=0,  # number of warmup steps for learning rate scheduler\n",
    "            weight_decay=0.01,  # strength of weight decay\n",
    "            logging_dir='./logs',  # directory for storing logs\n",
    "            load_best_model_at_end=True,\n",
    "            # load the best model when finished training (default metric is loss)    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "            logging_steps=10,  # log & save weights each logging_steps\n",
    "            evaluation_strategy=\"epoch\",  # evaluate each `logging_steps`\n",
    "            learning_rate=2e-5,\n",
    "            save_strategy='epoch',\n",
    "            save_total_limit=3,\n",
    "            metric_for_best_model='f1'\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,  # the instantiated Transformers model to be trained\n",
    "            args=training_args,  # training arguments, defined above\n",
    "            train_dataset=train_dataset,  # training dataset\n",
    "            eval_dataset=valid_dataset,  # evaluation dataset\n",
    "            compute_metrics=compute_metrics,  # the callback that computes metrics of interest\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "        )\n",
    "\n",
    "        # trainer = Trainer(\n",
    "        #     model=model,  # the instantiated Transformers model to be trained\n",
    "        #     args=training_args,  # training arguments, defined above\n",
    "        #     train_dataset=train_dataset,  # training dataset\n",
    "        #     eval_dataset=valid_dataset,  # evaluation dataset\n",
    "        #     compute_metrics=compute_metrics\n",
    "        # )\n",
    "\n",
    "        print('[INFO] [{}] start training...'.format(get_ts()))\n",
    "        trainer.train()\n",
    "\n",
    "        info_state_model = trainer.evaluate()\n",
    "        print('[INFO] [{}] finish training.'.format(get_ts()))\n",
    "\n",
    "        ################## start to do eval ##################\n",
    "\n",
    "        (samples_test, _, indexs_label_test, _), target_names = read_passages(path_test, labels, 0)\n",
    "        labels_test = [target_names[index_label_test] for index_label_test in indexs_label_test]\n",
    "\n",
    "        list_conf_output = []\n",
    "        list_label_output = []\n",
    "        # list_attention_output = []\n",
    "\n",
    "        for sample_test, label_origin in zip(samples_test, labels_test):\n",
    "            input_tokenized = tokenizer.encode_plus(sample_test, padding=True, truncation=True, max_length=MAX_LENGTH,\n",
    "                                                    return_tensors='pt')\n",
    "            with torch.no_grad():\n",
    "                # out = model(**input_tokenized, output_hidden_states=True, output_attentions=True)\n",
    "                # logits_this, attention_this = predict_plus(input_tokenized, model)\n",
    "                logits_this, _ = predict_plus(input_tokenized, model)\n",
    "            # end\n",
    "\n",
    "            probas_evaluate = torch.nn.functional.softmax(logits_this, dim=-1)\n",
    "            answer_evaluate = int(probas_evaluate.argmax())\n",
    "            label_evaluate = target_names[answer_evaluate]\n",
    "\n",
    "            list_conf_output.append(probas_evaluate.numpy().tolist()[0][answer_evaluate])\n",
    "            list_label_output.append(label_evaluate)\n",
    "            # list_attention_output.append(attention_this)\n",
    "        # end\n",
    "\n",
    "        print('[INFO] [{}] finish testing.'.format(get_ts()))\n",
    "\n",
    "        pairs_label_conf = [[a, b, c] for a, b, c in zip(list_label_output, list_conf_output, labels_test)]\n",
    "\n",
    "        with open(path_output, 'w+') as file:\n",
    "            file.write(json.dumps(pairs_label_conf))\n",
    "        # end\n",
    "\n",
    "        print('[INFO] [{}] main_train_and_evaluate finished.'.format(get_ts()))\n",
    "    # end\n",
    "\n",
    "    def main(self, env_training):\n",
    "        path_folder_checkpoints = 'results'\n",
    "        path_folder_train = os.path.join(self.path_folder_base, ModelFramework_SequenceClassification.FOLDER_DATA)\n",
    "        filenames = sorted([filename for filename in os.listdir(path_folder_train) if filename[0] != '.' and 'train' in filename])\n",
    "\n",
    "        model_last = None\n",
    "\n",
    "        for _filename in filenames:\n",
    "            filename_base = _filename.split('_')[0]\n",
    "            version_current = int(filename_base)    # str_timestamp -> int\n",
    "\n",
    "            filename_test = f'{filename_base}_test.csv'\n",
    "            filename_train = _filename\n",
    "            filename_output = f'output-{filename_base}.json'\n",
    "\n",
    "            path_data_train = os.path.join(path_folder_train, filename_train)\n",
    "            path_data_test = os.path.join(path_folder_train, filename_test)\n",
    "            path_file_output = os.path.join(self.path_folder_base, ModelFramework_SequenceClassification.FOLDER_OUTPUT, filename_output)\n",
    "\n",
    "            self.train_and_evaluate(env_training, path_data_train, path_data_test, path_file_output, path_folder_checkpoints)\n",
    "            self.save_training_environment(env_training, version_current)\n",
    "\n",
    "            subprocess.run(f\"rm -rf {path_folder_checkpoints}\", shell=True)\n",
    "        # end\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6c5cd8-9d33-4a3e-9123-9148eace7400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] config ./framework.json loaded\n"
     ]
    }
   ],
   "source": [
    "framework = ModelFramework_SequenceClassification('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f371b6-d330-4ae3-a5b2-f00d142e8905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model: distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading tokenizer: distilbert-base-uncased\n",
      "[INFO] [2023-11-22T11:42:29] start main_train_and_evaluate with ./data/202206171000_train_0.35_15.csv ./data/202206171000_test.csv\n",
      "[INFO] [2023-11-22T11:42:35] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 17577\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8792\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7693' max='8792' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7693/8792 56:10 < 08:01, 2.28 it/s, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.038092</td>\n",
       "      <td>0.991295</td>\n",
       "      <td>0.991302</td>\n",
       "      <td>0.991295</td>\n",
       "      <td>0.991256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>0.997445</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>0.997442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>0.997485</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>0.997440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.998466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.020478</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>0.997463</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>0.997434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.997954</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.997950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.998464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-1099\n",
      "Configuration saved in results/checkpoint-1099/config.json\n",
      "Model weights saved in results/checkpoint-1099/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-2198\n",
      "Configuration saved in results/checkpoint-2198/config.json\n",
      "Model weights saved in results/checkpoint-2198/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3297\n",
      "Configuration saved in results/checkpoint-3297/config.json\n",
      "Model weights saved in results/checkpoint-3297/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-4396\n",
      "Configuration saved in results/checkpoint-4396/config.json\n",
      "Model weights saved in results/checkpoint-4396/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1099] due to args.save_total_limit\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-5495\n",
      "Configuration saved in results/checkpoint-5495/config.json\n",
      "Model weights saved in results/checkpoint-5495/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2198] due to args.save_total_limit\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6594\n",
      "Configuration saved in results/checkpoint-6594/config.json\n",
      "Model weights saved in results/checkpoint-6594/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-3297] due to args.save_total_limit\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-7693\n",
      "Configuration saved in results/checkpoint-7693/config.json\n",
      "Model weights saved in results/checkpoint-7693/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-5495] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-4396 (score: 0.9984657074255011).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123/123 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:39:57] finish training.\n",
      "[INFO] [2023-11-22T12:39:57] finish testing.\n",
      "[INFO] [2023-11-22T12:39:57] main_train_and_evaluate finished.\n",
      "[INFO] start to save ./distilbert-base-uncased-202206171000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202206171000/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202206171000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202206171000 saved\n",
      "[INFO] config updated to 202206171000\n",
      "[INFO] [2023-11-22T12:40:08] start main_train_and_evaluate with ./data/202207021500_train_0.35_15.csv ./data/202207021500_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:40:09] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1822\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 912\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/912 04:11 < 04:12, 1.81 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.012553</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.039398</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-114\n",
      "Configuration saved in results/checkpoint-114/config.json\n",
      "Model weights saved in results/checkpoint-114/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-228\n",
      "Configuration saved in results/checkpoint-228/config.json\n",
      "Model weights saved in results/checkpoint-228/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-342\n",
      "Configuration saved in results/checkpoint-342/config.json\n",
      "Model weights saved in results/checkpoint-342/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-456\n",
      "Configuration saved in results/checkpoint-456/config.json\n",
      "Model weights saved in results/checkpoint-456/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-228] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-114 (score: 0.9950587158761628).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:45:16] finish training.\n",
      "[INFO] [2023-11-22T12:45:17] finish testing.\n",
      "[INFO] [2023-11-22T12:45:17] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202206171000 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207021500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207021500/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207021500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207021500 saved\n",
      "[INFO] config updated to 202207021500\n",
      "[INFO] [2023-11-22T12:45:27] start main_train_and_evaluate with ./data/202207041600_train_0.35_15.csv ./data/202207041600_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:45:28] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1080\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 544\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/544 02:44 < 02:45, 1.64 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-68\n",
      "Configuration saved in results/checkpoint-68/config.json\n",
      "Model weights saved in results/checkpoint-68/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-136\n",
      "Configuration saved in results/checkpoint-136/config.json\n",
      "Model weights saved in results/checkpoint-136/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-204\n",
      "Configuration saved in results/checkpoint-204/config.json\n",
      "Model weights saved in results/checkpoint-204/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-272\n",
      "Configuration saved in results/checkpoint-272/config.json\n",
      "Model weights saved in results/checkpoint-272/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-136] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-68 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:49:08] finish training.\n",
      "[INFO] [2023-11-22T12:49:09] finish testing.\n",
      "[INFO] [2023-11-22T12:49:09] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207021500 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207041600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207041600/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207041600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207041600 saved\n",
      "[INFO] config updated to 202207041600\n",
      "[INFO] [2023-11-22T12:49:19] start main_train_and_evaluate with ./data/202207151000_train_0.35_15.csv ./data/202207151000_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:49:20] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 648\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 328\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/328 02:15 < 02:17, 1.19 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-41\n",
      "Configuration saved in results/checkpoint-41/config.json\n",
      "Model weights saved in results/checkpoint-41/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-82\n",
      "Configuration saved in results/checkpoint-82/config.json\n",
      "Model weights saved in results/checkpoint-82/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-123\n",
      "Configuration saved in results/checkpoint-123/config.json\n",
      "Model weights saved in results/checkpoint-123/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-164\n",
      "Configuration saved in results/checkpoint-164/config.json\n",
      "Model weights saved in results/checkpoint-164/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-82] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-41 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:52:31] finish training.\n",
      "[INFO] [2023-11-22T12:52:31] finish testing.\n",
      "[INFO] [2023-11-22T12:52:32] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207041600 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207151000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207151000/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207151000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207151000 saved\n",
      "[INFO] config updated to 202207151000\n",
      "[INFO] [2023-11-22T12:52:42] start main_train_and_evaluate with ./data/202207221500_train_0.35_15.csv ./data/202207221500_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:52:43] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1417\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 712\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='356' max='712' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [356/712 03:02 < 03:03, 1.94 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-89\n",
      "Configuration saved in results/checkpoint-89/config.json\n",
      "Model weights saved in results/checkpoint-89/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-178\n",
      "Configuration saved in results/checkpoint-178/config.json\n",
      "Model weights saved in results/checkpoint-178/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-267\n",
      "Configuration saved in results/checkpoint-267/config.json\n",
      "Model weights saved in results/checkpoint-267/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-356\n",
      "Configuration saved in results/checkpoint-356/config.json\n",
      "Model weights saved in results/checkpoint-356/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-89 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:56:41] finish training.\n",
      "[INFO] [2023-11-22T12:56:41] finish testing.\n",
      "[INFO] [2023-11-22T12:56:41] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207151000 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207221500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207221500/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207221500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207221500 saved\n",
      "[INFO] config updated to 202207221500\n",
      "[INFO] [2023-11-22T12:56:51] start main_train_and_evaluate with ./data/202207260728_train_0.35_15.csv ./data/202207260728_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T12:56:52] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1080\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 544\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/544 02:37 < 02:38, 1.72 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-68\n",
      "Configuration saved in results/checkpoint-68/config.json\n",
      "Model weights saved in results/checkpoint-68/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-136\n",
      "Configuration saved in results/checkpoint-136/config.json\n",
      "Model weights saved in results/checkpoint-136/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-204\n",
      "Configuration saved in results/checkpoint-204/config.json\n",
      "Model weights saved in results/checkpoint-204/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-272\n",
      "Configuration saved in results/checkpoint-272/config.json\n",
      "Model weights saved in results/checkpoint-272/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-136] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-68 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:00:24] finish training.\n",
      "[INFO] [2023-11-22T13:00:25] finish testing.\n",
      "[INFO] [2023-11-22T13:00:25] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207221500 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207260728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207260728/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207260728/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207260728 saved\n",
      "[INFO] config updated to 202207260728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:00:36] start main_train_and_evaluate with ./data/202208031141_train_0.35_15.csv ./data/202208031141_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:00:36] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/24 01:41 < 02:02, 0.10 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3\n",
      "Configuration saved in results/checkpoint-3/config.json\n",
      "Model weights saved in results/checkpoint-3/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-9\n",
      "Configuration saved in results/checkpoint-9/config.json\n",
      "Model weights saved in results/checkpoint-9/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-3 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:03:14] finish training.\n",
      "[INFO] [2023-11-22T13:03:14] finish testing.\n",
      "[INFO] [2023-11-22T13:03:14] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207260728 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202208031141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202208031141/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202208031141/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202208031141 saved\n",
      "[INFO] config updated to 202208031141\n",
      "[INFO] [2023-11-22T13:03:24] start main_train_and_evaluate with ./data/202208172100_train_0.35_15.csv ./data/202208172100_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:03:25] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 729\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 368\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [184/368 02:24 < 02:26, 1.26 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-46\n",
      "Configuration saved in results/checkpoint-46/config.json\n",
      "Model weights saved in results/checkpoint-46/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-92\n",
      "Configuration saved in results/checkpoint-92/config.json\n",
      "Model weights saved in results/checkpoint-92/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-138\n",
      "Configuration saved in results/checkpoint-138/config.json\n",
      "Model weights saved in results/checkpoint-138/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-184\n",
      "Configuration saved in results/checkpoint-184/config.json\n",
      "Model weights saved in results/checkpoint-184/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-92] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-46 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:06:45] finish training.\n",
      "[INFO] [2023-11-22T13:06:45] finish testing.\n",
      "[INFO] [2023-11-22T13:06:45] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202208031141 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202208172100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202208172100/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202208172100/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202208172100 saved\n",
      "[INFO] config updated to 202208172100\n",
      "[INFO] [2023-11-22T13:06:56] start main_train_and_evaluate with ./data/202208190706_train_0.35_15.csv ./data/202208190706_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:06:57] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 972\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 488\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='244' max='488' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [244/488 03:11 < 03:12, 1.26 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.034923</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.990734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.035843</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.990734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.044367</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.990734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.042748</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.990734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-61\n",
      "Configuration saved in results/checkpoint-61/config.json\n",
      "Model weights saved in results/checkpoint-61/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-122\n",
      "Configuration saved in results/checkpoint-122/config.json\n",
      "Model weights saved in results/checkpoint-122/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-183\n",
      "Configuration saved in results/checkpoint-183/config.json\n",
      "Model weights saved in results/checkpoint-183/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-244\n",
      "Configuration saved in results/checkpoint-244/config.json\n",
      "Model weights saved in results/checkpoint-244/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-122] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-61 (score: 0.9907335907335907).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:11:04] finish training.\n",
      "[INFO] [2023-11-22T13:11:04] finish testing.\n",
      "[INFO] [2023-11-22T13:11:05] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202208172100 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202208190706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202208190706/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202208190706/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202208190706 saved\n",
      "[INFO] config updated to 202208190706\n",
      "[INFO] [2023-11-22T13:11:15] start main_train_and_evaluate with ./data/202208240500_train_0.35_15.csv ./data/202208240500_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:11:16] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/24 01:41 < 02:01, 0.10 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3\n",
      "Configuration saved in results/checkpoint-3/config.json\n",
      "Model weights saved in results/checkpoint-3/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-9\n",
      "Configuration saved in results/checkpoint-9/config.json\n",
      "Model weights saved in results/checkpoint-9/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-3 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:13:52] finish training.\n",
      "[INFO] [2023-11-22T13:13:52] finish testing.\n",
      "[INFO] [2023-11-22T13:13:52] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202208190706 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202208240500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202208240500/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202208240500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202208240500 saved\n",
      "[INFO] config updated to 202208240500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:14:03] start main_train_and_evaluate with ./data/202209081034_train_0.35_15.csv ./data/202209081034_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:14:03] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 27\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/16 02:25 < 00:58, 0.07 it/s, Epoch 6/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.727473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.434253</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.034995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.116200</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.116200</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-2\n",
      "Configuration saved in results/checkpoint-2/config.json\n",
      "Model weights saved in results/checkpoint-2/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-4\n",
      "Configuration saved in results/checkpoint-4/config.json\n",
      "Model weights saved in results/checkpoint-4/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-8\n",
      "Configuration saved in results/checkpoint-8/config.json\n",
      "Model weights saved in results/checkpoint-8/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2] due to args.save_total_limit\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-10\n",
      "Configuration saved in results/checkpoint-10/config.json\n",
      "Model weights saved in results/checkpoint-10/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-4] due to args.save_total_limit\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-8] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-6 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:17:23] finish training.\n",
      "[INFO] [2023-11-22T13:17:24] finish testing.\n",
      "[INFO] [2023-11-22T13:17:24] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202208240500 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202209081034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202209081034/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202209081034/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202209081034 saved\n",
      "[INFO] config updated to 202209081034\n",
      "[INFO] [2023-11-22T13:17:34] start main_train_and_evaluate with ./data/202209081634_train_0.35_15.csv ./data/202209081634_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:17:35] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1863\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 936\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='468' max='936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [468/936 03:43 < 03:44, 2.08 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.105544</td>\n",
       "      <td>0.966184</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.965723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.096170</td>\n",
       "      <td>0.961353</td>\n",
       "      <td>0.967593</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.960279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.110797</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.957555</td>\n",
       "      <td>0.956303</td>\n",
       "      <td>0.956375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.155262</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>0.952140</td>\n",
       "      <td>0.951541</td>\n",
       "      <td>0.951599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-117\n",
      "Configuration saved in results/checkpoint-117/config.json\n",
      "Model weights saved in results/checkpoint-117/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-234\n",
      "Configuration saved in results/checkpoint-234/config.json\n",
      "Model weights saved in results/checkpoint-234/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-351\n",
      "Configuration saved in results/checkpoint-351/config.json\n",
      "Model weights saved in results/checkpoint-351/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-468\n",
      "Configuration saved in results/checkpoint-468/config.json\n",
      "Model weights saved in results/checkpoint-468/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-234] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-117 (score: 0.9657228017883756).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:22:14] finish training.\n",
      "[INFO] [2023-11-22T13:22:14] finish testing.\n",
      "[INFO] [2023-11-22T13:22:15] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202209081034 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202209081634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202209081634/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202209081634/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202209081634 saved\n",
      "[INFO] config updated to 202209081634\n",
      "[INFO] [2023-11-22T13:22:25] start main_train_and_evaluate with ./data/202209151400_train_0.35_15.csv ./data/202209151400_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:22:26] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 121\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 64\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/64 01:55 < 02:02, 0.26 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-8\n",
      "Configuration saved in results/checkpoint-8/config.json\n",
      "Model weights saved in results/checkpoint-8/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-16\n",
      "Configuration saved in results/checkpoint-16/config.json\n",
      "Model weights saved in results/checkpoint-16/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-32\n",
      "Configuration saved in results/checkpoint-32/config.json\n",
      "Model weights saved in results/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-16] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-8 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:25:16] finish training.\n",
      "[INFO] [2023-11-22T13:25:16] finish testing.\n",
      "[INFO] [2023-11-22T13:25:16] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202209081634 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202209151400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202209151400/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202209151400/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202209151400 saved\n",
      "[INFO] config updated to 202209151400\n",
      "[INFO] [2023-11-22T13:25:27] start main_train_and_evaluate with ./data/202210102130_train_0.35_15.csv ./data/202210102130_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:25:27] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 567\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 288\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='144' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [144/288 02:03 < 02:05, 1.15 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-36\n",
      "Configuration saved in results/checkpoint-36/config.json\n",
      "Model weights saved in results/checkpoint-36/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-72\n",
      "Configuration saved in results/checkpoint-72/config.json\n",
      "Model weights saved in results/checkpoint-72/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-108\n",
      "Configuration saved in results/checkpoint-108/config.json\n",
      "Model weights saved in results/checkpoint-108/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-144\n",
      "Configuration saved in results/checkpoint-144/config.json\n",
      "Model weights saved in results/checkpoint-144/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-72] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-36 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:28:26] finish training.\n",
      "[INFO] [2023-11-22T13:28:27] finish testing.\n",
      "[INFO] [2023-11-22T13:28:27] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202209151400 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210102130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210102130/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210102130/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210102130 saved\n",
      "[INFO] config updated to 202210102130\n",
      "[INFO] [2023-11-22T13:28:38] start main_train_and_evaluate with ./data/202210110644_train_0.35_15.csv ./data/202210110644_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:28:39] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3078\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1544\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='772' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 772/1544 05:38 < 05:39, 2.28 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-193\n",
      "Configuration saved in results/checkpoint-193/config.json\n",
      "Model weights saved in results/checkpoint-193/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-386\n",
      "Configuration saved in results/checkpoint-386/config.json\n",
      "Model weights saved in results/checkpoint-386/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-579\n",
      "Configuration saved in results/checkpoint-579/config.json\n",
      "Model weights saved in results/checkpoint-579/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-772\n",
      "Configuration saved in results/checkpoint-772/config.json\n",
      "Model weights saved in results/checkpoint-772/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-386] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-193 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:35:13] finish training.\n",
      "[INFO] [2023-11-22T13:35:14] finish testing.\n",
      "[INFO] [2023-11-22T13:35:14] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210102130 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210110644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210110644/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210110644/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210110644 saved\n",
      "[INFO] config updated to 202210110644\n",
      "[INFO] [2023-11-22T13:35:24] start main_train_and_evaluate with ./data/202210121247_train_0.35_15.csv ./data/202210121247_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:35:25] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 364\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 184\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 92/184 01:52 < 01:55, 0.80 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>0.468240</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.925517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>0.377383</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.925517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.359369</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.925517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.292039</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.925517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-23\n",
      "Configuration saved in results/checkpoint-23/config.json\n",
      "Model weights saved in results/checkpoint-23/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-46\n",
      "Configuration saved in results/checkpoint-46/config.json\n",
      "Model weights saved in results/checkpoint-46/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-69\n",
      "Configuration saved in results/checkpoint-69/config.json\n",
      "Model weights saved in results/checkpoint-69/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-92\n",
      "Configuration saved in results/checkpoint-92/config.json\n",
      "Model weights saved in results/checkpoint-92/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-46] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-23 (score: 0.9255172413793104).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:38:13] finish training.\n",
      "[INFO] [2023-11-22T13:38:13] finish testing.\n",
      "[INFO] [2023-11-22T13:38:13] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210110644 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210121247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210121247/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210121247/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210121247 saved\n",
      "[INFO] config updated to 202210121247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:38:24] start main_train_and_evaluate with ./data/202210130649_train_0.35_15.csv ./data/202210130649_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:38:24] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 13\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/8 01:38 < 03:17, 0.02 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.074746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-1\n",
      "Configuration saved in results/checkpoint-1/config.json\n",
      "Model weights saved in results/checkpoint-1/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-2\n",
      "Configuration saved in results/checkpoint-2/config.json\n",
      "Model weights saved in results/checkpoint-2/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3\n",
      "Configuration saved in results/checkpoint-3/config.json\n",
      "Model weights saved in results/checkpoint-3/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-4\n",
      "Configuration saved in results/checkpoint-4/config.json\n",
      "Model weights saved in results/checkpoint-4/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-1 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:40:59] finish training.\n",
      "[INFO] [2023-11-22T13:40:59] finish testing.\n",
      "[INFO] [2023-11-22T13:40:59] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210121247 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210130649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210130649/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210130649/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210130649 saved\n",
      "[INFO] config updated to 202210130649\n",
      "[INFO] [2023-11-22T13:41:09] start main_train_and_evaluate with ./data/202210181310_train_0.35_15.csv ./data/202210181310_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:41:10] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 24\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/24 01:41 < 02:02, 0.10 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3\n",
      "Configuration saved in results/checkpoint-3/config.json\n",
      "Model weights saved in results/checkpoint-3/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-9\n",
      "Configuration saved in results/checkpoint-9/config.json\n",
      "Model weights saved in results/checkpoint-9/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-3 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:43:47] finish training.\n",
      "[INFO] [2023-11-22T13:43:47] finish testing.\n",
      "[INFO] [2023-11-22T13:43:47] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210130649 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210181310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210181310/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210181310/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210181310 saved\n",
      "[INFO] config updated to 202210181310\n",
      "[INFO] [2023-11-22T13:43:57] start main_train_and_evaluate with ./data/202210200116_train_0.35_15.csv ./data/202210200116_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:43:58] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 270\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 136\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='136' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 68/136 02:17 < 02:21, 0.48 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.702000</td>\n",
       "      <td>0.094293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-17\n",
      "Configuration saved in results/checkpoint-17/config.json\n",
      "Model weights saved in results/checkpoint-17/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-34\n",
      "Configuration saved in results/checkpoint-34/config.json\n",
      "Model weights saved in results/checkpoint-34/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-51\n",
      "Configuration saved in results/checkpoint-51/config.json\n",
      "Model weights saved in results/checkpoint-51/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-68\n",
      "Configuration saved in results/checkpoint-68/config.json\n",
      "Model weights saved in results/checkpoint-68/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-34] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-17 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:47:14] finish training.\n",
      "[INFO] [2023-11-22T13:47:14] finish testing.\n",
      "[INFO] [2023-11-22T13:47:14] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210181310 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210200116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210200116/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210200116/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210200116 saved\n",
      "[INFO] config updated to 202210200116\n",
      "[INFO] [2023-11-22T13:47:25] start main_train_and_evaluate with ./data/202212132000_train_0.35_15.csv ./data/202212132000_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:47:26] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 162\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 88\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/88 02:01 < 02:07, 0.35 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-11\n",
      "Configuration saved in results/checkpoint-11/config.json\n",
      "Model weights saved in results/checkpoint-11/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-22\n",
      "Configuration saved in results/checkpoint-22/config.json\n",
      "Model weights saved in results/checkpoint-22/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-33\n",
      "Configuration saved in results/checkpoint-33/config.json\n",
      "Model weights saved in results/checkpoint-33/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-44\n",
      "Configuration saved in results/checkpoint-44/config.json\n",
      "Model weights saved in results/checkpoint-44/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-22] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-11 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:50:22] finish training.\n",
      "[INFO] [2023-11-22T13:50:23] finish testing.\n",
      "[INFO] [2023-11-22T13:50:23] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210200116 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202212132000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202212132000/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202212132000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202212132000 saved\n",
      "[INFO] config updated to 202212132000\n",
      "[INFO] [2023-11-22T13:50:34] start main_train_and_evaluate with ./data/202302070551_train_0.35_15.csv ./data/202302070551_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T13:50:35] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6412\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3208\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1604' max='3208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1604/3208 11:52 < 11:53, 2.25 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-401\n",
      "Configuration saved in results/checkpoint-401/config.json\n",
      "Model weights saved in results/checkpoint-401/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-802\n",
      "Configuration saved in results/checkpoint-802/config.json\n",
      "Model weights saved in results/checkpoint-802/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-1203\n",
      "Configuration saved in results/checkpoint-1203/config.json\n",
      "Model weights saved in results/checkpoint-1203/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-1604\n",
      "Configuration saved in results/checkpoint-1604/config.json\n",
      "Model weights saved in results/checkpoint-1604/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-802] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-401 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:03:27] finish training.\n",
      "[INFO] [2023-11-22T14:03:28] finish testing.\n",
      "[INFO] [2023-11-22T14:03:28] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202212132000 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202302070551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202302070551/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202302070551/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202302070551 saved\n",
      "[INFO] config updated to 202302070551\n",
      "[INFO] [2023-11-22T14:03:39] start main_train_and_evaluate with ./data/202302071150_train_0.35_15.csv ./data/202302071150_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:03:39] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 108\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/56 01:44 < 01:52, 0.25 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-7\n",
      "Configuration saved in results/checkpoint-7/config.json\n",
      "Model weights saved in results/checkpoint-7/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-14\n",
      "Configuration saved in results/checkpoint-14/config.json\n",
      "Model weights saved in results/checkpoint-14/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-21\n",
      "Configuration saved in results/checkpoint-21/config.json\n",
      "Model weights saved in results/checkpoint-21/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-28\n",
      "Configuration saved in results/checkpoint-28/config.json\n",
      "Model weights saved in results/checkpoint-28/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-14] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-7 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:06:19] finish training.\n",
      "[INFO] [2023-11-22T14:06:19] finish testing.\n",
      "[INFO] [2023-11-22T14:06:19] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202302070551 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202302071150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202302071150/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202302071150/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202302071150 saved\n",
      "[INFO] config updated to 202302071150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:06:30] start main_train_and_evaluate with ./data/202304102150_train_0.35_15.csv ./data/202304102150_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:06:30] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 27\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8/16 01:30 < 02:00, 0.07 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-2\n",
      "Configuration saved in results/checkpoint-2/config.json\n",
      "Model weights saved in results/checkpoint-2/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-4\n",
      "Configuration saved in results/checkpoint-4/config.json\n",
      "Model weights saved in results/checkpoint-4/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-8\n",
      "Configuration saved in results/checkpoint-8/config.json\n",
      "Model weights saved in results/checkpoint-8/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-4] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-2 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:08:56] finish training.\n",
      "[INFO] [2023-11-22T14:08:56] finish testing.\n",
      "[INFO] [2023-11-22T14:08:56] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202302071150 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304102150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304102150/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304102150/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304102150 saved\n",
      "[INFO] config updated to 202304102150\n",
      "[INFO] [2023-11-22T14:09:07] start main_train_and_evaluate with ./data/202304110353_train_0.35_15.csv ./data/202304110353_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:09:07] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 378\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 192\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 96/192 02:10 < 02:13, 0.72 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.004795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-48\n",
      "Configuration saved in results/checkpoint-48/config.json\n",
      "Model weights saved in results/checkpoint-48/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-72\n",
      "Configuration saved in results/checkpoint-72/config.json\n",
      "Model weights saved in results/checkpoint-72/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-96\n",
      "Configuration saved in results/checkpoint-96/config.json\n",
      "Model weights saved in results/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-48] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-24 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:12:13] finish training.\n",
      "[INFO] [2023-11-22T14:12:14] finish testing.\n",
      "[INFO] [2023-11-22T14:12:14] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304102150 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304110353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304110353/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304110353/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304110353 saved\n",
      "[INFO] config updated to 202304110353\n",
      "[INFO] [2023-11-22T14:12:24] start main_train_and_evaluate with ./data/202304110953_train_0.35_15.csv ./data/202304110953_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:12:25] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 378\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 192\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 96/192 02:17 < 02:20, 0.68 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-48\n",
      "Configuration saved in results/checkpoint-48/config.json\n",
      "Model weights saved in results/checkpoint-48/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-72\n",
      "Configuration saved in results/checkpoint-72/config.json\n",
      "Model weights saved in results/checkpoint-72/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-96\n",
      "Configuration saved in results/checkpoint-96/config.json\n",
      "Model weights saved in results/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-48] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-24 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:15:38] finish training.\n",
      "[INFO] [2023-11-22T14:15:38] finish testing.\n",
      "[INFO] [2023-11-22T14:15:38] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304110353 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304110953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304110953/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304110953/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304110953 saved\n",
      "[INFO] config updated to 202304110953\n",
      "[INFO] [2023-11-22T14:15:49] start main_train_and_evaluate with ./data/202304140402_train_0.35_15.csv ./data/202304140402_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:15:49] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1080\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 544\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/544 03:08 < 03:10, 1.43 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-68\n",
      "Configuration saved in results/checkpoint-68/config.json\n",
      "Model weights saved in results/checkpoint-68/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-136\n",
      "Configuration saved in results/checkpoint-136/config.json\n",
      "Model weights saved in results/checkpoint-136/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-204\n",
      "Configuration saved in results/checkpoint-204/config.json\n",
      "Model weights saved in results/checkpoint-204/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-272\n",
      "Configuration saved in results/checkpoint-272/config.json\n",
      "Model weights saved in results/checkpoint-272/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-136] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-68 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:19:54] finish training.\n",
      "[INFO] [2023-11-22T14:19:54] finish testing.\n",
      "[INFO] [2023-11-22T14:19:54] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304110953 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304140402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304140402/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304140402/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304140402 saved\n",
      "[INFO] config updated to 202304140402\n",
      "[INFO] [2023-11-22T14:20:05] start main_train_and_evaluate with ./data/202304191023_train_0.35_15.csv ./data/202304191023_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:20:05] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 81\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/48 01:47 < 01:57, 0.20 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-18\n",
      "Configuration saved in results/checkpoint-18/config.json\n",
      "Model weights saved in results/checkpoint-18/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-12] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-6 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:22:48] finish training.\n",
      "[INFO] [2023-11-22T14:22:48] finish testing.\n",
      "[INFO] [2023-11-22T14:22:49] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304140402 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304191023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304191023/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304191023/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304191023 saved\n",
      "[INFO] config updated to 202304191023\n",
      "[INFO] [2023-11-22T14:22:59] start main_train_and_evaluate with ./data/202304270449_train_0.35_15.csv ./data/202304270449_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:22:59] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 81\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/48 01:46 < 01:56, 0.21 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.023306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.315900</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.315900</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-18\n",
      "Configuration saved in results/checkpoint-18/config.json\n",
      "Model weights saved in results/checkpoint-18/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-12] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-6 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:25:42] finish training.\n",
      "[INFO] [2023-11-22T14:25:42] finish testing.\n",
      "[INFO] [2023-11-22T14:25:42] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304191023 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304270449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304270449/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304270449/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304270449 saved\n",
      "[INFO] config updated to 202304270449\n",
      "[INFO] [2023-11-22T14:25:53] start main_train_and_evaluate with ./data/202305091133_train_0.35_15.csv ./data/202305091133_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:25:53] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 96\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/96 01:49 < 01:54, 0.42 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-36\n",
      "Configuration saved in results/checkpoint-36/config.json\n",
      "Model weights saved in results/checkpoint-36/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-48\n",
      "Configuration saved in results/checkpoint-48/config.json\n",
      "Model weights saved in results/checkpoint-48/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-24] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-12 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:28:44] finish training.\n",
      "[INFO] [2023-11-22T14:28:44] finish testing.\n",
      "[INFO] [2023-11-22T14:28:44] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304270449 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202305091133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202305091133/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202305091133/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202305091133 saved\n",
      "[INFO] config updated to 202305091133\n",
      "[INFO] [2023-11-22T14:28:55] start main_train_and_evaluate with ./data/202305221222_train_0.35_15.csv ./data/202305221222_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:28:55] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 202\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 104\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 52/104 01:51 < 01:55, 0.45 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.235000</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-13\n",
      "Configuration saved in results/checkpoint-13/config.json\n",
      "Model weights saved in results/checkpoint-13/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-26\n",
      "Configuration saved in results/checkpoint-26/config.json\n",
      "Model weights saved in results/checkpoint-26/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-39\n",
      "Configuration saved in results/checkpoint-39/config.json\n",
      "Model weights saved in results/checkpoint-39/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-52\n",
      "Configuration saved in results/checkpoint-52/config.json\n",
      "Model weights saved in results/checkpoint-52/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-26] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-13 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:31:42] finish training.\n",
      "[INFO] [2023-11-22T14:31:42] finish testing.\n",
      "[INFO] [2023-11-22T14:31:42] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202305091133 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202305221222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202305221222/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202305221222/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202305221222 saved\n",
      "[INFO] config updated to 202305221222\n",
      "[INFO] [2023-11-22T14:31:53] start main_train_and_evaluate with ./data/202307030930_train_0.35_15.csv ./data/202307030930_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:31:53] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 445\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 224\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/224 02:21 < 02:24, 0.78 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-28\n",
      "Configuration saved in results/checkpoint-28/config.json\n",
      "Model weights saved in results/checkpoint-28/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-56\n",
      "Configuration saved in results/checkpoint-56/config.json\n",
      "Model weights saved in results/checkpoint-56/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-84\n",
      "Configuration saved in results/checkpoint-84/config.json\n",
      "Model weights saved in results/checkpoint-84/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-112\n",
      "Configuration saved in results/checkpoint-112/config.json\n",
      "Model weights saved in results/checkpoint-112/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-56] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-28 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:35:11] finish training.\n",
      "[INFO] [2023-11-22T14:35:11] finish testing.\n",
      "[INFO] [2023-11-22T14:35:11] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202305221222 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202307030930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202307030930/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202307030930/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202307030930 saved\n",
      "[INFO] config updated to 202307030930\n",
      "[INFO] [2023-11-22T14:35:22] start main_train_and_evaluate with ./data/202307050919_train_0.35_15.csv ./data/202307050919_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:35:22] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2362\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1184\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='740' max='1184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 740/1184 06:26 < 03:52, 1.91 it/s, Epoch 5/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.042183</td>\n",
       "      <td>0.996198</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.996190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.996198</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.996190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.996198</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.996190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-148\n",
      "Configuration saved in results/checkpoint-148/config.json\n",
      "Model weights saved in results/checkpoint-148/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-296\n",
      "Configuration saved in results/checkpoint-296/config.json\n",
      "Model weights saved in results/checkpoint-296/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-444\n",
      "Configuration saved in results/checkpoint-444/config.json\n",
      "Model weights saved in results/checkpoint-444/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-592\n",
      "Configuration saved in results/checkpoint-592/config.json\n",
      "Model weights saved in results/checkpoint-592/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-148] due to args.save_total_limit\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-740\n",
      "Configuration saved in results/checkpoint-740/config.json\n",
      "Model weights saved in results/checkpoint-740/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-444] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-296 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:42:45] finish training.\n",
      "[INFO] [2023-11-22T14:42:45] finish testing.\n",
      "[INFO] [2023-11-22T14:42:46] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202307030930 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202307050919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202307050919/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202307050919/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202307050919 saved\n",
      "[INFO] config updated to 202307050919\n",
      "[INFO] [2023-11-22T14:42:56] start main_train_and_evaluate with ./data/202307070327_train_0.35_15.csv ./data/202307070327_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:42:57] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 202\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 104\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 65/104 02:24 < 01:29, 0.43 it/s, Epoch 5/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.352200</td>\n",
       "      <td>0.249482</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.909596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.438900</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-13\n",
      "Configuration saved in results/checkpoint-13/config.json\n",
      "Model weights saved in results/checkpoint-13/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-26\n",
      "Configuration saved in results/checkpoint-26/config.json\n",
      "Model weights saved in results/checkpoint-26/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-39\n",
      "Configuration saved in results/checkpoint-39/config.json\n",
      "Model weights saved in results/checkpoint-39/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-52\n",
      "Configuration saved in results/checkpoint-52/config.json\n",
      "Model weights saved in results/checkpoint-52/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-13] due to args.save_total_limit\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-65\n",
      "Configuration saved in results/checkpoint-65/config.json\n",
      "Model weights saved in results/checkpoint-65/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-39] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-26 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:46:17] finish training.\n",
      "[INFO] [2023-11-22T14:46:17] finish testing.\n",
      "[INFO] [2023-11-22T14:46:18] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202307050919 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202307070327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202307070327/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202307070327/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202307070327 saved\n",
      "[INFO] config updated to 202307070327\n",
      "[INFO] [2023-11-22T14:46:29] start main_train_and_evaluate with ./data/202307191009_train_0.35_15.csv ./data/202307191009_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:46:29] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 108\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 56\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/56 01:38 < 01:45, 0.27 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-7\n",
      "Configuration saved in results/checkpoint-7/config.json\n",
      "Model weights saved in results/checkpoint-7/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-14\n",
      "Configuration saved in results/checkpoint-14/config.json\n",
      "Model weights saved in results/checkpoint-14/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-21\n",
      "Configuration saved in results/checkpoint-21/config.json\n",
      "Model weights saved in results/checkpoint-21/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-28\n",
      "Configuration saved in results/checkpoint-28/config.json\n",
      "Model weights saved in results/checkpoint-28/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-14] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-7 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:49:03] finish training.\n",
      "[INFO] [2023-11-22T14:49:03] finish testing.\n",
      "[INFO] [2023-11-22T14:49:03] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202307070327 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202307191009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202307191009/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202307191009/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202307191009 saved\n",
      "[INFO] config updated to 202307191009\n",
      "[INFO] [2023-11-22T14:49:14] start main_train_and_evaluate with ./data/202308030456_train_0.35_15.csv ./data/202308030456_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:49:14] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 216\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 112\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 70/112 02:12 < 01:21, 0.51 it/s, Epoch 5/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.395400</td>\n",
       "      <td>0.174154</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-14\n",
      "Configuration saved in results/checkpoint-14/config.json\n",
      "Model weights saved in results/checkpoint-14/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-28\n",
      "Configuration saved in results/checkpoint-28/config.json\n",
      "Model weights saved in results/checkpoint-28/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-42\n",
      "Configuration saved in results/checkpoint-42/config.json\n",
      "Model weights saved in results/checkpoint-42/pytorch_model.bin\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-56\n",
      "Configuration saved in results/checkpoint-56/config.json\n",
      "Model weights saved in results/checkpoint-56/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-14] due to args.save_total_limit\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-70\n",
      "Configuration saved in results/checkpoint-70/config.json\n",
      "Model weights saved in results/checkpoint-70/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-42] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-28 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "<ipython-input-1-750f4b9a3411>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T14:52:22] finish training.\n",
      "[INFO] [2023-11-22T14:52:22] finish testing.\n",
      "[INFO] [2023-11-22T14:52:22] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202307191009 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202308030456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202308030456/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202308030456/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202308030456 saved\n",
      "[INFO] config updated to 202308030456\n"
     ]
    }
   ],
   "source": [
    "env_training = framework.load_training_environment()\n",
    "framework.main(env_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da750245-0a67-4fa9-81d5-e5c370d15ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
