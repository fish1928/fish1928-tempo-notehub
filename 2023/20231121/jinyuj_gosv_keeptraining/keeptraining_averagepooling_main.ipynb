{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7562747d-4d6d-4aba-9b5d-1f5887d05d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from torch import BoolTensor\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, EarlyStoppingCallback\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "DEVICE_DEFAULT = 'cuda'\n",
    "seed_val = 234\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf0d011-5223-4c69-9848-086ccd857614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "class DistilBertForSequenceClassification_AveragePooling(DistilBertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[SequenceClassifierOutput, Tuple[torch.Tensor, ...]]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n",
    "        \n",
    "        hidden_state_filled = hidden_state.masked_fill(attention_mask.unsqueeze(-1) == 0, 0.0)\n",
    "        pooled_output = torch.mean(hidden_state_filled, dim=1)\n",
    "\n",
    "        # pooled_output = hidden_state[:, 0]  # (bs, dim)\n",
    "        pooled_output = self.pre_classifier(pooled_output)  # (bs, dim)\n",
    "        pooled_output = nn.ReLU()(pooled_output)  # (bs, dim)\n",
    "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        logits = self.classifier(pooled_output)  # (bs, num_labels)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + distilbert_output[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=distilbert_output.hidden_states,\n",
    "            attentions=distilbert_output.attentions,\n",
    "        )\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "febbc033-fa27-42fc-87a5-1db6a7d2a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts():\n",
    "    return datetime.utcnow().replace(microsecond=0).isoformat()\n",
    "# end\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "def read_passages(path_data, labels_origin, test_size=0):\n",
    "    df = pd.read_csv(path_data)\n",
    "\n",
    "    documents = df['processed'].to_list()\n",
    "    labels_str = df['target'].to_list()\n",
    "\n",
    "    samples = documents\n",
    "\n",
    "    labels_list = sorted(labels_origin)\n",
    "\n",
    "    labels_all = {l: idx for idx, l in enumerate(labels_list)}\n",
    "\n",
    "    labels = [labels_all[label_str] for label_str in labels_str]\n",
    "\n",
    "    if test_size > 0:\n",
    "        return train_test_split(samples, labels, test_size=test_size, stratify=labels, random_state=234), labels_list\n",
    "    else:\n",
    "        return (samples, samples, labels, labels), labels_list\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.reshape(-1)\n",
    "    preds = pred.predictions.argmax(-1).reshape(-1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    precision = precision_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, zero_division=1, average='macro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "# end\n",
    "\n",
    "def predict_plus(input_tokenized, model):\n",
    "    masks_sample = input_tokenized.attention_mask\n",
    "\n",
    "    indicates_sample = BoolTensor(masks_sample == 1)\n",
    "    indicates_sample = indicates_sample.to(DEVICE_DEFAULT)\n",
    "\n",
    "    out = model(**input_tokenized.to(DEVICE_DEFAULT), output_attentions=True)\n",
    "\n",
    "    logits = out.logits.cpu()\n",
    "    # attentions = out.attentions[-1].cpu()\n",
    "\n",
    "    # attentions_sum = torch.masked_select((torch.sum(attentions[:, :, 0, :], 1) / attentions.shape[1])[0],\n",
    "                                         # indicates_sample).tolist()[1:-1]\n",
    "\n",
    "    # return logits, attentions_sum\n",
    "    return logits, None\n",
    "# end\n",
    "\n",
    "\n",
    "class TrainingEnvironment:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    # end\n",
    "\n",
    "    def add_label(self, labels):\n",
    "        self.labels = labels\n",
    "        return self\n",
    "    # end\n",
    "\n",
    "# end\n",
    "\n",
    "class ModelFramework_SequenceClassification:\n",
    "    FILENAME_CONFIG_FRAMEWORK = 'framework.json'\n",
    "    FILENAME_CHECKSUM = 'checksum.md5'\n",
    "    FOLDER_DATA = 'data'\n",
    "    FOLDER_OUTPUT = 'output'\n",
    "\n",
    "    CONFIG_FRAMEWORK_TEMPLATE = {   # model_full_name = '{model_name}-{model_version}'\n",
    "        'folder_structure': {\n",
    "            FOLDER_DATA: '# folder for train/eval data',\n",
    "            FILENAME_CONFIG_FRAMEWORK: '# jsonfile for framework configuration',\n",
    "            FILENAME_CHECKSUM: '# framework config checksum',\n",
    "            FOLDER_OUTPUT: '# folder for output'\n",
    "        },\n",
    "        'defaults': {\n",
    "            'model_name': 'distilbert-base-uncased',\n",
    "            'model': 'DistilBertForSequenceClassification',\n",
    "            'tokenizer': 'DistilBertTokenizerFast',\n",
    "            'tokenizer_name': 'distilbert-base-uncased',\n",
    "        },\n",
    "        'model': {\n",
    "            'model_name': '',\n",
    "            'model': '',\n",
    "            'tokenizer': '',\n",
    "            'labels': [],\n",
    "            'model_version': '',\n",
    "            'historical_datasets': []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self, path_folder_base):\n",
    "        self.path_folder_base = path_folder_base\n",
    "        self.config_framework = None\n",
    "\n",
    "        path_file_config_framework = os.path.join(path_folder_base, ModelFramework_SequenceClassification.FILENAME_CONFIG_FRAMEWORK)\n",
    "        if os.path.exists(path_file_config_framework):\n",
    "            with open(path_file_config_framework, 'r') as file:\n",
    "                self.config_framework = json.load(file)\n",
    "            # end\n",
    "\n",
    "            print('[INFO] config {} loaded'.format(path_file_config_framework))\n",
    "        else:\n",
    "            print('[WARN] please run ModelFramework_SequenceClassification.generate_default_config first.')\n",
    "        # end\n",
    "\n",
    "    # end\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def generate_default_config(cls, path_folder_base):\n",
    "        os.makedirs(path_folder_base, exist_ok=True)\n",
    "\n",
    "        path_file_config_framework = os.path.join(path_folder_base, cls.FILENAME_CONFIG_FRAMEWORK)\n",
    "\n",
    "        with open(path_file_config_framework, 'w+') as file:\n",
    "            file.write(json.dumps(ModelFramework_SequenceClassification.CONFIG_FRAMEWORK_TEMPLATE))\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def load_training_environment(self):\n",
    "        if not self.config_framework:\n",
    "            print('[ERROR] initialize failed, config_framework is not loaded')\n",
    "            return None\n",
    "        # end\n",
    "\n",
    "        config_model = self.config_framework['model']\n",
    "\n",
    "        if not config_model['labels']:\n",
    "            print('[ERROR] please add labels into framework.config')\n",
    "            return None\n",
    "        # end\n",
    "\n",
    "        if not config_model['model']:\n",
    "            for k, v in self.config_framework['defaults'].items():  # fill model config by defaults\n",
    "                config_model[k] = v\n",
    "            # end\n",
    "        # end\n",
    "\n",
    "        model_name = config_model['model_name']\n",
    "        model_version = config_model['model_version']\n",
    "        labels = config_model['labels']\n",
    "\n",
    "        module_transformers = importlib.import_module('transformers')\n",
    "        try:\n",
    "            print('[INFO] try importing model from transformers: {}'.format(config_model['model']))\n",
    "            klass_model = getattr(module_transformers, config_model['model'])\n",
    "        except:\n",
    "            print('[INFO] try importing model from current script: {}'.format(config_model['model']))\n",
    "            klass_model = getattr(sys.modules['__main__'], config_model['model'])\n",
    "        # end\n",
    "        \n",
    "        print('[INFO] model class imported: {}'.format(klass_model))\n",
    "        klass_tokenizer = getattr(module_transformers, config_model['tokenizer'])\n",
    "\n",
    "\n",
    "        name_model_full = f\"{model_name}-{model_version}\" if model_version else model_name\n",
    "        print('[INFO] loading model: {}'.format(name_model_full))\n",
    "        model = klass_model.from_pretrained(name_model_full, num_labels=len(labels))\n",
    "        # model = model.to('cpu')\n",
    "        \n",
    "        tokenizer_name = config_model.get('tokenizer_name', model_name)\n",
    "        print('[INFO] loading tokenizer: {}'.format(tokenizer_name))\n",
    "        tokenizer = klass_tokenizer.from_pretrained(tokenizer_name, do_lower_case=True)\n",
    "\n",
    "        env_training = TrainingEnvironment(model, tokenizer).add_label(labels)\n",
    "        return env_training\n",
    "    # end\n",
    "\n",
    "    # update config and save model\n",
    "    def save_training_environment(self, env_training, version_current):\n",
    "        model = env_training.model\n",
    "        config_model = self.config_framework['model']\n",
    "\n",
    "        name_model = config_model['model_name']\n",
    "        version_model = config_model['model_version']\n",
    "        name_model_full = f'{name_model}-{version_model}'\n",
    "        path_model = os.path.join(self.path_folder_base, name_model_full)\n",
    "        \n",
    "        if version_model:\n",
    "            subprocess.run('rm -rf {}'.format(path_model), shell=True)\n",
    "            print('[INFO] model {} cleared'.format(name_model_full))\n",
    "        # end\n",
    "\n",
    "        name_model_full_current = f'{name_model}-{version_current}'\n",
    "        path_model_current = os.path.join(self.path_folder_base, name_model_full_current)\n",
    "        print('[INFO] start to save {}'.format(path_model_current))\n",
    "        model.save_pretrained(path_model_current)\n",
    "        print('[INFO] model {} saved'.format(path_model_current))\n",
    "\n",
    "        config_model['model_version'] = version_current\n",
    "        config_model['historical_datasets'].append(version_model)\n",
    "\n",
    "        path_config_framework = os.path.join(self.path_folder_base, ModelFramework_SequenceClassification.FILENAME_CONFIG_FRAMEWORK)\n",
    "        with open(path_config_framework, 'w+') as file:\n",
    "            file.write(json.dumps(self.config_framework, indent=4))\n",
    "        # end\n",
    "        print('[INFO] config updated to {}'.format(version_current))\n",
    "    # end\n",
    "\n",
    "    def train_and_evaluate(self, env_training, path_train, path_test, path_output, path_checkpoint_model):\n",
    "        print('[INFO] [{}] start main_train_and_evaluate with {} {}'.format(get_ts(), path_train, path_test))\n",
    "\n",
    "        output_dir = path_checkpoint_model\n",
    "        labels = env_training.labels\n",
    "        (train_samples, valid_samples, train_labels, valid_labels), target_names = read_passages(path_train, labels, 0.1)\n",
    "\n",
    "        tokenizer = env_training.tokenizer\n",
    "        train_encodings = tokenizer.batch_encode_plus(train_samples, truncation=True, padding=True,\n",
    "                                                      max_length=MAX_LENGTH,\n",
    "                                                      return_tensors='pt')\n",
    "        valid_encodings = tokenizer.batch_encode_plus(valid_samples, truncation=True, padding=True,\n",
    "                                                      max_length=MAX_LENGTH,\n",
    "                                                      return_tensors='pt')\n",
    "\n",
    "        train_dataset = SimpleDataset(train_encodings, train_labels)\n",
    "        valid_dataset = SimpleDataset(valid_encodings, valid_labels)\n",
    "\n",
    "        model = env_training.model\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,  # output directory\n",
    "            num_train_epochs=6,  # total number of training epochs\n",
    "            per_device_train_batch_size=16,  # batch size per device during training\n",
    "            per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "            warmup_steps=0,  # number of warmup steps for learning rate scheduler\n",
    "            weight_decay=0.01,  # strength of weight decay\n",
    "            logging_dir='./logs',  # directory for storing logs\n",
    "            load_best_model_at_end=True,\n",
    "            # load the best model when finished training (default metric is loss)    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "            logging_steps=10,  # log & save weights each logging_steps\n",
    "            evaluation_strategy=\"epoch\",  # evaluate each `logging_steps`\n",
    "            learning_rate=2e-5,\n",
    "            save_strategy='epoch',\n",
    "            save_total_limit=3,\n",
    "            metric_for_best_model='f1'\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,  # the instantiated Transformers model to be trained\n",
    "            args=training_args,  # training arguments, defined above\n",
    "            train_dataset=train_dataset,  # training dataset\n",
    "            eval_dataset=valid_dataset,  # evaluation dataset\n",
    "            compute_metrics=compute_metrics,  # the callback that computes metrics of interest\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "        )\n",
    "\n",
    "        # trainer = Trainer(\n",
    "        #     model=model,  # the instantiated Transformers model to be trained\n",
    "        #     args=training_args,  # training arguments, defined above\n",
    "        #     train_dataset=train_dataset,  # training dataset\n",
    "        #     eval_dataset=valid_dataset,  # evaluation dataset\n",
    "        #     compute_metrics=compute_metrics\n",
    "        # )\n",
    "\n",
    "        print('[INFO] [{}] start training...'.format(get_ts()))\n",
    "        trainer.train()\n",
    "\n",
    "        info_state_model = trainer.evaluate()\n",
    "        print('[INFO] [{}] finish training.'.format(get_ts()))\n",
    "\n",
    "        ################## start to do eval ##################\n",
    "\n",
    "        (samples_test, _, indexs_label_test, _), target_names = read_passages(path_test, labels, 0)\n",
    "        labels_test = [target_names[index_label_test] for index_label_test in indexs_label_test]\n",
    "\n",
    "        list_conf_output = []\n",
    "        list_label_output = []\n",
    "        # list_attention_output = []\n",
    "\n",
    "        for sample_test, label_origin in zip(samples_test, labels_test):\n",
    "            input_tokenized = tokenizer.encode_plus(sample_test, padding=True, truncation=True, max_length=MAX_LENGTH,\n",
    "                                                    return_tensors='pt')\n",
    "            with torch.no_grad():\n",
    "                # out = model(**input_tokenized, output_hidden_states=True, output_attentions=True)\n",
    "                # logits_this, attention_this = predict_plus(input_tokenized, model)\n",
    "                logits_this, _ = predict_plus(input_tokenized, model)\n",
    "            # end\n",
    "\n",
    "            probas_evaluate = torch.nn.functional.softmax(logits_this, dim=-1)\n",
    "            answer_evaluate = int(probas_evaluate.argmax())\n",
    "            label_evaluate = target_names[answer_evaluate]\n",
    "\n",
    "            list_conf_output.append(probas_evaluate.numpy().tolist()[0][answer_evaluate])\n",
    "            list_label_output.append(label_evaluate)\n",
    "            # list_attention_output.append(attention_this)\n",
    "        # end\n",
    "\n",
    "        print('[INFO] [{}] finish testing.'.format(get_ts()))\n",
    "\n",
    "        pairs_label_conf = [[a, b, c] for a, b, c in zip(list_label_output, list_conf_output, labels_test)]\n",
    "\n",
    "        with open(path_output, 'w+') as file:\n",
    "            file.write(json.dumps(pairs_label_conf))\n",
    "        # end\n",
    "\n",
    "        print('[INFO] [{}] main_train_and_evaluate finished.'.format(get_ts()))\n",
    "    # end\n",
    "\n",
    "    def main(self, env_training):\n",
    "        path_folder_checkpoints = 'results'\n",
    "        path_folder_train = os.path.join(self.path_folder_base, ModelFramework_SequenceClassification.FOLDER_DATA)\n",
    "        filenames = sorted([filename for filename in os.listdir(path_folder_train) if filename[0] != '.' and 'train' in filename])\n",
    "\n",
    "        model_last = None\n",
    "\n",
    "        for _filename in filenames:\n",
    "            filename_base = _filename.split('_')[0]\n",
    "            version_current = int(filename_base)    # str_timestamp -> int\n",
    "\n",
    "            filename_test = f'{filename_base}_test.csv'\n",
    "            filename_train = _filename\n",
    "            filename_output = f'output-{filename_base}.json'\n",
    "\n",
    "            path_data_train = os.path.join(path_folder_train, filename_train)\n",
    "            path_data_test = os.path.join(path_folder_train, filename_test)\n",
    "            path_file_output = os.path.join(self.path_folder_base, ModelFramework_SequenceClassification.FOLDER_OUTPUT, filename_output)\n",
    "\n",
    "            self.train_and_evaluate(env_training, path_data_train, path_data_test, path_file_output, path_folder_checkpoints)\n",
    "            self.save_training_environment(env_training, version_current)\n",
    "\n",
    "            subprocess.run(f\"rm -rf {path_folder_checkpoints}\", shell=True)\n",
    "        # end\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6c5cd8-9d33-4a3e-9123-9148eace7400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] config ./framework.json loaded\n"
     ]
    }
   ],
   "source": [
    "framework = ModelFramework_SequenceClassification('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f371b6-d330-4ae3-a5b2-f00d142e8905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] try importing model from transformers: DistilBertForSequenceClassification_AveragePooling\n",
      "[INFO] try importing model from current script: DistilBertForSequenceClassification_AveragePooling\n",
      "[INFO] model class imported: <class '__main__.DistilBertForSequenceClassification_AveragePooling'>\n",
      "[INFO] loading model: distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification_AveragePooling: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification_AveragePooling from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification_AveragePooling from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification_AveragePooling were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading tokenizer: distilbert-base-uncased\n",
      "[INFO] [2023-11-22T08:28:45] start main_train_and_evaluate with ./data/202206171000_train_0.35_15.csv ./data/202206171000_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 17577\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T08:28:51] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6594' max='6594' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6594/6594 48:06, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.189827</td>\n",
       "      <td>0.992832</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>0.992832</td>\n",
       "      <td>0.992811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.058897</td>\n",
       "      <td>0.994880</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>0.994880</td>\n",
       "      <td>0.994876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.996933</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.996927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.996926</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.996926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.014518</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.997954</td>\n",
       "      <td>0.997952</td>\n",
       "      <td>0.997950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.017910</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.996930</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>0.996928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-1099\n",
      "Configuration saved in results/checkpoint-1099/config.json\n",
      "Model weights saved in results/checkpoint-1099/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-2198\n",
      "Configuration saved in results/checkpoint-2198/config.json\n",
      "Model weights saved in results/checkpoint-2198/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3297\n",
      "Configuration saved in results/checkpoint-3297/config.json\n",
      "Model weights saved in results/checkpoint-3297/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-4396\n",
      "Configuration saved in results/checkpoint-4396/config.json\n",
      "Model weights saved in results/checkpoint-4396/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1099] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-5495\n",
      "Configuration saved in results/checkpoint-5495/config.json\n",
      "Model weights saved in results/checkpoint-5495/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2198] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6594\n",
      "Configuration saved in results/checkpoint-6594/config.json\n",
      "Model weights saved in results/checkpoint-6594/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-3297] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-5495 (score: 0.9979500171904389).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1953\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123/123 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:18:08] finish training.\n",
      "[INFO] [2023-11-22T09:18:09] finish testing.\n",
      "[INFO] [2023-11-22T09:18:09] main_train_and_evaluate finished.\n",
      "[INFO] start to save ./distilbert-base-uncased-202206171000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202206171000/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202206171000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202206171000 saved\n",
      "[INFO] config updated to 202206171000\n",
      "[INFO] [2023-11-22T09:18:20] start main_train_and_evaluate with ./data/202207021500_train_0.35_15.csv ./data/202207021500_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:18:21] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1822\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 684\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='684' max='684' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [684/684 06:14, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.092581</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.980354</td>\n",
       "      <td>0.980366</td>\n",
       "      <td>0.980183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.031639</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>0.990122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.027976</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005964</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-114\n",
      "Configuration saved in results/checkpoint-114/config.json\n",
      "Model weights saved in results/checkpoint-114/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-228\n",
      "Configuration saved in results/checkpoint-228/config.json\n",
      "Model weights saved in results/checkpoint-228/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-342\n",
      "Configuration saved in results/checkpoint-342/config.json\n",
      "Model weights saved in results/checkpoint-342/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-456\n",
      "Configuration saved in results/checkpoint-456/config.json\n",
      "Model weights saved in results/checkpoint-456/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-114] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-570\n",
      "Configuration saved in results/checkpoint-570/config.json\n",
      "Model weights saved in results/checkpoint-570/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-228] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-684\n",
      "Configuration saved in results/checkpoint-684/config.json\n",
      "Model weights saved in results/checkpoint-684/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-456] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-342 (score: 0.9950587158761628).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 203\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:25:33] finish training.\n",
      "[INFO] [2023-11-22T09:25:33] finish testing.\n",
      "[INFO] [2023-11-22T09:25:33] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202206171000 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207021500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207021500/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207021500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207021500 saved\n",
      "[INFO] config updated to 202207021500\n",
      "[INFO] [2023-11-22T09:25:44] start main_train_and_evaluate with ./data/202207041600_train_0.35_15.csv ./data/202207041600_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:25:44] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1080\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 408\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/408 02:43 < 01:22, 1.65 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-68\n",
      "Configuration saved in results/checkpoint-68/config.json\n",
      "Model weights saved in results/checkpoint-68/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-136\n",
      "Configuration saved in results/checkpoint-136/config.json\n",
      "Model weights saved in results/checkpoint-136/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-204\n",
      "Configuration saved in results/checkpoint-204/config.json\n",
      "Model weights saved in results/checkpoint-204/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-272\n",
      "Configuration saved in results/checkpoint-272/config.json\n",
      "Model weights saved in results/checkpoint-272/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-136] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-68 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:29:24] finish training.\n",
      "[INFO] [2023-11-22T09:29:24] finish testing.\n",
      "[INFO] [2023-11-22T09:29:24] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207021500 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207041600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207041600/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207041600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207041600 saved\n",
      "[INFO] config updated to 202207041600\n",
      "[INFO] [2023-11-22T09:29:34] start main_train_and_evaluate with ./data/202207151000_train_0.35_15.csv ./data/202207151000_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:29:35] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 648\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 246\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='246' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/246 02:16 < 01:09, 1.18 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-41\n",
      "Configuration saved in results/checkpoint-41/config.json\n",
      "Model weights saved in results/checkpoint-41/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-82\n",
      "Configuration saved in results/checkpoint-82/config.json\n",
      "Model weights saved in results/checkpoint-82/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-123\n",
      "Configuration saved in results/checkpoint-123/config.json\n",
      "Model weights saved in results/checkpoint-123/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-164\n",
      "Configuration saved in results/checkpoint-164/config.json\n",
      "Model weights saved in results/checkpoint-164/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-82] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-41 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 72\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:32:50] finish training.\n",
      "[INFO] [2023-11-22T09:32:50] finish testing.\n",
      "[INFO] [2023-11-22T09:32:50] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207041600 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207151000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207151000/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207151000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207151000 saved\n",
      "[INFO] config updated to 202207151000\n",
      "[INFO] [2023-11-22T09:33:01] start main_train_and_evaluate with ./data/202207221500_train_0.35_15.csv ./data/202207221500_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:33:01] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1417\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 534\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='356' max='534' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [356/534 03:01 < 01:31, 1.95 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-89\n",
      "Configuration saved in results/checkpoint-89/config.json\n",
      "Model weights saved in results/checkpoint-89/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-178\n",
      "Configuration saved in results/checkpoint-178/config.json\n",
      "Model weights saved in results/checkpoint-178/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-267\n",
      "Configuration saved in results/checkpoint-267/config.json\n",
      "Model weights saved in results/checkpoint-267/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-356\n",
      "Configuration saved in results/checkpoint-356/config.json\n",
      "Model weights saved in results/checkpoint-356/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-178] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-89 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 158\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:36:59] finish training.\n",
      "[INFO] [2023-11-22T09:36:59] finish testing.\n",
      "[INFO] [2023-11-22T09:36:59] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207151000 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207221500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207221500/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207221500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207221500 saved\n",
      "[INFO] config updated to 202207221500\n",
      "[INFO] [2023-11-22T09:37:10] start main_train_and_evaluate with ./data/202207260728_train_0.35_15.csv ./data/202207260728_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:37:10] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1080\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 408\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/408 02:43 < 01:22, 1.65 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-68\n",
      "Configuration saved in results/checkpoint-68/config.json\n",
      "Model weights saved in results/checkpoint-68/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-136\n",
      "Configuration saved in results/checkpoint-136/config.json\n",
      "Model weights saved in results/checkpoint-136/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-204\n",
      "Configuration saved in results/checkpoint-204/config.json\n",
      "Model weights saved in results/checkpoint-204/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-272\n",
      "Configuration saved in results/checkpoint-272/config.json\n",
      "Model weights saved in results/checkpoint-272/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-136] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-68 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:40:49] finish training.\n",
      "[INFO] [2023-11-22T09:40:49] finish testing.\n",
      "[INFO] [2023-11-22T09:40:49] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207221500 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202207260728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202207260728/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202207260728/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202207260728 saved\n",
      "[INFO] config updated to 202207260728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:41:00] start main_train_and_evaluate with ./data/202208031141_train_0.35_15.csv ./data/202208031141_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:41:00] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/18 01:46 < 01:03, 0.09 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3\n",
      "Configuration saved in results/checkpoint-3/config.json\n",
      "Model weights saved in results/checkpoint-3/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-9\n",
      "Configuration saved in results/checkpoint-9/config.json\n",
      "Model weights saved in results/checkpoint-9/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-3 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:43:42] finish training.\n",
      "[INFO] [2023-11-22T09:43:42] finish testing.\n",
      "[INFO] [2023-11-22T09:43:42] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202207260728 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202208031141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202208031141/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202208031141/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202208031141 saved\n",
      "[INFO] config updated to 202208031141\n",
      "[INFO] [2023-11-22T09:43:53] start main_train_and_evaluate with ./data/202208172100_train_0.35_15.csv ./data/202208172100_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:43:53] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 729\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 276\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [184/276 02:25 < 01:13, 1.25 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-46\n",
      "Configuration saved in results/checkpoint-46/config.json\n",
      "Model weights saved in results/checkpoint-46/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-92\n",
      "Configuration saved in results/checkpoint-92/config.json\n",
      "Model weights saved in results/checkpoint-92/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-138\n",
      "Configuration saved in results/checkpoint-138/config.json\n",
      "Model weights saved in results/checkpoint-138/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-184\n",
      "Configuration saved in results/checkpoint-184/config.json\n",
      "Model weights saved in results/checkpoint-184/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-92] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-46 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 81\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:47:14] finish training.\n",
      "[INFO] [2023-11-22T09:47:14] finish testing.\n",
      "[INFO] [2023-11-22T09:47:14] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202208031141 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202208172100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202208172100/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202208172100/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202208172100 saved\n",
      "[INFO] config updated to 202208172100\n",
      "[INFO] [2023-11-22T09:47:24] start main_train_and_evaluate with ./data/202208190706_train_0.35_15.csv ./data/202208190706_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:47:25] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 972\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 366\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='244' max='366' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [244/366 03:19 < 01:40, 1.21 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-61\n",
      "Configuration saved in results/checkpoint-61/config.json\n",
      "Model weights saved in results/checkpoint-61/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-122\n",
      "Configuration saved in results/checkpoint-122/config.json\n",
      "Model weights saved in results/checkpoint-122/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-183\n",
      "Configuration saved in results/checkpoint-183/config.json\n",
      "Model weights saved in results/checkpoint-183/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-244\n",
      "Configuration saved in results/checkpoint-244/config.json\n",
      "Model weights saved in results/checkpoint-244/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-122] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-61 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 108\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:51:41] finish training.\n",
      "[INFO] [2023-11-22T09:51:41] finish testing.\n",
      "[INFO] [2023-11-22T09:51:41] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202208172100 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202208190706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202208190706/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202208190706/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202208190706 saved\n",
      "[INFO] config updated to 202208190706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:51:51] start main_train_and_evaluate with ./data/202208240500_train_0.35_15.csv ./data/202208240500_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:51:52] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/18 01:41 < 01:00, 0.10 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3\n",
      "Configuration saved in results/checkpoint-3/config.json\n",
      "Model weights saved in results/checkpoint-3/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-9\n",
      "Configuration saved in results/checkpoint-9/config.json\n",
      "Model weights saved in results/checkpoint-9/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-3 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:54:28] finish training.\n",
      "[INFO] [2023-11-22T09:54:28] finish testing.\n",
      "[INFO] [2023-11-22T09:54:29] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202208190706 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202208240500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202208240500/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202208240500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202208240500 saved\n",
      "[INFO] config updated to 202208240500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:54:39] start main_train_and_evaluate with ./data/202209081034_train_0.35_15.csv ./data/202209081034_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:54:40] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 27\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 02:25, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>21.303446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.993266</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.528100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.528100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-2\n",
      "Configuration saved in results/checkpoint-2/config.json\n",
      "Model weights saved in results/checkpoint-2/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-4\n",
      "Configuration saved in results/checkpoint-4/config.json\n",
      "Model weights saved in results/checkpoint-4/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-8\n",
      "Configuration saved in results/checkpoint-8/config.json\n",
      "Model weights saved in results/checkpoint-8/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-10\n",
      "Configuration saved in results/checkpoint-10/config.json\n",
      "Model weights saved in results/checkpoint-10/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-4] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-8] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-6 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:58:00] finish training.\n",
      "[INFO] [2023-11-22T09:58:00] finish testing.\n",
      "[INFO] [2023-11-22T09:58:00] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202208240500 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202209081034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202209081034/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202209081034/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202209081034 saved\n",
      "[INFO] config updated to 202209081034\n",
      "[INFO] [2023-11-22T09:58:11] start main_train_and_evaluate with ./data/202209081634_train_0.35_15.csv ./data/202209081634_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T09:58:11] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1863\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 702\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='702' max='702' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [702/702 05:35, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.112678</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>0.953419</td>\n",
       "      <td>0.951401</td>\n",
       "      <td>0.951436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.135041</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>0.953419</td>\n",
       "      <td>0.951401</td>\n",
       "      <td>0.951436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.166684</td>\n",
       "      <td>0.966184</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.965723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.209206</td>\n",
       "      <td>0.966184</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.965686</td>\n",
       "      <td>0.965723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.215113</td>\n",
       "      <td>0.961353</td>\n",
       "      <td>0.963248</td>\n",
       "      <td>0.961064</td>\n",
       "      <td>0.961149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.148200</td>\n",
       "      <td>0.224988</td>\n",
       "      <td>0.961353</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.960924</td>\n",
       "      <td>0.960951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-117\n",
      "Configuration saved in results/checkpoint-117/config.json\n",
      "Model weights saved in results/checkpoint-117/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-234\n",
      "Configuration saved in results/checkpoint-234/config.json\n",
      "Model weights saved in results/checkpoint-234/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-351\n",
      "Configuration saved in results/checkpoint-351/config.json\n",
      "Model weights saved in results/checkpoint-351/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-468\n",
      "Configuration saved in results/checkpoint-468/config.json\n",
      "Model weights saved in results/checkpoint-468/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-117] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-585\n",
      "Configuration saved in results/checkpoint-585/config.json\n",
      "Model weights saved in results/checkpoint-585/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-234] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-702\n",
      "Configuration saved in results/checkpoint-702/config.json\n",
      "Model weights saved in results/checkpoint-702/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-468] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-351 (score: 0.9657228017883756).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:04:43] finish training.\n",
      "[INFO] [2023-11-22T10:04:43] finish testing.\n",
      "[INFO] [2023-11-22T10:04:43] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202209081034 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202209081634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202209081634/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202209081634/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202209081634 saved\n",
      "[INFO] config updated to 202209081634\n",
      "[INFO] [2023-11-22T10:04:54] start main_train_and_evaluate with ./data/202209151400_train_0.35_15.csv ./data/202209151400_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:04:54] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 121\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/48 01:47 < 00:57, 0.28 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-8\n",
      "Configuration saved in results/checkpoint-8/config.json\n",
      "Model weights saved in results/checkpoint-8/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-16\n",
      "Configuration saved in results/checkpoint-16/config.json\n",
      "Model weights saved in results/checkpoint-16/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-32\n",
      "Configuration saved in results/checkpoint-32/config.json\n",
      "Model weights saved in results/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-16] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-8 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 14\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:07:37] finish training.\n",
      "[INFO] [2023-11-22T10:07:37] finish testing.\n",
      "[INFO] [2023-11-22T10:07:37] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202209081634 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202209151400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202209151400/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202209151400/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202209151400 saved\n",
      "[INFO] config updated to 202209151400\n",
      "[INFO] [2023-11-22T10:07:48] start main_train_and_evaluate with ./data/202210102130_train_0.35_15.csv ./data/202210102130_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:07:49] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 567\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 216\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='144' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [144/216 02:13 < 01:07, 1.06 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-36\n",
      "Configuration saved in results/checkpoint-36/config.json\n",
      "Model weights saved in results/checkpoint-36/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-72\n",
      "Configuration saved in results/checkpoint-72/config.json\n",
      "Model weights saved in results/checkpoint-72/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-108\n",
      "Configuration saved in results/checkpoint-108/config.json\n",
      "Model weights saved in results/checkpoint-108/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-144\n",
      "Configuration saved in results/checkpoint-144/config.json\n",
      "Model weights saved in results/checkpoint-144/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-72] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-36 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 63\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:10:58] finish training.\n",
      "[INFO] [2023-11-22T10:10:58] finish testing.\n",
      "[INFO] [2023-11-22T10:10:59] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202209151400 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210102130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210102130/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210102130/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210102130 saved\n",
      "[INFO] config updated to 202210102130\n",
      "[INFO] [2023-11-22T10:11:09] start main_train_and_evaluate with ./data/202210110644_train_0.35_15.csv ./data/202210110644_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:11:10] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3078\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1158\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='772' max='1158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 772/1158 05:37 < 02:49, 2.28 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-193\n",
      "Configuration saved in results/checkpoint-193/config.json\n",
      "Model weights saved in results/checkpoint-193/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-386\n",
      "Configuration saved in results/checkpoint-386/config.json\n",
      "Model weights saved in results/checkpoint-386/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-579\n",
      "Configuration saved in results/checkpoint-579/config.json\n",
      "Model weights saved in results/checkpoint-579/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-772\n",
      "Configuration saved in results/checkpoint-772/config.json\n",
      "Model weights saved in results/checkpoint-772/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-386] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-193 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 342\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:17:44] finish training.\n",
      "[INFO] [2023-11-22T10:17:44] finish testing.\n",
      "[INFO] [2023-11-22T10:17:45] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210102130 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210110644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210110644/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210110644/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210110644 saved\n",
      "[INFO] config updated to 202210110644\n",
      "[INFO] [2023-11-22T10:17:55] start main_train_and_evaluate with ./data/202210121247_train_0.35_15.csv ./data/202210121247_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:17:56] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 364\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 138\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 92/138 01:53 < 00:58, 0.79 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.265819</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.925517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.468576</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.925517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.357154</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.925517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.318978</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.925517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-23\n",
      "Configuration saved in results/checkpoint-23/config.json\n",
      "Model weights saved in results/checkpoint-23/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-46\n",
      "Configuration saved in results/checkpoint-46/config.json\n",
      "Model weights saved in results/checkpoint-46/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-69\n",
      "Configuration saved in results/checkpoint-69/config.json\n",
      "Model weights saved in results/checkpoint-69/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-92\n",
      "Configuration saved in results/checkpoint-92/config.json\n",
      "Model weights saved in results/checkpoint-92/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-46] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-23 (score: 0.9255172413793104).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 41\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:20:45] finish training.\n",
      "[INFO] [2023-11-22T10:20:45] finish testing.\n",
      "[INFO] [2023-11-22T10:20:45] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210110644 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210121247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210121247/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210121247/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210121247 saved\n",
      "[INFO] config updated to 202210121247\n",
      "[INFO] [2023-11-22T10:20:55] start main_train_and_evaluate with ./data/202210130649_train_0.35_15.csv ./data/202210130649_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:20:56] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 13\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/6 01:40 < 01:40, 0.02 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-1\n",
      "Configuration saved in results/checkpoint-1/config.json\n",
      "Model weights saved in results/checkpoint-1/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-2\n",
      "Configuration saved in results/checkpoint-2/config.json\n",
      "Model weights saved in results/checkpoint-2/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3\n",
      "Configuration saved in results/checkpoint-3/config.json\n",
      "Model weights saved in results/checkpoint-3/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-4\n",
      "Configuration saved in results/checkpoint-4/config.json\n",
      "Model weights saved in results/checkpoint-4/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-2] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-1 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:23:32] finish training.\n",
      "[INFO] [2023-11-22T10:23:32] finish testing.\n",
      "[INFO] [2023-11-22T10:23:32] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210121247 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210130649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210130649/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210130649/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210130649 saved\n",
      "[INFO] config updated to 202210130649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:23:42] start main_train_and_evaluate with ./data/202210181310_train_0.35_15.csv ./data/202210181310_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:23:43] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 40\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/18 01:33 < 00:56, 0.11 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-3\n",
      "Configuration saved in results/checkpoint-3/config.json\n",
      "Model weights saved in results/checkpoint-3/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-9\n",
      "Configuration saved in results/checkpoint-9/config.json\n",
      "Model weights saved in results/checkpoint-9/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-3 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 5\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:26:11] finish training.\n",
      "[INFO] [2023-11-22T10:26:12] finish testing.\n",
      "[INFO] [2023-11-22T10:26:12] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210130649 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210181310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210181310/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210181310/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210181310 saved\n",
      "[INFO] config updated to 202210181310\n",
      "[INFO] [2023-11-22T10:26:22] start main_train_and_evaluate with ./data/202210200116_train_0.35_15.csv ./data/202210200116_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:26:23] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 270\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 102\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 68/102 01:59 < 01:01, 0.55 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.065800</td>\n",
       "      <td>0.107621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-17\n",
      "Configuration saved in results/checkpoint-17/config.json\n",
      "Model weights saved in results/checkpoint-17/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-34\n",
      "Configuration saved in results/checkpoint-34/config.json\n",
      "Model weights saved in results/checkpoint-34/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-51\n",
      "Configuration saved in results/checkpoint-51/config.json\n",
      "Model weights saved in results/checkpoint-51/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-68\n",
      "Configuration saved in results/checkpoint-68/config.json\n",
      "Model weights saved in results/checkpoint-68/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-34] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-17 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:29:18] finish training.\n",
      "[INFO] [2023-11-22T10:29:18] finish testing.\n",
      "[INFO] [2023-11-22T10:29:18] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210181310 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202210200116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202210200116/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202210200116/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202210200116 saved\n",
      "[INFO] config updated to 202210200116\n",
      "[INFO] [2023-11-22T10:29:29] start main_train_and_evaluate with ./data/202212132000_train_0.35_15.csv ./data/202212132000_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:29:29] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 162\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 66\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44/66 01:55 < 01:00, 0.37 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.841400</td>\n",
       "      <td>0.110508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-11\n",
      "Configuration saved in results/checkpoint-11/config.json\n",
      "Model weights saved in results/checkpoint-11/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-22\n",
      "Configuration saved in results/checkpoint-22/config.json\n",
      "Model weights saved in results/checkpoint-22/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-33\n",
      "Configuration saved in results/checkpoint-33/config.json\n",
      "Model weights saved in results/checkpoint-33/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-44\n",
      "Configuration saved in results/checkpoint-44/config.json\n",
      "Model weights saved in results/checkpoint-44/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-22] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-11 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:32:19] finish training.\n",
      "[INFO] [2023-11-22T10:32:20] finish testing.\n",
      "[INFO] [2023-11-22T10:32:21] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202210200116 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202212132000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202212132000/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202212132000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202212132000 saved\n",
      "[INFO] config updated to 202212132000\n",
      "[INFO] [2023-11-22T10:32:31] start main_train_and_evaluate with ./data/202302070551_train_0.35_15.csv ./data/202302070551_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:32:33] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6412\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2406\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1604' max='2406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1604/2406 12:09 < 06:05, 2.20 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-401\n",
      "Configuration saved in results/checkpoint-401/config.json\n",
      "Model weights saved in results/checkpoint-401/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-802\n",
      "Configuration saved in results/checkpoint-802/config.json\n",
      "Model weights saved in results/checkpoint-802/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-1203\n",
      "Configuration saved in results/checkpoint-1203/config.json\n",
      "Model weights saved in results/checkpoint-1203/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-1604\n",
      "Configuration saved in results/checkpoint-1604/config.json\n",
      "Model weights saved in results/checkpoint-1604/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-802] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-401 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 713\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:45:42] finish training.\n",
      "[INFO] [2023-11-22T10:45:42] finish testing.\n",
      "[INFO] [2023-11-22T10:45:43] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202212132000 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202302070551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202302070551/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202302070551/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202302070551 saved\n",
      "[INFO] config updated to 202302070551\n",
      "[INFO] [2023-11-22T10:45:53] start main_train_and_evaluate with ./data/202302071150_train_0.35_15.csv ./data/202302071150_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:45:54] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 108\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/42 01:48 < 00:58, 0.24 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-7\n",
      "Configuration saved in results/checkpoint-7/config.json\n",
      "Model weights saved in results/checkpoint-7/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-14\n",
      "Configuration saved in results/checkpoint-14/config.json\n",
      "Model weights saved in results/checkpoint-14/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-21\n",
      "Configuration saved in results/checkpoint-21/config.json\n",
      "Model weights saved in results/checkpoint-21/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-28\n",
      "Configuration saved in results/checkpoint-28/config.json\n",
      "Model weights saved in results/checkpoint-28/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-14] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-7 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:48:38] finish training.\n",
      "[INFO] [2023-11-22T10:48:38] finish testing.\n",
      "[INFO] [2023-11-22T10:48:38] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202302070551 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202302071150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202302071150/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202302071150/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202302071150 saved\n",
      "[INFO] config updated to 202302071150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:48:48] start main_train_and_evaluate with ./data/202304102150_train_0.35_15.csv ./data/202304102150_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:48:49] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 27\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8/12 01:38 < 01:05, 0.06 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-2\n",
      "Configuration saved in results/checkpoint-2/config.json\n",
      "Model weights saved in results/checkpoint-2/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-4\n",
      "Configuration saved in results/checkpoint-4/config.json\n",
      "Model weights saved in results/checkpoint-4/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-8\n",
      "Configuration saved in results/checkpoint-8/config.json\n",
      "Model weights saved in results/checkpoint-8/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-4] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-2 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:51:23] finish training.\n",
      "[INFO] [2023-11-22T10:51:23] finish testing.\n",
      "[INFO] [2023-11-22T10:51:23] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202302071150 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304102150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304102150/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304102150/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304102150 saved\n",
      "[INFO] config updated to 202304102150\n",
      "[INFO] [2023-11-22T10:51:33] start main_train_and_evaluate with ./data/202304110353_train_0.35_15.csv ./data/202304110353_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:51:34] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 378\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 144\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 96/144 02:10 < 01:06, 0.72 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-48\n",
      "Configuration saved in results/checkpoint-48/config.json\n",
      "Model weights saved in results/checkpoint-48/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-72\n",
      "Configuration saved in results/checkpoint-72/config.json\n",
      "Model weights saved in results/checkpoint-72/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-96\n",
      "Configuration saved in results/checkpoint-96/config.json\n",
      "Model weights saved in results/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-48] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-24 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:54:40] finish training.\n",
      "[INFO] [2023-11-22T10:54:40] finish testing.\n",
      "[INFO] [2023-11-22T10:54:40] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304102150 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304110353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304110353/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304110353/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304110353 saved\n",
      "[INFO] config updated to 202304110353\n",
      "[INFO] [2023-11-22T10:54:50] start main_train_and_evaluate with ./data/202304110953_train_0.35_15.csv ./data/202304110953_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:54:51] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 378\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 144\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 96/144 02:17 < 01:10, 0.68 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-48\n",
      "Configuration saved in results/checkpoint-48/config.json\n",
      "Model weights saved in results/checkpoint-48/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-72\n",
      "Configuration saved in results/checkpoint-72/config.json\n",
      "Model weights saved in results/checkpoint-72/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-96\n",
      "Configuration saved in results/checkpoint-96/config.json\n",
      "Model weights saved in results/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-48] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-24 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 42\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:58:04] finish training.\n",
      "[INFO] [2023-11-22T10:58:04] finish testing.\n",
      "[INFO] [2023-11-22T10:58:05] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304110353 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304110953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304110953/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304110953/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304110953 saved\n",
      "[INFO] config updated to 202304110953\n",
      "[INFO] [2023-11-22T10:58:15] start main_train_and_evaluate with ./data/202304140402_train_0.35_15.csv ./data/202304140402_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T10:58:16] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1080\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 408\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/408 03:09 < 01:35, 1.42 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-68\n",
      "Configuration saved in results/checkpoint-68/config.json\n",
      "Model weights saved in results/checkpoint-68/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-136\n",
      "Configuration saved in results/checkpoint-136/config.json\n",
      "Model weights saved in results/checkpoint-136/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-204\n",
      "Configuration saved in results/checkpoint-204/config.json\n",
      "Model weights saved in results/checkpoint-204/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-272\n",
      "Configuration saved in results/checkpoint-272/config.json\n",
      "Model weights saved in results/checkpoint-272/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-136] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-68 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 120\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:02:21] finish training.\n",
      "[INFO] [2023-11-22T11:02:21] finish testing.\n",
      "[INFO] [2023-11-22T11:02:22] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304110953 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304140402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304140402/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304140402/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304140402 saved\n",
      "[INFO] config updated to 202304140402\n",
      "[INFO] [2023-11-22T11:02:32] start main_train_and_evaluate with ./data/202304191023_train_0.35_15.csv ./data/202304191023_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:02:33] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 81\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/36 01:56 < 01:03, 0.19 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.278100</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.278100</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-18\n",
      "Configuration saved in results/checkpoint-18/config.json\n",
      "Model weights saved in results/checkpoint-18/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-12] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-6 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:05:24] finish training.\n",
      "[INFO] [2023-11-22T11:05:24] finish testing.\n",
      "[INFO] [2023-11-22T11:05:24] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304140402 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304191023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304191023/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304191023/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304191023 saved\n",
      "[INFO] config updated to 202304191023\n",
      "[INFO] [2023-11-22T11:05:35] start main_train_and_evaluate with ./data/202304270449_train_0.35_15.csv ./data/202304270449_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:05:36] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 81\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 36\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/36 02:11 < 00:28, 0.21 it/s, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.912527</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.652500</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.652500</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-6\n",
      "Configuration saved in results/checkpoint-6/config.json\n",
      "Model weights saved in results/checkpoint-6/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-18\n",
      "Configuration saved in results/checkpoint-18/config.json\n",
      "Model weights saved in results/checkpoint-18/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-6] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-30\n",
      "Configuration saved in results/checkpoint-30/config.json\n",
      "Model weights saved in results/checkpoint-30/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-18] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-12 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:08:52] finish training.\n",
      "[INFO] [2023-11-22T11:08:52] finish testing.\n",
      "[INFO] [2023-11-22T11:08:52] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304191023 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202304270449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202304270449/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202304270449/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202304270449 saved\n",
      "[INFO] config updated to 202304270449\n",
      "[INFO] [2023-11-22T11:09:03] start main_train_and_evaluate with ./data/202305091133_train_0.35_15.csv ./data/202305091133_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:09:03] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 189\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/72 01:51 < 00:58, 0.41 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.910100</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-12\n",
      "Configuration saved in results/checkpoint-12/config.json\n",
      "Model weights saved in results/checkpoint-12/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-24\n",
      "Configuration saved in results/checkpoint-24/config.json\n",
      "Model weights saved in results/checkpoint-24/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-36\n",
      "Configuration saved in results/checkpoint-36/config.json\n",
      "Model weights saved in results/checkpoint-36/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-48\n",
      "Configuration saved in results/checkpoint-48/config.json\n",
      "Model weights saved in results/checkpoint-48/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-24] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-12 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 21\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:11:50] finish training.\n",
      "[INFO] [2023-11-22T11:11:50] finish testing.\n",
      "[INFO] [2023-11-22T11:11:51] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202304270449 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202305091133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202305091133/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202305091133/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202305091133 saved\n",
      "[INFO] config updated to 202305091133\n",
      "[INFO] [2023-11-22T11:12:01] start main_train_and_evaluate with ./data/202305221222_train_0.35_15.csv ./data/202305221222_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:12:01] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 202\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/78 01:52 < 00:58, 0.44 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.063000</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-13\n",
      "Configuration saved in results/checkpoint-13/config.json\n",
      "Model weights saved in results/checkpoint-13/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-26\n",
      "Configuration saved in results/checkpoint-26/config.json\n",
      "Model weights saved in results/checkpoint-26/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-39\n",
      "Configuration saved in results/checkpoint-39/config.json\n",
      "Model weights saved in results/checkpoint-39/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-52\n",
      "Configuration saved in results/checkpoint-52/config.json\n",
      "Model weights saved in results/checkpoint-52/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-26] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-13 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:14:49] finish training.\n",
      "[INFO] [2023-11-22T11:14:50] finish testing.\n",
      "[INFO] [2023-11-22T11:14:50] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202305091133 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202305221222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202305221222/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202305221222/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202305221222 saved\n",
      "[INFO] config updated to 202305221222\n",
      "[INFO] [2023-11-22T11:15:00] start main_train_and_evaluate with ./data/202307030930_train_0.35_15.csv ./data/202307030930_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:15:01] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 445\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 168\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='112' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [112/168 02:22 < 01:12, 0.77 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-28\n",
      "Configuration saved in results/checkpoint-28/config.json\n",
      "Model weights saved in results/checkpoint-28/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-56\n",
      "Configuration saved in results/checkpoint-56/config.json\n",
      "Model weights saved in results/checkpoint-56/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-84\n",
      "Configuration saved in results/checkpoint-84/config.json\n",
      "Model weights saved in results/checkpoint-84/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-112\n",
      "Configuration saved in results/checkpoint-112/config.json\n",
      "Model weights saved in results/checkpoint-112/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-56] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-28 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:18:20] finish training.\n",
      "[INFO] [2023-11-22T11:18:20] finish testing.\n",
      "[INFO] [2023-11-22T11:18:20] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202305221222 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202307030930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202307030930/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202307030930/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202307030930 saved\n",
      "[INFO] config updated to 202307030930\n",
      "[INFO] [2023-11-22T11:18:31] start main_train_and_evaluate with ./data/202307050919_train_0.35_15.csv ./data/202307050919_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:18:32] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2362\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 888\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='740' max='888' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [740/888 06:25 < 01:17, 1.91 it/s, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.057824</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.992380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-148\n",
      "Configuration saved in results/checkpoint-148/config.json\n",
      "Model weights saved in results/checkpoint-148/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-296\n",
      "Configuration saved in results/checkpoint-296/config.json\n",
      "Model weights saved in results/checkpoint-296/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-444\n",
      "Configuration saved in results/checkpoint-444/config.json\n",
      "Model weights saved in results/checkpoint-444/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-592\n",
      "Configuration saved in results/checkpoint-592/config.json\n",
      "Model weights saved in results/checkpoint-592/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-148] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-740\n",
      "Configuration saved in results/checkpoint-740/config.json\n",
      "Model weights saved in results/checkpoint-740/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-444] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-296 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 263\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:25:54] finish training.\n",
      "[INFO] [2023-11-22T11:25:54] finish testing.\n",
      "[INFO] [2023-11-22T11:25:54] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202307030930 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202307050919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202307050919/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202307050919/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202307050919 saved\n",
      "[INFO] config updated to 202307050919\n",
      "[INFO] [2023-11-22T11:26:05] start main_train_and_evaluate with ./data/202307070327_train_0.35_15.csv ./data/202307070327_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:26:05] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 202\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 78\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 02:42, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.991600</td>\n",
       "      <td>0.097023</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.953247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-13\n",
      "Configuration saved in results/checkpoint-13/config.json\n",
      "Model weights saved in results/checkpoint-13/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-26\n",
      "Configuration saved in results/checkpoint-26/config.json\n",
      "Model weights saved in results/checkpoint-26/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-39\n",
      "Configuration saved in results/checkpoint-39/config.json\n",
      "Model weights saved in results/checkpoint-39/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-52\n",
      "Configuration saved in results/checkpoint-52/config.json\n",
      "Model weights saved in results/checkpoint-52/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-13] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-65\n",
      "Configuration saved in results/checkpoint-65/config.json\n",
      "Model weights saved in results/checkpoint-65/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-26] due to args.save_total_limit\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-78\n",
      "Configuration saved in results/checkpoint-78/config.json\n",
      "Model weights saved in results/checkpoint-78/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-52] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-39 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 23\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:29:44] finish training.\n",
      "[INFO] [2023-11-22T11:29:44] finish testing.\n",
      "[INFO] [2023-11-22T11:29:44] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202307050919 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202307070327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202307070327/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202307070327/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202307070327 saved\n",
      "[INFO] config updated to 202307070327\n",
      "[INFO] [2023-11-22T11:29:54] start main_train_and_evaluate with ./data/202307191009_train_0.35_15.csv ./data/202307191009_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:29:55] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 108\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 42\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/42 01:36 < 00:51, 0.27 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.642700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-7\n",
      "Configuration saved in results/checkpoint-7/config.json\n",
      "Model weights saved in results/checkpoint-7/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-14\n",
      "Configuration saved in results/checkpoint-14/config.json\n",
      "Model weights saved in results/checkpoint-14/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-21\n",
      "Configuration saved in results/checkpoint-21/config.json\n",
      "Model weights saved in results/checkpoint-21/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-28\n",
      "Configuration saved in results/checkpoint-28/config.json\n",
      "Model weights saved in results/checkpoint-28/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-14] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-7 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 12\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:32:27] finish training.\n",
      "[INFO] [2023-11-22T11:32:27] finish testing.\n",
      "[INFO] [2023-11-22T11:32:27] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202307070327 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202307191009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202307191009/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202307191009/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202307191009 saved\n",
      "[INFO] config updated to 202307191009\n",
      "[INFO] [2023-11-22T11:32:37] start main_train_and_evaluate with ./data/202308030456_train_0.35_15.csv ./data/202308030456_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:32:38] start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 216\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 84\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/84 01:52 < 00:58, 0.48 it/s, Epoch 4/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.452400</td>\n",
       "      <td>0.037938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-14\n",
      "Configuration saved in results/checkpoint-14/config.json\n",
      "Model weights saved in results/checkpoint-14/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-28\n",
      "Configuration saved in results/checkpoint-28/config.json\n",
      "Model weights saved in results/checkpoint-28/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-42\n",
      "Configuration saved in results/checkpoint-42/config.json\n",
      "Model weights saved in results/checkpoint-42/pytorch_model.bin\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to results/checkpoint-56\n",
      "Configuration saved in results/checkpoint-56/config.json\n",
      "Model weights saved in results/checkpoint-56/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-28] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from results/checkpoint-14 (score: 1.0).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 24\n",
      "  Batch size = 16\n",
      "<ipython-input-3-fd40b46b2d01>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2023-11-22T11:35:26] finish training.\n",
      "[INFO] [2023-11-22T11:35:26] finish testing.\n",
      "[INFO] [2023-11-22T11:35:26] main_train_and_evaluate finished.\n",
      "[INFO] model distilbert-base-uncased-202307191009 cleared\n",
      "[INFO] start to save ./distilbert-base-uncased-202308030456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./distilbert-base-uncased-202308030456/config.json\n",
      "Model weights saved in ./distilbert-base-uncased-202308030456/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] model ./distilbert-base-uncased-202308030456 saved\n",
      "[INFO] config updated to 202308030456\n"
     ]
    }
   ],
   "source": [
    "env_training = framework.load_training_environment()\n",
    "framework.main(env_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da750245-0a67-4fa9-81d5-e5c370d15ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
