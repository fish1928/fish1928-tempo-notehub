[{"id": 5890, "name": "4", "raw": "2023-03-23 18:07:54,023 | Failed at Play [pvrdma_network_device_ops] *****************\n2023-03-23 18:07:54,023 | TASK [pvrdma_network_device_ops][Check new RDMA device exists] \ntask path: /home/worker/workspace/Ansible_RHEL_8.x_80GA_PARAVIRTUAL_E1000E_EFI/ansible-vsphere-gos-validation/linux/network_device_ops/check_and_reload_pvrdma.yml:22\nfatal: [localhost]: FAILED! => No new RDMA device is detected on VM test_vm\nerror message:\nNo new RDMA device is detected on VM test_vm", "category": null, "processed": "timestamp failed at play pvrdma network device ops timestamp task pvrdma network device ops check new remote direct memory access device exists task path home worker workspace ansible rhel number x number ga para virtual efi ansible vsphere gos validation linux network device ops check and reload pvrdma yml number fatal localhost failed no new remote direct memory access device is detected on vm test vm error message no new remote direct memory access device is detected on vm test vm", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5885, "name": "4", "raw": "2023-03-23 19:59:21,023 | Failed at Play [check_os_fullname] *************************\n2023-03-23 19:59:21,023 | TASK [check_os_fullname][Check guest family in VM's guest info with VMware Tools 12.1.5 on ESXi 7.0.3] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/check_os_fullname/validate_os_fullname.yml:99\nfatal: [localhost]: FAILED! => VM's guest family in guest info is 'otherGuestFamily',\n not expected 'linuxGuest'.\nerror message:\nVM's guest family in guest info is 'otherGuestFamily',\n not expected 'linuxGuest'.", "category": null, "processed": "timestamp failed at play check os full name timestamp task check os full name check guest family in vm s guest info with vmware tools version id on esxi version id task path home worker workspace ansible rhel number x nvme vmxnet number efi ansible vsphere gos validation linux check os full name validate os full name yml number fatal localhost failed vm s guest family in guest info is other guest family not expected linux guest error message vm s guest family in guest info is other guest family not expected linux guest", "solution": "deepdive", "target": "product", "version": 202304110953}, {"id": 5896, "name": "5", "raw": "2023-03-03 07:42:15,003 | Failed at Play [check_os_fullname] *************************\n2023-03-03 07:42:15,003 | TASK [check_os_fullname][Assert VM has valid IPv4 address for VM 'test_windows11_22538'] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/common/vm_get_primary_nic.yml:15\nfatal: [localhost]: FAILED! => Not found valid IPv4 address for VM 'test_windows11_22538'\nerror message:\nNot found valid IPv4 address for VM 'test_windows11_22538'", "category": null, "processed": "timestamp failed at play check os full name timestamp task check os full name assert vm has valid ip v number address for vm test windows number task path home worker workspace ansible regression windows number ansible vsphere gos validation common vm get primary nic yml number fatal localhost failed not found valid ip v number address for vm test windows number error message not found valid ip v number address for vm test windows number number", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5901, "name": "5", "raw": "2023-03-09 07:11:57,009 | Failed at Play [nvdimm_cold_add_remove] ********************\n2023-03-09 07:11:57,009 | TASK [nvdimm_cold_add_remove][Revert snapshot failed] ******\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_Physical_VBS_80GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:47\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed\nerror message:\nRevert to snapshot 'BaseSnapshot' failed", "category": null, "processed": "timestamp failed at play nvdimm cold add remove timestamp task nvdimm cold add remove revert snapshot failed task path home worker workspace ansible windows server lts c physical vbs number ga lsi logic sas efi ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed error message revert to snapshot base snapshot failed", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5898, "name": "5", "raw": "2023-03-03 07:48:24,003 | Failed at Play [nvdimm_cold_add_remove] ********************\n2023-03-03 07:48:24,003 | TASK [nvdimm_cold_add_remove][Assert VM has valid IPv4 address for VM 'test_windows11_22538'] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/common/vm_get_primary_nic.yml:15\nfatal: [localhost]: FAILED! => Not found valid IPv4 address for VM 'test_windows11_22538'\nerror message:\nNot found valid IPv4 address for VM 'test_windows11_22538'", "category": null, "processed": "timestamp failed at play nvdimm cold add remove timestamp task nvdimm cold add remove assert vm has valid ip v number address for vm test windows number task path home worker workspace ansible regression windows number ansible vsphere gos validation common vm get primary nic yml number fatal localhost failed not found valid ip v number address for vm test windows number error message not found valid ip v number address for vm test windows number number", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5886, "name": "4", "raw": "2023-03-24 05:42:29,024 | Failed at Play [deploy_vm_efi_lsilogicsas_vmxnet3] *********\n2023-03-24 05:42:29,024 | TASK [deploy_vm_efi_lsilogicsas_vmxnet3][Datastore file operation] \ntask path: /home/worker/workspace/Ansible_Windows_11_70U3_LSILOGICSAS_VMXNET3_EFI/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:28\nfatal: [localhost]: FAILED! => File 'OS/Other/Windows/Windows11/v21H2/en-us_windows_11_business_editions_x64_dvd_3a304c08.iso' is absent, cannot continue\nerror message:\nFile 'OS/Other/Windows/Windows11/v21H2/en-us_windows_11_business_editions_x64_dvd_3a304c08.iso' is absent, cannot continue\n2023-03-24 05:42:31,024 | TASK [deploy_vm_efi_lsilogicsas_vmxnet3][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_Windows_11_70U3_LSILOGICSAS_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:91\nfatal: [localhost]: FAILED! => Exit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_vmxnet3\nerror message:\nExit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_vmxnet3", "category": null, "processed": "timestamp failed at play deploy vm efi lsi logic sas vmxnet number timestamp task deploy vm efi lsi logic sas vmxnet number data store file operation task path home worker workspace ansible windows number lsi logic sas vmxnet number efi ansible vsphere gos validation common esxi check delete data store file yml number fatal localhost failed file os other windows windows number v number h number en us windows number business editions x number dvd hex id iso is absent can not continue error message file os other windows windows number v number h number en us windows number business editions x number dvd hex id iso is absent can not continue timestamp task deploy vm efi lsi logic sas vmxnet number testing exit due to failure task path home worker workspace ansible windows number lsi logic sas vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing because exit testing when fail is set to true in test case deploy vm efi lsi logic sas vmxnet number error message exit testing because exit testing when fail is set to true in test case deploy vm efi lsi logic sas vmxnet number", "solution": "deepdive", "target": "usererror", "version": 202304110953}, {"id": 5887, "name": "4", "raw": "2023-03-20 13:53:41,020 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2023-03-20 13:53:41,020 | TASK [deploy_vm_efi_paravirtual_vmxnet3][Check VMware Tools is running and collects guest IPv4 address successfully] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:49\nfatal: [localhost]: FAILED! => [\"It's timed out for VMware Tools collecting guest IPv4 address in 600 seconds.\", \"VMware Tools running status is 'guestToolsRunning'.\", \"VM's IP address in guest info is '2620:124:6020:c302:e798:9e56:5b3b:b0ee'.\", \"VM's all IP addresses in guest info are '['2620:124:6020:c302:e798:9e56:5b3b:b0ee', '2620:124:6020:c302:250:56ff:fe9f:af72', 'fe80::250:56ff:fe9f:af72']'.\"]\nerror message:\nIt's timed out for VMware Tools collecting guest IPv4 address in 600 seconds.\nVMware Tools running status is 'guestToolsRunning'.\nVM's IP address in guest info is '2620:124:6020:c302:e798:9e56:5b3b:b0ee'.\nVM's all IP addresses in guest info are '['2620:124:6020:c302:e798:9e56:5b3b:b0ee', '2620:124:6020:c302:250:56ff:fe9f:af72', 'fe80::250:56ff:fe9f:af72']'.\n2023-03-20 13:54:26,020 | TASK [deploy_vm_efi_paravirtual_vmxnet3][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:77\nfatal: [localhost]: FAILED! => Exit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3\nerror message:\nExit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": null, "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task deploy vm efi para virtual vmxnet number check vmware tools is running and collects guest ip v number address successfully task path home worker workspace ansible sles main para virtual vmxnet number efi ansible vsphere gos validation common vm wait guest ip yml number fatal localhost failed it s timed out for vmware tools collecting guest ip v number address in number seconds vmware tools running status is guest tools running vm sip address in guest info is ip address vm s all ip addresses in guest info are ip address ip address ip address error message it s timed out for vmware tools collecting guest ip v number address in number seconds vmware tools running status is guest tools running vm sip address in guest info is ip address vm s all ip addresses in guest info are ip address ip address ip address timestamp task deploy vm efi para virtual vmxnet number testing exit due to failure task path home worker workspace ansible sles main para virtual vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing because exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number error message exit testing because exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "nimbus", "version": 202304110953}, {"id": 5888, "name": "4", "raw": "2023-03-24 12:30:55,024 | Failed at Play [deploy_vm_bios_ide_e1000e] *****************\n2023-03-24 12:30:55,024 | TASK [deploy_vm_bios_ide_e1000e][Upload local file to ESXi datastore] \ntask path: /home/worker/workspace/Ansible_Ubuntu_22.04_Desktop_ISO_70GA_IDE_E1000E_BIOS/ansible-vsphere-gos-validation/common/esxi_upload_datastore_file.yml:11\nssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:2384)\nurllib.error.URLError: <urlopen error EOF occurred in violation of protocol (_ssl.c:2384)>\nTypeError: 'URLError' object is not subscriptable\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error\nerror message:\nMODULE FAILURE\nSee stdout/stderr for the exact error\nssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:2384)\nurllib.error.URLError: <urlopen error EOF occurred in violation of protocol (_ssl.c:2384)>\nTypeError: 'URLError' object is not subscriptable\n2023-03-24 12:30:57,024 | TASK [deploy_vm_bios_ide_e1000e][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_Ubuntu_22.04_Desktop_ISO_70GA_IDE_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:91\nfatal: [localhost]: FAILED! => Exit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_ide_e1000e\nerror message:\nExit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_ide_e1000e", "category": null, "processed": "timestamp failed at play deploy vm bios ide timestamp task deploy vm bios ide upload local file to esxi data store task path home worker workspace ansible ubuntu number desktop iso number ga ide bios ansible vsphere gos validation common esxi upload data store file yml number ssl ssl eof error eof occurred in violation of protocol ssl c number url library error url error url open error eof occurred in violation of protocol ssl c number type error url error object is not sub scriptable fatal localhost failed module failure see stdout stderr for the exact error error message module failure see stdout stderr for the exact error ssl ssl eof error eof occurred in violation of protocol ssl c number url library error url error url open error eof occurred in violation of protocol ssl c number type error url error object is not sub scriptable timestamp task deploy vm bios ide testing exit due to failure task path home worker workspace ansible ubuntu number desktop iso number ga ide bios ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing because exit testing when fail is set to true in test case deploy vm bios ide e number e error message exit testing because exit testing when fail is set to true in test case deploy vm bios ide e number e", "solution": "retry", "target": "nimbus", "version": 202304110953}, {"id": 5889, "name": "4", "raw": "2023-03-22 02:30:48,022 | Failed at Play [deploy_vm_efi_ide_e1000e] ******************\n2023-03-22 02:30:48,022 | TASK [deploy_vm_efi_ide_e1000e][Add IDE boot disk] *********\ntask path: /home/worker/workspace/Ansible_Photon_5.x_ISO_80GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_create_with_ide_disk.yml:49\nfatal: [localhost -> 10.182.5.68]: FAILED! => non-zero return code when vim-cmd\nerror message:\nnon-zero return code: 1\nReconfigure failed: (vim.fault.NoDiskSpace) {\n   faultCause = (vmodl.MethodFault) null, \n   faultMessage = (vmodl.LocalizableMessage) [\n      (vmodl.LocalizableMessage) {\n         key = \"vob.fssvec.SetFileAttributes.file.failed\", \n         arg = <unset>, \n         message = \"File system specific implementation of SetFileAttributes[file] failed\"\n      }\n   ], \n   file = \"[datastore2] test_vm_1679451863797/test_vm_1679451863797_1.vmdk\", \n   datastore = \"datastore2\"\n   msg = \"Insufficient disk space on datastore 'datastore2'.\"\n}\n2023-03-22 02:30:50,022 | TASK [deploy_vm_efi_ide_e1000e][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_Photon_5.x_ISO_80GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:77\nfatal: [localhost]: FAILED! => Exit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_ide_e1000e\nerror message:\nExit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_ide_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi ide timestamp task deploy vm efi ide add ide boot disk task path home worker workspace ansible photon number x iso number ga ide efi ansible vsphere gos validation common vm create with ide disk yml number fatal localhost ip address failed nonzero return code when vim command error message nonzero return code number re configure failed vim fault no disk space fault cause vmodl method fault null fault message vmodl localizable message vmodl localizable message key vob fss vec set file attributes file failed arg un set message file system specific implementation of set file attributes file failed file data store number test vm number test vm number vmdk data store data store number message insufficient disk space on data store data store number timestamp task deploy vm efi ide testing exit due to failure task path home worker workspace ansible photon number x iso number ga ide efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing because exit testing when fail is set to true in test case deploy vm efi ide e number e error message exit testing because exit testing when fail is set to true in test case deploy vm efi ide e number e", "solution": "retry", "target": "nimbus", "version": 202304110953}, {"id": 5906, "name": "7", "raw": "2023-03-20 05:20:07,020 | Failed at Play [pvrdma_network_device_ops] *****************\n2023-03-20 05:20:07,020 | TASK [pvrdma_network_device_ops][Check RDMA ping result from client VM to server VM] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_70GA_LSILOGICSAS_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/network_device_ops/pvrdma_network_device_ops.yml:149\nfatal: [localhost]: FAILED! => Failed to run RDMA ping from client VM 'test_vm_client_20230320051421' to server VM 'test_vm'. Hit error 'cma event RDMA_CM_EVENT_REJECTED, error 8'\nerror message:\nFailed to run RDMA ping from client VM 'test_vm_client_20230320051421' to server VM 'test_vm'. Hit error 'cma event RDMA_CM_EVENT_REJECTED, error 8'", "category": null, "processed": "timestamp failed at play pvrdma network device ops timestamp task pvrdma network device ops check remote direct memory access ping result from client vm to server vm task path home worker workspace ansible sles number ga lsi logic sas vmxnet number efi ansible vsphere gos validation linux network device ops pvrdma network device ops yml number fatal localhost failed failed to run remote direct memory access ping from client vm test vm client timestamp to server vm test vm hit error cma event remote direct memory access cm event rejected error number error message failed to run remote direct memory access ping from client vm test vm client timestamp to server vm test vm hit error cma event remote direct memory access cm event rejected error number", "solution": "retry", "target": "targetvm", "version": 202304110953}, {"id": 5894, "name": "5", "raw": "2023-03-03 07:53:20,003 | Failed at Play [check_os_fullname] *************************\n2023-03-03 07:53:20,003 | TASK [check_os_fullname][Assert VM has valid IPv4 address for VM 'test_ubuntu20.04.5_server_iso'] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_20.04_Server_ISO/ansible-vsphere-gos-validation/common/vm_get_primary_nic.yml:15\nfatal: [localhost]: FAILED! => Not found valid IPv4 address for VM 'test_ubuntu20.04.5_server_iso'\nerror message:\nNot found valid IPv4 address for VM 'test_ubuntu20.04.5_server_iso'\n2023-03-03 07:54:04,003 | TASK [check_os_fullname][Check guest file path is provided] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_20.04_Server_ISO/ansible-vsphere-gos-validation/linux/utils/get_file_stat_info.yml:11\nfatal: [localhost]: FAILED! => 'guest_file_path' must be set with a file path in guest OS\nerror message:\n'guest_file_path' must be set with a file path in guest OS", "category": null, "processed": "timestamp failed at play check os full name timestamp task check os full name assert vm has valid ip v number address for vm test ubuntu version id server iso task path home worker workspace ansible regression ubuntu number server iso ansible vsphere gos validation common vm get primary nic yml number fatal localhost failed not found valid ip v number address for vm test ubuntu version id server iso error message not found valid ip v number address for vm test ubuntu version id server iso timestamp task check os full name check guest file path is provided task path home worker workspace ansible regression ubuntu number server iso ansible vsphere gos validation linux utilities get file stat info yml number fatal localhost failed guest file path must be set with a file path in guest os error message guest file path must be set with a file path in guest os", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5899, "name": "5", "raw": "2023-03-22 02:16:29,022 | Failed at Play [gosc_cloudinit_staticip] *******************\n2023-03-22 02:16:29,022 | TASK [gosc_cloudinit_staticip][Check GOSC complete message] \ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/guest_customization/wait_gosc_complete_msg.yml:46\nfatal: [localhost]: FAILED! => It's timed out to wait for GOSC complete message 'Cloud-init .*finished at.*Datasource DataSourceOVF \\[seed=vmware-tools\\]' present in /var/log/cloud-init.log in 100 seconds.\nerror message:\nIt's timed out to wait for GOSC complete message 'Cloud-init .*finished at.*Datasource DataSourceOVF \\[seed=vmware-tools\\]' present in /var/log/cloud-init.log in 100 seconds.", "category": null, "processed": "timestamp failed at play go sc cloud init static ip timestamp task go sc cloud init static ip check go sc complete message task path home worker workspace ansible cycle photon number iso ansible vsphere gos validation linux guest customization wait go sc complete message yml number fatal localhost failed it s timed out to wait for go sc complete message cloud init finished at data source data source ovf seed vmware tools present in var log cloud init log in number seconds error message it s timed out to wait for go sc complete message cloud init finished at data source data source ovf seed vmware tools present in var log cloud init log in number seconds", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5904, "name": "6", "raw": "2023-03-09 07:18:19,009 | Failed at Play [wsl_distro_install_uninstall] **************\n2023-03-09 07:18:19,009 | TASK [wsl_distro_install_uninstall][Revert snapshot failed] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_Physical_VBS_80GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:47\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed\nerror message:\nRevert to snapshot 'BaseSnapshot' failed", "category": null, "processed": "timestamp failed at play wsl distro install un install timestamp task wsl distro install un install revert snapshot failed task path home worker workspace ansible windows server lts c physical vbs number ga lsi logic sas efi ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed error message revert to snapshot base snapshot failed", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5909, "name": "7", "raw": "2023-03-23 18:25:33,023 | Failed at Play [pvrdma_network_device_ops] *****************\n2023-03-23 18:25:33,023 | TASK [pvrdma_network_device_ops][Remove a network adapter from VM 'test_vm'] \ntask path: /home/worker/workspace/Ansible_RHEL_8.x_70U1_SATA_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_remove_network_adapter.yml:4\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error\nerror message:\nMODULE FAILURE\nSee stdout/stderr for the exact error\npyVmomi.VmomiSupport.GenericVmConfigFault: (vim.fault.GenericVmConfigFault) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = \"The guest operating system did not respond to a hot-remove request for device 'ethernet1' in a timely manner.\",\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) [\n      (vmodl.LocalizableMessage) {\n         dynamicType = <unset>,\n         dynamicProperty = (vmodl.DynamicProperty) [],\n         key = 'msg.vigor.hotRemoveStillExists',\n         arg = (vmodl.KeyAnyValue) [\n            (vmodl.KeyAnyValue) {\n               dynamicType = <unset>,\n               dynamicProperty = (vmodl.DynamicProperty) [],\n               key = '1',\n               value = 'ethernet1'\n            }\n         ],\n         message = \"The guest operating system did not respond to a hot-remove request for device 'ethernet1' in a timely manner.\"\n      }\n   ],\n   reason = \"The guest operating system did not respond to a hot-remove request for device 'ethernet1' in a timely manner.\"\n}\nThe above exception was the direct cause of the following exception:\nansible_collections.community.vmware.plugins.module_utils.vmware.TaskError: (\"The guest operating system did not respond to a hot-remove request for device 'ethernet1' in a timely manner.\", None)", "category": null, "processed": "timestamp failed at play pvrdma network device ops timestamp task pvrdma network device ops remove a network adapter from vm test vm task path home worker workspace ansible rhel number x sata vmxnet number bios ansible vsphere gos validation common vm remove network adapter yml number fatal localhost failed module failure see stdout stderr for the exact error error message module failure see stdout stderr for the exact error python vmomi vmomi support generic vm configuration fault vim fault generic vm configuration fault dynamic type un set dynamic property vmodl dynamic property message the guest operating system did not respond to a hot remove request for device ethernet number in a timely manner fault cause un set fault message vmodl localizable message vmodl localizable message dynamic type un set dynamic property vmodl dynamic property key message vigor hot remove still exists arg vmodl key any value vmodl key any value dynamic type un set dynamic property vmodl dynamic property key number value ethernet number message the guest operating system did not respond to a hot remove request for device ethernet number in a timely manner reason the guest operating system did not respond to a hot remove request for device ethernet number in a timely manner the above exception was the direct cause of the following exception ansible collections community vmware plugins module utilities vmware task error the guest operating system did not respond to a hot remove request for device ethernet number in a timely manner none", "solution": "retry", "target": "targetvm", "version": 202304110953}, {"id": 5891, "name": "4", "raw": "2023-03-03 07:17:26,003 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2023-03-03 07:17:26,003 | TASK [deploy_vm_efi_paravirtual_vmxnet3][Assert VM has valid IPv4 address for VM 'test_photon3_iso'] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/common/vm_get_primary_nic.yml:15\nfatal: [localhost]: FAILED! => Not found valid IPv4 address for VM 'test_photon3_iso'\nerror message:\nNot found valid IPv4 address for VM 'test_photon3_iso'\n2023-03-03 07:18:10,003 | TASK [deploy_vm_efi_paravirtual_vmxnet3][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/common/test_rescue.yml:59\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3\nerror message:\nExit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": null, "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task deploy vm efi para virtual vmxnet number assert vm has valid ip v number address for vm test photon number iso task path home worker workspace ansible regression photon number iso ansible vsphere gos validation common vm get primary nic yml number fatal localhost failed not found valid ip v number address for vm test photon number iso error message not found valid ip v number address for vm test photon number iso timestamp task deploy vm efi para virtual vmxnet number testing exit due to failure task path home worker workspace ansible regression photon number iso ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number error message exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5892, "name": "4", "raw": "2023-03-21 04:32:54,021 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2023-03-21 04:32:54,021 | TASK [deploy_vm_efi_paravirtual_vmxnet3][Download datastore file] \ntask path: /home/worker/workspace/Ansible_Cycle_Debian_10.x_64bit/ansible-vsphere-gos-validation/common/esxi_download_datastore_file.yml:36\nTimeoutError: The read operation timed out\nfatal: [localhost]: FAILED! => failed to create temporary content file: The read operation timed out\nerror message:\nfailed to create temporary content file: The read operation timed out\n2023-03-21 04:32:55,021 | TASK [deploy_vm_efi_paravirtual_vmxnet3][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_Cycle_Debian_10.x_64bit/ansible-vsphere-gos-validation/common/test_rescue.yml:77\nfatal: [localhost]: FAILED! => Exit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3\nerror message:\nExit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": null, "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task deploy vm efi para virtual vmxnet number download data store file task path home worker workspace ansible cycle debian number x number b it ansible vsphere gos validation common esxi download data store file yml number timeout error the read operation timed out fatal localhost failed failed to create temporary content file the read operation timed out error message failed to create temporary content file the read operation timed out timestamp task deploy vm efi para virtual vmxnet number testing exit due to failure task path home worker workspace ansible cycle debian number x number b it ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing because exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number error message exit testing because exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "testbed", "version": 202304110953}, {"id": 5897, "name": "5", "raw": "2023-03-20 06:59:59,020 | Failed at Play [nvdimm_cold_add_remove] ********************\n2023-03-20 06:59:59,020 | TASK [nvdimm_cold_add_remove][Check VMware Tools is running and collects guest IPv4 address successfully] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_70U3_NVME_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:49\nfatal: [localhost]: FAILED! => [\"It's timed out for VMware Tools collecting guest IPv4 address in 900 seconds.\", \"VMware Tools running status is 'guestToolsRunning'.\", \"VM's IP address in guest info is '2620:124:6020:c308:0:a:0:63f'.\", \"VM's all IP addresses in guest info are '['2620:124:6020:c308:0:a:0:63f', '2620:124:6020:c308:8e1b:eac0:4aaf:5f59', '2620:124:6020:c308:250:56ff:fe9f:23f9', 'fe80::250:56ff:fe9f:23f9']'.\"]\nerror message:\nIt's timed out for VMware Tools collecting guest IPv4 address in 900 seconds.\nVMware Tools running status is 'guestToolsRunning'.\nVM's IP address in guest info is '2620:124:6020:c308:0:a:0:63f'.\nVM's all IP addresses in guest info are '['2620:124:6020:c308:0:a:0:63f', '2620:124:6020:c308:8e1b:eac0:4aaf:5f59', '2620:124:6020:c308:250:56ff:fe9f:23f9', 'fe80::250:56ff:fe9f:23f9']'.", "category": null, "processed": "timestamp failed at play nvdimm cold add remove timestamp task nvdimm cold add remove check vmware tools is running and collects guest ip v number address successfully task path home worker workspace ansible sles nvme efi ansible vsphere gos validation common vm wait guest ip yml number fatal localhost failed it s timed out for vmware tools collecting guest ip v number address in number seconds vmware tools running status is guest tools running vm sip address in guest info is ip address vm s all ip addresses in guest info are ip address ip address ip address ip address error message it s timed out for vmware tools collecting guest ip v number address in number seconds vmware tools running status is guest tools running vm sip address in guest info is ip address vm s all ip addresses in guest info are ip address ip address ip address ip address", "solution": "retry", "target": "nimbus", "version": 202304110953}, {"id": 5902, "name": "6", "raw": "2023-03-09 07:17:19,009 | Failed at Play [vbs_enable_disable] ************************\n2023-03-09 07:17:19,009 | TASK [vbs_enable_disable][Revert snapshot failed] **********\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_Physical_VBS_80GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:47\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed\nerror message:\nRevert to snapshot 'BaseSnapshot' failed", "category": null, "processed": "timestamp failed at play vbs enable disable timestamp task vbs enable disable revert snapshot failed task path home worker workspace ansible windows server lts c physical vbs number ga lsi logic sas efi ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed error message revert to snapshot base snapshot failed", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5907, "name": "7", "raw": "2023-03-27 09:39:06,027 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2023-03-27 09:39:06,027 | TASK [deploy_vm_efi_paravirtual_vmxnet3][Check VM 'suvp_win11_v21h2_70u3' IP address] \ntask path: /home/worker/workspace/Ansible_SUVP_Windows_11_Physical_70U3_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'suvp_win11_v21h2_70u3' IP Address\nerror message:\nFailed to get VM 'suvp_win11_v21h2_70u3' IP Address\n2023-03-27 09:39:31,027 | TASK [deploy_vm_efi_paravirtual_vmxnet3][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_SUVP_Windows_11_Physical_70U3_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:91\nfatal: [localhost]: FAILED! => Exit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3\nerror message:\nExit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": null, "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task deploy vm efi para virtual vmxnet number check vm suvp v number h number ip address task path home worker workspace ansible suvp windows number physical para virtual vmxnet number efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm suvp v number h number ip address error message failed to get vm suvp v number h number ip address timestamp task deploy vm efi para virtual vmxnet number testing exit due to failure task path home worker workspace ansible suvp windows number physical para virtual vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing because exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number error message exit testing because exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5893, "name": "4", "raw": "2023-03-22 04:28:46,022 | Failed at Play [deploy_vm_efi_ide_e1000e] ******************\n2023-03-22 04:28:46,022 | TASK [deploy_vm_efi_ide_e1000e][Wait for message 'Autoinstall is completed.' appear in VM log serial-20230322032551.log] \ntask path: /home/worker/workspace/Ansible_Photon_5.x_ISO_80GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:40\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 120,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\nerror message:\n2023-03-22 04:29:30,022 | TASK [deploy_vm_efi_ide_e1000e][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_Photon_5.x_ISO_80GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:77\nfatal: [localhost]: FAILED! => Exit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_ide_e1000e\nerror message:\nExit testing because 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_ide_e1000e\n2023-03-22 04:35:18,022 | TASK [deploy_vm_efi_ide_e1000e][Check VMware Tools is running and collects guest OS fullname successfully] \ntask path: /home/worker/workspace/Ansible_Photon_5.x_ISO_80GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_wait_guest_fullname.yml:46\nfatal: [localhost]: FAILED! => It's timed out for VMware Tools collecting guest OS fullname in 300 seconds. Current VMware Tools running status is 'guestToolsNotRunning', and guest OS fullname is ''.\nerror message:\nIt's timed out for VMware Tools collecting guest OS fullname in 300 seconds. Current VMware Tools running status is 'guestToolsNotRunning', and guest OS fullname is ''.", "category": null, "processed": "timestamp failed at play deploy vm efi ide timestamp task deploy vm efi ide wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible photon number x iso number ga ide efi ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false error message timestamp task deploy vm efi ide testing exit due to failure task path home worker workspace ansible photon number x iso number ga ide efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing because exit testing when fail is set to true in test case deploy vm efi ide e number e error message exit testing because exit testing when fail is set to true in test case deploy vm efi ide e number e timestamp task deploy vm efi ide check vmware tools is running and collects guest os full name successfully task path home worker workspace ansible photon number x iso number ga ide efi ansible vsphere gos validation common vm wait guest full name yml number fatal localhost failed it s timed out for vmware tools collecting guest os full name in number seconds current vmware tools running status is guest tools not running and guest os full name is error message it s timed out for vmware tools collecting guest os full name in number seconds current vmware tools running status is guest tools not running and guest os full name is", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5903, "name": "6", "raw": "2023-03-03 07:48:55,003 | Failed at Play [e1000e_network_device_ops] *****************\n2023-03-03 07:48:55,003 | TASK [e1000e_network_device_ops][Assert VM has valid IPv4 address for VM 'test_windows11_22538'] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/common/vm_get_primary_nic.yml:15\nfatal: [localhost]: FAILED! => Not found valid IPv4 address for VM 'test_windows11_22538'\nerror message:\nNot found valid IPv4 address for VM 'test_windows11_22538'", "category": null, "processed": "timestamp failed at play network device ops timestamp task network device ops assert vm has valid ip v number address for vm test windows number task path home worker workspace ansible regression windows number ansible vsphere gos validation common vm get primary nic yml number fatal localhost failed not found valid ip v number address for vm test windows number error message not found valid ip v number address for vm test windows number number", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5908, "name": "7", "raw": "2023-04-10 06:43:02,010 | Failed at Play [5_wsl_distro_install_uninstall] ************\n2023-04-10 06:43:02,010 | TASK [5_wsl_distro_install_uninstall][Check WSL version setting result] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_Physical_70U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/windows/wsl_distro_install_uninstall/install_wsl.yml:102\nfatal: [localhost]: FAILED! => Setting WSL default version to 2 failed. Please check log file wsl_set_default_version_to_2.txt.\nerror message:\nSetting WSL default version to 2 failed. Please check log file wsl_set_default_version_to_2.txt.", "category": null, "processed": "timestamp failed at play number wsl distro install un install timestamp task number wsl distro install un install check wsl version setting result task path home worker workspace ansible windows server lts c physical lsi logic sas efi ansible vsphere gos validation windows wsl distro install un install install wsl yml number fatal localhost failed setting wsl default version to number failed please check log file wsl set default version to number text error message setting wsl default version to number failed please check log file wsl set default version to number text", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5895, "name": "5", "raw": "2023-03-21 09:31:21,021 | Failed at Play [deploy_photon_ova] *************************\n2023-03-21 09:31:21,021 | TASK [deploy_photon_ova][Check ping IP address 10.78.226.240 is successful] \ntask path: /home/worker/workspace/Ansible_Photon_5.x_OVA_80GA/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:28\nfatal: [localhost]: FAILED! => Pinging IP address 10.78.226.240 failed in 300 seconds.\nerror message:\nPinging IP address 10.78.226.240 failed in 300 seconds.\n2023-03-21 09:31:49,021 | TASK [deploy_photon_ova][Testing exit due to failure] ******\ntask path: /home/worker/workspace/Ansible_Photon_5.x_OVA_80GA/ansible-vsphere-gos-validation/common/test_rescue.yml:77\nfatal: [localhost]: FAILED! => Exit testing because 'exit_testing_when_fail' is set to True in test case deploy_photon_ova\nerror message:\nExit testing because 'exit_testing_when_fail' is set to True in test case deploy_photon_ova\n2023-03-21 09:32:06,021 | TASK [deploy_photon_ova][Fetch file /tmp/cloud-init_2023-03-21-09-31-56.tar.gz from VM guest] \ntask path: /home/worker/workspace/Ansible_Photon_5.x_OVA_80GA/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:91\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root\nerror message:\nInvalid guest login for user root", "category": null, "processed": "timestamp failed at play deploy photon ova timestamp task deploy photon ova check ping ip address ip address is successful task path home worker workspace ansible photon number x ova number ga ansible vsphere gos validation common vm wait ping yml number fatal localhost failed pinging ip address ip address failed in number seconds error message pinging ip address ip address failed in number seconds timestamp task deploy photon ova testing exit due to failure task path home worker workspace ansible photon number x ova number ga ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing because exit testing when fail is set to true in test case deploy photon ova error message exit testing because exit testing when fail is set to true in test case deploy photon ova timestamp task deploy photon ova fetch file tmp cloud init timestamp number tar gz from vm guest task path home worker workspace ansible photon number x ova number ga ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root error message invalid guest login for user root", "solution": "deepdive", "target": "targetvm", "version": 202304110953}, {"id": 5900, "name": "5", "raw": "2023-03-06 06:33:36,006 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2023-03-06 06:33:36,006 | TASK [gosc_cloudinit_dhcp][GOS customization failed] *******\ntask path: /home/worker/workspace/Ansible_Regression_AmazonLinux_2_OVA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:114\nfatal: [localhost]: FAILED! => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com', 'gosc.test.com'] not expected search domains ['test.com', 'gosc.test.com']\"]\nerror message:\nVM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com', 'gosc.test.com'] not expected search domains ['test.com', 'gosc.test.com']", "category": null, "processed": "timestamp failed at play go sc cloud init dhcp timestamp task go sc cloud init dhcp gos customization failed task path home worker workspace ansible regression amazon linux number ova ansible vsphere gos validation linux guest customization linux go sc verify yml number fatal localhost failed vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com go sc test com not expected search domains test com go sc test com error message vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com go sc test com not expected search domains test com go sc test com", "solution": "deepdive", "target": "product", "version": 202304110953}, {"id": 5905, "name": "6", "raw": "2023-03-09 06:14:54,009 | Failed at Play [wsl_distro_install_uninstall] **************\n2023-03-09 06:14:54,009 | TASK [wsl_distro_install_uninstall][Change VM power state failure] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_Physical_VBS_80GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:69\nfatal: [localhost]: FAILED! => Unable to communicate with the remote host, since it is disconnected. \nerror message:\nUnable to communicate with the remote host, since it is disconnected.", "category": null, "processed": "timestamp failed at play wsl distro install un install timestamp task wsl distro install un install change vm power state failure task path home worker workspace ansible windows server lts c physical vbs number ga lsi logic sas efi ansible vsphere gos validation common vm set power state yml number fatal localhost failed unable to communicate with the remote host since it is disconnected error message unable to communicate with the remote host since it is disconnected", "solution": "retry", "target": "nimbus", "version": 202304110953}, {"id": 5910, "name": "7", "raw": "2023-04-08 20:43:38,008 | Failed at Play [1_nvme_vhba_device_ops_spec13] *************\n2023-04-08 20:43:38,008 | TASK [1_nvme_vhba_device_ops_spec13][Verify disk number increases in guest OS] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_VMXNET3_EFI_HW17/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hotadd_vm_disk_existing_ctrl.yml:46\nfatal: [localhost]: FAILED! => Disk number not increase 2 after hotadding disks to new controller and existing controller, before hotadd: 1, after hotadd: 2\nerror message:\nDisk number not increase 2 after hotadding disks to new controller and existing controller, before hotadd: 1, after hotadd: 2", "category": null, "processed": "timestamp failed at play number nvme v hba device ops spec number timestamp task number nvme v hba device ops spec number verify disk number increases in guest os task path home worker workspace ansible windows server lts c main lsi logic sas vmxnet number efi ansible vsphere gos validation windows v hba hot add remove hot add vm disk existing ctrl yml number fatal localhost failed disk number not increase number after hot adding disks to new controller and existing controller before hot add number after hot add number error message disk number not increase number after hot adding disks to new controller and existing controller before hot add number after hot add number", "solution": "deepdive", "target": "product", "version": 202304110953}]