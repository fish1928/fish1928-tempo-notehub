[{"id": 1058, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Regression_RHEL_9_x-69_failed_tasks_log.0", "raw": "2022-03-25 12:20:53,025 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-03-25 12:20:53,025 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM static IPv4 address is '192.168.192.169', expected IPv4 address is 192.168.192.101\", \"VM static IPv4 gateway is '192.168.1.1', expected IPv4 gateway is 192.168.192.1\"]", "category": "ip_not_expect_0509", "processed": "timestamp failed at play go sc cloud init static ip timestamp task gos customization failed fatal localhost failed vm static ip vnumber address is ip address expected ip vnumber address is ip address vm static ip vnumber gateway is ip address expected ip vnumber gateway is ip address", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1150, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_SLES_15SP4_70U3_PARAVIRTUAL_VMXNET3_BIOS-26_failed_tasks_log.0", "raw": "2022-04-12 12:22:05,012 | Failed at Play [env_setup] *********************************\n2022-04-12 12:22:05,012 | TASK [Deploy VM from ovf template] *************************\ntask path: /home/worker/workspace/Ansible_SLES_15SP4_70U3_PARAVIRTUAL_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/ovf_deploy.yml:4\nexception in /AnsiballZ_vmware_deploy_ovf.py when _ansiballz_main in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_0509", "processed": "timestamp failed at play environment setup timestamp task deploy vm from ovf template exception in ansi ball z vmware deploy ovf python when ansi ball z main in soap adapter python when invoke method fatal localhost failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1171, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Windows_Server_LTSC_vNext-1_logs_failed_tasks_log.1", "raw": "2022-01-26 06:04:10,026 | Failed at Play [check_quiesce_snapshot] ********************\n2022-01-26 06:04:10,026 | TASK [Check specified file status until it exists in Windows guest] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_wait_file_exist.yml:8\nfatal: [localhost -> 10.185.226.50]: FAILED! => {\n    \"attempts\": 40,\n    \"changed\": false,\n    \"invocation\": {\n        \"module_args\": {\n            \"checksum_algorithm\": \"sha1\",\n            \"follow\": false,\n            \"get_checksum\": true,\n            \"path\": \"C:\\\\test_pre_freeze.txt\"\n        }\n    },\n    \"stat\": {\n        \"exists\": false\n    }\n}", "category": "test_pre_freeze_0509", "processed": "timestamp failed at play check quiesce snapshot timestamp task check specified file status until it exists in windows guest fatal localhost ip address failed", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1059, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_RHEL_7_x-55_failed_tasks_log.0", "raw": "2022-02-21 03:41:20,021 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-02-21 03:41:20,021 | TASK [Create snapshot 'BaseSnapshot' on 'test_rhel7'] ******\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_7.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play nvme v hba device ops timestamp task create snapshot base snapshot on test rhel number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1172, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Ubuntu_LTS_Server_OVA_67GA-4_failed_tasks_log.0", "raw": "2022-02-24 02:45:37,024 | Failed at Play [deploy_ubuntu_ova] *************************\n2022-02-24 02:45:37,024 | TASK [Remove a serial port using output file] **************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_67GA/ansible-vsphere-gos-validation/common/vm_remove_serial_port.yml:16\nfatal: [localhost]: FAILED! => A serial device cannot be added to a VM in the current state(poweredOn). Please use the vmware_guest_powerstate module to power off the VM\n2022-02-24 02:46:34,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_67GA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_ubuntu_ova", "category": "device_cannot_be_added_0509", "processed": "timestamp failed at play deploy ubuntu ova timestamp task remove a serial port using output file fatal localhost failed a serial device can not be added to a vm in the current state powered on please use the vmware guest power state module to power off the vm timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy ubuntu ova", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1173, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_Windows_10_32-42_failed_tasks_log.0", "raw": "2022-02-21 07:58:48,021 | Failed at Play [deploy_vm_efi_nvme_e1000e] *****************\n2022-02-21 07:58:48,021 | TASK [Wait for getting VM 'test_windows10_32_1645428736027' IP address on ESXi 'pek2-hs1-a0409.eng.vmware.com'] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_32/ansible-vsphere-gos-validation/common/vm_get_ip_esxcli.yml:51\nfatal: [localhost]: UNREACHABLE! => Data could not be sent to remote host \"pek2-hs1-a0409.eng.vmware.com\". Make sure this host can be reached over ssh: ssh: connect to host pek2-hs1-a0409.eng.vmware.com port 22: Connection timed out", "category": "data_not_sent_to_remote_0509", "processed": "timestamp failed at play deploy vm efi nvme timestamp task wait for getting vm test windows number ip address on esxi pe knumber hsnumber eng vmware com fatal localhost un reachable data could not be sent to remote host pe knumber hsnumber eng vmware com make sure this host can be reached over ssh ssh connect to host pe knumber hsnumber eng vmware com port number connection timed out", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1073, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.5", "raw": "2022-02-16 10:46:35,016 | Failed at Play [stat_hosttime] *****************************\n2022-02-16 10:46:35,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play stat host time timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1174, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_Windows_10_64-46_failed_tasks_log.0", "raw": "2022-02-21 07:58:49,021 | Failed at Play [deploy_vm_efi_nvme_e1000e] *****************\n2022-02-21 07:58:49,021 | TASK [Wait for getting VM 'test_windows10_64_1645428722003' IP address on ESXi 'pek2-hs1-a0409.eng.vmware.com'] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_64/ansible-vsphere-gos-validation/common/vm_get_ip_esxcli.yml:51\nfatal: [localhost]: UNREACHABLE! => Data could not be sent to remote host \"pek2-hs1-a0409.eng.vmware.com\". Make sure this host can be reached over ssh: ssh: connect to host pek2-hs1-a0409.eng.vmware.com port 22: Connection timed out", "category": "data_not_sent_to_remote_0509", "processed": "timestamp failed at play deploy vm efi nvme timestamp task wait for getting vm test windows number ip address on esxi pe knumber hsnumber eng vmware com fatal localhost un reachable data could not be sent to remote host pe knumber hsnumber eng vmware com make sure this host can be reached over ssh ssh connect to host pe knumber hsnumber eng vmware com port number connection timed out", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1175, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_Windows_Server_2022-55_failed_tasks_log.0", "raw": "2022-02-21 07:58:34,021 | Failed at Play [deploy_vm_efi_nvme_e1000e] *****************\n2022-02-21 07:58:34,021 | TASK [Wait for getting VM 'test_windows_server_ltsc_22538_1645428724556' IP address on ESXi 'pek2-hs1-a0409.eng.vmware.com'] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_2022/ansible-vsphere-gos-validation/common/vm_get_ip_esxcli.yml:51\nfatal: [localhost]: UNREACHABLE! => Data could not be sent to remote host \"pek2-hs1-a0409.eng.vmware.com\". Make sure this host can be reached over ssh: ssh: connect to host pek2-hs1-a0409.eng.vmware.com port 22: Connection timed out", "category": "data_not_sent_to_remote_0509", "processed": "timestamp failed at play deploy vm efi nvme timestamp task wait for getting vm test windows server lts c number ip address on esxi pe knumber hsnumber eng vmware com fatal localhost un reachable data could not be sent to remote host pe knumber hsnumber eng vmware com make sure this host can be reached over ssh ssh connect to host pe knumber hsnumber eng vmware com port number connection timed out", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1176, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_67GA_LSILOGIC_VMXNET3_BIOS-41_failed_tasks_log.1", "raw": "2022-03-28 04:34:53,028 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-03-28 04:34:53,028 | TASK [Wait for device list changed] ************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_67GA_LSILOGIC_VMXNET3_BIOS/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:80\nfatal: [localhost]: FAILED! => Failed to set execute bit on remote files (rc: 1, err: chmod: changing permissions of '/tmp/ansible-tmp-1648442093.7594314-3680-240718087425637/': Read-only file system\nchmod: changing permissions of '/tmp/ansible-tmp-1648442093.7594314-3680-240718087425637/AnsiballZ_command.py': Read-only file system\n)", "category": "chmod_readonly_0509", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task wait for device list changed fatal localhost failed failed to set execute bit on remote files rc number error chmod changing permissions of tmp ansible tmp hex id number timestamp read only file system chmod changing permissions of tmp ansible tmp hex id number timestamp ansi ball z command python read only file system", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1177, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS-27_failed_tasks_log.0", "raw": "2022-03-25 12:20:23,025 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-03-25 12:20:23,025 | TASK [Wait for device list changed] ************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:97\nfatal: [localhost]: FAILED! => Failed to set execute bit on remote files (rc: 1, err: chmod: changing permissions of '/tmp/ansible-tmp-1648210822.8840117-3383-200670728620988/': Read-only file system\nchmod: changing permissions of '/tmp/ansible-tmp-1648210822.8840117-3383-200670728620988/AnsiballZ_command.py': Read-only file system\n)", "category": "chmod_readonly_0509", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task wait for device list changed fatal localhost failed failed to set execute bit on remote files rc number error chmod changing permissions of tmp ansible tmp hex id number timestamp read only file system chmod changing permissions of tmp ansible tmp hex id number timestamp ansi ball z command python read only file system", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1178, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Windows_10_32-57_failed_tasks_log.1", "raw": "2022-02-12 03:50:30,012 | Failed at Play [memory_hot_add_basic] **********************\n2022-02-12 03:50:30,012 | TASK [Set VM power state to 'shutdown-guest'] **************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => VMware tools should be installed for guest shutdown/reboot", "category": "vmtool_not_installed_0509", "processed": "timestamp failed at play memory hot add basic timestamp task set vm power state to shutdown guest fatal localhost failed vmware tools should be installed for guest shutdown reboot", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1186, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_SLED_15_x-27_failed_tasks_log.1", "raw": "2022-02-21 07:10:21,021 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-02-21 07:10:21,021 | TASK [Check disk controller facts are same as before hot adding tests] \ntask path: /home/worker/workspace/Ansible_Cycle_SLED_15.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/vhba_device_hot_add_remove.yml:109\nfatal: [localhost]: FAILED! => After tests VM disk controller fact is: {'scsi': {'0': {'controller_summary': 'VMware paravirtual SCSI', 'controller_label': 'SCSI controller 0', 'controller_busnumber': 0, 'controller_controllerkey': 100, 'controller_devicekey': 1000, 'controller_unitnumber': 3, 'controller_disks_devicekey': [2000], 'controller_bus_sharing': 'noSharing'}, '1': {'controller_summary': 'VMware paravirtual SCSI', 'controller_label': 'SCSI controller 1', 'controller_busnumber': 1, 'controller_controllerkey': 100, 'controller_devicekey': 1001, 'controller_unitnumber': 4, 'controller_disks_devicekey': [], 'controller_bus_sharing': 'noSharing'}}, 'sata': {}, 'nvme': {}, 'usb2': {}, 'usb3': {}}; before tests it's: {'scsi': {'0': {'controller_summary': 'VMware paravirtual SCSI', 'controller_label': 'SCSI controller 0', 'controller_busnumber': 0, 'controller_controllerkey': 100, 'controller_devicekey': 1000, 'controller_unitnumber': 3, 'controller_disks_devicekey': [2000], 'controller_bus_sharing': 'noSharing'}}, 'sata': {}, 'nvme': {}, 'usb2': {}, 'usb3': {}}", "category": "dick_controller_fact_is_0509", "processed": "timestamp failed at play para virtual v hba device ops timestamp task check disk controller facts are same as before hot adding tests fatal localhost failed after tests vm disk controller fact is scsi number controller summary vmware para virtual scsi controller label scsi controller number controller bus number controller controller key number controller device key number controller unit number controller disks device key number controller bus sharing no sharing number controller summary vmware para virtual scsi controller label scsi controller number controller bus number controller controller key number controller device key number controller unit number controller disks device key controller bus sharing no sharing sata nvme usb number usb number before tests it s scsi number controller summary vmware para virtual scsi controller label scsi controller number controller bus number controller controller key number controller device key number controller unit number controller disks device key number controller bus sharing no sharing sata nvme usb number usb number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1072, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.3", "raw": "2022-02-16 10:45:35,016 | Failed at Play [check_ip_address] **************************\n2022-02-16 10:45:35,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check ip address timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1187, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Ubuntu_21_10_ISO-35_failed_tasks_log.0", "raw": "2022-02-22 10:15:16,022 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-02-22 10:15:16,022 | TASK [Check disk controller facts are same as before hot adding tests] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/vhba_device_hot_add_remove.yml:109\nfatal: [localhost]: FAILED! => After tests VM disk controller fact is: {'scsi': {'0': {'controller_summary': 'VMware paravirtual SCSI', 'controller_label': 'SCSI controller 0', 'controller_busnumber': 0, 'controller_controllerkey': 100, 'controller_devicekey': 1000, 'controller_unitnumber': 3, 'controller_disks_devicekey': [2000], 'controller_bus_sharing': 'noSharing'}}, 'sata': {}, 'nvme': {'0': {'controller_summary': 'NVME controller 0', 'controller_label': 'NVME controller 0', 'controller_busnumber': 0, 'controller_controllerkey': 100, 'controller_devicekey': 31000, 'controller_unitnumber': 30, 'controller_disks_devicekey': [32000]}}, 'usb2': {}, 'usb3': {}}; before tests it's: {'scsi': {'0': {'controller_summary': 'VMware paravirtual SCSI', 'controller_label': 'SCSI controller 0', 'controller_busnumber': 0, 'controller_controllerkey': 100, 'controller_devicekey': 1000, 'controller_unitnumber': 3, 'controller_disks_devicekey': [2000], 'controller_bus_sharing': 'noSharing'}}, 'sata': {}, 'nvme': {}, 'usb2': {}, 'usb3': {}}", "category": "dick_controller_fact_is_0509", "processed": "timestamp failed at play nvme v hba device ops timestamp task check disk controller facts are same as before hot adding tests fatal localhost failed after tests vm disk controller fact is scsi number controller summary vmware para virtual scsi controller label scsi controller number controller bus number controller controller key number controller device key number controller unit number controller disks device key number controller bus sharing no sharing sata nvme number controller summary nvme controller number controller label nvme controller number controller bus number controller controller key number controller device key number controller unit number controller disks device key number usb number usb number before tests it s scsi number controller summary vmware para virtual scsi controller label scsi controller number controller bus number controller controller key number controller device key number controller unit number controller disks device key number controller bus sharing no sharing sata nvme usb number usb number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1188, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_70GA_IDE_E1000E_EFI-13_failed_tasks_log.10", "raw": "2022-04-28 07:23:42,028 | Failed at Play [gosc_sanity_dhcp] **************************\n2022-04-28 07:23:42,028 | TASK [Check guest customization state] *********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_wait_gosc_completed.yml:35\nfatal: [localhost]: FAILED! => Not found 'ToolsDeployPkgPublishState: state=5, code=0' in vmware.log\n2022-04-28 07:39:08,028 | TASK [Check if specified file exists in Windows guest OS] **\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_check_file_exist.yml:14\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: HTTPSConnectionPool(host='10.186.81.255', port=5986): Max retries exceeded with url: /wsman (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f2aabab5040>: Failed to establish a new connection: [Errno 110] Connection timed out'))", "category": "failed_establish_new_connect_0509", "processed": "timestamp failed at play go sc sanity dhcp timestamp task check guest customization state fatal localhost failed not found tools deploy package publish state state number code number in vmware log timestamp task check if specified file exists in windows guest os fatal localhost un reachable failed to connect to the host via psrp https connection pool host ip address port number max retries exceeded with url wsman caused by new connection error url library number connection https connection object at hex id failed to establish a new connection error number connection timed out", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1191, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_AlmaLinux_8_x-56_failed_tasks_log.1", "raw": "2022-02-21 07:10:36,021 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-02-21 07:10:36,021 | TASK [Check CPU cores per socket is set correctly] *********\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_set_cpu_number.yml:31\nfatal: [localhost]: FAILED! => Failed to set CPU cores per socket to '12'\n2022-02-21 07:10:40,021 | TASK [Check VM snapshot is taken and is the current one] ***\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:26\nfatal: [localhost]: FAILED! => Failed to take snapshot 'fail-cpu_multicores_per_socket-2022-02-21-07-10-37' on VM 'test_vm'.", "category": "fail_to_take_snapshot_0509", "processed": "timestamp failed at play cpu multi cores per socket timestamp task check cpu cores per socket is set correctly fatal localhost failed failed to set cpu cores per socket to number timestamp task check vm snapshot is taken and is the current one fatal localhost failed failed to take snapshot fail cpu multi cores per socket timestamp number on vm test vm", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1192, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI-18_failed_tasks_log.0", "raw": "2022-03-31 14:17:34,031 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-03-31 14:17:34,031 | TASK [Add virtual TPM device to VM] ************************\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_add_remove_vtpm.yml:14\nexception in /vmware_guest_tpm.py when vtpm_operation in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => Failed to configure vTPM device on virtual machine due to '('RuntimeFault.summary', None)'\n2022-03-31 14:17:41,031 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "vtpm_device_on_vm_0509", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task add virtual tpm device to vm exception in vmware guest tpm python when vtpm operation in vmware python when wait for task fatal localhost failed failed to configure vtpm device on virtual machine due to runtime fault summary none timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1193, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_70GA_IDE_E1000E_EFI-13_failed_tasks_log.0", "raw": "2022-04-28 06:09:19,028 | Failed at Play [secureboot_enable_disable] *****************\n2022-04-28 06:09:19,028 | TASK [Check secure boot is enabled in guest OS] ************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/windows/secureboot_enable_disable/change_secureboot_config.yml:34\nfatal: [localhost]: FAILED! => Secure boot enabled status in guest OS: False", "category": "secure_boot_status_off_0509", "processed": "timestamp failed at play secure boot enable disable timestamp task check secure boot is enabled in guest os fatal localhost failed secure boot enabled status in guest os false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1194, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_70U1_LSILOGICSAS_VMXNET3_BIOS-5_failed_tasks_log.0", "raw": "2022-02-10 05:00:07,010 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-02-10 05:00:07,010 | TASK [Rescan all scsi devices] *****************************\ntask path: /home/worker/workspace/Ansible_SLES_15SP4_70U1_LSILOGICSAS_VMXNET3_BIOS/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:30\nFileNotFoundError: [Errno 2] No usable temporary directory found in ['/tmp', '/var/tmp', '/usr/tmp', '/root']\nfatal: [localhost -> 10.184.87.34]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "no_usable_temp_dir_found_in_0509", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task re scan all scsi devices file not found error error number no usable temporary directory found in tmp var tmp user tmp root fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1151, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS-42_failed_tasks_log.0", "raw": "2022-04-07 13:22:46,007 | Failed at Play [deploy_vm_bios_lsilogicsas_e1000e] *********\n2022-04-07 13:22:46,007 | TASK [Datastore file operation] ****************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => File 'OS/Linux/Ubuntu/22.04/20220406/jammy-live-server-amd64.iso' is absent, cannot continue\n2022-04-07 13:23:29,007 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_lsilogicsas_e1000e", "category": "absent_cannot_continue_0509", "processed": "timestamp failed at play deploy vm bios lsi logic sas timestamp task data store file operation fatal localhost failed file os linux ubuntu number hex id jammy live server amd number i so is absent can not continue timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios lsi logic sas enumbere", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1152, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS-7_failed_tasks_log.0", "raw": "2022-03-07 09:48:42,007 | Failed at Play [deploy_vm_bios_lsilogicsas_e1000e] *********\n2022-03-07 09:48:42,007 | TASK [Datastore file operation] ****************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => File 'OS/Linux/Ubuntu/22.04/jammy-live-server-amd64.iso' is absent, cannot continue\n2022-03-07 09:49:14,007 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_lsilogicsas_e1000e", "category": "absent_cannot_continue_0509", "processed": "timestamp failed at play deploy vm bios lsi logic sas timestamp task data store file operation fatal localhost failed file os linux ubuntu number jammy live server amd number i so is absent can not continue timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios lsi logic sas enumbere", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1153, "name": "ansible_gosv_logs_FAILURE_Ansible_Photon_4_x_ISO_70GA_SATA-1_logs_failed_tasks_log.0", "raw": "2022-01-28 01:36:29,028 | Failed at Play [deploy_vm_bios_sata_e1000e] ****************\n2022-01-28 01:36:29,028 | TASK [Datastore file operation] ****************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_ISO_70GA_SATA/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => File 'OS/Linux/Photon/4.0/Rev2/photon-4.0-c001795b8.iso' is absent, cannot continue\n2022-01-28 01:37:11,028 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Photon_4.x_ISO_70GA_SATA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_sata_e1000e", "category": "absent_cannot_continue_0509", "processed": "timestamp failed at play deploy vm bios sata timestamp task data store file operation fatal localhost failed file os linux photon number rev number photon number iso is absent can not continue timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios sata enumbere", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1154, "name": "ansible_gosv_logs_FAILURE_Ansible_Photon_4_x_ISO_70U1_LsiLogicSAS-1_logs_failed_tasks_log.0", "raw": "2022-01-28 01:39:09,028 | Failed at Play [deploy_vm_bios_lsilogicsas_vmxnet3] ********\n2022-01-28 01:39:09,028 | TASK [Datastore file operation] ****************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_ISO_70U1_LsiLogicSAS/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => File 'OS/Linux/Photon/4.0/Rev2/photon-4.0-c001795b8.iso' is absent, cannot continue\n2022-01-28 01:39:51,028 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Photon_4.x_ISO_70U1_LsiLogicSAS/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_lsilogicsas_vmxnet3", "category": "absent_cannot_continue_0509", "processed": "timestamp failed at play deploy vm bios lsi logic sas vmxnet number timestamp task data store file operation fatal localhost failed file os linux photon number rev number photon number iso is absent can not continue timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios lsi logic sas vmxnet number", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1165, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Ubuntu_LTS_Server_OVA_MAIN-21_failed_tasks_log.0", "raw": "2022-04-25 08:09:01,025 | Failed at Play [env_setup] *********************************\n2022-04-25 08:09:01,025 | TASK [Check variables for new VM settings] *****************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_MAIN/ansible-vsphere-gos-validation/env_setup/check_testing_vars.yml:57\nfatal: [localhost]: FAILED! => Invalid variables for new VM settings", "category": "invalid_variable_0509", "processed": "timestamp failed at play environment setup timestamp task check variables for new vm settings fatal localhost failed invalid variables for new vm settings", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1195, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_RHEL_9_x_67U2_PARAVIRTUAL_E1000E_BIOS-2_failed_tasks_log.0", "raw": "2022-02-16 23:54:02,016 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-02-16 23:54:02,016 | TASK [Parameter error] *************************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_67U2_PARAVIRTUAL_E1000E_BIOS/newgos_testing_internal/testbed_deploy/testbed_deploy_nimbus.yml:84\nfatal: [localhost]: FAILED! => Parameter 'testbed_version' is not valid: '67U2', valid values: ['main', 'cycle', '70U3', '70U2', '70U1', '70GA', '67U3', '67U1', '67GA', '65U3', '65GA']", "category": "param_testbed_not_valid_0509", "processed": "timestamp failed at play testbed deploy nimbus timestamp task parameter error fatal localhost failed parameter testbed version is not valid valid values main cycle numberga numberga numberga", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1184, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-49_failed_tasks_log.24", "raw": "2022-02-11 17:43:12,011 | Failed at Play [sata_vhba_device_ops] **********************\n2022-02-11 17:43:12,011 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.191.142.209:443 : [Errno 113] No route to host", "category": "unknown_error_no_route_0509", "processed": "timestamp failed at play sata v hba device ops timestamp task get specified property info for vm test vm exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number no route to host", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1162, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70GA_LSILOGICSAS_VMXNET3_EFI-39_failed_tasks_log.0", "raw": "2022-03-28 03:38:45,028 | Failed at Play [deploy_vm_efi_lsilogicsas_vmxnet3] *********\n2022-03-28 03:38:45,028 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70GA_LSILOGICSAS_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:30\nfatal: [localhost]: FAILED! => IP 10.185.244.81 is not pingable\n2022-03-28 03:39:48,028 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70GA_LSILOGICSAS_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_lsilogicsas_vmxnet3", "category": "failed_not_pingable_0509", "processed": "timestamp failed at play deploy vm efi lsi logic sas vmxnet number timestamp task fail fatal localhost failed ip ip address is not pingable timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi lsi logic sas vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1189, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_SLES_15SP4_67GA_LSILOGIC_E1000E_BIOS-30_failed_tasks_log.1", "raw": "2022-04-13 17:43:04,013 | Failed at Play [stat_hosttime] *****************************\n2022-04-13 17:43:04,013 | TASK [Check difference between stat host time and the real host time is less than 15s] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67GA_LSILOGIC_E1000E_BIOS/ansible-vsphere-gos-validation/linux/stat_hosttime/stat_hosttime.yml:47\nfatal: [localhost]: FAILED! => Difference between stat host time and real host time is larger than 15s: 33.0s", "category": "diff_host_time_real_time_0509", "processed": "timestamp failed at play stat host time timestamp task check difference between stat host time and the real host time is less than fatal localhost failed difference between stat host time and real host time is larger than number numbers", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1065, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.18", "raw": "2022-02-16 10:53:24,016 | Failed at Play [gosc_perl_staticip] ************************\n2022-02-16 10:53:24,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1066, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.19", "raw": "2022-02-16 10:53:55,016 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-02-16 10:53:55,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1067, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.2", "raw": "2022-02-16 10:45:06,016 | Failed at Play [vgauth_check_service] **********************\n2022-02-16 10:45:06,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play vg auth check service timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1068, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.20", "raw": "2022-02-16 10:54:24,016 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-02-16 10:54:24,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1069, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.21", "raw": "2022-02-16 10:54:54,016 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-02-16 10:54:54,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play para virtual v hba device ops timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1070, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.24", "raw": "2022-02-16 10:56:24,016 | Failed at Play [sata_vhba_device_ops] **********************\n2022-02-16 10:56:24,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play sata v hba device ops timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1071, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.26", "raw": "2022-02-16 10:57:29,016 | Failed at Play [ovt_verify_uninstall] **********************\n2022-02-16 10:57:29,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify un install timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1074, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.7", "raw": "2022-02-16 10:47:35,016 | Failed at Play [check_os_fullname] *************************\n2022-02-16 10:47:35,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check os full name timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1075, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.8", "raw": "2022-02-16 10:48:06,016 | Failed at Play [check_efi_firmware] ************************\n2022-02-16 10:48:06,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check efi firmware timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1076, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.9", "raw": "2022-02-16 10:48:38,016 | Failed at Play [cpu_hot_add_basic] *************************\n2022-02-16 10:48:38,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play cpu hot add basic timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1077, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.0", "raw": "2022-02-16 10:45:51,016 | Failed at Play [ovt_verify_install] ************************\n2022-02-16 10:45:51,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify install timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1078, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.1", "raw": "2022-02-16 10:46:22,016 | Failed at Play [ovt_verify_status] *************************\n2022-02-16 10:46:22,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify status timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1079, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.11", "raw": "2022-02-16 10:51:35,016 | Failed at Play [memory_hot_add_basic] **********************\n2022-02-16 10:51:35,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play memory hot add basic timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1080, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.13", "raw": "2022-02-16 10:52:36,016 | Failed at Play [secureboot_enable_disable] *****************\n2022-02-16 10:52:36,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play secure boot enable disable timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1081, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.17", "raw": "2022-02-16 10:54:43,016 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-02-16 10:54:43,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1082, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.18", "raw": "2022-02-16 10:55:13,016 | Failed at Play [gosc_perl_staticip] ************************\n2022-02-16 10:55:13,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1083, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.19", "raw": "2022-02-16 10:55:44,016 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-02-16 10:55:44,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1084, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.2", "raw": "2022-02-16 10:46:53,016 | Failed at Play [vgauth_check_service] **********************\n2022-02-16 10:46:53,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play vg auth check service timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1085, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.20", "raw": "2022-02-16 10:56:15,016 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-02-16 10:56:15,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1086, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.26", "raw": "2022-02-16 10:59:20,016 | Failed at Play [ovt_verify_uninstall] **********************\n2022-02-16 10:59:20,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify un install timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1087, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.3", "raw": "2022-02-16 10:47:23,016 | Failed at Play [check_ip_address] **************************\n2022-02-16 10:47:23,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check ip address timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1088, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.5", "raw": "2022-02-16 10:48:24,016 | Failed at Play [stat_hosttime] *****************************\n2022-02-16 10:48:24,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play stat host time timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1089, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.6", "raw": "2022-02-16 10:48:56,016 | Failed at Play [check_inbox_driver] ************************\n2022-02-16 10:48:56,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check inbox driver timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1090, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.7", "raw": "2022-02-16 10:49:31,016 | Failed at Play [check_os_fullname] *************************\n2022-02-16 10:49:31,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check os full name timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1091, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.8", "raw": "2022-02-16 10:50:01,016 | Failed at Play [check_efi_firmware] ************************\n2022-02-16 10:50:01,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check efi firmware timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1092, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.9", "raw": "2022-02-16 10:50:33,016 | Failed at Play [cpu_hot_add_basic] *************************\n2022-02-16 10:50:33,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006357061'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67GA_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play cpu hot add basic timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1093, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.0", "raw": "2022-02-16 10:46:59,016 | Failed at Play [ovt_verify_install] ************************\n2022-02-16 10:46:59,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify install timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1094, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.1", "raw": "2022-02-16 10:47:32,016 | Failed at Play [ovt_verify_status] *************************\n2022-02-16 10:47:32,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify status timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1096, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.13", "raw": "2022-02-16 10:54:14,016 | Failed at Play [secureboot_enable_disable] *****************\n2022-02-16 10:54:14,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play secure boot enable disable timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1097, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.17", "raw": "2022-02-16 10:56:24,016 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-02-16 10:56:24,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1098, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.18", "raw": "2022-02-16 10:56:56,016 | Failed at Play [gosc_perl_staticip] ************************\n2022-02-16 10:56:56,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1099, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.19", "raw": "2022-02-16 10:57:28,016 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-02-16 10:57:28,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1100, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.2", "raw": "2022-02-16 10:48:03,016 | Failed at Play [vgauth_check_service] **********************\n2022-02-16 10:48:03,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play vg auth check service timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1144, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Photon_4_x_OVA_70GA-19_failed_tasks_log.0", "raw": "2022-03-31 16:20:29,031 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-03-31 16:20:29,031 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_OVA_70GA/newgos_testing_internal/testbed_deploy/testbed_deploy_nimbus.yml:195\nfatal: [localhost]: FAILED! => Get deployment result in testbedInfo.json is not PASS: deployment_result=INVALID", "category": "deploy_result_not_pass_0509", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail fatal localhost failed get deployment result in testbed info json is not pass deployment result invalid", "solution": "retry", "target": "nimbus", "version": 202205240000}, {"id": 1145, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_OVA_70GA-25_failed_tasks_log.0", "raw": "2022-03-24 06:10:24,024 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-03-24 06:10:24,024 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_70GA/newgos_testing_internal/testbed_deploy/testbed_deploy_nimbus.yml:189\nfatal: [localhost]: FAILED! => Get deployment result in testbedInfo.json is not PASS", "category": "deploy_result_not_pass_0509", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail fatal localhost failed get deployment result in testbed info json is not pass", "solution": "retry", "target": "nimbus", "version": 202205240000}, {"id": 1141, "name": "ansible_gosv_logs_FAILURE_Ansible_AmazonLinux_2_70GA-3_logs_failed_tasks_log.0", "raw": "2022-01-06 05:52:29,006 | Failed at Play [ovt_verify_install] ************************\n2022-01-06 05:52:29,006 | TASK [Collect filtered guest information for '10.187.128.65'] \ntask path: /home/worker/workspace/Ansible_AmazonLinux_2_70GA/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via ssh: Warning: Permanently added '10.187.128.65' (ED25519) to the list of known hosts.\nroot@10.187.128.65: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).", "category": "permission_deny", "processed": "timestamp failed at play ovt verify install timestamp task collect filtered guest information for ip address fatal localhost un reachable failed to connect to the host via ssh warning permanently added ip address to the list of known hosts root ip address permission denied public key gss api k eye x gss api with mic", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1142, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Flatcar_OVA-20_logs_failed_tasks_log.0", "raw": "2022-01-05 07:24:06,005 | Failed at Play [env_setup] *********************************\n2022-01-05 07:24:06,005 | TASK [Check supershell] ************************************\ntask path: /home/worker/workspace/Ansible_Regression_Flatcar_OVA/ansible-vsphere-gos-validation/env_setup/env_setup.yml:53\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via ssh: root@10.78.233.66: Permission denied (publickey,keyboard-interactive).", "category": "permission_deny", "processed": "timestamp failed at play environment setup timestamp task check super shell fatal localhost un reachable failed to connect to the host via ssh root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1143, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_3_0_ISO-23_logs_failed_tasks_log.0", "raw": "2022-01-05 07:48:03,005 | Failed at Play [env_setup] *********************************\n2022-01-05 07:48:03,005 | TASK [Get shell executable on ESXi server] *****************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:53\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via ssh: root@10.168.212.31: Permission denied (publickey,keyboard-interactive).", "category": "permission_deny", "processed": "timestamp failed at play environment setup timestamp task get shell executable on esxi server fatal localhost un reachable failed to connect to the host via ssh root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1138, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.7", "raw": "2022-02-16 10:42:01,016 | Failed at Play [check_os_fullname] *************************\n2022-02-16 10:42:01,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check os full name timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1101, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.20", "raw": "2022-02-16 10:58:03,016 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-02-16 10:58:03,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1102, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.26", "raw": "2022-02-16 11:01:26,016 | Failed at Play [ovt_verify_uninstall] **********************\n2022-02-16 11:01:26,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify un install timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1103, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.3", "raw": "2022-02-16 10:48:36,016 | Failed at Play [check_ip_address] **************************\n2022-02-16 10:48:36,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check ip address timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1104, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.5", "raw": "2022-02-16 10:49:46,016 | Failed at Play [stat_hosttime] *****************************\n2022-02-16 10:49:46,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play stat host time timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1148, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Windows_10_32-27_failed_tasks_log.0", "raw": "2022-02-07 21:01:35,007 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-02-07 21:01:35,007 | TASK [Transfer nimbus testbed deploy spec to dbc server] ***\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/newgos_testing_internal/testbed_deploy/deploy_from_dbc_prepare.yml:52\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 3 retries to prevent account lockout: Warning: Permanently added 'wdc-dbc2108.eng.vmware.com' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nsvc.gosv-automation@wdc-dbc2108.eng.vmware.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "invalid_password_0509", "processed": "timestamp failed at play testbed deploy nimbus timestamp task transfer nimbus testbed deploy spec to database c server fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added wdc eng vmware com to the list of known hosts permission denied please try again permission denied please try again svc go sv automation wdc eng vmware com permission denied public key gss api k eye x gss api with mic password", "solution": "deepdive", "target": "infra", "version": 202205240000}, {"id": 1149, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Cycle_CentOS_8_x-62_failed_tasks_log.0", "raw": "2022-03-01 14:14:48,001 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-03-01 14:14:48,001 | TASK [Transfer nimbus testbed deploy spec to dbc server] ***\ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/newgos_testing_internal/testbed_deploy/deploy_from_dbc_prepare.yml:52\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 4 retries to prevent account lockout: Warning: Permanently added 'wdc-dbc2108.eng.vmware.com' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nsvc.gosv-automation@wdc-dbc2108.eng.vmware.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "invalid_password_0509", "processed": "timestamp failed at play testbed deploy nimbus timestamp task transfer nimbus testbed deploy spec to database c server fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added wdc eng vmware com to the list of known hosts permission denied please try again permission denied please try again svc go sv automation wdc eng vmware com permission denied public key gss api k eye x gss api with mic password", "solution": "deepdive", "target": "infra", "version": 202205240000}, {"id": 1156, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_SLES_15SP4_MAIN_NVME_E1000E_BIOS-42_failed_tasks_log.0", "raw": "2022-04-29 04:02:31,029 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-04-29 04:02:31,029 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_SLES_15SP4_MAIN_NVME_E1000E_BIOS/newgos_testing_internal/testbed_deploy/parse_testbed_info.yml:46\nfatal: [localhost]: FAILED! => There is no VMFS datastore on ESXi server 10.182.178.193. Nimbus testbed deployment failed.", "category": "no_vmfs_datastore_0509", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail fatal localhost failed there is no vmfs data store on esxi server ip address nimbus testbed deployment failed", "solution": "deepdive", "target": "nimbus", "version": 202205240000}, {"id": 1155, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_70U3_LSILOGICSAS_E1000E_BIOS-18_failed_tasks_log.0", "raw": "2022-04-21 15:28:33,021 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-04-21 15:28:33,021 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_LSILOGICSAS_E1000E_BIOS/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/testbed_result/Ansible_Windows_Server_LTSC_70U3_LSILOGICSAS_E1000E_BIOS-18/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "failed_to_fetch_nimbus_testbed_0509", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus testbed result ansible windows server lts c lsi logic sas bios number testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202205240000}, {"id": 1157, "name": "ansible_gosv_logs_202202_ABORTED_Ansible_Cycle_CentOS_8_x-16_failed_tasks_log.3", "raw": "2022-02-06 14:33:40,006 | Failed at Play [memory_hot_add_basic] **********************\n2022-02-06 14:33:40,006 | TASK [Get ESXi host specified property] ********************\ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/common/esxi_get_property.yml:8\nexception in /vmware.py when connect_to_api in /ssl.py when do_handshake\nfatal: [localhost]: FAILED! => Unable to connect to vCenter or ESXi API at 10.187.157.136 on TCP/443: EOF occurred in violation of protocol (_ssl.c:1123)", "category": "unable_to_vc_or_esx_0509", "processed": "timestamp failed at play memory hot add basic timestamp task get esxi host specified property exception in vmware python when connect to api in ssl python when do handshake fatal localhost failed unable to connect to vcenter or esxi api at ip address on tcp number eof occurred in violation of protocol ssl c number", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1105, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.6", "raw": "2022-02-16 10:50:19,016 | Failed at Play [check_inbox_driver] ************************\n2022-02-16 10:50:19,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check inbox driver timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1160, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_3_0_ISO-31_logs_failed_tasks_log.0", "raw": "2022-01-18 16:36:53,018 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-01-18 16:36:53,018 | TASK [Run iozone test on new added disk] *******************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/run_iozone_test.yml:14\nfatal: [localhost -> 10.187.152.164]: FAILED! => non-zero return code", "category": "non_zero_return", "processed": "timestamp failed at play para virtual v hba device ops timestamp task run io zone test on new added disk fatal localhost ip address failed non zero return code", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1106, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.7", "raw": "2022-02-16 10:50:51,016 | Failed at Play [check_os_fullname] *************************\n2022-02-16 10:50:51,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check os full name timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1163, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_CentOS_8_x_70GA_IDE_VMXNET3_BIOS-5_failed_tasks_log.0", "raw": "2022-04-16 19:49:56,016 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-04-16 19:49:56,016 | TASK [Set VM CPU number and/or cores per socket number] ****\ntask path: /home/worker/workspace/Ansible_CentOS_8.x_70GA_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_set_cpu_number.yml:9\nfatal: [localhost]: FAILED! => An error occurred while communicating with the remote host.", "category": "error_occur_while_commu_0509", "processed": "timestamp failed at play cpu multi cores per socket timestamp task set vm cpu number and or cores per socket number fatal localhost failed an error occurred while communicating with the remote host", "solution": "deepdive", "target": "testbed", "version": 202205240000}, {"id": 1164, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_SLED_15SP4_70U3_NVME_E1000E_EFI-20_failed_tasks_log.1", "raw": "2022-04-12 10:30:39,012 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-04-12 10:30:39,012 | TASK [absent disk to VM] ***********************************\ntask path: /home/worker/workspace/Ansible_SLED_15SP4_70U3_NVME_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_hot_add_remove_disk.yml:44\nexception in /vmware_guest_disk.py when main in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => Failed to manage disks for virtual machine 'test_vm' with exception : ('An error occurred while communicating with the remote host.', None)", "category": "error_occur_while_commu_0509", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task absent disk to vm exception in vmware guest disk python when main in vmware python when wait for task fatal localhost failed failed to manage disks for virtual machine test vm with exception an error occurred while communicating with the remote host none", "solution": "deepdive", "target": "testbed", "version": 202205240000}, {"id": 1166, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Photon_4_x_ISO_MAIN_PARAVIRTUAL_VMXNET3_BIOS-4_failed_tasks_log.0", "raw": "2022-02-21 07:30:07,021 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-02-21 07:30:07,021 | TASK [present disk to VM] **********************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_ISO_MAIN_PARAVIRTUAL_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_hot_add_remove_disk.yml:44\nexception in /vmware_guest_disk.py when main in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => Failed to manage disks for virtual machine 'test_vm' with exception : ('Unable to communicate with the remote host, since it is disconnected.', None)", "category": "unable_to_commu_as_disconnect_0509", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task present disk to vm exception in vmware guest disk python when main in vmware python when wait for task fatal localhost failed failed to manage disks for virtual machine test vm with exception unable to communicate with the remote host since it is disconnected none", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1107, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.8", "raw": "2022-02-16 10:51:24,016 | Failed at Play [check_efi_firmware] ************************\n2022-02-16 10:51:24,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check efi firmware timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1108, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.1", "raw": "2022-02-16 10:40:47,016 | Failed at Play [ovt_verify_status] *************************\n2022-02-16 10:40:47,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify status timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1169, "name": "ansible_gosv_logs_202203_FAILURE_zyh_ansible_ubuntu_existing_testbed_3_1-4_failed_tasks_log.0", "raw": "2022-03-02 06:31:40,002 | Failed at Play [env_setup] *********************************\n2022-03-02 06:31:40,002 | TASK [Add a new 'e1000' adapter in 'vSwitch2022-03-02-06-30-45_PG' to VM 'Ansible_Router_VM_2022-03-02-06-30-45'] \ntask path: /home/worker/workspace/zyh_ansible_ubuntu_existing_testbed_3.1/ansible-vsphere-gos-validation/common/vm_add_network_adapter.yml:4\nexception in /vmware_guest_network.py when _nic_present in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => ('Unable to communicate with the remote host, since it is disconnected.', None)", "category": "unable_to_commu_as_disconnect_0509", "processed": "timestamp failed at play environment setup timestamp task add a new adapter in vswitch timestamp number page to vm ansible router vm timestamp number exception in vmware guest network python when nic present in vmware python when wait for task fatal localhost failed unable to communicate with the remote host since it is disconnected none", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1170, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Cycle_Windows_10_64-136_failed_tasks_log.7", "raw": "2022-05-04 10:24:20,004 | Failed at Play [e1000e_network_device_ops] *****************\n2022-05-04 10:24:20,004 | TASK [Add a standard vSwitch vSwitch2022-05-04-09-12-56 to ESXi host] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/esxi_add_vswitch.yml:4\nexception in /vmware_vswitch.py when state_create_vswitch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Failed to add vSwitch 'vSwitch2022-05-04-09-12-56' due to generic exception : (vmodl.fault.HostNotConnected) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'Unable to communicate with the remote host, since it is disconnected.',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) []\n}", "category": "unable_to_commu_as_disconnect_0509", "processed": "timestamp failed at play network device ops timestamp task add a standard vswitch vswitch timestamp number to esxi host exception in vmware vswitch python when state create vswitch in soap adapter python when invoke method fatal localhost failed failed to add vswitch vswitch timestamp number due to generic exception vmodl fault host not connected dynamic property vmodl dynamic property message unable to communicate with the remote host since it is disconnected fault message vmodl localizable message", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1109, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.11", "raw": "2022-02-16 10:46:17,016 | Failed at Play [memory_hot_add_basic] **********************\n2022-02-16 10:46:17,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play memory hot add basic timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1110, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.13", "raw": "2022-02-16 10:47:21,016 | Failed at Play [secureboot_enable_disable] *****************\n2022-02-16 10:47:21,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play secure boot enable disable timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1219, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Cycle_Windows_10_64-108_failed_tasks_log.0", "raw": "2022-03-15 17:28:28,015 | Failed at Play [check_inbox_driver] ************************\n2022-03-15 17:28:28,015 | TASK [Collect filtered guest information for '10.186.237.131'] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play check inbox driver timestamp task collect filtered guest information for ip address fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1179, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-49_failed_tasks_log.15", "raw": "2022-02-11 17:41:48,011 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-02-11 17:41:48,011 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.191.142.209:443 : [Errno 113] No route to host", "category": "unknown_error_no_route_0509", "processed": "timestamp failed at play vmxnet number network device ops timestamp task get specified property info for vm test vm exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number no route to host", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1180, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-49_failed_tasks_log.19", "raw": "2022-02-11 17:42:26,011 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-02-11 17:42:26,011 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.191.142.209:443 : [Errno 113] No route to host", "category": "unknown_error_no_route_0509", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task get specified property info for vm test vm exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number no route to host", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1181, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-49_failed_tasks_log.20", "raw": "2022-02-11 17:42:33,011 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-02-11 17:42:33,011 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.191.142.209:443 : [Errno 113] No route to host", "category": "unknown_error_no_route_0509", "processed": "timestamp failed at play go sc cloud init static ip timestamp task get specified property info for vm test vm exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number no route to host", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1111, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.17", "raw": "2022-02-16 10:49:33,016 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-02-16 10:49:33,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1112, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.18", "raw": "2022-02-16 10:50:05,016 | Failed at Play [gosc_perl_staticip] ************************\n2022-02-16 10:50:05,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1185, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-93_logs_failed_tasks_log.0", "raw": "2022-01-18 10:26:45,018 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2022-01-18 10:26:45,018 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log bundle serial-20220118090529.log] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/vm_wait_logbundle_msg.yml:27\nfatal: [localhost]: FAILED! => OK (54 bytes)\n2022-01-18 10:57:21,018 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "failed_ok_54_bytes_0509", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task wait for message auto install is completed appear in vm log bundle serial timestamp log fatal localhost failed ok number bytes timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1182, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-49_failed_tasks_log.21", "raw": "2022-02-11 17:42:43,011 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-02-11 17:42:43,011 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.191.142.209:443 : [Errno 113] No route to host", "category": "unknown_error_no_route_0509", "processed": "timestamp failed at play para virtual v hba device ops timestamp task get specified property info for vm test vm exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number no route to host", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1183, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-49_failed_tasks_log.22", "raw": "2022-02-11 17:42:52,011 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-02-11 17:42:52,011 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.191.142.209:443 : [Errno 113] No route to host", "category": "unknown_error_no_route_0509", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task get specified property info for vm test vm exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number no route to host", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1190, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Cycle_Windows_10_64-120_failed_tasks_log.0", "raw": "2022-03-31 03:16:29,031 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2022-03-31 03:16:29,031 | TASK [Configure VM CDROM to 'client'] **********************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_configure_cdrom.yml:14\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.78.212.146:443 : [Errno 110] Connection timed out\n2022-03-31 03:20:46,031 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "unknown_error_connect_timeout_0509", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task configure vm cdrom to client exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number connection timed out timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1113, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.19", "raw": "2022-02-16 10:50:40,016 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-02-16 10:50:40,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1114, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.2", "raw": "2022-02-16 10:41:22,016 | Failed at Play [vgauth_check_service] **********************\n2022-02-16 10:41:22,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play vg auth check service timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1313, "name": "__Ansible_Regression_Photon_4_0_OVA-6_logs_failed_tasks_log.0", "raw": "2021-12-02 09:48:55,002 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-02 09:48:55,002 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play go sc perl dhcp timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1115, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.20", "raw": "2022-02-16 10:51:12,016 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-02-16 10:51:12,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1116, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.21", "raw": "2022-02-16 10:51:44,016 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-02-16 10:51:44,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play para virtual v hba device ops timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1117, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.24", "raw": "2022-02-16 10:53:20,016 | Failed at Play [sata_vhba_device_ops] **********************\n2022-02-16 10:53:20,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play sata v hba device ops timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1118, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.26", "raw": "2022-02-16 10:54:28,016 | Failed at Play [ovt_verify_uninstall] **********************\n2022-02-16 10:54:28,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify un install timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1119, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.3", "raw": "2022-02-16 10:41:54,016 | Failed at Play [check_ip_address] **************************\n2022-02-16 10:41:54,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check ip address timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1120, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.4", "raw": "2022-02-16 10:42:26,016 | Failed at Play [stat_balloon] ******************************\n2022-02-16 10:42:26,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play stat balloon timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1260, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Cycle_Ubuntu_20_04_4_ISO-118_failed_tasks_log.0", "raw": "2022-05-05 07:01:09,005 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-05-05 07:01:09,005 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "ping_issue", "processed": "timestamp failed at play vmxnet number network device ops timestamp task try to ping ip fatal localhost failed non zero return code when ping", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1212, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_RHEL_8_x_67GA_PARAVIRTUAL_E1000E_EFI-9_failed_tasks_log.2", "raw": "2022-04-20 07:44:08,020 | Failed at Play [gosc_perl_staticip] ************************\n2022-04-20 07:44:08,020 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_67GA_PARAVIRTUAL_E1000E_EFI/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM DNS domain search domains are  [] not expected search domains ['test.com', 'gosc.test.com']\"]", "category": "domain_not_expect", "processed": "timestamp failed at play go sc perl static ip timestamp task gos customization failed fatal localhost failed vm dns domain search domains are not expected search domains test com go sc test com", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1213, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_Windows_10_32-35_failed_tasks_log.1", "raw": "2022-02-17 05:34:03,017 | Failed at Play [sata_vhba_device_ops] **********************\n2022-02-17 05:34:03,017 | TASK [Create partition of the raw disk in Windows guest OS] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_create_disk_partition.yml:8\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play sata v hba device ops timestamp task create partition of the raw disk in windows guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1214, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_Windows_10_32-35_failed_tasks_log.2", "raw": "2022-02-17 05:38:04,017 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-02-17 05:38:04,017 | TASK [Create partition of the raw disk in Windows guest OS] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_create_disk_partition.yml:8\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play nvme v hba device ops timestamp task create partition of the raw disk in windows guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1215, "name": "ansible_gosv_logs_202203_ABORTED_Ansible_Cycle_Windows_10_64-101_failed_tasks_log.7", "raw": "2022-03-08 06:33:40,008 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-03-08 06:33:40,008 | TASK [Get VMware tools version and build number in guest OS] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_get_vmtools_version_build.yml:13\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task get vmware tools version and build number in guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1216, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Cycle_Windows_10_32-100_failed_tasks_log.0", "raw": "2022-03-10 03:41:45,010 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-03-10 03:41:45,010 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nsocket.timeout: timed out\nurllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f58e38d3fa0>, 'Connection to 10.168.188.211 timed out. (connect timeout=30)')\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='10.168.188.211', port=5986): Max retries exceeded with url: /wsman (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f58e38d3fa0>, 'Connection to 10.168.188.211 timed out. (connect timeout=30)'))\nrequests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='10.168.188.211', port=5986): Max retries exceeded with url: /wsman (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f58e38d3fa0>, 'Connection to 10.168.188.211 timed out. (connect timeout=30)'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play nvme v hba device ops timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer url library number exceptions connect timeout error url library number connection https connection object at hex id connection to ip address timed out connect timeout number url library number exceptions max retry error https connection pool host ip address port number max retries exceeded with url wsman caused by connect timeout error url library number connection https connection object at hex id connection to ip address timed out connect timeout number requests exceptions connect timeout https connection pool host ip address port number max retries exceeded with url wsman caused by connect timeout error url library number connection https connection object at hex id connection to ip address timed out connect timeout number fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1217, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Cycle_Windows_10_64-100_failed_tasks_log.0", "raw": "2022-03-08 03:15:41,008 | Failed at Play [check_efi_firmware] ************************\n2022-03-08 03:15:41,008 | TASK [Get firmware type in Windows guest OS] ***************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_get_firmware.yml:5\nfatal: [localhost]: UNREACHABLE! => basic: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play check efi firmware timestamp task get firmware type in windows guest os fatal localhost un reachable basic connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1218, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Windows_11_70GA_IDE_E1000E_EFI-5_failed_tasks_log.1", "raw": "2022-03-08 15:46:14,008 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-03-08 15:46:14,008 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play para virtual v hba device ops timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1220, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Windows_11_70U3_PARAVIRTUAL_E1000E_EFI-23_failed_tasks_log.0", "raw": "2022-05-05 10:17:13,005 | Failed at Play [sata_vhba_device_ops] **********************\n2022-05-05 10:17:13,005 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_70U3_PARAVIRTUAL_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play sata v hba device ops timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1221, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Windows_11_70U1_SATA_E1000E_EFI-7_failed_tasks_log.0", "raw": "2022-03-30 15:28:03,030 | Failed at Play [cpu_hot_add_basic] *************************\n2022-03-30 15:28:03,030 | TASK [Shutdown guest OS inside OS] *************************\ntask path: /home/worker/workspace/Ansible_Windows_11_70U1_SATA_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_shutdown_restart.yml:8\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play cpu hot add basic timestamp task shutdown guest os inside os fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1222, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Windows_Server_LTSC_70GA_SATA_E1000E_BIOS-10_failed_tasks_log.0", "raw": "2022-03-08 03:34:21,008 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-03-08 03:34:21,008 | TASK [Shutdown guest OS inside OS] *************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_SATA_E1000E_BIOS/ansible-vsphere-gos-validation/windows/utils/win_shutdown_restart.yml:8\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play cpu multi cores per socket timestamp task shutdown guest os inside os fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1223, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_11_70U3_LSILOGICSAS_E1000E_EFI-15_failed_tasks_log.3", "raw": "2022-04-14 14:55:36,014 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-04-14 14:55:36,014 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_70U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play nvme v hba device ops timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1224, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Cycle_Windows_10_64-124_failed_tasks_log.1", "raw": "2022-04-11 07:57:49,011 | Failed at Play [wintools_uninstall_verify] *****************\n2022-04-11 07:57:49,011 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play win tools un install verify timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1225, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Debian_10_x_32bit_MAIN_NVME_VMXNET3_EFI-24_failed_tasks_log.0", "raw": "2022-03-08 14:21:32,008 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2022-03-08 14:21:32,008 | TASK [Upload local file to ESXi datastore] *****************\ntask path: /home/worker/workspace/Ansible_Debian_10.x_32bit_MAIN_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/common/esxi_upload_datastore_file.yml:11\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib.error.URLError: <urlopen error [Errno 104] Connection reset by peer>\nTypeError: 'URLError' object is not subscriptable\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error\n2022-03-08 14:21:32,008 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Debian_10.x_32bit_MAIN_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "connectionreset", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task upload local file to esxi data store connection reset error error number connection reset by peer url library error url error url open error error number connection reset by peer type error url error object is not sub scriptable fatal localhost failed module failure see stdout stderr for the exact error timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1226, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Regression_Windows_Server_2022-58_failed_tasks_log.2", "raw": "2022-03-10 06:04:23,010 | Failed at Play [sata_vhba_device_ops] **********************\n2022-03-10 06:04:23,010 | TASK [Create partition of the raw disk in Windows guest OS] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_2022/ansible-vsphere-gos-validation/windows/utils/win_create_disk_partition.yml:8\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play sata v hba device ops timestamp task create partition of the raw disk in windows guest os fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1227, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Cycle_Windows_11_64-93_failed_tasks_log.0", "raw": "2022-04-02 10:57:04,002 | Failed at Play [check_quiesce_snapshot] ********************\n2022-04-02 10:57:04,002 | TASK [Copy file from local to Windows guest] ***************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_copy_file_from_local.yml:9\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play check quiesce snapshot timestamp task copy file from local to windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1228, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Windows_11_MAIN_NVME_E1000E_EFI-3_failed_tasks_log.0", "raw": "2022-03-10 06:28:51,010 | Failed at Play [check_quiesce_snapshot] ********************\n2022-03-10 06:28:51,010 | TASK [Check if specified file exists in Windows guest OS] **\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_check_file_exist.yml:14\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play check quiesce snapshot timestamp task check if specified file exists in windows guest os fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1229, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_11_70GA_LSILOGICSAS_E1000E_EFI-8_failed_tasks_log.0", "raw": "2022-04-14 16:47:50,014 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-04-14 16:47:50,014 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_70GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1230, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Cycle_Windows_11_64-99_failed_tasks_log.0", "raw": "2022-04-15 06:01:01,015 | Failed at Play [stat_balloon] ******************************\n2022-04-15 06:01:01,015 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play stat balloon timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1231, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Cycle_Windows_11_64-98_failed_tasks_log.0", "raw": "2022-04-15 03:16:48,015 | Failed at Play [mouse_driver_vmtools] **********************\n2022-04-15 03:16:48,015 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play mouse driver vm tools timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1232, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Cycle_Windows_11_64-106_failed_tasks_log.1", "raw": "2022-05-04 11:20:25,004 | Failed at Play [gosc_sanity_dhcp] **************************\n2022-05-04 11:20:25,004 | TASK [Get the absolute path in Windows guest] **************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_get_path.yml:10\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play go sc sanity dhcp timestamp task get the absolute path in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1233, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_11_70U1_NVME_E1000E_EFI-6_failed_tasks_log.1", "raw": "2022-04-14 11:45:28,014 | Failed at Play [e1000e_network_device_ops] *****************\n2022-04-14 11:45:28,014 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_70U1_NVME_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play network device ops timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1234, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Cycle_Windows_Server_2022_64-124_failed_tasks_log.0", "raw": "2022-05-04 05:51:28,004 | Failed at Play [vgauth_check_service] **********************\n2022-05-04 05:51:28,004 | TASK [Check specified service 'VGAuthService' status in Windows] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_2022_64/ansible-vsphere-gos-validation/windows/utils/win_get_service_status.yml:15\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play vg auth check service timestamp task check specified service vg auth service status in windows fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1235, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_70U3_NVME_E1000E_EFI-23_failed_tasks_log.1", "raw": "2022-04-28 06:00:06,028 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-04-28 06:00:06,028 | TASK [Get number of logical processors in Windows guest OS] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_NVME_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_get_cpu_cores_sockets.yml:10\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play cpu multi cores per socket timestamp task get number of logical processors in windows guest os fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1236, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_70U3_PARAVIRTUAL_E1000E_EFI-26_failed_tasks_log.0", "raw": "2022-04-25 08:25:10,025 | Failed at Play [check_efi_firmware] ************************\n2022-04-25 08:25:10,025 | TASK [Get firmware type in Windows guest OS] ***************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_PARAVIRTUAL_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_get_firmware.yml:5\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play check efi firmware timestamp task get firmware type in windows guest os fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1237, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Windows_11_70GA_IDE_E1000E_EFI-27_failed_tasks_log.0", "raw": "2022-05-06 06:08:34,006 | Failed at Play [memory_hot_add_basic] **********************\n2022-05-06 06:08:34,006 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play memory hot add basic timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1238, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Cycle_Windows_10_64-135_failed_tasks_log.0", "raw": "2022-05-04 10:05:15,004 | Failed at Play [sata_vhba_device_ops] **********************\n2022-05-04 10:05:15,004 | TASK [Create an empty file in Windows guest OS] ************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_create_file.yml:8\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play sata v hba device ops timestamp task create an empty file in windows guest os fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1239, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Cycle_Windows_11_64-111_failed_tasks_log.0", "raw": "2022-05-05 09:05:53,005 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-05-05 09:05:53,005 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play vmxnet number network device ops timestamp task execute powershell command in windows guest fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1240, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_Windows_Server_LTSC_vNext-5_logs_failed_tasks_log.1", "raw": "2021-11-30 08:22:24,030 | Failed at Play [check_ip_address] **************************\n2021-11-30 08:22:24,030 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => basic: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play check ip address timestamp task execute powershell command in windows guest fatal localhost un reachable basic connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1241, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_9_x-25_logs_failed_tasks_log.0", "raw": "2021-12-21 13:05:27,021 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2021-12-21 13:05:27,021 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nConnectionResetError: [Errno 104] Connection reset by peer\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error\n2021-12-21 13:06:58,021 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "connectionreset", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task wait for port number to become open or contain specific keyword connection reset error error number connection reset by peer fatal localhost failed module failure see stdout stderr for the exact error timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1242, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Cycle_RHEL_9_x-22_failed_tasks_log.0", "raw": "2022-02-11 21:56:40,011 | Failed at Play [ovt_verify_install] ************************\n2022-02-11 21:56:40,011 | TASK [Check VM 'test_vm_1644612776118' IP address] *********\ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_9.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1644612776118' IP Address", "category": "ip_address", "processed": "timestamp failed at play ovt verify install timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1243, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_Windows_Server_2022-52_failed_tasks_log.0", "raw": "2022-02-21 04:05:36,021 | Failed at Play [deploy_vm_efi_nvme_e1000e] *****************\n2022-02-21 04:05:36,021 | TASK [Check VM 'test_windows_server_ltsc_22538' IP address] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_2022/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_windows_server_ltsc_22538' IP Address\n2022-02-21 04:05:42,021 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_2022/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "ip_address", "processed": "timestamp failed at play deploy vm efi nvme timestamp task check vm test windows server lts c number ip address fatal localhost failed failed to get vm test windows server lts c number ip address timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1244, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_9_x-21_logs_failed_tasks_log.0", "raw": "2021-12-10 17:00:47,010 | Failed at Play [ovt_verify_install] ************************\n2021-12-10 17:00:47,010 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address", "category": "ip_address", "processed": "timestamp failed at play ovt verify install timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1245, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Regression_RHEL_8_x-48_failed_tasks_log.0", "raw": "2022-03-25 06:44:30,025 | Failed at Play [ovt_verify_uninstall] **********************\n2022-03-25 06:44:30,025 | TASK [Check VM 'test_rhel8' IP address] ********************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_rhel8' IP Address", "category": "ip_address", "processed": "timestamp failed at play ovt verify un install timestamp task check vm test rhel number ip address fatal localhost failed failed to get vm test rhel number ip address", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1246, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI-55_failed_tasks_log.0", "raw": "2022-04-25 03:30:36,025 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-04-25 03:30:36,025 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-04-25 03:31:04,025 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:42\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_e1000e", "category": "ip_address", "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas enumbere", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1247, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_70GA_SATA_E1000E_BIOS-17_failed_tasks_log.0", "raw": "2022-04-22 02:42:45,022 | Failed at Play [deploy_vm_bios_sata_e1000e] ****************\n2022-04-22 02:42:45,022 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_SATA_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-04-22 02:43:22,022 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_SATA_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:42\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_sata_e1000e", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios sata timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios sata enumbere", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1248, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_70GA_SATA_E1000E_BIOS-16_failed_tasks_log.0", "raw": "2022-04-21 17:13:19,021 | Failed at Play [deploy_vm_bios_sata_e1000e] ****************\n2022-04-21 17:13:19,021 | TASK [Check VM 'test_vm_1650556495367' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_SATA_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1650556495367' IP Address\n2022-04-21 17:13:55,021 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_SATA_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:42\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_sata_e1000e", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios sata timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios sata enumbere", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1249, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Windows_Server_LTSC_70U1_IDE_E1000E_BIOS-22_failed_tasks_log.0", "raw": "2022-04-22 02:50:26,022 | Failed at Play [deploy_vm_bios_ide_e1000e] *****************\n2022-04-22 02:50:26,022 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U1_IDE_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-04-22 02:50:57,022 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U1_IDE_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:42\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_ide_e1000e", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios ide timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios ide enumbere", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1250, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Cycle_Windows_10_64-136_failed_tasks_log.13", "raw": "2022-05-04 10:46:43,004 | Failed at Play [wintools_uninstall_verify] *****************\n2022-05-04 10:46:43,004 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address", "category": "ip_address", "processed": "timestamp failed at play win tools un install verify timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1298, "name": "__Ansible_Regression_Ubuntu_20_04_Server_ISO-20_logs_failed_tasks_log.0", "raw": "2021-11-26 07:50:43,026 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-11-26 07:50:43,026 | TASK [Assert cloud-init guest customization checks all PASS] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_20.04.3_Server_ISO/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:41\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "domain_not_expect", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task assert cloud init guest customization checks all pass failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1251, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Windows_11_70U3_LSILOGICSAS_VMXNET3_EFI-14_failed_tasks_log.0", "raw": "2022-05-04 03:25:16,004 | Failed at Play [deploy_vm_efi_lsilogicsas_vmxnet3] *********\n2022-05-04 03:25:16,004 | TASK [Check VM 'test_vm_1651630204141' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_70U3_LSILOGICSAS_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1651630204141' IP Address\n2022-05-04 03:25:48,004 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_11_70U3_LSILOGICSAS_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm efi lsi logic sas vmxnet number timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1252, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70GA-2_logs_failed_tasks_log.0", "raw": "2021-12-10 17:46:56,010 | Failed at Play [deploy_vm_bios_paravirtual_vmxnet3] ********\n2021-12-10 17:46:56,010 | TASK [Check VM 'test_vm_1639153639529' IP address] *********\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70GA/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1639153639529' IP Address\n2021-12-10 17:47:58,010 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70GA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_paravirtual_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios para virtual vmxnet number timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1253, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_70U1-11_logs_failed_tasks_log.0", "raw": "2021-12-22 07:19:08,022 | Failed at Play [deploy_vm_bios_paravirtual_vmxnet3] ********\n2021-12-22 07:19:08,022 | TASK [Check VM 'test_vm_1640152973589' IP address] *********\ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_70U1/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1640152973589' IP Address\n2021-12-22 07:20:09,022 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_70U1/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_paravirtual_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios para virtual vmxnet number timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1254, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_70U1-5_logs_failed_tasks_log.0", "raw": "2021-12-13 05:13:19,013 | Failed at Play [deploy_vm_bios_paravirtual_vmxnet3] ********\n2021-12-13 05:13:19,013 | TASK [Check VM 'test_vm_1639366994091' IP address] *********\ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_70U1/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1639366994091' IP Address\n2021-12-13 05:14:21,013 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_70U1/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_paravirtual_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios para virtual vmxnet number timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1255, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_Server_LTSC_64bit_70U3_LSILogicSAS_BIOS-7_logs_failed_tasks_log.0", "raw": "2021-12-13 15:09:24,013 | Failed at Play [deploy_vm_bios_lsilogicsas_e1000e] *********\n2021-12-13 15:09:24,013 | TASK [Check VM 'test_vm_1639402871391' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U3_LSILogicSAS_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1639402871391' IP Address\n2021-12-13 15:10:17,013 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U3_LSILogicSAS_BIOS/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios lsi logic sas timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1256, "name": "ansible_gosv_logs_FAILURE_Ansible_exclude_Regression_SLED_15_x-11_logs_failed_tasks_log.0", "raw": "2021-12-14 17:00:23,014 | Failed at Play [deploy_vm_bios_nvme_vmxnet3] ***************\n2021-12-14 17:00:23,014 | TASK [Check VM 'test_vm_1639495953017' IP address] *********\ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1639495953017' IP Address\n2021-12-14 17:01:56,014 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_nvme_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios nvme vmxnet number timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1301, "name": "__Ansible_Regression_Ubuntu_21_10_Server_ISO-30_logs_failed_tasks_log.1", "raw": "2021-12-02 22:38:25,002 | Failed at Play [vmxnet3_network_device_ops] ****************\n2021-12-02 22:38:25,002 | TASK [Apply netplan configuration file for new added nic ens224] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:62\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.185.13.124 port 22: Connection timed out", "category": "ssh_to_host_failure", "processed": "timestamp failed at play vmxnet number network device ops timestamp task apply net plan configuration file for new added nic fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1257, "name": "ansible_gosv_logs_FAILURE_Ansible_exclude_Regression_SLED_15_x-5_logs_failed_tasks_log.0", "raw": "2021-12-14 08:21:58,014 | Failed at Play [deploy_vm_bios_nvme_vmxnet3] ***************\n2021-12-14 08:21:58,014 | TASK [Check VM 'test_vm_1639464945501' IP address] *********\ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1639464945501' IP Address\n2021-12-14 08:23:17,014 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_nvme_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios nvme vmxnet number timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1258, "name": "ansible_gosv_logs_FAILURE_Ansible_exclude_Regression_SLED_15_x-8_logs_failed_tasks_log.0", "raw": "2021-12-14 11:47:06,014 | Failed at Play [deploy_vm_bios_nvme_vmxnet3] ***************\n2021-12-14 11:47:06,014 | TASK [Check VM 'test_vm_1639476962068' IP address] *********\ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1639476962068' IP Address\n2021-12-14 11:49:16,014 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_nvme_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios nvme vmxnet number timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1259, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Cycle_Ubuntu_21_10_ISO-83_failed_tasks_log.0", "raw": "2022-05-04 10:51:33,004 | Failed at Play [e1000e_network_device_ops] *****************\n2022-05-04 10:51:33,004 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "ping_issue", "processed": "timestamp failed at play network device ops timestamp task try to ping ip fatal localhost failed non zero return code when ping", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1261, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Desktop_ISO-29_logs_failed_tasks_log.0", "raw": "2021-12-23 06:38:10,023 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-23 06:38:10,023 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Desktop_ISO/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "ping_issue", "processed": "timestamp failed at play go sc perl dhcp timestamp task try to ping ip fatal localhost failed non zero return code when ping", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1262, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Debian_10_x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI-13_failed_tasks_log.1", "raw": "2022-03-07 14:50:36,007 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-03-07 14:50:36,007 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_Debian_10.x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM DNS servers are ['192.168.1.1'], not expected DNS servers ['192.168.1.1', '192.168.1.2']\", \"VM DNS domain search domains are  ['lan'] not expected search domains ['test.com', 'gosc.test.com']\", \"VM static IPv4 address is '192.168.1.194', expected IPv4 address is 192.168.1.101\"]", "category": "dns_not_expect", "processed": "timestamp failed at play go sc cloud init static ip timestamp task gos customization failed fatal localhost failed vm dns servers are ip address not expected dns servers ip address ip address vm dns domain search domains are lan not expected search domains test com go sc test com vm static ip vnumber address is ip address expected ip vnumber address is ip address", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1263, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_RHEL_9_x_70U3p04_NVME_VMXNET3_EFI-2_failed_tasks_log.0", "raw": "2022-03-18 07:53:40,018 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-03-18 07:53:40,018 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3p04_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM DNS servers are ['10.195.12.31', '10.172.40.1', 'fd01:1:3:1001::10'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"]", "category": "dns_not_expect", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task gos customization failed fatal localhost failed vm dns servers are ip address ip address ip address not expected dns servers ip address ip address", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1264, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Debian_10_x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI-18_failed_tasks_log.1", "raw": "2022-04-01 09:44:07,001 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-04-01 09:44:07,001 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_Debian_10.x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM DNS servers are ['192.168.192.1'], not expected DNS servers ['192.168.1.1', '192.168.1.2']\", \"VM DNS domain search domains are  ['lan'] not expected search domains ['test.com', 'gosc.test.com']\", \"VM static IPv4 address is '192.168.192.133', expected IPv4 address is 192.168.192.101\", \"VM static IPv4 gateway is '192.168.1.1', expected IPv4 gateway is 192.168.192.1\"]", "category": "dns_not_expect", "processed": "timestamp failed at play go sc cloud init static ip timestamp task gos customization failed fatal localhost failed vm dns servers are ip address not expected dns servers ip address ip address vm dns domain search domains are lan not expected search domains test com go sc test com vm static ip vnumber address is ip address expected ip vnumber address is ip address vm static ip vnumber gateway is ip address expected ip vnumber gateway is ip address", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1302, "name": "__Ansible_Regression_Ubuntu_21_10_Desktop_ISO-19_logs_failed_tasks_log.0", "raw": "2021-12-08 04:51:37,008 | Failed at Play [env_setup] *********************************\n2021-12-08 04:51:37,008 | TASK [Enable GuestIPHack on ESXi host '10.78.118.4'] *******\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Desktop_ISO/ansible-vsphere-gos-validation/common/esxi_enable_guest_ip_hack.yml:5\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via ssh: ssh: connect to host 10.78.118.4 port 22: Connection timed out", "category": "ssh_to_host_failure", "processed": "timestamp failed at play environment setup timestamp task enable guest ip hack on esxi host ip address fatal localhost un reachable failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1279, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_ISO-4_logs_failed_tasks_log.0", "raw": "2022-01-12 16:40:08,012 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-01-12 16:40:08,012 | TASK [Wait for autoinstall completed message] **************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/deploy_vm/wait_autoinstall_completed.yml:4\nfatal: [localhost -> 10.186.6.59]: FAILED! => non-zero return code when grep\n2022-01-12 16:41:06,012 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_vmxnet3", "category": "greperror", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for auto install completed message fatal localhost ip address failed non zero return code when grep timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1265, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_67U3-1_logs_failed_tasks_log.0", "raw": "2021-12-10 15:06:50,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 15:06:50,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_67U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc2-10-187-120-243, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.195.12.31', '10.172.40.1'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1266, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70GA-3_logs_failed_tasks_log.0", "raw": "2021-12-15 12:18:52,015 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-15 12:18:52,015 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70GA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is wdc-10-191-178-154, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.132.7.1', '10.142.7.1', '10.128.242.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'vmware.com', 'nimbus.eng.vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is wdc number expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com vmware com nimbus eng vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1283, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-14_logs_failed_tasks_log.2", "raw": "2022-01-19 03:01:05,019 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-01-19 03:01:05,019 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_vm", "category": "unable_gather_information", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task get specified property info for vm test vm fatal localhost failed unable to gather information for non existing vm test vm", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1267, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70U1-1_logs_failed_tasks_log.0", "raw": "2021-12-10 13:44:56,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 13:44:56,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70U1/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc1-10-78-88-80, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.166.1.1', '10.166.1.2', '10.142.7.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1268, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70U1-2_logs_failed_tasks_log.0", "raw": "2021-12-10 16:42:59,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 16:42:59,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70U1/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc1-10-78-82-157, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.166.1.1', '10.166.1.2', '10.142.7.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1299, "name": "__Ansible_Regression_Ubuntu_21_10_Server_ISO-23_logs_failed_tasks_log.0", "raw": "2021-12-02 14:18:30,002 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-02 14:18:30,002 | TASK [Assert cloud-init guest customization checks all PASS] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'nimbus.eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "domain_not_expect", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task assert cloud init guest customization checks all pass failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com nimbus eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1269, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70U2-1_logs_failed_tasks_log.0", "raw": "2021-12-10 14:06:45,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 14:06:45,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70U2/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc2-10-184-84-255, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.172.40.1', '10.172.40.2', '10.142.7.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1270, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70U2-2_logs_failed_tasks_log.0", "raw": "2021-12-10 17:01:54,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 17:01:54,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70U2/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc2-10-184-94-83, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.172.40.1', '10.172.40.2', '10.142.7.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1271, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70U3-1_logs_failed_tasks_log.0", "raw": "2021-12-10 13:47:50,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 13:47:50,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc1-10-168-185-206, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.162.204.1', '10.166.1.1'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1272, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70U3-2_logs_failed_tasks_log.0", "raw": "2021-12-10 16:45:06,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 16:45:06,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc1-10-168-186-201, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.162.204.1', '10.166.1.1'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1273, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_AlmaLinux_8_x-17_logs_failed_tasks_log.0", "raw": "2021-12-10 17:13:48,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 17:13:48,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_Regression_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc1-10-78-161-170, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.166.1.1', '10.166.1.2', '10.142.7.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1274, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_AlmaLinux_8_x-18_logs_failed_tasks_log.0", "raw": "2021-12-10 21:24:48,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 21:24:48,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_Regression_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc1-10-78-168-71, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.166.1.1', '10.166.1.2', '10.142.7.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is scnumber expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1275, "name": "ansible_gosv_logs_FAILURE_Ansible_RockyLinux_8_x_70GA-1_logs_failed_tasks_log.0", "raw": "2021-12-09 12:36:40,009 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-09 12:36:40,009 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70GA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is wdc-10-191-154-234, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.132.7.1', '10.142.7.1', '10.128.242.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'vmware.com', 'nimbus.eng.vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is wdc number expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com vmware com nimbus eng vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1276, "name": "ansible_gosv_logs_FAILURE_Ansible_RockyLinux_8_x_70GA-2_logs_failed_tasks_log.0", "raw": "2021-12-09 14:12:21,009 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-09 14:12:21,009 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70GA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is wdc-10-191-159-69, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.132.7.1', '10.142.7.1', '10.128.242.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'vmware.com', 'nimbus.eng.vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is wdc number expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com vmware com nimbus eng vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1277, "name": "ansible_gosv_logs_FAILURE_Ansible_RockyLinux_8_x_70U1-3_logs_failed_tasks_log.0", "raw": "2021-12-10 04:37:42,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 04:37:42,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70U1/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is wdc-10-191-232-218, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.132.7.1', '10.142.7.1', '10.128.242.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'vmware.com', 'nimbus.eng.vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is wdc number expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com vmware com nimbus eng vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1278, "name": "ansible_gosv_logs_FAILURE_Ansible_RockyLinux_8_x_70U2-2_logs_failed_tasks_log.0", "raw": "2021-12-09 14:12:20,009 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-09 14:12:20,009 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70U2/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is wdc-10-191-224-30, expected hostname is gosc-dhcp-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.132.7.1', '10.142.7.1', '10.128.242.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'vmware.com', 'nimbus.eng.vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is wdc number expected hostname is go sc dhcp vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com expected domain name is go sc test com and dns domain success is false failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com vmware com nimbus eng vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1280, "name": "ansible_gosv_logs_FAILURE_Ansible_Ubuntu_Desktop_ISO_main-2_logs_failed_tasks_log.0", "raw": "2021-12-13 23:44:13,013 | Failed at Play [deploy_vm_bios_nvme_e1000e] ****************\n2021-12-13 23:44:13,013 | TASK [Wait for autoinstall early commands] *****************\ntask path: /home/worker/workspace/Ansible_Ubuntu_Desktop_ISO_main/ansible-vsphere-gos-validation/linux/deploy_vm/ubuntu/ubuntu_install_os.yml:9\nfatal: [localhost -> 10.186.53.51]: FAILED! => non-zero return code when grep\n2021-12-13 23:45:26,013 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Ubuntu_Desktop_ISO_main/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_nvme_e1000e", "category": "greperror", "processed": "timestamp failed at play deploy vm bios nvme timestamp task wait for auto install early commands fatal localhost ip address failed non zero return code when grep timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme enumbere", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1281, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_Windows_11_70GA_LSILOGICSAS_E1000E_EFI-14_failed_tasks_log.0", "raw": "2022-05-04 02:47:21,004 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-05-04 02:47:21,004 | TASK [Guest OS connection failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_11_70GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_check_winrm.yml:26\nfatal: [localhost]: FAILED! => Guest winrm is not connectable in 1800 seconds.\n2022-05-04 02:48:12,004 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_11_70GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_e1000e", "category": "guest_winrm", "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task guest os connection failure fatal localhost failed guest win rm is not connectable in number seconds timestamp task testing exit due to failure fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas enumbere", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1282, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-14_logs_failed_tasks_log.1", "raw": "2022-01-19 03:01:01,019 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-01-19 03:01:01,019 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_vm", "category": "unable_gather_information", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task get specified property info for vm test vm fatal localhost failed unable to gather information for non existing vm test vm", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1284, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-26_logs_failed_tasks_log.0", "raw": "2022-01-06 06:38:41,006 | Failed at Play [e1000e_network_device_ops] *****************\n2022-01-06 06:38:41,006 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_vm", "category": "unable_gather_information", "processed": "timestamp failed at play network device ops timestamp task get specified property info for vm test vm fatal localhost failed unable to gather information for non existing vm test vm", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1285, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-26_logs_failed_tasks_log.1", "raw": "2022-01-06 06:38:44,006 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-01-06 06:38:44,006 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_vm", "category": "unable_gather_information", "processed": "timestamp failed at play vmxnet number network device ops timestamp task get specified property info for vm test vm fatal localhost failed unable to gather information for non existing vm test vm", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1286, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_OVA-46_logs_failed_tasks_log.2", "raw": "2022-01-20 09:37:07,020 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-20 09:37:07,020 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_vm", "category": "unable_gather_information", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task get specified property info for vm test vm fatal localhost failed unable to gather information for non existing vm test vm", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1287, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_Flatcar_OVA-40_failed_tasks_log.0", "raw": "2022-02-21 04:59:29,021 | Failed at Play [deploy_flatcar_ova] ************************\n2022-02-21 04:59:29,021 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_Flatcar_OVA/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-02-21 06:30:30,021 | TASK [Remove local path /tmp/nfs_ap9owhl3] *****************\ntask path: /home/worker/workspace/Ansible_Regression_Flatcar_OVA/ansible-vsphere-gos-validation/common/delete_local_file.yml:5\nfatal: [localhost]: FAILED! => rmtree failed: [Errno 30] Read-only file system: 'IPMICFG.EXE'", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play deploy flatcar ova timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table timestamp task remove local path tmp nfs fatal localhost failed rm tree failed error number read only file system ipmi configuration exe", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1288, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_Photon_4_0_OVA-44_failed_tasks_log.0", "raw": "2022-02-21 04:56:15,021 | Failed at Play [deploy_vmwarephoton_ova] *******************\n2022-02-21 04:56:15,021 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-02-21 06:26:55,021 | TASK [Remove local path /tmp/nfs_w3dyc958] *****************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/delete_local_file.yml:5\nfatal: [localhost]: FAILED! => rmtree failed: [Errno 30] Read-only file system: 'IPMICFG.EXE'", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play deploy vmware photon ova timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table timestamp task remove local path tmp nfs fatal localhost failed rm tree failed error number read only file system ipmi configuration exe", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1289, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_OVA-52_logs_failed_tasks_log.0", "raw": "2022-01-24 07:59:38,024 | Failed at Play [deploy_ubuntu_ova] *************************\n2022-01-24 07:59:38,024 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-01-24 08:02:02,024 | TASK [Remove local path /tmp/nfs_zt8f328j] *****************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/common/delete_local_file.yml:5\nfatal: [localhost]: FAILED! => rmtree failed: [Errno 30] Read-only file system: '._.DS_Store'", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play deploy ubuntu ova timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table timestamp task remove local path tmp nfs fatal localhost failed rm tree failed error number read only file system ds store", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1290, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Regression_Windows_10_64-48_failed_tasks_log.0", "raw": "2022-03-10 08:27:36,010 | Failed at Play [wintools_complete_install_verify] **********\n2022-03-10 08:27:36,010 | TASK [Wait for VM power status to 'poweredOn'] *************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_64/ansible-vsphere-gos-validation/common/vm_wait_power_state.yml:11\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "failed_hardware_config_only", "processed": "timestamp failed at play win tools complete install verify timestamp task wait for vm power status to powered on fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1291, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Windows_Server_LTSC_vNext-38_logs_failed_tasks_log.0", "raw": "2022-01-15 07:52:35,015 | Failed at Play [sata_vhba_device_ops] **********************\n2022-01-15 07:52:35,015 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nsocket.timeout: The read operation timed out\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='10.168.117.200', port=5986): Read timed out. (read timeout=30)\nrequests.exceptions.ReadTimeout: HTTPSConnectionPool(host='10.168.117.200', port=5986): Read timed out. (read timeout=30)\nansible.errors.AnsibleConnectionFailure: winrm connection error: HTTPSConnectionPool(host='10.168.117.200', port=5986): Read timed out. (read timeout=30)\nOSError: [Errno 113] No route to host\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7effc2630b80>: Failed to establish a new connection: [Errno 113] No route to host\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='10.168.117.200', port=5986): Max retries exceeded with url: /wsman (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7effc2630b80>: Failed to establish a new connection: [Errno 113] No route to host'))\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='10.168.117.200', port=5986): Max retries exceeded with url: /wsman (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7effc2630b80>: Failed to establish a new connection: [Errno 113] No route to host'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.\n2022-01-15 07:52:55,015 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "winconnectionerror", "processed": "timestamp failed at play sata v hba device ops timestamp task execute powershell command in windows guest socket timeout the read operation timed out url library number exceptions read timeout error https connection pool host ip address port number read timed out read timeout number requests exceptions read timeout https connection pool host ip address port number read timed out read timeout number ansible errors ansible connection failure win rm connection error https connection pool host ip address port number read timed out read timeout number os error error number no route to host url library number exceptions new connection error url library number connection https connection object at hex id failed to establish a new connection error number no route to host url library number exceptions max retry error https connection pool host ip address port number max retries exceeded with url wsman caused by new connection error url library number connection https connection object at hex id failed to establish a new connection error number no route to host requests exceptions connection error https connection pool host ip address port number max retries exceeded with url wsman caused by new connection error url library number connection https connection object at hex id failed to establish a new connection error number no route to host fatal localhost failed unexpected failure during module execution timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1292, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Regression_Photon_4_0_ISO-40_failed_tasks_log.0", "raw": "2022-03-25 07:44:02,025 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-03-25 07:44:02,025 | TASK [Execute guest OS shutdown] ***************************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/utils/shutdown.yml:5\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via ssh: ssh: connect to host 10.180.193.122 port 22: No route to host", "category": "ssh_to_host_failure", "processed": "timestamp failed at play cpu multi cores per socket timestamp task execute guest os shutdown fatal localhost un reachable failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1293, "name": "__Ansible_Regression_RHEL_9_x-8_logs_failed_tasks_log.0", "raw": "2021-11-25 08:14:44,025 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2021-11-25 08:14:44,025 | TASK [include_tasks] ***************************************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/deploy_vm/deploy_vm_from_iso.yml:49\nfatal: [localhost]: FAILED! => Could not find or access '/home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/common/vm_get_video_card.yml' on the Ansible Controller.\n2021-11-25 08:15:39,025 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "on_the_ansible_controller", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task include tasks fatal localhost failed could not find or access home worker workspace ansible regression rhel number x ansible vsphere gos validation common vm get video card yml on the ansible controller timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1300, "name": "__Ansible_Regression_Ubuntu_21_10_Server_ISO-30_logs_failed_tasks_log.0", "raw": "2021-12-02 20:22:17,002 | Failed at Play [e1000e_network_device_ops] *****************\n2021-12-02 20:22:17,002 | TASK [Apply netplan configuration file for new added nic ens224] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:62\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.185.13.124 port 22: Connection timed out", "category": "ssh_to_host_failure", "processed": "timestamp failed at play network device ops timestamp task apply net plan configuration file for new added nic fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1303, "name": "__Ansible_Regression_Ubuntu_21_10_Server_OVA-8_logs_failed_tasks_log.0", "raw": "2021-12-03 02:35:29,003 | Failed at Play [device_list] *******************************\n2021-12-03 02:35:29,003 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nexception in /vmware.py when connect_to_api in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Unable to log on to vCenter or ESXi API at 10.186.230.253:443  as Administrator@vsphere.local: Cannot complete login due to an incorrect user name or password.", "category": "incorrect_username", "processed": "timestamp failed at play device list timestamp task get specified property info for vm test vm exception in vmware python when connect to api in soap adapter python when invoke method fatal localhost failed unable to log on to vcenter or esxi api at ip address as administrator vsphere local can not complete login due to an incorrect user name or password", "solution": "retry", "target": "nimbus", "version": 202205240000}, {"id": 1294, "name": "__Ansible_RHEL_9_x_70U2-2_logs_failed_tasks_log.0", "raw": "2021-12-08 09:31:42,008 | Failed at Play [deploy_vm_efi_sata_vmxnet3] ****************\n2021-12-08 09:31:42,008 | TASK [Create unattend config file from template] ***********\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U2/ansible-vsphere-gos-validation/linux/deploy_vm/create_unattend_install_iso.yml:49\nIf you are using a module and expect the file to exist on the remote, see the remote_src option\nfatal: [localhost]: FAILED! => Could not find or access '/home/worker/workspace/Ansible_RHEL_9.x_70U2/ansible-vsphere-gos-validation/autoinstall/RHEL/9/server_with_GUI/ks.cfg' on the Ansible Controller.\nIf you are using a module and expect the file to exist on the remote, see the remote_src option\n2021-12-08 09:32:14,008 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U2/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_sata_vmxnet3", "category": "on_the_ansible_controller", "processed": "timestamp failed at play deploy vm efi sata vmxnet number timestamp task create un attend configuration file from template if you are using a module and expect the file to exist on the remote see the remote source option fatal localhost failed could not find or access home worker workspace ansible rhel number x ansible vsphere gos validation auto install rhel number server with gui ks configuration on the ansible controller if you are using a module and expect the file to exist on the remote see the remote source option timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi sata vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1295, "name": "__Ansible_RHEL_9_x_70GA-1_logs_failed_tasks_log.0", "raw": "2021-12-08 09:04:39,008 | Failed at Play [deploy_vm_bios_paravirtual_e1000e] *********\n2021-12-08 09:04:39,008 | TASK [Create unattend config file from template] ***********\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70GA/ansible-vsphere-gos-validation/linux/deploy_vm/create_unattend_install_iso.yml:49\nIf you are using a module and expect the file to exist on the remote, see the remote_src option\nfatal: [localhost]: FAILED! => Could not find or access '/home/worker/workspace/Ansible_RHEL_9.x_70GA/ansible-vsphere-gos-validation/autoinstall/RHEL/9/server_with_GUI/ks.cfg' on the Ansible Controller.\nIf you are using a module and expect the file to exist on the remote, see the remote_src option\n2021-12-08 09:05:11,008 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70GA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_paravirtual_e1000e", "category": "on_the_ansible_controller", "processed": "timestamp failed at play deploy vm bios para virtual timestamp task create un attend configuration file from template if you are using a module and expect the file to exist on the remote see the remote source option fatal localhost failed could not find or access home worker workspace ansible rhel number x number ga ansible vsphere gos validation auto install rhel number server with gui ks configuration on the ansible controller if you are using a module and expect the file to exist on the remote see the remote source option timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios para virtual e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1296, "name": "__Ansible_RHEL_9_x_70U1-2_logs_failed_tasks_log.0", "raw": "2021-12-08 09:31:39,008 | Failed at Play [deploy_vm_bios_nvme_vmxnet3] ***************\n2021-12-08 09:31:39,008 | TASK [Create unattend config file from template] ***********\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U1/ansible-vsphere-gos-validation/linux/deploy_vm/create_unattend_install_iso.yml:49\nIf you are using a module and expect the file to exist on the remote, see the remote_src option\nfatal: [localhost]: FAILED! => Could not find or access '/home/worker/workspace/Ansible_RHEL_9.x_70U1/ansible-vsphere-gos-validation/autoinstall/RHEL/9/server_with_GUI/ks.cfg' on the Ansible Controller.\nIf you are using a module and expect the file to exist on the remote, see the remote_src option\n2021-12-08 09:32:12,008 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U1/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_nvme_vmxnet3", "category": "on_the_ansible_controller", "processed": "timestamp failed at play deploy vm bios nvme vmxnet number timestamp task create un attend configuration file from template if you are using a module and expect the file to exist on the remote see the remote source option fatal localhost failed could not find or access home worker workspace ansible rhel number x ansible vsphere gos validation auto install rhel number server with gui ks configuration on the ansible controller if you are using a module and expect the file to exist on the remote see the remote source option timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1297, "name": "__Ansible_RHEL_9_x_70U3-1_logs_failed_tasks_log.0", "raw": "2021-12-08 09:24:54,008 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2021-12-08 09:24:54,008 | TASK [Create unattend config file from template] ***********\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/linux/deploy_vm/create_unattend_install_iso.yml:49\nIf you are using a module and expect the file to exist on the remote, see the remote_src option\nfatal: [localhost]: FAILED! => Could not find or access '/home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/autoinstall/RHEL/9/server_with_GUI/ks.cfg' on the Ansible Controller.\nIf you are using a module and expect the file to exist on the remote, see the remote_src option\n2021-12-08 09:25:26,008 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_e1000e", "category": "on_the_ansible_controller", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task create un attend configuration file from template if you are using a module and expect the file to exist on the remote see the remote source option fatal localhost failed could not find or access home worker workspace ansible rhel number x ansible vsphere gos validation auto install rhel number server with gui ks configuration on the ansible controller if you are using a module and expect the file to exist on the remote see the remote source option timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1311, "name": "__Ansible_Regression_RHEL_9_x-9_logs_failed_tasks_log.2", "raw": "2021-11-25 11:30:53,025 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-11-25 11:30:53,025 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play go sc cloud init static ip timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1304, "name": "__Ansible_Windows_11_64bit_70U1_IDE_BIOS-1_logs_failed_tasks_log.0", "raw": "2021-12-07 09:17:01,007 | Failed at Play [deploy_vm_bios_ide_e1000e] *****************\n2021-12-07 09:17:01,007 | TASK [Create a new VM 'test_vm' on server '10.78.230.177'] *\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_70U1_IDE_BIOS/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => value of controller_type must be one of: buslogic, lsilogic, paravirtual, lsilogicsas, sata, nvme, got: ide found in disk\n2021-12-07 09:17:32,007 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_70U1_IDE_BIOS/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "controller_type", "processed": "timestamp failed at play deploy vm bios ide timestamp task create a new vm test vm on server ip address fatal localhost failed value of controller type must be one of bus logic lsi logic para virtual lsi logic sas sata nvme got ide found in disk timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1305, "name": "__Ansible_Windows_11_64bit_70GA_IDE_EFI-1_logs_failed_tasks_log.0", "raw": "2021-12-07 08:56:28,007 | Failed at Play [deploy_vm_efi_ide_e1000e] ******************\n2021-12-07 08:56:28,007 | TASK [Create a new VM 'test_vm' on server '10.168.190.131'] \ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_70GA_IDE_EFI/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => value of controller_type must be one of: buslogic, lsilogic, paravirtual, lsilogicsas, sata, nvme, got: ide found in disk\n2021-12-07 08:56:58,007 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_70GA_IDE_EFI/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "controller_type", "processed": "timestamp failed at play deploy vm efi ide timestamp task create a new vm test vm on server ip address fatal localhost failed value of controller type must be one of bus logic lsi logic para virtual lsi logic sas sata nvme got ide found in disk timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1306, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-6_logs_failed_tasks_log.2", "raw": "2021-11-30 11:41:24,030 | Failed at Play [memory_hot_add_basic] **********************\n2021-11-30 11:41:24,030 | TASK [Check memory size got from guest OS] *****************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/memory_hot_add_basic/hotadd_memory_verify.yml:24\nfatal: [localhost]: FAILED! => Get memory size in guest: 4096MB, not expected: 5120MB", "category": "memory_issue", "processed": "timestamp failed at play memory hot add basic timestamp task check memory size got from guest os fatal localhost failed get memory size in guest number mb not expected number mb", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1307, "name": "__Ansible_Regression_RHEL_8_x-18_logs_failed_tasks_log.0", "raw": "2021-12-06 08:46:52,006 | Failed at Play [testbed_deploy_nimbus] *********************\n2021-12-06 08:46:52,006 | TASK [Check nimbus testbed deploy status every 15 seconds] *\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:15\nfatal: [localhost -> wdc-dbc2108.eng.vmware.com]: FAILED! => nimbus-testbeddeploy error", "category": "nimbus_testbed_issue", "processed": "timestamp failed at play testbed deploy nimbus timestamp task check nimbus testbed deploy status every number seconds fatal localhost wdc eng vmware com failed nimbus testbed deploy error", "solution": "retry", "target": "nimbus", "version": 202205240000}, {"id": 1308, "name": "__Ansible_Windows_11_64bit_70U3_NVMe_BIOS-1_logs_failed_tasks_log.1", "raw": "2021-12-07 09:48:36,007 | Failed at Play [nvme_vhba_device_ops] **********************\n2021-12-07 09:48:36,007 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_70U3_NVMe_BIOS/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => winrm connection error: HTTPSConnectionPool(host='10.187.157.121', port=5986): Read timed out. (read timeout=30)", "category": "winconnectionerror", "processed": "timestamp failed at play nvme v hba device ops timestamp task execute powershell command in windows guest fatal localhost un reachable win rm connection error https connection pool host ip address port number read timed out read timeout number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1309, "name": "__Ansible_Windows_11_64bit_70U3_PVSCSI_EFI-1_logs_failed_tasks_log.0", "raw": "2021-12-07 09:46:03,007 | Failed at Play [wintools_complete_install_verify] **********\n2021-12-07 09:46:03,007 | TASK [Download VMware tools] *******************************\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_70U3_PVSCSI_EFI/ansible-vsphere-gos-validation/windows/wintools_complete_install_verify/download_vmtools_and_transfer.yml:9\nfatal: [localhost]: FAILED! => Request failed HTTP Error 404: Not Found when get link", "category": "link_not_found", "processed": "timestamp failed at play win tools complete install verify timestamp task download vmware tools fatal localhost failed request failed http error number not found when get link", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1310, "name": "__Ansible_Regression_Ubuntu_21_10_Desktop_ISO-15_logs_failed_tasks_log.0", "raw": "2021-12-02 17:40:27,002 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2021-12-02 17:40:27,002 | TASK [Wait for autoinstall early commands] *****************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Desktop_ISO/ansible-vsphere-gos-validation/linux/deploy_vm/ubuntu/ubuntu_install_os.yml:9\nfatal: [localhost -> 10.78.188.168]: FAILED! => non-zero return code when grep\n2021-12-02 17:41:27,002 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Desktop_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "greperror", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task wait for auto install early commands fatal localhost ip address failed non zero return code when grep timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1312, "name": "__Ansible_Regression_Photon_4_0_OVA-6_logs_failed_tasks_log.1", "raw": "2021-12-02 10:17:13,002 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-02 10:17:13,002 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play go sc perl static ip timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1314, "name": "__Ansible_Cycle_Ubuntu_20_04_3_ISO-8_logs_failed_tasks_log.0", "raw": "2021-11-30 07:07:52,030 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2021-11-30 07:07:52,030 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table\n2021-11-30 07:09:02,030 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_vmxnet3", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1315, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.8", "raw": "2021-12-01 12:45:25,001 | Failed at Play [check_efi_firmware] ************************\n2021-12-01 12:45:25,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play check efi firmware timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1316, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.15", "raw": "2021-12-01 15:31:23,001 | Failed at Play [vmxnet3_network_device_ops] ****************\n2021-12-01 15:31:23,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play vmxnet number network device ops timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1317, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.12", "raw": "2021-12-01 14:20:08,001 | Failed at Play [device_list] *******************************\n2021-12-01 14:20:08,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play device list timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1318, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.24", "raw": "2021-12-01 19:05:42,001 | Failed at Play [sata_vhba_device_ops] **********************\n2021-12-01 19:05:42,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play sata v hba device ops timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1319, "name": "__Ansible_Regression_Ubuntu_21_10_Server_OVA-7_logs_failed_tasks_log.0", "raw": "2021-12-02 13:13:39,002 | Failed at Play [deploy_ubuntu_ova] *************************\n2021-12-02 13:13:39,002 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table\n2021-12-02 13:14:20,002 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_ubuntu_ova", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play deploy ubuntu ova timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy ubuntu ova", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1320, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.23", "raw": "2021-12-01 18:42:03,001 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2021-12-01 18:42:03,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1321, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.22", "raw": "\n2021-12-01 18:18:32,001 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2021-12-01 18:18:32,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1322, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.25", "raw": "2021-12-01 19:29:30,001 | Failed at Play [nvme_vhba_device_ops] **********************\n2021-12-01 19:29:30,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play nvme v hba device ops timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1323, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.13", "raw": "2021-12-01 14:43:54,001 | Failed at Play [secureboot_enable_disable] *****************\n2021-12-01 14:43:54,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play secure boot enable disable timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1324, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.14", "raw": "2021-12-01 15:07:34,001 | Failed at Play [e1000e_network_device_ops] *****************\n2021-12-01 15:07:34,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play network device ops timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1325, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.9", "raw": "2021-12-01 13:09:06,001 | Failed at Play [cpu_hot_add_basic] *************************\n2021-12-01 13:09:06,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play cpu hot add basic timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1326, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.11", "raw": "2021-12-01 13:56:27,001 | Failed at Play [memory_hot_add_basic] **********************\n2021-12-01 13:56:27,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play memory hot add basic timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1327, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.16", "raw": "2021-12-01 15:55:10,001 | Failed at Play [cpu_multicores_per_socket] *****************\n2021-12-01 15:55:10,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play cpu multi cores per socket timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1328, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.26", "raw": "2021-12-01 19:53:09,001 | Failed at Play [ovt_verify_uninstall] **********************\n2021-12-01 19:53:09,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play ovt verify un install timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1329, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.19", "raw": "2021-12-01 17:06:26,001 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-01 17:06:26,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1330, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.21", "raw": "2021-12-01 17:54:17,001 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2021-12-01 17:54:17,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play para virtual v hba device ops timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1331, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.10", "raw": "2021-12-01 13:32:44,001 | Failed at Play [check_quiesce_snapshot_custom_script] ******\n2021-12-01 13:32:44,001 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "vm_wait_guest_ip", "processed": "timestamp failed at play check quiesce snapshot custom script timestamp task wait for vmware tools collecting guest info fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1332, "name": "__Ansible_Autoinstall_CentOS_8_x-14_logs_failed_tasks_log.0", "raw": "2021-12-06 06:46:18,006 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2021-12-06 06:46:18,006 | TASK [Check VM 'test_vm_1638768091724' IP address] *********\ntask path: /home/worker/workspace/Ansible_Autoinstall_CentOS_8.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1638768091724' IP Address\n2021-12-06 06:46:48,006 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Autoinstall_CentOS_8.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1333, "name": "__Ansible_Regression_OracleLinux_8_x-5_logs_failed_tasks_log.0", "raw": "2021-12-01 12:48:09,001 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2021-12-01 12:48:09,001 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Regression_OracleLinux_8.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2021-12-01 12:49:13,001 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_OracleLinux_8.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1334, "name": "__Ansible_Autoinstall_CentOS_8_x-13_logs_failed_tasks_log.0", "raw": "2021-12-06 04:07:42,006 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2021-12-06 04:07:42,006 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Autoinstall_CentOS_8.x/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2021-12-06 04:08:15,006 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Autoinstall_CentOS_8.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_vmxnet3", "category": "ip_address", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1335, "name": "__Ansible_Windows_Server_LTSC_64bit_70U1_SATA_BIOS-2_logs_failed_tasks_log.0", "raw": "2021-12-08 09:28:55,008 | Failed at Play [deploy_vm_bios_sata_e1000e] ****************\n2021-12-08 09:28:55,008 | TASK [Check VM 'test_vm_1638950974124' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U1_SATA_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1638950974124' IP Address\n2021-12-08 09:29:51,008 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U1_SATA_BIOS/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios sata timestamp task check vm test vm number ip address fatal localhost failed failed to get vm test vm number ip address timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1336, "name": "__Ansible_Windows_Server_LTSC_64bit_67U3_LSILogicSAS_EFI-1_logs_failed_tasks_log.0", "raw": "2021-12-07 10:13:57,007 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2021-12-07 10:13:57,007 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_67U3_LSILogicSAS_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2021-12-07 10:15:16,007 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_67U3_LSILogicSAS_EFI/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "ip_address", "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1337, "name": "__Ansible_Windows_Server_LTSC_64bit_70GA_SATA_BIOS-1_logs_failed_tasks_log.0", "raw": "2021-12-07 10:11:32,007 | Failed at Play [deploy_vm_bios_sata_e1000e] ****************\n2021-12-07 10:11:32,007 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70GA_SATA_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2021-12-07 10:12:38,007 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70GA_SATA_BIOS/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "ip_address", "processed": "timestamp failed at play deploy vm bios sata timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1338, "name": "__Ansible_Regression_Windows_10_32-5_logs_failed_tasks_log.0", "raw": "2021-11-23 11:08:45,023 | Failed at Play [deploy_vm_efi_nvme_e1000e] *****************\n2021-11-23 11:08:45,023 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_32/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2021-11-23 11:09:59,023 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_32/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "ip_address", "processed": "timestamp failed at play deploy vm efi nvme timestamp task check vm test vm ip address fatal localhost failed failed to get vm test vm ip address timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1339, "name": "__Ansible_Regression_RockyLinux_8_x-13_logs_failed_tasks_log.0", "raw": "2021-12-08 06:02:19,008 | Failed at Play [testbed_deploy_nimbus] *********************\n2021-12-08 06:02:19,008 | TASK [Check nimbus testbed deploy status every 15 seconds] *\ntask path: /home/worker/workspace/Ansible_Regression_RockyLinux_8.x/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:15\nfatal: [localhost -> wdc-dbc2108.eng.vmware.com]: FAILED! => ansible job 272064635345.25364 started and not finished", "category": "ansible_start_not_finish", "processed": "timestamp failed at play testbed deploy nimbus timestamp task check nimbus testbed deploy status every number seconds fatal localhost wdc eng vmware com failed ansible job hex id number started and not finished", "solution": "retry", "target": "nimbus", "version": 202205240000}, {"id": 1340, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-6_logs_failed_tasks_log.4", "raw": "2021-11-30 11:46:29,030 | Failed at Play [cpu_multicores_per_socket] *****************\n2021-11-30 11:46:29,030 | TASK [Shutdown guest OS inside OS] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_shutdown_restart.yml:8\nfatal: [localhost]: UNREACHABLE! => basic: HTTPSConnectionPool(host='10.191.158.93', port=5986): Read timed out. (read timeout=30)", "category": "https_connection_pool", "processed": "timestamp failed at play cpu multi cores per socket timestamp task shutdown guest os inside os fatal localhost un reachable basic https connection pool host ip address port number read timed out read timeout number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1341, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.6", "raw": "2021-12-01 12:19:56,001 | Failed at Play [check_inbox_driver] ************************\n2021-12-01 12:19:56,001 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm'] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Detected an invalid snapshot configuration.", "category": "snapshot_config_error", "processed": "timestamp failed at play check inbox driver timestamp task create snapshot base snapshot on test vm fatal localhost failed detected an invalid snapshot configuration", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1342, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.1", "raw": "2021-12-01 12:13:00,001 | Failed at Play [ovt_verify_status] *************************\n2021-12-01 12:13:00,001 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm'] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Detected an invalid snapshot configuration.", "category": "snapshot_config_error", "processed": "timestamp failed at play ovt verify status timestamp task create snapshot base snapshot on test vm fatal localhost failed detected an invalid snapshot configuration", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1343, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.7", "raw": "2021-12-01 12:20:59,001 | Failed at Play [check_os_fullname] *************************\n2021-12-01 12:20:59,001 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm'] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Detected an invalid snapshot configuration.", "category": "snapshot_config_error", "processed": "timestamp failed at play check os full name timestamp task create snapshot base snapshot on test vm fatal localhost failed detected an invalid snapshot configuration", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1344, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.2", "raw": "2021-12-01 12:15:07,001 | Failed at Play [vgauth_check_service] **********************\n2021-12-01 12:15:07,001 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm'] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Detected an invalid snapshot configuration.", "category": "snapshot_config_error", "processed": "timestamp failed at play vg auth check service timestamp task create snapshot base snapshot on test vm fatal localhost failed detected an invalid snapshot configuration", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1345, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.5", "raw": "2021-12-01 12:18:54,001 | Failed at Play [stat_hosttime] *****************************\n2021-12-01 12:18:54,001 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm'] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Detected an invalid snapshot configuration.", "category": "snapshot_config_error", "processed": "timestamp failed at play stat host time timestamp task create snapshot base snapshot on test vm fatal localhost failed detected an invalid snapshot configuration", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1346, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.4", "raw": "2021-12-01 12:18:20,001 | Failed at Play [stat_balloon] ******************************\n2021-12-01 12:18:20,001 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm'] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Detected an invalid snapshot configuration.", "category": "snapshot_config_error", "processed": "timestamp failed at play stat balloon timestamp task create snapshot base snapshot on test vm fatal localhost failed detected an invalid snapshot configuration", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1347, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.3", "raw": "2021-12-01 12:17:10,001 | Failed at Play [check_ip_address] **************************\n2021-12-01 12:17:10,001 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm'] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Detected an invalid snapshot configuration.", "category": "snapshot_config_error", "processed": "timestamp failed at play check ip address timestamp task create snapshot base snapshot on test vm fatal localhost failed detected an invalid snapshot configuration", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1348, "name": "__Ansible_Regression_Windows_11_64-12_logs_failed_tasks_log.1", "raw": "2021-11-24 08:48:38,024 | Failed at Play [gosc_sanity_dhcp] **************************\n2021-11-24 08:48:38,024 | TASK [Customize Windows guest OS] **************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/windows/guest_customization/win_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization failed. For detailed information see warnings Waiting for customization result event timed out.", "category": "warn_detail_timeout", "processed": "timestamp failed at play go sc sanity dhcp timestamp task customize windows guest os fatal localhost failed customization failed for detailed information see warnings waiting for customization result event timed out", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1349, "name": "__Ansible_Regression_Photon_4_0_OVA-10_logs_failed_tasks_log.0", "raw": "2021-12-06 10:24:45,006 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-06 10:24:45,006 | TASK [Customize Linux guest OS] ****************************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization failed. For detailed information see warnings Waiting for customization result event timed out.", "category": "warn_detail_timeout", "processed": "timestamp failed at play go sc perl dhcp timestamp task customize linux guest os fatal localhost failed customization failed for detailed information see warnings waiting for customization result event timed out", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1350, "name": "__Ansible_Regression_Photon_4_0_OVA-10_logs_failed_tasks_log.1", "raw": "2021-12-06 10:41:44,006 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-06 10:41:44,006 | TASK [Customize Linux guest OS] ****************************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization failed. For detailed information see warnings Waiting for customization result event timed out.", "category": "warn_detail_timeout", "processed": "timestamp failed at play go sc perl static ip timestamp task customize linux guest os fatal localhost failed customization failed for detailed information see warnings waiting for customization result event timed out", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1351, "name": "__Ansible_Regression_Windows_11_64-12_logs_failed_tasks_log.0", "raw": "2021-11-24 08:06:07,024 | Failed at Play [gosc_sanity_staticip] **********************\n2021-11-24 08:06:07,024 | TASK [Customize Windows guest OS] **************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/windows/guest_customization/win_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization failed. For detailed information see warnings Waiting for customization result event timed out.", "category": "warn_detail_timeout", "processed": "timestamp failed at play go sc sanity static ip timestamp task customize windows guest os fatal localhost failed customization failed for detailed information see warnings waiting for customization result event timed out", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1371, "name": "__Ansible_Regression_SLES_15_x-3_logs_failed_tasks_log.0", "raw": "2021-12-01 14:02:34,001 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2021-12-01 14:02:34,001 | TASK [Wait for device list changed] ************************\ntask path: /home/worker/workspace/Ansible_Regression_SLES_15.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:97\nfatal: [localhost -> 10.191.189.69]: FAILED! =>  when lsblk", "category": "origin", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task wait for device list changed fatal localhost ip address failed when ls blk", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1352, "name": "__Ansible_Regression_Flatcar_OVA-8_logs_failed_tasks_log.0", "raw": "2021-12-02 17:54:35,002 | Failed at Play [deploy_flatcar_ova] ************************\n2021-12-02 17:54:35,002 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Regression_Flatcar_OVA/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping\n2021-12-02 17:55:21,002 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Flatcar_OVA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_flatcar_ova", "category": "ping_issue", "processed": "timestamp failed at play deploy flatcar ova timestamp task try to ping ip fatal localhost failed non zero return code when ping timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy flatcar ova", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1353, "name": "__Ansible_Regression_Ubuntu_21_10_Server_ISO-32_logs_failed_tasks_log.0", "raw": "2021-12-06 10:21:24,006 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2021-12-06 10:21:24,006 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping\n2021-12-06 10:22:38,006 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "ping_issue", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task try to ping ip fatal localhost failed non zero return code when ping timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1354, "name": "__Ansible_Regression_RHEL_9_x-15_logs_failed_tasks_log.0", "raw": "2021-12-02 09:30:45,002 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-02 09:30:45,002 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.132.7.1', '10.142.7.1', '10.128.242.2'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item dns servers success is false vm dns servers are ip address ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1355, "name": "__Ansible_Regression_RHEL_9_x-20_logs_failed_tasks_log.0", "raw": "2021-12-07 07:28:16,007 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-07 07:28:16,007 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.162.204.1', '10.166.1.1'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['nimbus.eng.vmware.com', 'eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item dns servers success is false vm dns servers are ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are nimbus eng vmware com eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1356, "name": "__Ansible_Regression_Ubuntu_21_10_Server_OVA-13_logs_failed_tasks_log.0", "raw": "2021-12-03 07:54:22,003 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-03 07:54:22,003 | TASK [Assert cloud-init guest customization checks all PASS] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=dns_servers_success is False) => [\"VM DNS servers are ['10.195.12.31', '10.172.40.1'], not expected DNS servers ['10.10.1.1', '10.10.1.2']\"] and dns_servers_success is False\nfailed: [localhost] => (item=dns_suffix_success is False) => [\"VM DNS domain search domains are  ['eng.vmware.com', 'nimbus.eng.vmware.com', 'vmware.com'] not expected search domains ['test.com', 'gosc.test.com']\"] and dns_suffix_success is False", "category": "dns_not_expect", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task assert cloud init guest customization checks all pass failed localhost item dns servers success is false vm dns servers are ip address ip address not expected dns servers ip address ip address and dns servers success is false failed localhost item dns suffix success is false vm dns domain search domains are eng vmware com nimbus eng vmware com vmware com not expected search domains test com go sc test com and dns suffix success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1370, "name": "__Ansible_Regression_RHEL_8_x-14_logs_failed_tasks_log.0", "raw": "2021-12-01 12:11:42,001 | Failed at Play [ovt_verify_install] ************************\n2021-12-01 12:11:42,001 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm'] *********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Unable to retrieve the current working directory: 5 (Input/output error). Check if the directory has been deleted or unmounted. ", "category": "retrieve_current_dir", "processed": "timestamp failed at play ovt verify install timestamp task create snapshot base snapshot on test vm fatal localhost failed unable to retrieve the current working directory number input output error check if the directory has been deleted or un mounted", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1380, "name": "__Ansible_Autoinstall_Windows_11_64-27_logs_failed_tasks_log.0", "raw": "2021-12-07 01:54:01,007 | Failed at Play [secureboot_enable_disable] *****************\n2021-12-07 01:54:01,007 | TASK [Wait for VM power status to 'poweredOff'] ************\ntask path: /home/worker/workspace/Ansible_Autoinstall_Windows_11_64/ansible-vsphere-gos-validation/common/vm_wait_power_state.yml:11\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "failed_hardware_config_only", "processed": "timestamp failed at play secure boot enable disable timestamp task wait for vm power status to powered off fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1357, "name": "__Ansible_Regression_RHEL_7_x-7_logs_failed_tasks_log.0", "raw": "2021-11-25 12:08:26,025 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2021-11-25 12:08:26,025 | TASK [Create a new VM 'test_vm' on server '10.186.62.44'] **\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_7.x/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : A component of the virtual machine is not accessible on the host.\n2021-11-25 12:08:57,025 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_RHEL_7.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "component_not_accessible", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task create a new vm test vm on server ip address fatal localhost failed failed to create a virtual machine a component of the virtual machine is not accessible on the host timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1358, "name": "__Ansible_Regression_SLES_15_x-6_logs_failed_tasks_log.0", "raw": "2021-12-02 19:26:38,002 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-02 19:26:38,002 | TASK [Check service 'cloud-config' is enabled] *************\ntask path: /home/worker/workspace/Ansible_Regression_SLES_15.x/ansible-vsphere-gos-validation/linux/utils/check_service_status.yml:55\nfatal: [localhost]: FAILED! => Serivce 'cloud-config' is not enabled", "category": "cloud_config", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task check service cloud configuration is enabled fatal localhost failed ser i vc e cloud configuration is not enabled", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1359, "name": "__Ansible_Cycle_Windows_10_64-5_logs_failed_tasks_log.1", "raw": "2021-11-30 11:32:27,030 | Failed at Play [memory_hot_add_basic] **********************\n2021-11-30 11:32:27,030 | TASK [Set VM power state to 'shutdown-guest'] **************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => Timeout while waiting for VM power off.\n2021-11-30 11:32:43,030 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "timeout_poweroff", "processed": "timestamp failed at play memory hot add basic timestamp task set vm power state to shutdown guest fatal localhost failed timeout while waiting for vm power off timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1360, "name": "__Ansible_exclude_Regression_CentOS_8_4-350_logs_failed_tasks_log.0", "raw": "2021-09-08 06:27:05,008 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-09-08 06:27:05,008 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /root/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:54\nfailed: [localhost] => (item=gosc_log_success is False) => perl guest customization with dhcp IP failed on: {'key': 'gosc_log_success', 'value': False} and gosc_log_success is False", "category": "static_ip_failed_on", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item go sc log success is false perl guest customization with dhcp ip failed on key go sc log success value false and go sc log success is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1361, "name": "__Ansible_exclude_Regression_CentOS_8_4-350_logs_failed_tasks_log.1", "raw": "2021-09-08 06:35:15,008 | Failed at Play [gosc_perl_staticip] ************************\n2021-09-08 06:35:15,008 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /root/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:54\nfailed: [localhost] => (item=gosc_log_success is False) => perl guest customization with static IP failed on: {'key': 'gosc_log_success', 'value': False} and gosc_log_success is False", "category": "static_ip_failed_on", "processed": "timestamp failed at play go sc perl static ip timestamp task assert perl guest customization checks all pass failed localhost item go sc log success is false perl guest customization with static ip failed on key go sc log success value false and go sc log success is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1362, "name": "__Ansible_Regression_Ubuntu_21_10_Server_OVA-17_logs_failed_tasks_log.0", "raw": "2021-12-08 05:01:26,008 | Failed at Play [deploy_ova] ********************************\n2021-12-08 05:01:26,008 | TASK [Deploy VM from ovf template] *************************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/common/ovf_deploy.yml:4\nexception in /vmware_deploy_ovf.py when run in /request.py when do_open\nfatal: [localhost]: FAILED! => <urlopen error The write operation timed out> Problem validating OVF import spec: Line 128: No space left for device '9' on parent controller '3'.\n2021-12-08 05:02:02,008 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_ova", "category": "deploy_ovf_request_error", "processed": "timestamp failed at play deploy ova timestamp task deploy vm from ovf template exception in vmware deploy ovf python when run in request python when do open fatal localhost failed url open error the write operation timed out problem validating ovf import spec line number no space left for device number on parent controller number timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy ova", "solution": "deepdive", "target": "nimbus", "version": 202205240000}, {"id": 1363, "name": "__Ansible_Windows_Server_LTSC_64bit_70U3_LSILogicSAS_BIOS-1_logs_failed_tasks_log.0", "raw": "2021-12-07 08:58:23,007 | Failed at Play [deploy_vm_bios_lsilogicsas_e1000e] *********\n2021-12-07 08:58:23,007 | TASK [Create a new VM 'test_vm' on server '10.187.105.78'] *\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U3_LSILogicSAS_BIOS/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : A specified parameter was not correct: configSpec.guestId\n2021-12-07 08:58:53,007 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U3_LSILogicSAS_BIOS/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "parameter_not_correct", "processed": "timestamp failed at play deploy vm bios lsi logic sas timestamp task create a new vm test vm on server ip address fatal localhost failed failed to create a virtual machine a specified parameter was not correct configuration spec guest id timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1364, "name": "__Ansible_Windows_Server_LTSC_64bit_70U3_PVSCSI_EFI-2_logs_failed_tasks_log.0", "raw": "2021-12-08 09:20:40,008 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2021-12-08 09:20:40,008 | TASK [Create a new VM 'test_vm' on server '10.182.12.168'] *\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U3_PVSCSI_EFI/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : A specified parameter was not correct: configSpec.guestId\n2021-12-08 09:21:10,008 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U3_PVSCSI_EFI/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "parameter_not_correct", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task create a new vm test vm on server ip address fatal localhost failed failed to create a virtual machine a specified parameter was not correct configuration spec guest id timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1365, "name": "__Ansible_Windows_Server_LTSC_64bit_Main_NVMe_BIOS-2_logs_failed_tasks_log.0", "raw": "2021-12-08 09:23:41,008 | Failed at Play [deploy_vm_bios_nvme_e1000e] ****************\n2021-12-08 09:23:41,008 | TASK [Create a new VM 'test_vm' on server '10.184.107.211'] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_Main_NVMe_BIOS/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : A specified parameter was not correct: configSpec.guestId\n2021-12-08 09:24:13,008 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_Main_NVMe_BIOS/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "parameter_not_correct", "processed": "timestamp failed at play deploy vm bios nvme timestamp task create a new vm test vm on server ip address fatal localhost failed failed to create a virtual machine a specified parameter was not correct configuration spec guest id timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1366, "name": "__Ansible_Photon_4_x_67U3-2_logs_failed_tasks_log.0", "raw": "2021-11-26 11:40:30,026 | Failed at Play [deploy_vmwarephoton_ova] *******************\n2021-11-26 11:40:30,026 | TASK [include_tasks] ***************************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_67U3/ansible-vsphere-gos-validation/linux/deploy_vm/photon/reconfigure_photon_vm.yml:10\nfatal: [localhost]: FAILED! => The conditional check 'guest_id == \"vmwarePhoton64Guest\"' failed. The error was: error while evaluating conditional (guest_id == \"vmwarePhoton64Guest\"): 'guest_id' is undefined\nThe error appears to be in '/home/worker/workspace/Ansible_Photon_4.x_67U3/ansible-vsphere-gos-validation/linux/deploy_vm/photon/reconfigure_photon_vm.yml': line 10, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\nThe offending line appears to be:\n# Photon OS OVA for HWv11 is using other3xlinux64 as guest id\n- include_tasks: ../../../common/vm_set_guest_id.yml\n  ^ here\n2021-11-26 11:41:05,026 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Photon_4.x_67U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vmwarephoton_ova", "category": "script_here_issue", "processed": "timestamp failed at play deploy vmware photon ova timestamp task include tasks fatal localhost failed the conditional check guest id vmware photon number guest failed the error was error while evaluating conditional guest id vmware photon number guest guest id is un defined the error appears to be in home worker workspace ansible photon number x ansible vsphere gos validation linux deploy vm photon re configure photon vm yml line number column number but may be elsewhere in the file depending on the exact syntax problem the offending line appears to be timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vmware photon ova", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1367, "name": "__Ansible_Photon_4_x_67GA-2_logs_failed_tasks_log.0", "raw": "2021-11-26 11:40:02,026 | Failed at Play [deploy_vmwarephoton_ova] *******************\n2021-11-26 11:40:02,026 | TASK [include_tasks] ***************************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/deploy_vm/photon/reconfigure_photon_vm.yml:10\nfatal: [localhost]: FAILED! => The conditional check 'guest_id == \"vmwarePhoton64Guest\"' failed. The error was: error while evaluating conditional (guest_id == \"vmwarePhoton64Guest\"): 'guest_id' is undefined\nThe error appears to be in '/home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/deploy_vm/photon/reconfigure_photon_vm.yml': line 10, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\nThe offending line appears to be:\n# Photon OS OVA for HWv11 is using other3xlinux64 as guest id\n- include_tasks: ../../../common/vm_set_guest_id.yml\n  ^ here\n2021-11-26 11:40:38,026 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vmwarephoton_ova", "category": "script_here_issue", "processed": "timestamp failed at play deploy vmware photon ova timestamp task include tasks fatal localhost failed the conditional check guest id vmware photon number guest failed the error was error while evaluating conditional guest id vmware photon number guest guest id is un defined the error appears to be in home worker workspace ansible photon number x number ga ansible vsphere gos validation linux deploy vm photon re configure photon vm yml line number column number but may be elsewhere in the file depending on the exact syntax problem the offending line appears to be timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vmware photon ova", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1368, "name": "__Ansible_Regression_Windows_10_32-11_logs_failed_tasks_log.0", "raw": "2021-12-03 08:23:32,003 | Failed at Play [deploy_vm_efi_nvme_e1000e] *****************\n2021-12-03 08:23:32,003 | TASK [Guest winrm should be connectable] *******************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_check_winrm.yml:29\nfatal: [localhost]: FAILED! => Guest winrm is not connectable in 1800 seconds.\n2021-12-03 08:24:42,003 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_32/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "guest_winrm", "processed": "timestamp failed at play deploy vm efi nvme timestamp task guest win rm should be connectable fatal localhost failed guest win rm is not connectable in number seconds timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1369, "name": "__Ansible_Autoinstall_Windows_10_32-8_logs_failed_tasks_log.0", "raw": "2021-11-29 06:50:16,029 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2021-11-29 06:50:16,029 | TASK [Guest winrm should be connectable] *******************\ntask path: /home/worker/workspace/Ansible_Autoinstall_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_check_winrm.yml:29\nfatal: [localhost]: FAILED! => Guest winrm is not connectable in 1800 seconds.\n2021-11-29 06:50:52,029 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Autoinstall_Windows_10_32/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "guest_winrm", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task guest win rm should be connectable fatal localhost failed guest win rm is not connectable in number seconds timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1373, "name": "__Ansible_Regression_Windows_Server_LTSC_vNext-22_logs_failed_tasks_log.1", "raw": "2021-12-02 17:46:06,002 | Failed at Play [mouse_driver_vmtools] **********************\n2021-12-02 17:46:06,002 | TASK [Wait for getting VM 'test_vm' IP address on ESXi '10.186.134.230'] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/common/vm_get_ip_esxcli.yml:51\nfatal: [localhost]: UNREACHABLE! => Failed to create temporary directory.In some cases, you may have been able to authenticate and did not have permissions on the target directory. Consider changing the remote tmp path in ansible.cfg to a path rooted in \"/tmp\", for more error information use -vvv. Failed command was: ( umask 77 && mkdir -p \"` echo /vmfs/volumes/datastore2 `\"&& mkdir \"` echo /vmfs/volumes/datastore2/ansible-tmp-1638467165.8364687-9162-114504268753598 `\" && echo ansible-tmp-1638467165.8364687-9162-114504268753598=\"` echo /vmfs/volumes/datastore2/ansible-tmp-1638467165.8364687-9162-114504268753598 `\" ), exited with result 1", "category": "origin", "processed": "timestamp failed at play mouse driver vm tools timestamp task wait for getting vm test vm ip address on esxi ip address fatal localhost un reachable failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo vmfs volumes data store number mkdir echo vmfs volumes data store number ansible tmp hex id number timestamp echo ansible tmp hex id number timestamp echo vmfs volumes data store number ansible tmp hex id number timestamp exited with result number", "solution": "retry", "target": "infra", "version": 202205240000}, {"id": 1374, "name": "__Ansible_Autoinstall_RHEL_8_x-15_logs_failed_tasks_log.0", "raw": "\n\n2021-12-07 02:18:44,007 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2021-12-07 02:18:44,007 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Autoinstall_RHEL_8.x/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.185.240.35:22\n2021-12-07 02:19:25,007 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Autoinstall_RHEL_8.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_vmxnet3\n", "category": "origin", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual vmxnet number", "solution": "deepdive", "target": "targetvm", "version": 202205240000}, {"id": 1375, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-7_logs_failed_tasks_log.1", "raw": "2021-11-30 11:45:19,030 | Failed at Play [check_ip_address] **************************\n2021-11-30 11:45:19,030 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nrequests.exceptions.HTTPError: 500 Server Error:  for url: https://10.191.158.93:5986/wsman\nwinrm.exceptions.WinRMTransportError: Bad HTTP response returned from server. Code 500\nwinrm.exceptions.WinRMError: The WS-Management service cannot process the request because the request contained invalid selectors for the resource.  (extended fault data: Bad HTTP response returned from server. Code 500 at s:Sender and w:InvalidSelectors)\nrequests.exceptions.HTTPError: 500 Server Error:  for url: https://10.191.158.93:5986/wsman\nwinrm.exceptions.WinRMTransportError: Bad HTTP response returned from server. Code 500\nwinrm.exceptions.WinRMError: The WS-Management service cannot process the request because the request contained invalid selectors for the resource.  (extended fault data: Bad HTTP response returned from server. Code 500 at s:Sender and w:InvalidSelectors)\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "origin", "processed": "timestamp failed at play check ip address timestamp task execute powershell command in windows guest requests exceptions http error number server error for url https ip address wsman win rm exceptions win rm transport error bad http response returned from server code number win rm exceptions win rm error the ws management service can not process the request because the request contained invalid selectors for the resource extended fault data bad http response returned from server code number ats sender and w invalid selectors requests exceptions http error number server error for url https ip address wsman win rm exceptions win rm transport error bad http response returned from server code number win rm exceptions win rm error the ws management service can not process the request because the request contained invalid selectors for the resource extended fault data bad http response returned from server code number ats sender and w invalid selectors fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "infra", "version": 202205240000}, {"id": 1376, "name": "__Ansible_Regression_RockyLinux_8_x-2_logs_failed_tasks_log.0", "raw": "2021-11-23 11:02:10,023 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-11-23 11:02:10,023 | TASK [Assert cloud-init guest customization checks all PASS] \ntask path: /home/worker/workspace/Ansible_Regression_RockyLinux_8.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=timezone_success is False) => ['VM timezone is America/Los_Angeles, expected timezone is Europe/Berlin'] and timezone_success is False", "category": "timezone_issue", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task assert cloud init guest customization checks all pass failed localhost item time zone success is false vm time zone is america los angeles expected time zone is europe berlin and time zone success is false", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1377, "name": "__Ansible_Regression_Windows_10_64-9_logs_failed_tasks_log.0", "raw": "2021-11-26 02:54:46,026 | Failed at Play [secureboot_enable_disable] *****************\n2021-11-26 02:54:46,026 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_64/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_vm\n2021-11-26 02:54:49,026 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_64/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "unable_gather_information", "processed": "timestamp failed at play secure boot enable disable timestamp task get specified property info for vm test vm fatal localhost failed unable to gather information for non existing vm test vm timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1379, "name": "__Ansible_Regression_Windows_11_64-15_logs_failed_tasks_log.1", "raw": "2021-12-02 10:22:24,002 | Failed at Play [memory_hot_add_basic] **********************\n2021-12-02 10:22:24,002 | TASK [Wait for VM power status to 'poweredOff'] ************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/common/vm_wait_power_state.yml:11\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "failed_hardware_config_only", "processed": "timestamp failed at play memory hot add basic timestamp task wait for vm power status to powered off fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1381, "name": "__Ansible_Regression_Photon_3_0_ISO-7_logs_failed_tasks_log.0", "raw": "2021-12-03 08:27:26,003 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2021-12-03 08:27:26,003 | TASK [Wait for VMware Tools collecting guest OS fullname] **\ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/common/vm_wait_guest_fullname.yml:17\nfatal: [localhost]: FAILED! => hardware configuration table\n2021-12-03 08:29:03,003 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "failed_hardware_config_only", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task wait for vmware tools collecting guest os full name fatal localhost failed hardware configuration table timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1382, "name": "__Ansible_Cycle_Windows_10_64-6_logs_failed_tasks_log.2", "raw": "2021-11-30 12:28:40,030 | Failed at Play [gosc_sanity_dhcp] **************************\n2021-11-30 12:28:40,030 | TASK [Wait for VM power status to 'poweredOff'] ************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_wait_power_state.yml:11\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "failed_hardware_config_only", "processed": "timestamp failed at play go sc sanity dhcp timestamp task wait for vm power status to powered off fatal localhost failed hardware configuration table", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1383, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-5_logs_failed_tasks_log.0", "raw": "2021-11-30 08:20:40,030 | Failed at Play [check_efi_firmware] ************************\n2021-11-30 08:20:40,030 | TASK [Get firmware type in Windows guest OS] ***************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_get_firmware.yml:5\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play check efi firmware timestamp task get firmware type in windows guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1384, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-5_logs_failed_tasks_log.1", "raw": "2021-11-30 08:22:24,030 | Failed at Play [check_ip_address] **************************\n2021-11-30 08:22:24,030 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => basic: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play check ip address timestamp task execute powershell command in windows guest fatal localhost un reachable basic connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1412, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_65U3-6_logs_failed_tasks_log.2", "raw": "2022-01-20 11:10:49,020 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-20 11:10:49,020 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:89\nfatal: [localhost]: FAILED! => ['Not found GOSC completed state keyword in vmware.log']", "category": "gosc_keyword_not_found", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task gos customization failed fatal localhost failed not found go sc completed state keyword in vmware log", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1385, "name": "__Ansible_Cycle_Windows_10_64-5_logs_failed_tasks_log.0", "raw": "2021-11-30 10:10:50,030 | Failed at Play [sata_vhba_device_ops] **********************\n2021-11-30 10:10:50,030 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play sata v hba device ops timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1386, "name": "__Ansible_Cycle_Windows_11_64-7_logs_failed_tasks_log.1", "raw": "2021-12-05 15:45:59,005 | Failed at Play [cpu_multicores_per_socket] *****************\n2021-12-05 15:45:59,005 | TASK [Shutdown guest OS inside OS] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_shutdown_restart.yml:8\nfatal: [localhost]: UNREACHABLE! => basic: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "connectionreset", "processed": "timestamp failed at play cpu multi cores per socket timestamp task shutdown guest os inside os fatal localhost un reachable basic connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1387, "name": "__Ansible_Cycle_Windows_11_64-7_logs_failed_tasks_log.0", "raw": "2021-12-05 14:21:41,005 | Failed at Play [nvme_vhba_device_ops] **********************\n2021-12-05 14:21:41,005 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play nvme v hba device ops timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1388, "name": "__Ansible_Regression_Windows_Server_LTSC_vNext-10_logs_failed_tasks_log.5", "raw": "2021-11-25 13:41:31,025 | Failed at Play [wintools_uninstall_verify] *****************\n2021-11-25 13:41:31,025 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play win tools un install verify timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1389, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-7_logs_failed_tasks_log.3", "raw": "2021-11-30 13:21:42,030 | Failed at Play [check_quiesce_snapshot] ********************\n2021-11-30 13:21:42,030 | TASK [Copy file from local to Windows guest] ***************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_copy_file_from_local.yml:9\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play check quiesce snapshot timestamp task copy file from local to windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1390, "name": "__Ansible_Regression_Windows_Server_LTSC_vNext-10_logs_failed_tasks_log.2", "raw": "2021-11-25 12:18:12,025 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2021-11-25 12:18:12,025 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1413, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_65U3-6_logs_failed_tasks_log.3", "raw": "2022-01-20 11:36:17,020 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-20 11:36:17,020 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:89\nfatal: [localhost]: FAILED! => ['Not found GOSC completed state keyword in vmware.log']", "category": "gosc_keyword_not_found", "processed": "timestamp failed at play go sc cloud init static ip timestamp task gos customization failed fatal localhost failed not found go sc completed state keyword in vmware log", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1391, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-7_logs_failed_tasks_log.2", "raw": "2021-11-30 11:51:21,030 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2021-11-30 11:51:21,030 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play para virtual v hba device ops timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1392, "name": "__Ansible_Regression_Windows_Server_LTSC_vNext-24_logs_failed_tasks_log.1", "raw": "2021-12-06 11:34:39,006 | Failed at Play [memory_hot_add_basic] **********************\n2021-12-06 11:34:39,006 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play memory hot add basic timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1427, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_67U3-4_logs_failed_tasks_log.0", "raw": "2021-12-20 14:54:08,020 | Failed at Play [ovt_verify_install] ************************\n2021-12-20 14:54:08,020 | TASK [Add zypper repository SLED-15.4-dvd-cdrom] ***********\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_67U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.168.123.242]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd cdrom fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1393, "name": "__Ansible_Autoinstall_Windows_11_64-10_logs_failed_tasks_log.0", "raw": "2021-11-30 10:24:07,030 | Failed at Play [secureboot_enable_disable] *****************\n2021-11-30 10:24:07,030 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Autoinstall_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.\n", "category": "connectionreset", "processed": "timestamp failed at play secure boot enable disable timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1394, "name": "__Ansible_Cycle_Windows_10_64-6_logs_failed_tasks_log.0", "raw": "2021-11-30 11:43:17,030 | Failed at Play [sata_vhba_device_ops] **********************\n2021-11-30 11:43:17,030 | TASK [Get VMware tools version and build number in guest OS] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_get_vmtools_version_build.yml:13\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play sata v hba device ops timestamp task get vmware tools version and build number in guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1395, "name": "__Ansible_Cycle_Windows_10_64-6_logs_failed_tasks_log.1", "raw": "2021-11-30 11:45:22,030 | Failed at Play [memory_hot_add_basic] **********************\n2021-11-30 11:45:22,030 | TASK [Get VMware tools version and build number in guest OS] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_get_vmtools_version_build.yml:13\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play memory hot add basic timestamp task get vmware tools version and build number in guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1396, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-6_logs_failed_tasks_log.0", "raw": "2021-11-30 10:42:50,030 | Failed at Play [check_ip_address] **************************\n2021-11-30 10:42:50,030 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play check ip address timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1397, "name": "__Ansible_Regression_Windows_Server_LTSC_vNext-26_logs_failed_tasks_log.0", "raw": "2021-12-08 09:40:54,008 | Failed at Play [check_quiesce_snapshot] ********************\n2021-12-08 09:40:54,008 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play check quiesce snapshot timestamp task execute powershell command in windows guest connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1398, "name": "__Ansible_Cycle_Windows_Server_LTSC_vNext-7_logs_failed_tasks_log.0", "raw": "2021-11-30 11:41:47,030 | Failed at Play [check_efi_firmware] ************************\n2021-11-30 11:41:47,030 | TASK [Get VMware tools version and build number in guest OS] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_get_vmtools_version_build.yml:13\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play check efi firmware timestamp task get vmware tools version and build number in guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1399, "name": "__Ansible_Cycle_Windows_10_64-7_logs_failed_tasks_log.0", "raw": "2021-12-05 13:40:41,005 | Failed at Play [check_os_fullname] *************************\n2021-12-05 13:40:41,005 | TASK [Get OS name in Windows guest OS] *********************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_get_fullname.yml:5\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play check os full name timestamp task get os name in windows guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1400, "name": "__Ansible_Cycle_Windows_11_64-10_logs_failed_tasks_log.1", "raw": "2021-12-06 08:57:00,006 | Failed at Play [check_quiesce_snapshot] ********************\n2021-12-06 08:57:00,006 | TASK [Get relative time value from 01/01/1970 in Windows guest OS] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_get_time.yml:5\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "connectionreset", "processed": "timestamp failed at play check quiesce snapshot timestamp task get relative time value from number in windows guest os connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1403, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-85_logs_failed_tasks_log.0", "raw": "2022-01-14 16:21:16,014 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2022-01-14 16:21:16,014 | TASK [Upload local file to ESXi datastore] *****************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/esxi_upload_datastore_file.yml:10\nexception in /vsphere_copy.py when main in /request.py when http_error_default\nfatal: [localhost]: FAILED! => HTTP Error 404: Not Found\n2022-01-14 16:21:23,014 | TASK [Set VM power state to 'powered-off'] *****************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => Unable to communicate with the remote host, since it is disconnected.", "category": "unable_to_communicate", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task upload local file to esxi data store exception in vsphere copy python when main in request python when http error default fatal localhost failed http error number not found timestamp task set vm power state to powered off fatal localhost failed unable to communicate with the remote host since it is disconnected", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1404, "name": "ansible_gosv_logs_FAILURE_Ansible_Photon_4_x_67GA-16_logs_failed_tasks_log.0", "raw": "2022-01-21 04:43:18,021 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-21 04:43:18,021 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM DHCP IPv4 gateway is '', expected IPv4 gateway should not be empty\"]", "category": "gateway_empty", "processed": "timestamp failed at play go sc perl dhcp timestamp task gos customization failed fatal localhost failed vm dhcp ip v number gateway is expected ip v number gateway should not be empty", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1405, "name": "ansible_gosv_logs_FAILURE_Ansible_Photon_4_x_67GA-16_logs_failed_tasks_log.2", "raw": "2022-01-21 04:54:29,021 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-21 04:54:29,021 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM DHCP IPv4 gateway is '', expected IPv4 gateway should not be empty\"]", "category": "gateway_empty", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task gos customization failed fatal localhost failed vm dhcp ip v number gateway is expected ip v number gateway should not be empty", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1406, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-5_logs_failed_tasks_log.0", "raw": "2021-12-10 14:54:27,010 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-10 14:54:27,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=gosc_state_keyword_found is False) => ['Not found GOSC completed state keyword in vmware.log'] and gosc_state_keyword_found is False\n", "category": "gosc_keyword_not_found", "processed": "timestamp failed at play go sc perl dhcp timestamp task assert perl guest customization checks all pass failed localhost item go sc state keyword found is false not found go sc completed state keyword in vmware log and go sc state keyword found is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1407, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-5_logs_failed_tasks_log.1", "raw": "2021-12-10 15:19:08,010 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-10 15:19:08,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=gosc_state_keyword_found is False) => ['Not found GOSC completed state keyword in vmware.log'] and gosc_state_keyword_found is False", "category": "gosc_keyword_not_found", "processed": "timestamp failed at play go sc perl static ip timestamp task assert perl guest customization checks all pass failed localhost item go sc state keyword found is false not found go sc completed state keyword in vmware log and go sc state keyword found is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1408, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-5_logs_failed_tasks_log.2", "raw": "2021-12-10 15:45:07,010 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-10 15:45:07,010 | TASK [Assert cloud-init guest customization checks all PASS] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=gosc_state_keyword_found is False) => ['Not found GOSC completed state keyword in vmware.log'] and gosc_state_keyword_found is False", "category": "gosc_keyword_not_found", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task assert cloud init guest customization checks all pass failed localhost item go sc state keyword found is false not found go sc completed state keyword in vmware log and go sc state keyword found is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1409, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-5_logs_failed_tasks_log.3", "raw": "2021-12-10 16:10:37,010 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-10 16:10:37,010 | TASK [Assert cloud-init guest customization checks all PASS] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=gosc_state_keyword_found is False) => ['Not found GOSC completed state keyword in vmware.log'] and gosc_state_keyword_found is False", "category": "gosc_keyword_not_found", "processed": "timestamp failed at play go sc cloud init static ip timestamp task assert cloud init guest customization checks all pass failed localhost item go sc state keyword found is false not found go sc completed state keyword in vmware log and go sc state keyword found is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1410, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_65U3-6_logs_failed_tasks_log.0", "raw": "2022-01-20 10:21:26,020 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-20 10:21:26,020 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:89\nfatal: [localhost]: FAILED! => ['Not found GOSC completed state keyword in vmware.log']", "category": "gosc_keyword_not_found", "processed": "timestamp failed at play go sc perl dhcp timestamp task gos customization failed fatal localhost failed not found go sc completed state keyword in vmware log", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1411, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_65U3-6_logs_failed_tasks_log.1", "raw": "2022-01-20 10:45:42,020 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-20 10:45:42,020 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:89\nfatal: [localhost]: FAILED! => ['Not found GOSC completed state keyword in vmware.log']", "category": "gosc_keyword_not_found", "processed": "timestamp failed at play go sc perl static ip timestamp task gos customization failed fatal localhost failed not found go sc completed state keyword in vmware log", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1414, "name": "ansible_gosv_logs_ABORTED_Ansible_Ubuntu_Desktop_ISO_70GA-8_logs_failed_tasks_log.0", "raw": "2021-12-17 11:48:05,017 | Failed at Play [ovt_verify_install] ************************\n2021-12-17 11:48:05,017 | TASK [Set VM power state to 'powered-on'] ******************\ntask path: /home/worker/workspace/Ansible_Ubuntu_Desktop_ISO_70GA/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => The serial port output file \"serial.log\" already exists. Do you want to replace it with new content or append new content to the end of the file?", "category": "file_already_exist", "processed": "timestamp failed at play ovt verify install timestamp task set vm power state to powered on fatal localhost failed the serial port output file serial log already exists do you want to replace it with new content or append new content to the end of the file", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1415, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-11_logs_failed_tasks_log.0", "raw": "2022-01-24 08:20:46,024 | Failed at Play [deploy_vm_bios_nvme_e1000e] ****************\n2022-01-24 08:20:46,024 | TASK [Set VM power state to 'powered-on'] ******************\ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => The serial port output file \"serial-20220124075631.log\" already exists. Do you want to replace it with new content or append new content to the end of the file?\n2022-01-24 08:26:32,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_nvme_e1000e", "category": "file_already_exist", "processed": "timestamp failed at play deploy vm bios nvme timestamp task set vm power state to powered on fatal localhost failed the serial port output file serial timestamp log already exists do you want to replace it with new content or append new content to the end of the file timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1424, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-3_logs_failed_tasks_log.0", "raw": "2021-12-20 11:27:13,020 | Failed at Play [ovt_verify_install] ************************\n2021-12-20 11:27:13,020 | TASK [Add zypper repository SLED-15.4-dvd-Module-Live-Patching] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.184.94.66]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module live patching fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1416, "name": "ansible_gosv_logs_FAILURE_Ansible_OracleLinux_8_x_67U1-11_logs_failed_tasks_log.0", "raw": "2022-01-24 08:21:26,024 | Failed at Play [deploy_vm_efi_lsilogic_e1000e] *************\n2022-01-24 08:21:26,024 | TASK [Set VM power state to 'powered-on'] ******************\ntask path: /home/worker/workspace/Ansible_OracleLinux_8.x_67U1/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => The serial port output file \"serial-20220124074909.log\" already exists. Do you want to replace it with new content or append new content to the end of the file?\n2022-01-24 08:27:38,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_OracleLinux_8.x_67U1/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_lsilogic_e1000e", "category": "file_already_exist", "processed": "timestamp failed at play deploy vm efi lsi logic timestamp task set vm power state to powered on fatal localhost failed the serial port output file serial timestamp log already exists do you want to replace it with new content or append new content to the end of the file timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi lsi logic e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1417, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_65U3-11_logs_failed_tasks_log.0", "raw": "2022-01-24 09:38:34,024 | Failed at Play [deploy_vm_efi_sata_e1000e] *****************\n2022-01-24 09:38:34,024 | TASK [Set VM power state to 'powered-on'] ******************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => The serial port output file \"serial-20220124091447.log\" already exists. Do you want to replace it with new content or append new content to the end of the file?\n2022-01-24 09:43:53,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_sata_e1000e", "category": "file_already_exist", "processed": "timestamp failed at play deploy vm efi sata timestamp task set vm power state to powered on fatal localhost failed the serial port output file serial timestamp log already exists do you want to replace it with new content or append new content to the end of the file timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi sata e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1418, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Windows_Server_LTSC_vNext-30_logs_failed_tasks_log.2", "raw": "2022-01-04 14:36:57,004 | Failed at Play [check_quiesce_snapshot] ********************\n2022-01-04 14:36:57,004 | TASK [Check specified file status until it exists in Windows guest] \ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/utils/win_wait_file_exist.yml:8\nfatal: [localhost -> 10.185.248.27]: FAILED! => {\n    \"attempts\": 40,\n    \"changed\": false,\n    \"invocation\": {\n        \"module_args\": {\n            \"checksum_algorithm\": \"sha1\",\n            \"follow\": false,\n            \"get_checksum\": true,\n            \"path\": \"C:\\\\test_pre_freeze.txt\"\n        }\n    },\n    \"stat\": {\n        \"exists\": false\n    }\n}\n2022-01-04 14:37:26,004 | TASK [Get vmware.log from ESXi host] ***********************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/check_quiesce_snapshot/collect_vss_logs.yml:5\nfatal: [localhost]: FAILED! => failed to transfer file to /vmfs/volumes/datastore2/test_vm//vmware.log /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/logs/test_vm/2022-01-04-12-12-28/check_quiesce_snapshot/vmware.log:\ndd: can't open '/vmfs/volumes/datastore2/test_vm//vmware.log': Operation not permitted", "category": "operation_not_permitted", "processed": "timestamp failed at play check quiesce snapshot timestamp task check specified file status until it exists in windows guest fatal localhost ip address failed timestamp task get vmware log from esxi host fatal localhost failed failed to transfer file to vmfs volumes data store number test vm vmware log home worker workspace ansible regression windows server lts c v next ansible vsphere gos validation logs test vm timestamp number check quiesce snapshot vmware log dd can t open vmfs volumes data store number test vm vmware log operation not permitted", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1419, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-12_logs_failed_tasks_log.0", "raw": "2021-12-21 17:02:39,021 | Failed at Play [ovt_verify_install] ************************\n2021-12-21 17:02:39,021 | TASK [Add zypper repository SLED-15.4-dvd-Module-Web-Scripting] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:97\nfatal: [localhost -> 10.186.140.235]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module web scripting fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1420, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-13_logs_failed_tasks_log.0", "raw": "2021-12-22 03:43:25,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 03:43:25,022 | TASK [Add zypper repository SLED-15.4-dvd-Module-SAP-Applications] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.184.79.142]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module sap applications fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1421, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-14_logs_failed_tasks_log.0", "raw": "2021-12-22 06:08:35,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 06:08:35,022 | TASK [Add zypper repository SLED-15.4-dvd-Module-Server-Applications] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.184.79.142]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module server applications fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1422, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-16_logs_failed_tasks_log.0", "raw": "2021-12-22 11:08:38,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 11:08:38,022 | TASK [Add zypper repository SLED-15.4-dvd-Module-HPC] ******\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.184.72.187]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module h pc fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1423, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-18_logs_failed_tasks_log.0", "raw": "2021-12-22 16:26:49,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 16:26:49,022 | TASK [Uninstall package on SLED 15.4] **********************\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nfatal: [localhost -> 10.186.105.31]: FAILED! => Zypper run command failed with return code 7. when /usr/bin/zypper", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task un install package on sled number fatal localhost ip address failed zypper run command failed with return code number when user bin zypper", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1425, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-5_logs_failed_tasks_log.0", "raw": "2021-12-21 11:46:50,021 | Failed at Play [ovt_verify_install] ************************\n2021-12-21 11:46:50,021 | TASK [Add zypper repository SLED-15.4-dvd-Module-Legacy] ***\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.185.232.155]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module legacy fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1426, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_67GA-10_logs_failed_tasks_log.0", "raw": "2021-12-22 11:33:21,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 11:33:21,022 | TASK [Add zypper repository SLED-15.4-dvd-Module-Basesystem] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_67GA/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.182.130.171]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module base system fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1428, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70GA-11_logs_failed_tasks_log.0", "raw": "2021-12-22 11:51:32,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 11:51:32,022 | TASK [Add zypper repository SLED-15.4-dvd-Module-Public-Cloud] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70GA/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.78.228.205]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module public cloud fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1429, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70GA-12_logs_failed_tasks_log.0", "raw": "2021-12-22 12:21:14,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 12:21:14,022 | TASK [Add zypper repository SLED-15.4-dvd-Module-Transactional-Server] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70GA/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.78.228.205]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module transactional server fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1430, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70GA-4_logs_failed_tasks_log.0", "raw": "2021-12-20 14:54:10,020 | Failed at Play [ovt_verify_install] ************************\n2021-12-20 14:54:10,020 | TASK [Add zypper repository SLED-15.4-dvd-Product-SLES] ****\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70GA/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.78.85.182]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd product sles fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1431, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70U1-3_logs_failed_tasks_log.0", "raw": "2021-12-20 11:24:57,020 | Failed at Play [ovt_verify_install] ************************\n2021-12-20 11:24:57,020 | TASK [Add zypper repository SLED-15.4-dvd-Module-Desktop-Applications] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70U1/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.168.173.121]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module desktop applications fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1432, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70U3-12_logs_failed_tasks_log.0", "raw": "2021-12-21 13:19:19,021 | Failed at Play [ovt_verify_install] ************************\n2021-12-21 13:19:19,021 | TASK [Add zypper repository SLED-15.4-dvd-Product-SLED] ****\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.182.8.249]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd product sled fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1433, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70U3-17_logs_failed_tasks_log.0", "raw": "2021-12-22 12:02:35,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 12:02:35,022 | TASK [Add zypper repository SLED-15.4-dvd-Product-SLES_SAP] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.187.117.192]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd product sles sap fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1434, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70U3-8_logs_failed_tasks_log.0", "raw": "2021-12-20 12:13:07,020 | Failed at Play [ovt_verify_install] ************************\n2021-12-20 12:13:07,020 | TASK [Add zypper repository SLED-15.4-dvd-Product-WE] ******\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70U3/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nfatal: [localhost -> 10.184.84.180]: FAILED! => Zypper failed with rc 7", "category": "zypper_failed", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd product we fatal localhost ip address failed zypper failed with rc number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1457, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_7_x-20_logs_failed_tasks_log.0", "raw": "2021-12-21 11:34:52,021 | Failed at Play [env_setup] *********************************\n2021-12-21 11:34:52,021 | TASK [Assert VM network adapters are in different port groups] \ntask path: /home/worker/workspace/Ansible_Regression_RHEL_7.x/ansible-vsphere-gos-validation/env_setup/check_vm_settings.yml:23\nfatal: [localhost]: FAILED! => Two or more VM network adapters are in same port group, which is not supported.\n", "category": "same_port_group", "processed": "timestamp failed at play environment setup timestamp task assert vm network adapters are in different port groups fatal localhost failed two or more vm network adapters are in same port group which is not supported", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1435, "name": "ansible_gosv_logs_FAILURE_Ansible_Photon_4_x_67GA-25_logs_failed_tasks_log.0", "raw": "2022-01-24 08:23:55,024 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-24 08:23:55,024 | TASK [Get guest FQDN] **************************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/guest_customization/check_hostname_and_domain.yml:31\nfatal: [localhost]: FAILED! => An unhandled exception occurred while running the lookup plugin 'file'. Error was a <class 'ansible.errors.AnsibleError'>, original message: could not locate file in lookup: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/logs/test_vm/2022-01-24-08-18-37/gosc_perl_dhcphostname_f.txt. could not locate file in lookup: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/logs/test_vm/2022-01-24-08-18-37/gosc_perl_dhcphostname_f.txt\n2022-01-24 08:24:46,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case gosc_perl_dhcp", "category": "unhandled_exception_occurred", "processed": "timestamp failed at play go sc perl dhcp timestamp task get guest fqdn fatal localhost failed an un handled exception occurred while running the lookup plugin file error was a class ansible errors ansible error original message could not locate file in lookup home worker workspace ansible photon number x number ga ansible vsphere gos validation logs test vm timestamp number go sc perl dhcp hostname f text could not locate file in lookup home worker workspace ansible photon number x number ga ansible vsphere gos validation logs test vm timestamp number go sc perl dhcp hostname f text timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case go sc perl dhcp", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1449, "name": "ansible_gosv_logs_FAILURE_Ansible_Flatcar_67GA-10_logs_failed_tasks_log.1", "raw": "2021-12-20 06:00:07,020 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2021-12-20 06:00:07,020 | TASK [Wait for device list changed] ************************\ntask path: /home/worker/workspace/Ansible_Flatcar_67GA/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:97\nfatal: [localhost -> 10.187.140.58]: FAILED! =>  when lsblk", "category": "lsblk", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task wait for device list changed fatal localhost ip address failed when ls blk", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1436, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_9_x-26_logs_failed_tasks_log.2", "raw": "2021-12-21 18:46:10,021 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-21 18:46:10,021 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.184.103.233]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, 1, 'n', 'on', 't', 'true', 'f', '0', 'false', 'y', 'off', '1', 'no', 'yes'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number n on t true f number false y off number no yes", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1437, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_9_x-26_logs_failed_tasks_log.3", "raw": "2021-12-21 18:48:29,021 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-21 18:48:29,021 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.184.103.233]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 'f', 1, 'y', 0, 'on', 'off', 'true', 'false', 't', 'n', '1', 'no', '0', 'yes'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init static ip timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include f number y number on off true false t n number no number yes", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1438, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_OVA-24_logs_failed_tasks_log.0", "raw": "2021-12-21 16:57:30,021 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-21 16:57:30,021 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_OVA/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.187.124.234]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, 1, 'yes', 'on', '0', 'no', 't', 'true', '1', 'n', 'off', 'false', 'y', 'f'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number yes on number no t true number n off false y f", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1454, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_70U2-2_logs_failed_tasks_log.0", "raw": "2021-12-09 09:00:21,009 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-09 09:00:21,009 | TASK [Customize Linux guest OS] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_70U2/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization failed. For detailed information see warnings Waiting for customization start event timed out.", "category": "waiting_custom_timeout", "processed": "timestamp failed at play go sc perl dhcp timestamp task customize linux guest os fatal localhost failed customization failed for detailed information see warnings waiting for customization start event timed out", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1439, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_65U3-18_logs_failed_tasks_log.3", "raw": "2021-12-22 05:38:26,022 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-22 05:38:26,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.78.125.176]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, 1, 'on', 't', 'true', 'false', 'yes', 'no', 'f', '0', 'y', 'n', '1', 'off'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number on t true false yes no f number y n number off", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1440, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_65U3-18_logs_failed_tasks_log.4", "raw": "2021-12-22 05:40:56,022 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-22 05:40:56,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.78.125.176]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 'on', 1, 0, 'f', 'y', 'n', '1', 'yes', 'no', 'off', 't', 'true', 'false', '0'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init static ip timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include on number f y n number yes no off t true false number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1441, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_67GA-19_logs_failed_tasks_log.2", "raw": "2021-12-22 04:19:32,022 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-22 04:19:32,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_67GA/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.168.123.112]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, 1, 'false', 'on', 'yes', 't', 'true', 'f', 'no', 'n', 'off', '0', 'y', '1'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number false on yes t true f no n off number y number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1442, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_67GA-19_logs_failed_tasks_log.3", "raw": "2021-12-22 04:21:01,022 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-22 04:21:01,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_67GA/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.168.123.112]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, 1, 'on', 'yes', 'y', 'true', 'false', 'off', 'no', 'f', 'n', '1', '0', 't'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init static ip timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number on yes y true false off no f n number t", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1443, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_67U3-7_logs_failed_tasks_log.0", "raw": "2021-12-22 04:12:30,022 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-22 04:12:30,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_67U3/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.168.200.136]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 'n', 1, 0, 'true', 'yes', 't', 'false', 'f', 'off', '1', 'no', 'on', '0', 'y'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include n number true yes t false f off number no on number y", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1444, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_67U3-7_logs_failed_tasks_log.1", "raw": "2021-12-22 04:14:05,022 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-22 04:14:05,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_67U3/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.168.200.136]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, 1, 'f', 'n', 'off', 'false', 'true', 'no', 'on', '0', 't', 'y', 'yes', '1'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init static ip timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number f n off false true no on number t y yes number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1445, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_70GA-7_logs_failed_tasks_log.0", "raw": "2021-12-22 04:26:47,022 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-22 04:26:47,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_70GA/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.78.186.101]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 'n', 't', 1, 0, 'true', 'yes', 'no', '0', 'false', 'on', 'y', '1', 'off', 'f'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include n t number true yes no number false on y number off f", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1446, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_70GA-7_logs_failed_tasks_log.1", "raw": "2021-12-22 04:28:17,022 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-22 04:28:17,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_70GA/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.78.186.101]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, '1', 1, '0', 'f', 'yes', 'no', 'n', 'true', 'on', 'false', 't', 'y', 'off'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init static ip timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number f yes no n true on false t y off", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1447, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_70U3-10_logs_failed_tasks_log.0", "raw": "2021-12-22 04:19:24,022 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-22 04:19:24,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_70U3/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.168.191.122]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, 1, 'f', 'on', '0', 'true', '1', 'yes', 'y', 'false', 'off', 'n', 'no', 't'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number f on number true number yes y false off n no t", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1448, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_70U3-10_logs_failed_tasks_log.1", "raw": "2021-12-22 04:20:28,022 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-22 04:20:28,022 | TASK [Update service cloud-init-local, enabled: True, state: started] \ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_70U3/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.168.191.122]: FAILED! => argument 'enabled' is of type <class 'str'> and we were unable to convert to bool: The value 'enabled' is not a valid boolean.  Valid booleans include: 0, 1, 'n', '1', 'f', 'false', 'on', 't', 'yes', '0', 'y', 'no', 'off', 'true'", "category": "value_is_not_valid", "processed": "timestamp failed at play go sc cloud init static ip timestamp task update service cloud init local enabled true state started fatal localhost ip address failed argument enabled is of type class string and we were unable to convert to bool the value enabled is not a valid boolean valid booleans include number n number f false on t yes number y no off true", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1450, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_70U3_LSILogicSAS_EFI-12_logs_failed_tasks_log.0", "raw": "2021-12-24 02:19:43,024 | Failed at Play [check_os_fullname] *************************\n2021-12-24 02:19:43,024 | TASK [Verify guest fullname in guest info is expected] *****\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_70U3_LSILogicSAS_EFI/ansible-vsphere-gos-validation/windows/check_os_fullname/check_os_fullname.yml:66\nfatal: [localhost]: FAILED! => Guest fullname in guest info: Windows 11 Enterprise, 64-bit (Build 22000.194), is not the same as expected one: Microsoft Windows 10 (64-bit).", "category": "not_the_same_one", "processed": "timestamp failed at play check os full name timestamp task verify guest full name in guest info is expected fatal localhost failed guest full name in guest info windows number enterprise number b it build number is not the same as expected one microsoft windows number b it", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1451, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_Server_LTSC_64bit_Main_LSILogicSAS_EFI-13_logs_failed_tasks_log.0", "raw": "2022-01-20 08:18:13,020 | Failed at Play [check_os_fullname] *************************\n2022-01-20 08:18:13,020 | TASK [Verify guest fullname in guest info is expected] *****\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_Main_LSILogicSAS_EFI/ansible-vsphere-gos-validation/windows/check_os_fullname/check_os_fullname.yml:66\nfatal: [localhost]: FAILED! => Guest fullname in guest info: Microsoft Windows Server 2022 (64-bit), is not the same as expected one: .", "category": "not_the_same_one", "processed": "timestamp failed at play check os full name timestamp task verify guest full name in guest info is expected fatal localhost failed guest full name in guest info microsoft windows server number b it is not the same as expected one", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1452, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70GA-8_logs_failed_tasks_log.0", "raw": "2021-12-22 02:10:18,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 02:10:18,022 | TASK [Update service packagekit.service, enabled: , state: stopped] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70GA/ansible-vsphere-gos-validation/linux/utils/service_operation.yml:27\nfatal: [localhost -> 10.168.169.146]: FAILED! => Unable to stop service packagekit.service: Job for packagekit.service canceled.", "category": "unable_to_stop_service", "processed": "timestamp failed at play ovt verify install timestamp task update service package kit service enabled state stopped fatal localhost ip address failed unable to stop service package kit service job for package kit service canceled", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1453, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-79_logs_failed_tasks_log.0", "raw": "2022-01-14 09:45:04,014 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2022-01-14 09:45:04,014 | TASK [Datastore file operation] ****************************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => Failed to query for file '1642152524-seed.iso'\n2022-01-14 09:46:02,014 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "fail_to_query_file", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task data store file operation fatal localhost failed failed to query for file hex id seed iso timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1455, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_9_x_70U3-11_logs_failed_tasks_log.3", "raw": "2021-12-13 04:44:27,013 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-13 04:44:27,013 | TASK [Customize Linux guest OS] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization failed. For detailed information see warnings Waiting for customization start event timed out.\n\n\npriority.target\ndeepdive.bug(product)", "category": "waiting_custom_timeout", "processed": "timestamp failed at play go sc perl static ip timestamp task customize linux guest os fatal localhost failed customization failed for detailed information see warnings waiting for customization start event timed out", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1456, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-10_logs_failed_tasks_log.0", "raw": "2021-12-21 16:31:08,021 | Failed at Play [ovt_verify_install] ************************\n2021-12-21 16:31:08,021 | TASK [Check the value of 'expected_service_state' and 'expected_service_status'] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/check_service_status.yml:23\nfatal: [localhost]: FAILED! => Invalid parameters: expected_service_state=inactive, expected_service_status=", "category": "invalid_parameters", "processed": "timestamp failed at play ovt verify install timestamp task check the value of expected service state and expected service status fatal localhost failed invalid parameters expected service state inactive expected service status", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1503, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.14", "raw": "2022-01-13 06:23:45,013 | Failed at Play [e1000e_network_device_ops] *****************\n2022-01-13 06:23:45,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play network device ops timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1458, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_Windows_Server_LTSC_vNext-13_logs_failed_tasks_log.2", "raw": "2021-12-10 08:17:19,010 | Failed at Play [check_quiesce_snapshot] ********************\n2021-12-10 08:17:19,010 | TASK [Check if get expected config in vmx] *****************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_LTSC_vNext/ansible-vsphere-gos-validation/windows/check_quiesce_snapshot/check_vmx_disk_enable_uuid.yml:12\nfatal: [localhost]: FAILED! => 'disk.EnableUUID = TRUE' is not in VM vmx file.\n", "category": "vmx_file_error", "processed": "timestamp failed at play check quiesce snapshot timestamp task check if get expected configuration in vmx fatal localhost failed disk enable uuid true is not in vm vmx file", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1494, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI-14_logs_failed_tasks_log.1", "raw": "2021-12-14 10:57:02,014 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2021-12-14 10:57:02,014 | TASK [Verify disk controller number increases in guest OS] *\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hotadd_vm_disk_new_ctrl.yml:25\nfatal: [localhost]: FAILED! => Disk controller number not increase 1, before hotadd: 1, after hotadd: 1", "category": "disk_controller_number", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task verify disk controller number increases in guest os fatal localhost failed disk controller number not increase number before hot add number after hot add number", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1459, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-97_logs_failed_tasks_log.0", "raw": "2022-01-19 04:18:57,019 | Failed at Play [deploy_vm_efi_buslogic_vmxnet3] ************\n2022-01-19 04:18:57,019 | TASK [Set VM power state to 'powered-on'] ******************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => The BusLogic SCSI adapter is not supported for 64-bit guests. See the documentation for the appropriate type of SCSI adapter to use with 64-bit guests. \n2022-01-19 04:19:00,019 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_buslogic_vmxnet3", "category": "adapter_not_support", "processed": "timestamp failed at play deploy vm efi bus logic vmxnet number timestamp task set vm power state to powered on fatal localhost failed the bus logic scsi adapter is not supported for number b it guests see the documentation for the appropriate type of scsi adapter to use with number b it guests timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi bus logic vmxnet number", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1460, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.1", "raw": "2022-01-17 04:30:49,017 | Failed at Play [cpu_hot_add_basic] *************************\n2022-01-17 04:30:49,017 | TASK [Set VM CPU number and/or cores per socket number] ****\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_set_cpu_number.yml:9\nfatal: [localhost]: FAILED! => The available Memory resources in the parent resource pool are insufficient for the operation.", "category": "resource_insufficient", "processed": "timestamp failed at play cpu hot add basic timestamp task set vm cpu number and or cores per socket number fatal localhost failed the available memory resources in the parent resource pool are insufficient for the operation", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1461, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.10", "raw": "2022-01-17 05:02:03,017 | Failed at Play [sata_vhba_device_ops] **********************\n2022-01-17 05:02:03,017 | TASK [Add new disk to VM via vmware_guest module] **********\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_hot_add_ctrl_disk.yml:28\nfatal: [localhost]: FAILED! => The available Memory resources in the parent resource pool are insufficient for the operation.", "category": "resource_insufficient", "processed": "timestamp failed at play sata v hba device ops timestamp task add new disk to vm via vmware guest module fatal localhost failed the available memory resources in the parent resource pool are insufficient for the operation", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1462, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.11", "raw": "2022-01-17 05:03:33,017 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-01-17 05:03:33,017 | TASK [Add new disk to VM via vmware_guest module] **********\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_hot_add_ctrl_disk.yml:28\nfatal: [localhost]: FAILED! => The available Memory resources in the parent resource pool are insufficient for the operation.", "category": "resource_insufficient", "processed": "timestamp failed at play nvme v hba device ops timestamp task add new disk to vm via vmware guest module fatal localhost failed the available memory resources in the parent resource pool are insufficient for the operation", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1463, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.2", "raw": "2022-01-17 04:36:15,017 | Failed at Play [memory_hot_add_basic] **********************\n2022-01-17 04:36:15,017 | TASK [Set memory size to 3072 MB] **************************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_set_memory_size.yml:4\nfatal: [localhost]: FAILED! => The available Memory resources in the parent resource pool are insufficient for the operation.", "category": "resource_insufficient", "processed": "timestamp failed at play memory hot add basic timestamp task set memory size to number mb fatal localhost failed the available memory resources in the parent resource pool are insufficient for the operation", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1464, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.9", "raw": "2022-01-17 04:59:22,017 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-01-17 04:59:22,017 | TASK [Add new disk to VM via vmware_guest module] **********\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_hot_add_ctrl_disk.yml:28\nfatal: [localhost]: FAILED! => The available Memory resources in the parent resource pool are insufficient for the operation.", "category": "resource_insufficient", "processed": "timestamp failed at play para virtual v hba device ops timestamp task add new disk to vm via vmware guest module fatal localhost failed the available memory resources in the parent resource pool are insufficient for the operation", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1465, "name": "ansible_gosv_logs_FAILURE_Ansible_Flatcar_67GA-10_logs_failed_tasks_log.0", "raw": "2021-12-20 05:54:46,020 | Failed at Play [check_ip_address] **************************\n2021-12-20 05:54:46,020 | TASK [Check IP address lists difference] *******************\ntask path: /home/worker/workspace/Ansible_Flatcar_67GA/ansible-vsphere-gos-validation/linux/check_ip_address/validate_ip_address.yml:17\nfatal: [localhost]: FAILED! => \"VM IP addresses got in guest info: ['10.187.140.58', 'fe80::250:56ff:feb7:42ad'], expected IP addresses got in guest OS: ['10.187.140.58', 'metric', '1024', 'fe80::250:56ff:feb7:42ad']\"\n", "category": "expect_ip_address3", "processed": "timestamp failed at play check ip address timestamp task check ip address lists difference fatal localhost failed vm ip addresses got in guest info ip address ip address expected ip addresses got in guest os ip address metric number ip address", "solution": "deepdive", "target": "targetvm", "version": 202205240000}, {"id": 1466, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_7_x-30_logs_failed_tasks_log.0", "raw": "2022-01-04 12:50:41,004 | Failed at Play [ovt_verify_status] *************************\n2022-01-04 12:50:41,004 | TASK [Check process 'vmtoolsd -n vmusr' is running] ********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_7.x/ansible-vsphere-gos-validation/linux/utils/check_process_status.yml:34\nfatal: [localhost]: FAILED! => User 'vmware' doesn't have running process 'vmtoolsd -n vmusr'\n\n\npriority.target\ndeepdive.testcase boot hang no auto login", "category": "no_running_process", "processed": "timestamp failed at play ovt verify status timestamp task check process vmtoolsd n vm user is running fatal localhost failed user vmware doesn t have running process vmtoolsd n vm user deep dive bug test case boot hang no auto login", "solution": "deepdive", "target": "targetvm", "version": 202205240000}, {"id": 1467, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_7_x-34_logs_failed_tasks_log.0", "raw": "2022-01-12 16:23:17,012 | Failed at Play [ovt_verify_status] *************************\n2022-01-12 16:23:17,012 | TASK [Check process 'vmtoolsd -n vmusr' is running] ********\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_7.x/ansible-vsphere-gos-validation/linux/utils/check_process_status.yml:34\nfatal: [localhost]: FAILED! => User 'vmware' doesn't have running process 'vmtoolsd -n vmusr'", "category": "no_running_process", "processed": "timestamp failed at play ovt verify status timestamp task check process vmtoolsd n vm user is running fatal localhost failed user vmware doesn t have running process vmtoolsd n vm user", "solution": "deepdive", "target": "targetvm", "version": 202205240000}, {"id": 1468, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.0", "raw": "2022-01-17 04:26:27,017 | Failed at Play [check_os_fullname] *************************\n2022-01-17 04:26:27,017 | TASK [Assert Guest OS fullname is either Other 4.x or later Linux (64-bit) or Other 4.x Linux (64-bit)] \ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/check_os_fullname/validate_os_fullname.yml:17\nfatal: [localhost]: FAILED! => \"VM 'test_vm' guest OS fullname is: 'AlmaLinux (64-bit)', not expected 'Other 4.x or later Linux (64-bit)' or 'Other 4.x Linux (64-bit)'\"", "category": "guestos_fullname", "processed": "timestamp failed at play check os full name timestamp task assert guest os full name is either other number x or later linux number b it or other number x linux number b it fatal localhost failed vm test vm guest os full name is alma linux number b it not expected other number x or later linux number b it or other number x linux number b it", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1469, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_RockyLinux_8_x-15_logs_failed_tasks_log.0", "raw": "2022-01-21 08:04:44,021 | Failed at Play [check_os_fullname] *************************\n2022-01-21 08:04:44,021 | TASK [Assert Guest OS fullname is either Other 4.x or later Linux (64-bit) or Other 4.x Linux (64-bit)] \ntask path: /home/worker/workspace/Ansible_Cycle_RockyLinux_8.x/ansible-vsphere-gos-validation/linux/check_os_fullname/validate_os_fullname.yml:17\nfatal: [localhost]: FAILED! => \"VM 'test_vm' guest OS fullname is: 'Rocky Linux (64-bit)', not expected 'Other 4.x or later Linux (64-bit)' or 'Other 4.x Linux (64-bit)'\"", "category": "guestos_fullname", "processed": "timestamp failed at play check os full name timestamp task assert guest os full name is either other number x or later linux number b it or other number x linux number b it fatal localhost failed vm test vm guest os full name is rocky linux number b it not expected other number x or later linux number b it or other number x linux number b it", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1470, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_RockyLinux_8_x-9_logs_failed_tasks_log.0", "raw": "2022-01-19 03:54:05,019 | Failed at Play [check_os_fullname] *************************\n2022-01-19 03:54:05,019 | TASK [Assert Guest OS fullname is either Other 4.x or later Linux (64-bit) or Other 4.x Linux (64-bit)] \ntask path: /home/worker/workspace/Ansible_Cycle_RockyLinux_8.x/ansible-vsphere-gos-validation/linux/check_os_fullname/validate_os_fullname.yml:17\nfatal: [localhost]: FAILED! => \"VM 'test_vm_1642560924961' guest OS fullname is: 'Rocky Linux (64-bit)', not expected 'Other 4.x or later Linux (64-bit)' or 'Other 4.x Linux (64-bit)'\"", "category": "guestos_fullname", "processed": "timestamp failed at play check os full name timestamp task assert guest os full name is either other number x or later linux number b it or other number x linux number b it fatal localhost failed vm test vm number guest os full name is rocky linux number b it not expected other number x or later linux number b it or other number x linux number b it", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1471, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_9_x_70GA-3_logs_failed_tasks_log.0", "raw": "2021-12-09 04:05:40,009 | Failed at Play [check_os_fullname] *************************\n2021-12-09 04:05:40,009 | TASK [Assert Guest OS fullname is Red Hat Enterprise Linux 9 (64-bit)] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70GA/ansible-vsphere-gos-validation/linux/check_os_fullname/validate_os_fullname.yml:29\nfatal: [localhost]: FAILED! => VM 'test_vm_1639020563600' guest OS fullname is: 'Red Hat Enterprise Linux 8 (64-bit)', not expected 'Red Hat Enterprise Linux 9 (64-bit)'", "category": "guestos_fullname", "processed": "timestamp failed at play check os full name timestamp task assert guest os full name is red hat enterprise linux number b it fatal localhost failed vm test vm number guest os full name is red hat enterprise linux number b it not expected red hat enterprise linux number b it", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1472, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.11", "raw": "2022-01-13 06:10:50,013 | Failed at Play [memory_hot_add_basic] **********************\n2022-01-13 06:10:50,013 | TASK [Get ESXi host specified property] ********************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/esxi_get_property.yml:8\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.185.254.254:443 : [Errno 110] Connection timed out", "category": "unknown_error", "processed": "timestamp failed at play memory hot add basic timestamp task get esxi host specified property exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number connection timed out", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1473, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.16", "raw": "2022-01-13 06:32:21,013 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-01-13 06:32:21,013 | TASK [Get ESXi host specified property] ********************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/esxi_get_property.yml:8\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.185.254.254:443 : [Errno 110] Connection timed out", "category": "unknown_error", "processed": "timestamp failed at play cpu multi cores per socket timestamp task get esxi host specified property exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number connection timed out", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1474, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.9", "raw": "2022-01-13 06:02:14,013 | Failed at Play [cpu_hot_add_basic] *************************\n2022-01-13 06:02:14,013 | TASK [Get ESXi host specified property] ********************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/esxi_get_property.yml:8\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.185.254.254:443 : [Errno 110] Connection timed out", "category": "unknown_error", "processed": "timestamp failed at play cpu hot add basic timestamp task get esxi host specified property exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number connection timed out", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1475, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-8_logs_failed_tasks_log.0", "raw": "2021-12-21 15:47:58,021 | Failed at Play [ovt_verify_install] ************************\n2021-12-21 15:47:58,021 | TASK [Check service 'packagekit.service' is disabled] ******\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/utils/check_service_status.yml:55\nfatal: [localhost]: FAILED! => Serivce 'packagekit.service' is not disabled", "category": "is_not_disabled", "processed": "timestamp failed at play ovt verify install timestamp task check service package kit service is disabled fatal localhost failed ser i vc e package kit service is not disabled", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1476, "name": "ansible_gosv_logs_FAILURE_Ansible_RockyLinux_8_x_70U1-1_logs_failed_tasks_log.0", "raw": "2021-12-09 11:04:39,009 | Failed at Play [deploy_vm_bios_nvme_e1000e] ****************\n2021-12-09 11:04:39,009 | TASK [Set VM boot options] *********************************\ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70U1/ansible-vsphere-gos-validation/common/vm_set_boot_options.yml:4\nfatal: [localhost]: FAILED! => EFI secure boot cannot be enabled when boot_firmware = bios.  VM's boot_firmware currently set to bios\n2021-12-09 11:05:24,009 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70U1/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_nvme_e1000e", "category": "secure_boot_cannot_enable", "processed": "timestamp failed at play deploy vm bios nvme timestamp task set vm boot options fatal localhost failed efi secure boot can not be enabled when boot firmware bios vm s boot firmware currently set to bios timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1477, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Flatcar_OVA-23_logs_failed_tasks_log.0", "raw": "2022-01-13 15:23:52,013 | Failed at Play [check_ip_address] **************************\n2022-01-13 15:23:52,013 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Regression_Flatcar_OVA/ansible-vsphere-gos-validation/linux/check_ip_address/vm_wait_guest_all_ip.yml:58\nfatal: [localhost]: FAILED! => Failed to collect all guest OS IP addresses in guest info", "category": "fail_guest_os_ip", "processed": "timestamp failed at play check ip address timestamp task fail fatal localhost failed failed to collect all guest os ip addresses in guest info", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1478, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-12_logs_failed_tasks_log.0", "raw": "2022-01-24 09:59:49,024 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-24 09:59:49,024 | TASK [Get guest DNS servers and search domains from /etc/resolv.conf] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/check_dns.yml:98\nfatal: [localhost]: FAILED! => Unexpected templating type error occurred on ({{ guest_resolv_conf | select('match', '^search\\\\s*') | map('regex_replace', '^search\\\\s*', '') | split() | map('regex_replace', '\\\\.$', '') }}): descriptor 'split' for 'str' objects doesn't apply to a 'list' object", "category": "unexpecting_templaing_type", "processed": "timestamp failed at play go sc perl dhcp timestamp task get guest dns servers and search domains from etc resolve configuration fatal localhost failed unexpected templating type error occurred on guest resolve configuration select match search s map regex replace search s split map regex replace descriptor split for string objects doesn t apply to a list object", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1479, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-12_logs_failed_tasks_log.1", "raw": "2022-01-24 10:13:34,024 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-24 10:13:34,024 | TASK [Get guest DNS servers and search domains from /etc/resolv.conf] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/check_dns.yml:98\nfatal: [localhost]: FAILED! => Unexpected templating type error occurred on ({{ guest_resolv_conf | select('match', '^search\\\\s*') | map('regex_replace', '^search\\\\s*', '') | split() | map('regex_replace', '\\\\.$', '') }}): descriptor 'split' for 'str' objects doesn't apply to a 'list' object", "category": "unexpecting_templaing_type", "processed": "timestamp failed at play go sc perl static ip timestamp task get guest dns servers and search domains from etc resolve configuration fatal localhost failed unexpected templating type error occurred on guest resolve configuration select match search s map regex replace search s split map regex replace descriptor split for string objects doesn t apply to a list object", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1480, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-12_logs_failed_tasks_log.2", "raw": "2022-01-24 10:27:53,024 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-24 10:27:53,024 | TASK [Get guest DNS servers and search domains from /etc/resolv.conf] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/check_dns.yml:98\nfatal: [localhost]: FAILED! => Unexpected templating type error occurred on ({{ guest_resolv_conf | select('match', '^search\\\\s*') | map('regex_replace', '^search\\\\s*', '') | split() | map('regex_replace', '\\\\.$', '') }}): descriptor 'split' for 'str' objects doesn't apply to a 'list' object", "category": "unexpecting_templaing_type", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task get guest dns servers and search domains from etc resolve configuration fatal localhost failed unexpected templating type error occurred on guest resolve configuration select match search s map regex replace search s split map regex replace descriptor split for string objects doesn t apply to a list object", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1481, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-12_logs_failed_tasks_log.3", "raw": "2022-01-24 10:42:09,024 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-24 10:42:09,024 | TASK [Get guest DNS servers and search domains from /etc/resolv.conf] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/check_dns.yml:98\nfatal: [localhost]: FAILED! => Unexpected templating type error occurred on ({{ guest_resolv_conf | select('match', '^search\\\\s*') | map('regex_replace', '^search\\\\s*', '') | split() | map('regex_replace', '\\\\.$', '') }}): descriptor 'split' for 'str' objects doesn't apply to a 'list' object", "category": "unexpecting_templaing_type", "processed": "timestamp failed at play go sc cloud init static ip timestamp task get guest dns servers and search domains from etc resolve configuration fatal localhost failed unexpected templating type error occurred on guest resolve configuration select match search s map regex replace search s split map regex replace descriptor split for string objects doesn t apply to a list object", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1504, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.15", "raw": "2022-01-13 06:28:03,013 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-01-13 06:28:03,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play vmxnet number network device ops timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1495, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI-15_logs_failed_tasks_log.2", "raw": "2021-12-14 13:35:27,014 | Failed at Play [nvme_vhba_device_ops] **********************\n2021-12-14 13:35:27,014 | TASK [Verify disk controller number increases in guest OS] *\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hotadd_vm_disk_new_ctrl.yml:25\nfatal: [localhost]: FAILED! => Disk controller number not increase 1, before hotadd: 0, after hotadd: 0", "category": "disk_controller_number", "processed": "timestamp failed at play nvme v hba device ops timestamp task verify disk controller number increases in guest os fatal localhost failed disk controller number not increase number before hot add number after hot add number", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1482, "name": "ansible_gosv_logs_FAILURE_Ansible_CentOS_8_x_65U3-13_logs_failed_tasks_log.0", "raw": "2022-01-24 11:30:24,024 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-24 11:30:24,024 | TASK [Get guest DNS servers and search domains from /etc/resolv.conf] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/check_dns.yml:98\nfatal: [localhost]: FAILED! => Unexpected templating type error occurred on ({{ guest_resolv_conf | select('match', '^search\\\\s*') | map('regex_replace', '^search\\\\s*', '') | split() | map('regex_replace', '\\\\.$', '') }}): descriptor 'split' for 'str' objects doesn't apply to a 'list' object\n2022-01-24 11:35:02,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_65U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case gosc_perl_dhcp", "category": "unexpecting_templaing_type", "processed": "timestamp failed at play go sc perl dhcp timestamp task get guest dns servers and search domains from etc resolve configuration fatal localhost failed unexpected templating type error occurred on guest resolve configuration select match search s map regex replace search s split map regex replace descriptor split for string objects doesn t apply to a list object timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case go sc perl dhcp", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1483, "name": "ansible_gosv_logs_FAILURE_Ansible_OracleLinux_8_x_67U1-12_logs_failed_tasks_log.0", "raw": "2022-01-24 09:20:12,024 | Failed at Play [env_setup] *********************************\n2022-01-24 09:20:12,024 | TASK [Check VM 'test_vm_2' exists] *************************\ntask path: /home/worker/workspace/Ansible_OracleLinux_8.x_67U1/ansible-vsphere-gos-validation/env_setup/env_setup.yml:32\nfatal: [localhost]: FAILED! => VM 'test_vm_2' doesn't exist. Please set new_vm to True to deploy the VM or provide an existing VM name.", "category": "new_vm", "processed": "timestamp failed at play environment setup timestamp task check vm test vm number exists fatal localhost failed vm test vm number doesn t exist please set new vm to true to deploy the vm or provide an existing vm name", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1484, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_65U3-14_logs_failed_tasks_log.0", "raw": "2022-01-25 02:23:07,025 | Failed at Play [env_setup] *********************************\n2022-01-25 02:23:07,025 | TASK [Check VM 'test_vm-2_1643077366890' exists] ***********\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/env_setup/env_setup.yml:32\nfatal: [localhost]: FAILED! => VM 'test_vm-2_1643077366890' doesn't exist. Please set new_vm to True to deploy the VM or provide an existing VM name.", "category": "new_vm", "processed": "timestamp failed at play environment setup timestamp task check vm test vm number exists fatal localhost failed vm test vm number doesn t exist please set new vm to true to deploy the vm or provide an existing vm name", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1485, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Flatcar_OVA-27_logs_failed_tasks_log.0", "raw": "2022-01-17 07:33:39,017 | Failed at Play [env_setup] *********************************\n2022-01-17 07:33:39,017 | TASK [Check VM 'test_vm' exists] ***************************\ntask path: /home/worker/workspace/Ansible_Regression_Flatcar_OVA/ansible-vsphere-gos-validation/env_setup/env_setup.yml:32\nfatal: [localhost]: FAILED! => VM 'test_vm' doesn't exist. Please set new_vm to True to deploy the VM or provide an existing VM name.", "category": "new_vm", "processed": "timestamp failed at play environment setup timestamp task check vm test vm exists fatal localhost failed vm test vm doesn t exist please set new vm to true to deploy the vm or provide an existing vm name", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1486, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70GA-3_logs_failed_tasks_log.1", "raw": "2021-12-15 12:24:23,015 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-15 12:24:23,015 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70GA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is wdc-10-191-178-154, expected hostname is gosc-static-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com.gosc.test.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=hwclock_success is False) => ['VM hwclockUTC is True, expected hwclockUTC is False'] and hwclock_success is False", "category": "expect_domain_name", "processed": "timestamp failed at play go sc perl static ip timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is wdc number expected hostname is go sc static vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com g osc test com expected domain name is go sc test com and dns domain success is false failed localhost item hw clock success is false vm hw clock utc is true expected hw clock utc is false and hw clock success is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1487, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70U1-1_logs_failed_tasks_log.1", "raw": "2021-12-10 13:49:48,010 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-10 13:49:48,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70U1/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc1-10-78-88-80, expected hostname is gosc-static-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is eng.vmware.com.gosc.test.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=hwclock_success is False) => ['VM hwclockUTC is True, expected hwclockUTC is False'] and hwclock_success is False", "category": "expect_domain_name", "processed": "timestamp failed at play go sc perl static ip timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is sc number expected hostname is go sc static vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is eng vmware com g osc test com expected domain name is go sc test com and dns domain success is false failed localhost item hw clock success is false vm hw clock utc is true expected hw clock utc is false and hw clock success is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1493, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI-14_logs_failed_tasks_log.0", "raw": "2021-12-14 10:55:08,014 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2021-12-14 10:55:08,014 | TASK [Verify disk controller number increases in guest OS] *\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hotadd_vm_disk_new_ctrl.yml:25\nfatal: [localhost]: FAILED! => Disk controller number not increase 1, before hotadd: 0, after hotadd: 0", "category": "disk_controller_number", "processed": "timestamp failed at play para virtual v hba device ops timestamp task verify disk controller number increases in guest os fatal localhost failed disk controller number not increase number before hot add number after hot add number", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1488, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_70U3-1_logs_failed_tasks_log.1", "raw": "2021-12-10 13:52:31,010 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-10 13:52:31,010 | TASK [Assert perl guest customization checks all PASS] *****\ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_70U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:46\nfailed: [localhost] => (item=hostname_success is False) => ['VM hostname is sc1-10-168-185-206, expected hostname is gosc-static-vm-01'] and hostname_success is False\nfailed: [localhost] => (item=dns_domain_success is False) => ['VM DNS domain name is nimbus.eng.vmware.com.gosc.test.com, expected domain name is gosc.test.com'] and dns_domain_success is False\nfailed: [localhost] => (item=hwclock_success is False) => ['VM hwclockUTC is True, expected hwclockUTC is False'] and hwclock_success is False", "category": "expect_domain_name", "processed": "timestamp failed at play go sc perl static ip timestamp task assert perl guest customization checks all pass failed localhost item hostname success is false vm hostname is sc number expected hostname is go sc static vm number and hostname success is false failed localhost item dns domain success is false vm dns domain name is nimbus eng vmware com g osc test com expected domain name is go sc test com and dns domain success is false failed localhost item hw clock success is false vm hw clock utc is true expected hw clock utc is false and hw clock success is false", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1489, "name": "ansible_gosv_logs_FAILURE_Ansible_Ubuntu_Server_ISO_main-5_logs_failed_tasks_log.0", "raw": "2021-12-17 11:07:16,017 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-17 11:07:16,017 | TASK [Fetch file /tmp/hostname_f.txt from VM guest] ********\ntask path: /home/worker/workspace/Ansible_Ubuntu_Server_ISO_main/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nfatal: [localhost]: FAILED! => Failed to fetch file : HTTP Error 500: Internal Server Error", "category": "failed_to_fetch_file", "processed": "timestamp failed at play go sc perl static ip timestamp task fetch file tmp hostname f text from vm guest fatal localhost failed failed to fetch file http error number internal server error", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1490, "name": "ansible_gosv_logs_FAILURE_Ansible_Ubuntu_Desktop_ISO_70GA-11_logs_failed_tasks_log.0", "raw": "2021-12-20 09:20:33,020 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-20 09:20:33,020 | TASK [Install package on Ubuntu 21.10] *********************\ntask path: /home/worker/workspace/Ansible_Ubuntu_Desktop_ISO_70GA/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:103\nfatal: [localhost -> 10.191.196.52]: FAILED! => '/usr/bin/apt-get -y -o \"Dpkg::Options::=--force-confdef\" -o \"Dpkg::Options::=--force-confold\"       install 'cloud-init'' failed: E: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/libe/libeatmydata/libeatmydata1_105-9build2_amd64.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/libe/libeatmydata/eatmydata_105-9build2_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python-attrs/python3-attr_20.3.0-1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/c/configobj/python3-configobj_5.0.6-4_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python3-stdlib-extensions/python3-distutils_3.9.7-1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/j/jinja2/python3-jinja2_2.11.3-1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python-json-pointer/python3-json-pointer_2.0-0ubuntu1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python-json-patch/python3-jsonpatch_1.25-3_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/s/setuptools/python3-setuptools_52.0.0-4_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/pyrsistent/python3-pyrsistent_0.15.5-1build3_amd64.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python-jsonschema/python3-jsonschema_3.2.0-0ubuntu2_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/pyserial/python3-serial_3.5%7eb0-1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/c/cloud-utils/cloud-guest-utils_0.32-22-g45fe84a5-0ubuntu1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/c/cloud-init/cloud-init_21.4-0ubuntu1%7e21.10.1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n\n\n\npriority.target\ndeepdive.testcase", "category": "unable_to_fetch_some_archive", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task install package on ubuntu number fatal localhost ip address failed user bin apt get y o dpkg options force configuration def o dpkg options force configuration old install cloud init failed e failed to fetch http us archive ubuntu com ubuntu pool main li be library eat my data library eat my data number build number amd number deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main li be library eat my data eat my data number build number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python attributes python number attribute version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main c configuration object python number configuration object version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python number standard library extensions python number dist utilities version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main j jinja number python number jinja number version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python json pointer python number j son pointer number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python json patch python number j son patch number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main s setup tools python number setup tools version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p p yrs i stent python number p yrs i stent version id build number amd number deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python json schema python number j son schema version id ubuntu number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python serial python number serial number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main c cloud utilities cloud guest utilities number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main c cloud init cloud init number id all deb temporary failure resolving us archive ubuntu com e unable to fetch some archives maybe run apt get update or try with fix missing", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1491, "name": "ansible_gosv_logs_FAILURE_Ansible_Ubuntu_Desktop_ISO_70GA-11_logs_failed_tasks_log.1", "raw": "2021-12-20 09:22:07,020 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-20 09:22:07,020 | TASK [Install package on Ubuntu 21.10] *********************\ntask path: /home/worker/workspace/Ansible_Ubuntu_Desktop_ISO_70GA/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:103\nfatal: [localhost -> 10.191.196.52]: FAILED! => '/usr/bin/apt-get -y -o \"Dpkg::Options::=--force-confdef\" -o \"Dpkg::Options::=--force-confold\"       install 'cloud-init'' failed: E: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/libe/libeatmydata/libeatmydata1_105-9build2_amd64.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/libe/libeatmydata/eatmydata_105-9build2_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python-attrs/python3-attr_20.3.0-1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/c/configobj/python3-configobj_5.0.6-4_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python3-stdlib-extensions/python3-distutils_3.9.7-1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/j/jinja2/python3-jinja2_2.11.3-1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python-json-pointer/python3-json-pointer_2.0-0ubuntu1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python-json-patch/python3-jsonpatch_1.25-3_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/s/setuptools/python3-setuptools_52.0.0-4_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/pyrsistent/python3-pyrsistent_0.15.5-1build3_amd64.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/python-jsonschema/python3-jsonschema_3.2.0-0ubuntu2_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/p/pyserial/python3-serial_3.5%7eb0-1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/c/cloud-utils/cloud-guest-utils_0.32-22-g45fe84a5-0ubuntu1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/c/cloud-init/cloud-init_21.4-0ubuntu1%7e21.10.1_all.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?", "category": "unable_to_fetch_some_archive", "processed": "timestamp failed at play go sc cloud init static ip timestamp task install package on ubuntu number fatal localhost ip address failed user bin apt get y o dpkg options force configuration def o dpkg options force configuration old install cloud init failed e failed to fetch http us archive ubuntu com ubuntu pool main li be library eat my data library eat my data number build number amd number deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main li be library eat my data eat my data number build number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python attributes python number attribute version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main c configuration object python number configuration object version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python number standard library extensions python number dist utilities version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main j jinja number python number jinja number version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python json pointer python number j son pointer number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python json patch python number j son patch number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main s setup tools python number setup tools version id all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p p yrs i stent python number p yrs i stent version id build number amd number deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python json schema python number j son schema version id ubuntu number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main p python serial python number serial number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main c cloud utilities cloud guest utilities number all deb temporary failure resolving us archive ubuntu com e failed to fetch http us archive ubuntu com ubuntu pool main c cloud init cloud init number id all deb temporary failure resolving us archive ubuntu com e unable to fetch some archives maybe run apt get update or try with fix missing", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1492, "name": "ansible_gosv_logs_FAILURE_Ansible_Ubuntu_Desktop_ISO_70GA-11_logs_failed_tasks_log.2", "raw": "2021-12-20 09:23:56,020 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2021-12-20 09:23:56,020 | TASK [Install package on Ubuntu 21.10] *********************\ntask path: /home/worker/workspace/Ansible_Ubuntu_Desktop_ISO_70GA/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:103\nfatal: [localhost -> 10.191.196.52]: FAILED! => '/usr/bin/apt-get -y -o \"Dpkg::Options::=--force-confdef\" -o \"Dpkg::Options::=--force-confold\"       install 'sg3-utils'' failed: E: Failed to fetch http://us.archive.ubuntu.com/ubuntu/pool/main/s/sg3-utils/sg3-utils_1.45-1ubuntu2_amd64.deb  Temporary failure resolving 'us.archive.ubuntu.com'\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?", "category": "unable_to_fetch_some_archive", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task install package on ubuntu number fatal localhost ip address failed user bin apt get y o dpkg options force configuration def o dpkg options force configuration old install sg number utilities failed e failed to fetch http us archive ubuntu com ubuntu pool main s sg number utilities sg number utilities number amd number deb temporary failure resolving us archive ubuntu com e unable to fetch some archives maybe run apt get update or try with fix missing", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1505, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.17", "raw": "2022-01-13 06:36:39,013 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-13 06:36:39,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play go sc perl dhcp timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1496, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-1_logs_failed_tasks_log.0", "raw": "2021-12-22 06:42:04,022 | Failed at Play [ovt_verify_install] ************************\n2021-12-22 06:42:04,022 | TASK [Add zypper repository SLED-15.3-dvd-Module-Live-Patching] \ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/add_repo_from_baseurl.yml:84\nImportError: No module named xml.dom.minidom\nfatal: [localhost -> 10.184.98.172]: FAILED! => Failed to import the required Python library (python-xml) on sc2-10-184-98-172.eng.vmware.com's Python /usr/bin/python. Please read the module documentation and install it in the appropriate location. If the required library is installed, but Ansible is using the wrong Python interpreter, please consult the documentation on ansible_python_interpreter\n", "category": "import_error_no_module", "processed": "timestamp failed at play ovt verify install timestamp task add zypper repository sled number dvd module live patching import error no module named xml dom mini dom fatal localhost ip address failed failed to import the required python library python xml on sc number eng vmware com s python user bin python please read the module documentation and install it in the appropriate location if the required library is installed but ansible is using the wrong python interpreter please consult the documentation on ansible python interpreter", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1497, "name": "ansible_gosv_logs_FAILURE_Ansible_Photon_4_x_67GA-16_logs_failed_tasks_log.1", "raw": "2022-01-21 04:48:24,021 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-21 04:48:24,021 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM static IPv4 gateway is '', expected IPv4 gateway is 192.168.1.1\"]", "category": "expect_ipv4_address2", "processed": "timestamp failed at play go sc perl static ip timestamp task gos customization failed fatal localhost failed vm static ip v number gateway is expected ip v number gateway is ip address", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1498, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_65U3-8_logs_failed_tasks_log.3", "raw": "2022-01-21 06:17:51,021 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-21 06:17:51,021 | TASK [GOS customization failed] ****************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_verify.yml:108\nfatal: [localhost]: FAILED! => [\"VM static IPv4 gateway is '', expected IPv4 gateway is 192.168.1.1\"]", "category": "expect_ipv4_address2", "processed": "timestamp failed at play go sc cloud init static ip timestamp task gos customization failed fatal localhost failed vm static ip v number gateway is expected ip v number gateway is ip address", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1499, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.1", "raw": "2022-01-13 05:27:50,013 | Failed at Play [ovt_verify_status] *************************\n2022-01-13 05:27:50,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play ovt verify status timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1500, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.10", "raw": "2022-01-13 06:06:33,013 | Failed at Play [check_quiesce_snapshot_custom_script] ******\n2022-01-13 06:06:33,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play check quiesce snapshot custom script timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1501, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.12", "raw": "2022-01-13 06:15:08,013 | Failed at Play [device_list] *******************************\n2022-01-13 06:15:08,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play device list timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1502, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.13", "raw": "2022-01-13 06:19:26,013 | Failed at Play [secureboot_enable_disable] *****************\n2022-01-13 06:19:26,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play secure boot enable disable timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1506, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.18", "raw": "2022-01-13 06:40:57,013 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-13 06:40:57,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play go sc perl static ip timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1507, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.19", "raw": "2022-01-13 06:45:15,013 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-13 06:45:15,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play go sc cloud init static ip timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1508, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.2", "raw": "2022-01-13 05:32:08,013 | Failed at Play [vgauth_check_service] **********************\n2022-01-13 05:32:08,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play vg auth check service timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1509, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.3", "raw": "2022-01-13 05:36:26,013 | Failed at Play [check_ip_address] **************************\n2022-01-13 05:36:26,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play check ip address timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1510, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.4", "raw": "2022-01-13 05:40:45,013 | Failed at Play [stat_balloon] ******************************\n2022-01-13 05:40:45,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play stat balloon timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1511, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.5", "raw": "2022-01-13 05:45:03,013 | Failed at Play [stat_hosttime] *****************************\n2022-01-13 05:45:03,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play stat host time timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1512, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.6", "raw": "2022-01-13 05:49:21,013 | Failed at Play [check_inbox_driver] ************************\n2022-01-13 05:49:21,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play check inbox driver timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1513, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.7", "raw": "2022-01-13 05:53:39,013 | Failed at Play [check_os_fullname] *************************\n2022-01-13 05:53:39,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play check os full name timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1514, "name": "ansible_gosv_logs_ABORTED_Ansible_Cycle_Ubuntu_21_10_ISO-7_logs_failed_tasks_log.8", "raw": "2022-01-13 05:57:57,013 | Failed at Play [check_efi_firmware] ************************\n2022-01-13 05:57:57,013 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_21.10_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play check efi firmware timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1515, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_Windows_11_64-23_logs_failed_tasks_log.0", "raw": "2022-01-06 11:45:18,006 | Failed at Play [memory_hot_add_basic] **********************\n2022-01-06 11:45:18,006 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed\n2022-01-06 11:45:22,006 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play memory hot add basic timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1516, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_9_x_70U3-7_logs_failed_tasks_log.5", "raw": "2021-12-10 14:02:45,010 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2021-12-10 14:02:45,010 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1517, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_9_x_70U3-7_logs_failed_tasks_log.6", "raw": "2021-12-10 14:02:49,010 | Failed at Play [sata_vhba_device_ops] **********************\n2021-12-10 14:02:49,010 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play sata v hba device ops timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1518, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_9_x_70U3-7_logs_failed_tasks_log.7", "raw": "2021-12-10 14:02:53,010 | Failed at Play [nvme_vhba_device_ops] **********************\n2021-12-10 14:02:53,010 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play nvme v hba device ops timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1519, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_9_x_70U3-7_logs_failed_tasks_log.8", "raw": "2021-12-10 14:02:56,010 | Failed at Play [ovt_verify_uninstall] **********************\n2021-12-10 14:02:56,010 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play ovt verify un install timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1520, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_3_0_ISO-31_logs_failed_tasks_log.1", "raw": "2022-01-18 16:36:59,018 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-01-18 16:36:59,018 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "snapshot_fail", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task revert snapshot failed fatal localhost failed revert to snapshot base snapshot failed", "solution": "retry", "target": "testcase", "version": 202205240000}, {"id": 1553, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_65U3-18_logs_failed_tasks_log.5", "raw": "2021-12-22 05:56:35,022 | Failed at Play [nvme_vhba_device_ops] **********************\n2021-12-22 05:56:35,022 | TASK [Get block devices] ***********************************\ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_65U3/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/get_vm_device_list.yml:8\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via ssh: Connection timed out during banner exchange\nConnection to 10.78.125.176 port 22 timed out", "category": "connection_timeout_during", "processed": "timestamp failed at play nvme v hba device ops timestamp task get block devices fatal localhost un reachable failed to connect to the host via ssh connection timed out during banner exchange connection to ip address port number timed out", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1521, "name": "ansible_gosv_logs_FAILURE_Ansible_OracleLinux_8_x_67U1-13_logs_failed_tasks_log.0", "raw": "2022-01-24 11:24:08,024 | Failed at Play [deploy_vm_efi_lsilogic_e1000e] *************\n2022-01-24 11:24:08,024 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_OracleLinux_8.x_67U1/ansible-vsphere-gos-validation/linux/deploy_vm/deploy_vm_from_iso.yml:176\nfatal: [localhost]: FAILED! => Failed to remove serial port from VM\n2022-01-24 11:24:40,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_OracleLinux_8.x_67U1/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_lsilogic_e1000e", "category": "fail_to_remove_from_vm", "processed": "timestamp failed at play deploy vm efi lsi logic timestamp task fail fatal localhost failed failed to remove serial port from vm timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi lsi logic e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1522, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_8_x_65U3-12_logs_failed_tasks_log.0", "raw": "2022-01-24 11:14:18,024 | Failed at Play [deploy_vm_efi_sata_e1000e] *****************\n2022-01-24 11:14:18,024 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/linux/deploy_vm/deploy_vm_from_iso.yml:176\nfatal: [localhost]: FAILED! => Failed to remove serial port from VM\n2022-01-24 11:14:51,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_RHEL_8.x_65U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_sata_e1000e", "category": "fail_to_remove_from_vm", "processed": "timestamp failed at play deploy vm efi sata timestamp task fail fatal localhost failed failed to remove serial port from vm timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi sata e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1523, "name": "ansible_gosv_logs_FAILURE_Ansible_Autoinstall_OracleLinux_8_x-29_logs_failed_tasks_log.0", "raw": "2021-12-16 10:01:27,016 | Failed at Play [testbed_deploy_nimbus] *********************\n2021-12-16 10:01:27,016 | TASK [Parameter error] *************************************\ntask path: /home/worker/workspace/Ansible_Autoinstall_OracleLinux_8.x/newgos_testing_internal/testbed_deploy/testbed_deploy_nimbus.yml:60\nfatal: [localhost]: FAILED! => Please specify vCenter build number in command line or in vars/internal_test.yml using 'vcenter_build_num' parameter", "category": "vcenter_number", "processed": "timestamp failed at play testbed deploy nimbus timestamp task parameter error fatal localhost failed please specify vcenter build number in command line or in vars internal test yml using vcenter build number parameter", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1524, "name": "ansible_gosv_logs_FAILURE_Ansible_Autoinstall_AlmaLinux_8_x-18_logs_failed_tasks_log.0", "raw": "2021-12-09 14:52:15,009 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2021-12-09 14:52:15,009 | TASK [Create a new VM 'test_vm' on server '10.187.103.183'] \ntask path: /home/worker/workspace/Ansible_Autoinstall_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : The operation is not supported on the object.\n2021-12-09 14:52:15,009 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Autoinstall_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_vmxnet3", "category": "operation_not_support", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task create a new vm test vm on server ip address fatal localhost failed failed to create a virtual machine the operation is not supported on the object timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual vmxnet number", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1525, "name": "ansible_gosv_logs_FAILURE_Ansible_Autoinstall_AlmaLinux_8_x-20_logs_failed_tasks_log.0", "raw": "2021-12-10 03:20:30,010 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2021-12-10 03:20:30,010 | TASK [Create a new VM 'test_vm_1639106335896' on server '10.185.107.93'] \ntask path: /home/worker/workspace/Ansible_Autoinstall_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : The operation is not supported on the object.\n2021-12-10 03:20:31,010 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Autoinstall_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_vmxnet3", "category": "operation_not_support", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task create a new vm test vm number on server ip address fatal localhost failed failed to create a virtual machine the operation is not supported on the object timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual vmxnet number", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1526, "name": "ansible_gosv_logs_FAILURE_Ansible_Autoinstall_Windows_10_32-18_logs_failed_tasks_log.0", "raw": "2021-12-09 14:56:10,009 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2021-12-09 14:56:10,009 | TASK [Create a new VM 'test_vm' on server '10.185.10.254'] *\ntask path: /home/worker/workspace/Ansible_Autoinstall_Windows_10_32/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : The operation is not supported on the object.\n2021-12-09 14:56:11,009 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Autoinstall_Windows_10_32/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "operation_not_support", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task create a new vm test vm on server ip address fatal localhost failed failed to create a virtual machine the operation is not supported on the object timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1554, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_9_x_70U3-10_logs_failed_tasks_log.1", "raw": "2021-12-10 16:26:16,010 | Failed at Play [memory_hot_add_basic] **********************\n2021-12-10 16:26:16,010 | TASK [Set memory size to 3072 MB] **************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/common/vm_set_memory_size.yml:4\nfatal: [localhost]: FAILED! => Invalid virtual machine configuration.", "category": "invalid_vm_config", "processed": "timestamp failed at play memory hot add basic timestamp task set memory size to number mb fatal localhost failed invalid virtual machine configuration", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1527, "name": "ansible_gosv_logs_FAILURE_Ansible_Autoinstall_Windows_10_32-21_logs_failed_tasks_log.0", "raw": "2021-12-10 03:20:35,010 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2021-12-10 03:20:35,010 | TASK [Create a new VM 'test_vm_1639106326532' on server '10.78.194.73'] \ntask path: /home/worker/workspace/Ansible_Autoinstall_Windows_10_32/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : The operation is not supported on the object.\n2021-12-10 03:20:36,010 | TASK [Check if exit testing parameter is set] **************\ntask path: /home/worker/workspace/Ansible_Autoinstall_Windows_10_32/ansible-vsphere-gos-validation/windows/setup/rescue_cleanup.yml:46\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True", "category": "operation_not_support", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task create a new vm test vm number on server ip address fatal localhost failed failed to create a virtual machine the operation is not supported on the object timestamp task check if exit testing parameter is set fatal localhost failed exit testing when exit testing when fail is set to true", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1528, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_67GA-12_logs_failed_tasks_log.0", "raw": "2021-12-22 16:34:37,022 | Failed at Play [vgauth_check_service] **********************\n2021-12-22 16:34:37,022 | TASK [Check service 'vgauthd' is enabled] ******************\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_67GA/ansible-vsphere-gos-validation/linux/utils/check_service_status.yml:55\nfatal: [localhost]: FAILED! => Serivce 'vgauthd' is not enabled\n", "category": "not_enable", "processed": "timestamp failed at play vg auth check service timestamp task check service vg authd is enabled fatal localhost failed ser i vc e vg authd is not enabled", "solution": "deepdive", "target": "targetvm", "version": 202205240000}, {"id": 1529, "name": "ansible_gosv_logs_ABORTED_Ansible_Regression_Ubuntu_21_10_Desktop_ISO-26_logs_failed_tasks_log.0", "raw": "2021-12-22 09:39:23,022 | Failed at Play [e1000e_network_device_ops] *****************\n2021-12-22 09:39:23,022 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Desktop_ISO/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.185.252.26:22", "category": "timeout_openssh__2", "processed": "timestamp failed at play network device ops timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1530, "name": "ansible_gosv_logs_ABORTED_Ansible_Regression_Ubuntu_21_10_Desktop_ISO-26_logs_failed_tasks_log.1", "raw": "2021-12-22 09:55:16,022 | Failed at Play [vmxnet3_network_device_ops] ****************\n2021-12-22 09:55:16,022 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Desktop_ISO/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.185.252.26:22", "category": "timeout_openssh__2", "processed": "timestamp failed at play vmxnet number network device ops timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1531, "name": "ansible_gosv_logs_ABORTED_Ansible_Regression_Ubuntu_21_10_Desktop_ISO-26_logs_failed_tasks_log.2", "raw": "2021-12-22 10:11:08,022 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-22 10:11:08,022 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Desktop_ISO/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.185.252.26:22", "category": "timeout_openssh__2", "processed": "timestamp failed at play go sc perl dhcp timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1532, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70U3-1_logs_failed_tasks_log.0", "raw": "2021-12-15 05:07:59,015 | Failed at Play [deploy_vm_efi_nvme_e1000e] *****************\n2021-12-15 05:07:59,015 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70U3/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.206.209.59:22\n2021-12-15 05:09:16,015 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_e1000e", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm efi nvme timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1533, "name": "ansible_gosv_logs_FAILURE_Ansible_exclude_Regression_SLED_15_x-12_logs_failed_tasks_log.0", "raw": "2021-12-15 03:07:09,015 | Failed at Play [deploy_vm_bios_nvme_vmxnet3] ***************\n2021-12-15 03:07:09,015 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.184.91.128:22\n2021-12-15 03:09:14,015 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_nvme_vmxnet3", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm bios nvme vmxnet number timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios nvme vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1534, "name": "ansible_gosv_logs_FAILURE_Ansible_exclude_Regression_SLED_15_x-13_logs_failed_tasks_log.0", "raw": "2021-12-15 04:03:36,015 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2021-12-15 04:03:36,015 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.206.109.85:22\n2021-12-15 04:05:03,015 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_exclude_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1536, "name": "ansible_gosv_logs_FAILURE_Ansible_RHEL_9_x_70U3-9_logs_failed_tasks_log.0", "raw": "2021-12-10 14:10:40,010 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2021-12-10 14:10:40,010 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.168.207.211:22\n2021-12-10 14:11:33,010 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_70U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_e1000e", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1537, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-1_logs_failed_tasks_log.0", "raw": "2021-12-15 05:00:34,015 | Failed at Play [deploy_vm_bios_paravirtual_vmxnet3] ********\n2021-12-15 05:00:34,015 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.191.166.147:22\n2021-12-15 05:02:32,015 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_paravirtual_vmxnet3", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm bios para virtual vmxnet number timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios para virtual vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1598, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-23_logs_failed_tasks_log.1", "raw": "2022-01-04 13:14:05,004 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-04 13:14:05,004 | TASK [Install package on VMware Photon OS 4.0] *************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:53\nfatal: [localhost -> 10.187.130.143]: FAILED! => non-zero return code when tdnf", "category": "non_zero_return", "processed": "timestamp failed at play go sc perl static ip timestamp task install package on vmware photon os number fatal localhost ip address failed non zero return code when tdnf", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1538, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_67GA-1_logs_failed_tasks_log.0", "raw": "2021-12-15 04:52:03,015 | Failed at Play [deploy_vm_efi_lsilogic_e1000e] *************\n2021-12-15 04:52:03,015 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_67GA/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.180.199.62:22\n2021-12-15 04:53:13,015 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_67GA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_lsilogic_e1000e", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm efi lsi logic timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi lsi logic e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1539, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_67U3-1_logs_failed_tasks_log.0", "raw": "2021-12-15 04:48:19,015 | Failed at Play [deploy_vm_bios_lsilogicsas_vmxnet3] ********\n2021-12-15 04:48:19,015 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_67U3/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.180.106.45:22\n2021-12-15 04:49:37,015 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_67U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_lsilogicsas_vmxnet3", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm bios lsi logic sas vmxnet number timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios lsi logic sas vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1540, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_70GA-1_logs_failed_tasks_log.0", "raw": "2021-12-15 04:56:48,015 | Failed at Play [deploy_vm_bios_sata_e1000e] ****************\n2021-12-15 04:56:48,015 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70GA/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.206.94.224:22\n2021-12-15 04:58:41,015 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_70GA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_bios_sata_e1000e", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm bios sata timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm bios sata e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1599, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-23_logs_failed_tasks_log.2", "raw": "2022-01-04 13:15:45,004 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-04 13:15:45,004 | TASK [Install package on VMware Photon OS 4.0] *************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:53\nfatal: [localhost -> 10.187.130.143]: FAILED! => non-zero return code when tdnf", "category": "non_zero_return", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task install package on vmware photon os number fatal localhost ip address failed non zero return code when tdnf", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1600, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-23_logs_failed_tasks_log.3", "raw": "2022-01-04 13:17:14,004 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-04 13:17:14,004 | TASK [Install package on VMware Photon OS 4.0] *************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:53\nfatal: [localhost -> 10.187.130.143]: FAILED! => non-zero return code when tdnf", "category": "non_zero_return", "processed": "timestamp failed at play go sc cloud init static ip timestamp task install package on vmware photon os number fatal localhost ip address failed non zero return code when tdnf", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1603, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-3_logs_failed_tasks_log.1", "raw": "2021-12-20 11:56:42,020 | Failed at Play [e1000e_network_device_ops] *****************\n2021-12-20 11:56:42,020 | TASK [Bring link 'eth1' up] ********************************\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:88\nfatal: [localhost -> 10.184.94.66]: FAILED! => non-zero return code when ifdown", "category": "non_zero_return", "processed": "timestamp failed at play network device ops timestamp task bring link eth number up fatal localhost ip address failed non zero return code when if down", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1550, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_Windows_10_64-20_logs_failed_tasks_log.0", "raw": "2022-01-05 05:49:28,005 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-01-05 05:49:28,005 | TASK [Check diskpart script file copied to guest OS] *******\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/create_partition_raw_disk.yml:69\nfatal: [localhost]: FAILED! => diskpart file not found in guest OS: C:\\test_diskpart\\diskpart.txt", "category": "file_not_found_in_guest", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task check diskpart script file copied to guest os fatal localhost failed diskpart file not found in guest os c test diskpart diskpart text", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1551, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_AlmaLinux_8_x-22_logs_failed_tasks_log.0", "raw": "2022-01-04 06:28:23,004 | Failed at Play [env_setup] *********************************\n2022-01-04 06:28:23,004 | TASK [Enable GuestIPHack on ESXi host '10.186.44.158'] *****\ntask path: /home/worker/workspace/Ansible_Regression_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/esxi_enable_guest_ip_hack.yml:5\nfatal: [localhost]: UNREACHABLE! => Failed to create temporary directory.In some cases, you may have been able to authenticate and did not have permissions on the target directory. Consider changing the remote tmp path in ansible.cfg to a path rooted in \"/tmp\", for more error information use -vvv. Failed command was: ( umask 77 && mkdir -p \"` echo /vmfs/volumes/datastore2 `\"&& mkdir \"` echo /vmfs/volumes/datastore2/ansible-tmp-1641277703.4004283-1648-2345984331423 `\" && echo ansible-tmp-1641277703.4004283-1648-2345984331423=\"` echo /vmfs/volumes/datastore2/ansible-tmp-1641277703.4004283-1648-2345984331423 `\" ), exited with result 1\n\n", "category": "failed_create_temporary_directory", "processed": "timestamp failed at play environment setup timestamp task enable guest ip hack on esxi host ip address fatal localhost un reachable failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo vmfs volumes data store number mkdir echo vmfs volumes data store number ansible tmp hex id number timestamp echo ansible tmp hex id number timestamp echo vmfs volumes data store number ansible tmp hex id number timestamp exited with result number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1552, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_3_0_ISO-32_logs_failed_tasks_log.0", "raw": "2022-01-18 17:22:23,018 | Failed at Play [env_setup] *********************************\n2022-01-18 17:22:23,018 | TASK [Enable GuestIPHack on ESXi host '10.187.150.27'] *****\ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/common/esxi_enable_guest_ip_hack.yml:5\nfatal: [localhost]: UNREACHABLE! => Failed to create temporary directory.In some cases, you may have been able to authenticate and did not have permissions on the target directory. Consider changing the remote tmp path in ansible.cfg to a path rooted in \"/tmp\", for more error information use -vvv. Failed command was: ( umask 77 && mkdir -p \"` echo /vmfs/volumes/datastore2 `\"&& mkdir \"` echo /vmfs/volumes/datastore2/ansible-tmp-1642526542.8186202-501-229866794392168 `\" && echo ansible-tmp-1642526542.8186202-501-229866794392168=\"` echo /vmfs/volumes/datastore2/ansible-tmp-1642526542.8186202-501-229866794392168 `\" ), exited with result 1", "category": "failed_create_temporary_directory", "processed": "timestamp failed at play environment setup timestamp task enable guest ip hack on esxi host ip address fatal localhost un reachable failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo vmfs volumes data store number mkdir echo vmfs volumes data store number ansible tmp hex id number timestamp echo ansible tmp hex id number timestamp echo vmfs volumes data store number ansible tmp hex id number timestamp exited with result number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1555, "name": "ansible_gosv_logs_FAILURE_Ansible_Photon_4_x_67GA-26_logs_failed_tasks_log.0", "raw": "2022-01-24 08:38:42,024 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-24 08:38:42,024 | TASK [Set fact of guest OS hostname and domain] ************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/guest_customization/check_hostname_and_domain.yml:35\njinja2.exceptions.TemplateRuntimeError: No filter named 'joint' found.\nfatal: [localhost]: FAILED! => {\n    \"changed\": false\n}\n2022-01-24 08:39:16,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Photon_4.x_67GA/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case gosc_perl_dhcp", "category": "jinja_exception", "processed": "timestamp failed at play go sc perl dhcp timestamp task set fact of guest os hostname and domain jinja number exceptions template runtime error no filter named joint found fatal localhost failed timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case go sc perl dhcp", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1556, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-107_logs_failed_tasks_log.0", "raw": "2022-01-24 09:36:13,024 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-24 09:36:13,024 | TASK [Set fact of guest OS hostname and domain] ************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/guest_customization/check_hostname_and_domain.yml:35\njinja2.exceptions.TemplateRuntimeError: No filter named 'joint' found.\nfatal: [localhost]: FAILED! => {\n    \"changed\": false\n}", "category": "jinja_exception", "processed": "timestamp failed at play go sc perl dhcp timestamp task set fact of guest os hostname and domain jinja number exceptions template runtime error no filter named joint found fatal localhost failed", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1557, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-107_logs_failed_tasks_log.1", "raw": "2022-01-24 09:40:35,024 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-24 09:40:35,024 | TASK [Set fact of guest OS hostname and domain] ************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/guest_customization/check_hostname_and_domain.yml:35\njinja2.exceptions.TemplateRuntimeError: No filter named 'joint' found.\nfatal: [localhost]: FAILED! => {\n    \"changed\": false\n}", "category": "jinja_exception", "processed": "timestamp failed at play go sc perl static ip timestamp task set fact of guest os hostname and domain jinja number exceptions template runtime error no filter named joint found fatal localhost failed", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1558, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-107_logs_failed_tasks_log.2", "raw": "2022-01-24 09:45:06,024 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-24 09:45:06,024 | TASK [Set fact of guest OS hostname and domain] ************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/guest_customization/check_hostname_and_domain.yml:35\njinja2.exceptions.TemplateRuntimeError: No filter named 'joint' found.\nfatal: [localhost]: FAILED! => {\n    \"changed\": false\n}", "category": "jinja_exception", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task set fact of guest os hostname and domain jinja number exceptions template runtime error no filter named joint found fatal localhost failed", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1559, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-107_logs_failed_tasks_log.3", "raw": "2022-01-24 09:49:32,024 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-24 09:49:32,024 | TASK [Set fact of guest OS hostname and domain] ************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/linux/guest_customization/check_hostname_and_domain.yml:35\njinja2.exceptions.TemplateRuntimeError: No filter named 'joint' found.\nfatal: [localhost]: FAILED! => {\n    \"changed\": false\n}", "category": "jinja_exception", "processed": "timestamp failed at play go sc cloud init static ip timestamp task set fact of guest os hostname and domain jinja number exceptions template runtime error no filter named joint found fatal localhost failed", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1560, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Windows_11_64-45_logs_failed_tasks_log.1", "raw": "2022-01-21 04:54:11,021 | Failed at Play [gosc_sanity_dhcp] **************************\n2022-01-21 04:54:11,021 | TASK [Check guest customization state] *********************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/common/vm_wait_gosc_completed.yml:35\nfatal: [localhost]: FAILED! => Not found 'ToolsDeployPkgPublishState: state=5, code=0' in vmware.log", "category": "tools_deploy_pkg_publish_state", "processed": "timestamp failed at play go sc sanity dhcp timestamp task check guest customization state fatal localhost failed not found tools deploy package publish state state number code number in vmware log", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1561, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_Windows_10_64-26_logs_failed_tasks_log.0", "raw": "2022-01-06 11:47:40,006 | Failed at Play [check_efi_firmware] ************************\n2022-01-06 11:47:40,006 | TASK [Get VMware tools version and build number in guest OS] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_get_vmtools_version_build.yml:13\nrequests.exceptions.HTTPError: 500 Server Error:  for url: https://10.185.96.250:5986/wsman\nwinrm.exceptions.WinRMTransportError: Bad HTTP response returned from server. Code 500\nwinrm.exceptions.WinRMError: The WS-Management service cannot process the request because the request contained invalid selectors for the resource.  (extended fault data: Bad HTTP response returned from server. Code 500 at s:Sender and w:InvalidSelectors)\nrequests.exceptions.HTTPError: 500 Server Error:  for url: https://10.185.96.250:5986/wsman\nwinrm.exceptions.WinRMTransportError: Bad HTTP response returned from server. Code 500\nwinrm.exceptions.WinRMError: The WS-Management service cannot process the request because the request contained invalid selectors for the resource.  (extended fault data: Bad HTTP response returned from server. Code 500 at s:Sender and w:InvalidSelectors)\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.\n", "category": "bad_http_from_server", "processed": "timestamp failed at play check efi firmware timestamp task get vmware tools version and build number in guest os requests exceptions http error number server error for url https ip address wsman win rm exceptions win rm transport error bad http response returned from server code number win rm exceptions win rm error the ws management service can not process the request because the request contained invalid selectors for the resource extended fault data bad http response returned from server code number ats sender and w invalid selectors requests exceptions http error number server error for url https ip address wsman win rm exceptions win rm transport error bad http response returned from server code number win rm exceptions win rm error the ws management service can not process the request because the request contained invalid selectors for the resource extended fault data bad http response returned from server code number ats sender and w invalid selectors fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1562, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI-14_logs_failed_tasks_log.3", "raw": "2021-12-14 11:06:22,014 | Failed at Play [e1000e_network_device_ops] *****************\n2021-12-14 11:06:22,014 | TASK [Check powershell command result] *********************\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI/ansible-vsphere-gos-validation/windows/utils/win_get_ethernet_name.yml:14\nfatal: [localhost]: FAILED! => Not get Ethernet name with specified MAC address: 00:50:56:af:3d:68\n", "category": "no_ethernet_name", "processed": "timestamp failed at play network device ops timestamp task check powershell command result fatal localhost failed not get ethernet name with specified mac address mac address", "solution": "deepdive", "target": "targetvm", "version": 202205240000}, {"id": 1563, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI-14_logs_failed_tasks_log.4", "raw": "2021-12-14 11:09:02,014 | Failed at Play [vmxnet3_network_device_ops] ****************\n2021-12-14 11:09:02,014 | TASK [Check powershell command result] *********************\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_67U3_LSILogicSAS_EFI/ansible-vsphere-gos-validation/windows/utils/win_get_ethernet_name.yml:14\nfatal: [localhost]: FAILED! => Not get Ethernet name with specified MAC address: 00:50:56:af:78:71", "category": "no_ethernet_name", "processed": "timestamp failed at play vmxnet number network device ops timestamp task check powershell command result fatal localhost failed not get ethernet name with specified mac address mac address", "solution": "deepdive", "target": "targetvm", "version": 202205240000}, {"id": 1564, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.3", "raw": "2022-01-17 04:40:42,017 | Failed at Play [e1000e_network_device_ops] *****************\n2022-01-17 04:40:42,017 | TASK [Add a new 'e1000e' adapter in 'vSwitch2022-01-17-03-48-31_PG' to VM 'test_vm'] \ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_add_network_adapter.yml:4\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play network device ops timestamp task add a new adapter in vswitch timestamp number page to vm test vm fatal localhost failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1565, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.4", "raw": "2022-01-17 04:42:11,017 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-01-17 04:42:11,017 | TASK [Add a new 'vmxnet3' adapter in 'vSwitch2022-01-17-03-48-31_PG' to VM 'test_vm'] \ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/common/vm_add_network_adapter.yml:4\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play vmxnet number network device ops timestamp task add a new vmxnet number adapter in vswitch timestamp number page to vm test vm fatal localhost failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1566, "name": "ansible_gosv_logs_FAILURE_Ansible_OracleLinux_8_x_67U1-14_logs_failed_tasks_log.0", "raw": "2022-01-24 11:46:34,024 | Failed at Play [deploy_vm_efi_lsilogic_e1000e] *************\n2022-01-24 11:46:34,024 | TASK [Add a serial port using output file] *****************\ntask path: /home/worker/workspace/Ansible_OracleLinux_8.x_67U1/ansible-vsphere-gos-validation/common/vm_add_serial_port.yml:15\nKeyError: 'type'\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error\n2022-01-24 11:47:06,024 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_OracleLinux_8.x_67U1/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_lsilogic_e1000e", "category": "module_failure_3_cases___", "processed": "timestamp failed at play deploy vm efi lsi logic timestamp task add a serial port using output file fatal localhost failed module failure see stdout stderr for the exact error timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi lsi logic e number e", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1567, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.0", "raw": "2022-01-05 09:30:58,005 | Failed at Play [ovt_verify_install] ************************\n2022-01-05 09:30:58,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play ovt verify install timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1568, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.1", "raw": "2022-01-05 09:32:00,005 | Failed at Play [ovt_verify_status] *************************\n2022-01-05 09:32:00,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play ovt verify status timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1569, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.10", "raw": "2022-01-05 09:41:02,005 | Failed at Play [check_quiesce_snapshot_custom_script] ******\n2022-01-05 09:41:02,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play check quiesce snapshot custom script timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1570, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.11", "raw": "2022-01-05 09:42:09,005 | Failed at Play [memory_hot_add_basic] **********************\n2022-01-05 09:42:09,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play memory hot add basic timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1571, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.12", "raw": "2022-01-05 09:43:11,005 | Failed at Play [device_list] *******************************\n2022-01-05 09:43:11,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play device list timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1572, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.13", "raw": "2022-01-05 09:44:21,005 | Failed at Play [secureboot_enable_disable] *****************\n2022-01-05 09:44:21,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play secure boot enable disable timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1573, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.14", "raw": "2022-01-05 09:45:22,005 | Failed at Play [e1000e_network_device_ops] *****************\n2022-01-05 09:45:22,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play network device ops timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1574, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.15", "raw": "2022-01-05 09:46:20,005 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-01-05 09:46:20,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play vmxnet number network device ops timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1575, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.16", "raw": "2022-01-05 09:47:22,005 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-01-05 09:47:22,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play cpu multi cores per socket timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1576, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.17", "raw": "2022-01-05 09:48:21,005 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-05 09:48:21,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play go sc perl dhcp timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1577, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.18", "raw": "2022-01-05 09:49:20,005 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-05 09:49:20,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play go sc perl static ip timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1578, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.19", "raw": "2022-01-05 09:50:17,005 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-05 09:50:17,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1579, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.2", "raw": "2022-01-05 09:32:58,005 | Failed at Play [vgauth_check_service] **********************\n2022-01-05 09:32:58,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play vg auth check service timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1580, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.20", "raw": "2022-01-05 09:51:14,005 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-05 09:51:14,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play go sc cloud init static ip timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1581, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.21", "raw": "2022-01-05 09:52:19,005 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-01-05 09:52:19,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play para virtual v hba device ops timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1582, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.22", "raw": "2022-01-05 09:53:18,005 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-01-05 09:53:18,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1583, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.23", "raw": "2022-01-05 09:54:19,005 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-01-05 09:54:19,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1584, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.24", "raw": "2022-01-05 09:55:18,005 | Failed at Play [sata_vhba_device_ops] **********************\n2022-01-05 09:55:18,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play sata v hba device ops timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1585, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.25", "raw": "2022-01-05 09:56:18,005 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-01-05 09:56:18,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play nvme v hba device ops timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1586, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.26", "raw": "2022-01-05 09:57:14,005 | Failed at Play [ovt_verify_uninstall] **********************\n2022-01-05 09:57:14,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play ovt verify un install timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1587, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.3", "raw": "2022-01-05 09:33:54,005 | Failed at Play [check_ip_address] **************************\n2022-01-05 09:33:54,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play check ip address timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1588, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.4", "raw": "2022-01-05 09:34:53,005 | Failed at Play [stat_balloon] ******************************\n2022-01-05 09:34:53,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play stat balloon timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1589, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.5", "raw": "2022-01-05 09:35:52,005 | Failed at Play [stat_hosttime] *****************************\n2022-01-05 09:35:52,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play stat host time timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1590, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.6", "raw": "2022-01-05 09:36:57,005 | Failed at Play [check_inbox_driver] ************************\n2022-01-05 09:36:57,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play check inbox driver timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1591, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.7", "raw": "2022-01-05 09:37:55,005 | Failed at Play [check_os_fullname] *************************\n2022-01-05 09:37:55,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play check os full name timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1592, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.8", "raw": "2022-01-05 09:38:56,005 | Failed at Play [check_efi_firmware] ************************\n2022-01-05 09:38:56,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play check efi firmware timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1593, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_SLED_15_x-5_logs_failed_tasks_log.9", "raw": "2022-01-05 09:39:56,005 | Failed at Play [cpu_hot_add_basic] *************************\n2022-01-05 09:39:56,005 | TASK [Uninstall package on SLED 15.3] **********************\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:96\nImportError: No module named xml\nfatal: [localhost -> 10.168.201.82]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "module_failure_3_cases___", "processed": "timestamp failed at play cpu hot add basic timestamp task un install package on sled number import error no module named xml fatal localhost ip address failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1594, "name": "ansible_gosv_logs_FAILURE_Ansible_OracleLinux_8_x_67U1-3_logs_failed_tasks_log.0", "raw": "2021-12-10 14:02:41,010 | Failed at Play [gosc_cloudinit_staticip] *******************\n2021-12-10 14:02:41,010 | TASK [Get default gateway] *********************************\ntask path: /home/worker/workspace/Ansible_OracleLinux_8.x_67U1/ansible-vsphere-gos-validation/linux/guest_customization/check_network_config.yml:53\nfatal: [localhost]: FAILED! => non-zero return code when cat", "category": "non_zero_return", "processed": "timestamp failed at play go sc cloud init static ip timestamp task get default gateway fatal localhost failed non zero return code when cat", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1595, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_3_0_ISO-27_logs_failed_tasks_log.0", "raw": "2022-01-12 11:37:30,012 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2022-01-12 11:37:30,012 | TASK [Rebuild ISO image with unattend install config file] *\ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/linux/deploy_vm/rebuild_unattend_install_iso.yml:99\nfatal: [localhost]: FAILED! => non-zero return code when xorriso\n2022-01-12 11:38:02,012 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3", "category": "non_zero_return", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task rebuild iso image with un attend install configuration file fatal localhost failed non zero return code when x orr iso timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1596, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_ISO-1_logs_failed_tasks_log.0", "raw": "2022-01-12 11:41:50,012 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-01-12 11:41:50,012 | TASK [Rebuild ISO image with unattend install config file] *\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/deploy_vm/rebuild_unattend_install_iso.yml:99\nfatal: [localhost]: FAILED! => non-zero return code when xorriso\n2022-01-12 11:42:24,012 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_paravirtual_vmxnet3", "category": "non_zero_return", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task rebuild iso image with un attend install configuration file fatal localhost failed non zero return code when x orr iso timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi para virtual vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1597, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-23_logs_failed_tasks_log.0", "raw": "2022-01-04 13:12:00,004 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-04 13:12:00,004 | TASK [Install package on VMware Photon OS 4.0] *************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:53\nfatal: [localhost -> 10.187.130.143]: FAILED! => non-zero return code when tdnf", "category": "non_zero_return", "processed": "timestamp failed at play go sc perl dhcp timestamp task install package on vmware photon os number fatal localhost ip address failed non zero return code when tdnf", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1601, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-26_logs_failed_tasks_log.0", "raw": "2022-01-05 10:00:30,005 | Failed at Play [ovt_verify_install] ************************\n2022-01-05 10:00:30,005 | TASK [Install packages ['open-vm-tools']] ******************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/linux/open_vm_tools/install_ovt.yml:31\nfatal: [localhost -> 10.185.13.207]: FAILED! => non-zero return code when tdnf", "category": "non_zero_return", "processed": "timestamp failed at play ovt verify install timestamp task install packages open vm tools fatal localhost ip address failed non zero return code when tdnf", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1602, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_7_x-25_logs_failed_tasks_log.0", "raw": "2021-12-21 13:26:11,021 | Failed at Play [e1000e_network_device_ops] *****************\n2021-12-21 13:26:11,021 | TASK [Bring link 'ens224' down for RedHat] *****************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_7.x/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:77\nfatal: [localhost -> 10.182.48.70]: FAILED! => non-zero return code when nmcli", "category": "non_zero_return", "processed": "timestamp failed at play network device ops timestamp task bring link down for redhat fatal localhost ip address failed non zero return code when nm cli", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1604, "name": "ansible_gosv_logs_FAILURE_Ansible_SLED_15_SP4_65U3-3_logs_failed_tasks_log.2", "raw": "2021-12-20 12:00:11,020 | Failed at Play [vmxnet3_network_device_ops] ****************\n2021-12-20 12:00:11,020 | TASK [Bring link 'eth1' up] ********************************\ntask path: /home/worker/workspace/Ansible_SLED_15_SP4_65U3/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:88\nfatal: [localhost -> 10.184.94.66]: FAILED! => non-zero return code when ifdown", "category": "non_zero_return", "processed": "timestamp failed at play vmxnet number network device ops timestamp task bring link eth number up fatal localhost ip address failed non zero return code when if down", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1605, "name": "ansible_gosv_logs_FAILURE_Ansible_SLES_15_SP4_67GA-10_logs_failed_tasks_log.0", "raw": "2021-12-14 10:24:51,014 | Failed at Play [ovt_verify_install] ************************\n2021-12-14 10:24:51,014 | TASK [Install packages ['open-vm-tools', 'libvmtools0']] ***\ntask path: /home/worker/workspace/Ansible_SLES_15_SP4_67GA/ansible-vsphere-gos-validation/linux/open_vm_tools/install_ovt.yml:31\nfatal: [localhost -> 10.191.155.173]: FAILED! => non-zero return code when zypper", "category": "non_zero_return", "processed": "timestamp failed at play ovt verify install timestamp task install packages open vm tools library vm tools number fatal localhost ip address failed non zero return code when zypper", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1606, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.5", "raw": "2022-01-17 04:53:31,017 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-17 04:53:31,017 | TASK [Customize Linux guest OS] ****************************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization of the guest operating system is not supported due to the given reason: ", "category": "customization_is_not_supported", "processed": "timestamp failed at play go sc perl dhcp timestamp task customize linux guest os fatal localhost failed customization of the guest operating system is not supported due to the given reason", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1607, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.6", "raw": "2022-01-17 04:54:50,017 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-17 04:54:50,017 | TASK [Customize Linux guest OS] ****************************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization of the guest operating system is not supported due to the given reason: ", "category": "customization_is_not_supported", "processed": "timestamp failed at play go sc perl static ip timestamp task customize linux guest os fatal localhost failed customization of the guest operating system is not supported due to the given reason", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1608, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.7", "raw": "2022-01-17 04:56:42,017 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-17 04:56:42,017 | TASK [Customize Linux guest OS] ****************************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization of the guest operating system is not supported due to the given reason: ", "category": "customization_is_not_supported", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task customize linux guest os fatal localhost failed customization of the guest operating system is not supported due to the given reason", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1609, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_AlmaLinux_8_x-10_logs_failed_tasks_log.8", "raw": "2022-01-17 04:58:32,017 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-17 04:58:32,017 | TASK [Customize Linux guest OS] ****************************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_8.x/ansible-vsphere-gos-validation/linux/guest_customization/linux_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization of the guest operating system is not supported due to the given reason: ", "category": "customization_is_not_supported", "processed": "timestamp failed at play go sc cloud init static ip timestamp task customize linux guest os fatal localhost failed customization of the guest operating system is not supported due to the given reason", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1610, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_Main_NVMe_EFI-12_logs_failed_tasks_log.6", "raw": "2022-01-20 05:13:13,020 | Failed at Play [gosc_sanity_staticip] **********************\n2022-01-20 05:13:13,020 | TASK [Customize Windows guest OS] **************************\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_Main_NVMe_EFI/ansible-vsphere-gos-validation/windows/guest_customization/win_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization of the guest operating system is not supported due to the given reason: ", "category": "customization_is_not_supported", "processed": "timestamp failed at play go sc sanity static ip timestamp task customize windows guest os fatal localhost failed customization of the guest operating system is not supported due to the given reason", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1611, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_Main_NVMe_EFI-12_logs_failed_tasks_log.7", "raw": "2022-01-20 05:16:21,020 | Failed at Play [gosc_sanity_dhcp] **************************\n2022-01-20 05:16:21,020 | TASK [Customize Windows guest OS] **************************\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_Main_NVMe_EFI/ansible-vsphere-gos-validation/windows/guest_customization/win_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization of the guest operating system is not supported due to the given reason: ", "category": "customization_is_not_supported", "processed": "timestamp failed at play go sc sanity dhcp timestamp task customize windows guest os fatal localhost failed customization of the guest operating system is not supported due to the given reason", "solution": "deepdive", "target": "product", "version": 202205240000}, {"id": 1612, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_RHEL_9_x-38_logs_failed_tasks_log.0", "raw": "2022-01-12 09:58:25,012 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2022-01-12 09:58:25,012 | TASK [Datastore file operation] ****************************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => File 'OS/Linux/RedHatEnterpriseLinux/9/9.0/Beta/RHEL-9.0.0-20211026.10-x86_64-dvd1.iso' is absent, cannot continue\n2022-01-12 09:59:01,012 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_nvme_vmxnet3\n", "category": "file_absent", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task data store file operation fatal localhost failed file os linux redhat enterprise linux number beta rhel version id hex id number x number dvd number i so is absent can not continue timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi nvme vmxnet number", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1161, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70GA_IDE_VMXNET3_EFI-1_failed_tasks_log.0", "raw": "2022-03-28 03:39:54,028 | Failed at Play [deploy_vm_efi_ide_vmxnet3] *****************\n2022-03-28 03:39:54,028 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70GA_IDE_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:30\nfatal: [localhost]: FAILED! => IP 10.185.250.54 is not pingable\n2022-03-28 03:40:58,028 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70GA_IDE_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_ide_vmxnet3", "category": "failed_not_pingable_0509", "processed": "timestamp failed at play deploy vm efi ide vmxnet number timestamp task fail fatal localhost failed ip ip address is not pingable timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi ide vmxnet number", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1060, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Regression_SLED_15_x-19_failed_tasks_log.0", "raw": "2022-02-21 03:28:34,021 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-02-21 03:28:34,021 | TASK [Create snapshot 'BaseSnapshot' on 'test_sled15'] *****\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play nvme v hba device ops timestamp task create snapshot base snapshot on test sled number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1095, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS-17_failed_tasks_log.11", "raw": "2022-02-16 10:53:05,016 | Failed at Play [memory_hot_add_basic] **********************\n2022-02-16 10:53:05,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006378126'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play memory hot add basic timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1140, "name": "ansible_gosv_logs_202203_FAILURE_zyh_ansible_ubuntu_existing_testbed_3_1-28_failed_tasks_log.0", "raw": "2022-03-04 14:31:54,004 | Failed at Play [ovt_verify_install] ************************\n2022-03-04 14:31:54,004 | TASK [Collect filtered guest information for '10.117.16.201'] \ntask path: /home/worker/workspace/zyh_ansible_ubuntu_existing_testbed_3.1/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via ssh: Warning: Permanently added '10.117.16.201' (ED25519) to the list of known hosts.\nroot@10.117.16.201: Permission denied (publickey).", "category": "unreachable_ssh_0509_2", "processed": "timestamp failed at play ovt verify install timestamp task collect filtered guest information for ip address fatal localhost un reachable failed to connect to the host via ssh warning permanently added ip address to the list of known hosts root ip address permission denied public key", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1159, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Cycle_SLES_15_x-49_failed_tasks_log.0", "raw": "2022-03-07 22:05:59,007 | Failed at Play [sata_vhba_device_ops] **********************\n2022-03-07 22:05:59,007 | TASK [Run iozone test on new added disk] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_SLES_15.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/run_iozone_test.yml:14\nfatal: [localhost -> 10.168.170.251]: FAILED! => non-zero return code", "category": "non_zero_return_only_0509", "processed": "timestamp failed at play sata v hba device ops timestamp task run io zone test on new added disk fatal localhost ip address failed non zero return code", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1061, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.1", "raw": "2022-02-16 10:44:36,016 | Failed at Play [ovt_verify_status] *************************\n2022-02-16 10:44:36,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify status timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1062, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.11", "raw": "2022-02-16 10:49:41,016 | Failed at Play [memory_hot_add_basic] **********************\n2022-02-16 10:49:41,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play memory hot add basic timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1063, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.13", "raw": "2022-02-16 10:50:43,016 | Failed at Play [secureboot_enable_disable] *****************\n2022-02-16 10:50:43,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play secure boot enable disable timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1064, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.15", "raw": "2022-02-16 10:51:48,016 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-02-16 10:51:48,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006362701'] \ntask path: /home/worker/workspace/Ansible_SLED_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play vmxnet number network device ops timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1121, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.5", "raw": "2022-02-16 10:42:58,016 | Failed at Play [stat_hosttime] *****************************\n2022-02-16 10:42:58,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play stat host time timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1122, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.6", "raw": "2022-02-16 10:43:30,016 | Failed at Play [check_inbox_driver] ************************\n2022-02-16 10:43:30,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check inbox driver timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1123, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.7", "raw": "2022-02-16 10:44:05,016 | Failed at Play [check_os_fullname] *************************\n2022-02-16 10:44:05,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check os full name timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1124, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot-17_failed_tasks_log.8", "raw": "2022-02-16 10:44:37,016 | Failed at Play [check_efi_firmware] ************************\n2022-02-16 10:44:37,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006396465'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_65U3_IDE_VMXNET3_EFI_SecureBoot/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check efi firmware timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1125, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.0", "raw": "2022-02-16 10:38:20,016 | Failed at Play [ovt_verify_install] ************************\n2022-02-16 10:38:20,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify install timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1126, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.1", "raw": "2022-02-16 10:38:51,016 | Failed at Play [ovt_verify_status] *************************\n2022-02-16 10:38:51,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify status timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1127, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.11", "raw": "2022-02-16 10:44:24,016 | Failed at Play [memory_hot_add_basic] **********************\n2022-02-16 10:44:24,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play memory hot add basic timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1128, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.13", "raw": "2022-02-16 10:45:26,016 | Failed at Play [secureboot_enable_disable] *****************\n2022-02-16 10:45:26,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play secure boot enable disable timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1129, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.17", "raw": "2022-02-16 10:47:33,016 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-02-16 10:47:33,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1130, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.18", "raw": "2022-02-16 10:48:04,016 | Failed at Play [gosc_perl_staticip] ************************\n2022-02-16 10:48:04,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc perl static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1131, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.19", "raw": "2022-02-16 10:48:37,016 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-02-16 10:48:37,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1132, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.2", "raw": "2022-02-16 10:39:23,016 | Failed at Play [vgauth_check_service] **********************\n2022-02-16 10:39:23,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play vg auth check service timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1133, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.20", "raw": "2022-02-16 10:49:10,016 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-02-16 10:49:10,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play go sc cloud init static ip timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1134, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.26", "raw": "2022-02-16 10:52:32,016 | Failed at Play [ovt_verify_uninstall] **********************\n2022-02-16 10:52:32,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play ovt verify un install timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1135, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.3", "raw": "2022-02-16 10:39:55,016 | Failed at Play [check_ip_address] **************************\n2022-02-16 10:39:55,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check ip address timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1136, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.5", "raw": "2022-02-16 10:40:59,016 | Failed at Play [stat_hosttime] *****************************\n2022-02-16 10:40:59,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play stat host time timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1137, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.6", "raw": "2022-02-16 10:41:30,016 | Failed at Play [check_inbox_driver] ************************\n2022-02-16 10:41:30,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check inbox driver timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1139, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS-15_failed_tasks_log.8", "raw": "2022-02-16 10:42:33,016 | Failed at Play [check_efi_firmware] ************************\n2022-02-16 10:42:33,016 | TASK [Create snapshot 'BaseSnapshot' on 'test_vm_1645006395172'] \ntask path: /home/worker/workspace/Ansible_SLES_15SP4_67U3_IDE_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => Insufficient disk space on datastore ''.", "category": "unsufficient_disk_space_0509", "processed": "timestamp failed at play check efi firmware timestamp task create snapshot base snapshot on test vm number fatal localhost failed insufficient disk space on data store", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1167, "name": "ansible_gosv_logs_202202_FAILURE_Ansible_Photon_4_x_OVA_MAIN-1_failed_tasks_log.0", "raw": "2022-02-21 07:45:05,021 | Failed at Play [sata_vhba_device_ops] **********************\n2022-02-21 07:45:05,021 | TASK [absent disk to VM] ***********************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_OVA_MAIN/ansible-vsphere-gos-validation/common/vm_hot_add_remove_disk.yml:44\nexception in /vmware_guest_disk.py when main in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => Failed to manage disks for virtual machine 'test_vm' with exception : ('Unable to communicate with the remote host, since it is disconnected.', None)", "category": "unable_to_commu_as_disconnect_0509", "processed": "timestamp failed at play sata v hba device ops timestamp task absent disk to vm exception in vmware guest disk python when main in vmware python when wait for task fatal localhost failed failed to manage disks for virtual machine test vm with exception unable to communicate with the remote host since it is disconnected none", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1168, "name": "ansible_gosv_logs_202203_FAILURE_zyh_ansible_ubuntu_existing_testbed_3_1-30_failed_tasks_log.4", "raw": "2022-03-05 10:57:35,005 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-03-05 10:57:35,005 | TASK [Set VM CPU number and/or cores per socket number] ****\ntask path: /home/worker/workspace/zyh_ansible_ubuntu_existing_testbed_3.1/ansible-vsphere-gos-validation/common/vm_set_cpu_number.yml:9\nfatal: [localhost]: FAILED! => Unable to communicate with the remote host, since it is disconnected.", "category": "unable_to_commu_as_disconnect_0509", "processed": "timestamp failed at play cpu multi cores per socket timestamp task set vm cpu number and or cores per socket number fatal localhost failed unable to communicate with the remote host since it is disconnected", "solution": "retry", "target": "testbed", "version": 202205240000}, {"id": 1146, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Debian_11_x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI-14_failed_tasks_log.0", "raw": "2022-03-05 18:14:29,005 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-03-05 18:14:29,005 | TASK [Fetch file /etc/network/interfaces.d/50-cloud-init.cfg from VM guest] \ntask path: /home/worker/workspace/Ansible_Debian_11.x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Guest file /etc/network/interfaces.d/50-cloud-init.cfg does not exist : File /etc/network/interfaces.d/50-cloud-init.cfg was not found", "category": "guest_file_not_exist_0509", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task fetch file etc network interfaces d number cloud init configuration from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed guest file etc network interfaces d number cloud init configuration does not exist file etc network interfaces d number cloud init configuration was not found", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1147, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Debian_11_x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI-14_failed_tasks_log.1", "raw": "2022-03-05 18:23:07,005 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-03-05 18:23:07,005 | TASK [Fetch file /etc/network/interfaces.d/50-cloud-init.cfg from VM guest] \ntask path: /home/worker/workspace/Ansible_Debian_11.x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Guest file /etc/network/interfaces.d/50-cloud-init.cfg does not exist : File /etc/network/interfaces.d/50-cloud-init.cfg was not found", "category": "guest_file_not_exist_0509", "processed": "timestamp failed at play go sc cloud init static ip timestamp task fetch file etc network interfaces d number cloud init configuration from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed guest file etc network interfaces d number cloud init configuration does not exist file etc network interfaces d number cloud init configuration was not found", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1372, "name": "__Ansible_Regression_Ubuntu_21_10_Server_ISO-30_logs_failed_tasks_log.2", "raw": "2021-12-02 23:03:27,002 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-02 23:03:27,002 | TASK [Fetch file /tmp/hostname_f.txt from VM guest] ********\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Failed to Fetch file from Vm VMware exception : (vim.fault.GuestOperationsUnavailable) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'The guest operations agent could not be contacted.',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) []\n}\n", "category": "origin", "processed": "timestamp failed at play go sc perl static ip timestamp task fetch file tmp hostname f text from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed failed to fetch file from vm vmware exception vim fault guest operations unavailable dynamic property vmodl dynamic property message the guest operations agent could not be contacted fault message vmodl localizable message", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1541, "name": "ansible_gosv_logs_FAILURE_Ansible_Cycle_Ubuntu_20_04_3_ISO-24_logs_failed_tasks_log.2", "raw": "2022-01-05 15:46:48,005 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-05 15:46:48,005 | TASK [Fetch file /etc/hosts from VM guest] *****************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.3_ISO/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Failed to Fetch file from Vm VMware exception : (vim.fault.GuestOperationsUnavailable) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'The guest operations agent could not be contacted.',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) []\n}", "category": "soap_adapter", "processed": "timestamp failed at play go sc perl static ip timestamp task fetch file etc hosts from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed failed to fetch file from vm vmware exception vim fault guest operations unavailable dynamic property vmodl dynamic property message the guest operations agent could not be contacted fault message vmodl localizable message", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1542, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-27_logs_failed_tasks_log.0", "raw": "2022-01-12 11:50:39,012 | Failed at Play [check_quiesce_snapshot_custom_script] ******\n2022-01-12 11:50:39,012 | TASK [Fetch file /vss.log from VM guest] *******************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "soap_adapter", "processed": "timestamp failed at play check quiesce snapshot custom script timestamp task fetch file vss log from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1543, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-27_logs_failed_tasks_log.1", "raw": "2022-01-12 12:17:14,012 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-01-12 12:17:14,012 | TASK [Fetch file /var/log/vmware-imc/toolsDeployPkg.log from VM guest] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "soap_adapter", "processed": "timestamp failed at play go sc perl dhcp timestamp task fetch file var log vmware imc tools deploy package log from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1544, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-27_logs_failed_tasks_log.2", "raw": "2022-01-12 12:22:53,012 | Failed at Play [gosc_perl_staticip] ************************\n2022-01-12 12:22:53,012 | TASK [Fetch file /var/log/vmware-imc/toolsDeployPkg.log from VM guest] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "soap_adapter", "processed": "timestamp failed at play go sc perl static ip timestamp task fetch file var log vmware imc tools deploy package log from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1545, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-27_logs_failed_tasks_log.3", "raw": "2022-01-12 12:29:05,012 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-01-12 12:29:05,012 | TASK [Fetch file /var/log/vmware-imc/toolsDeployPkg.log from VM guest] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "soap_adapter", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task fetch file var log vmware imc tools deploy package log from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1546, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Photon_4_0_OVA-27_logs_failed_tasks_log.4", "raw": "2022-01-12 12:35:16,012 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-01-12 12:35:16,012 | TASK [Fetch file /var/log/vmware-imc/toolsDeployPkg.log from VM guest] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "soap_adapter", "processed": "timestamp failed at play go sc cloud init static ip timestamp task fetch file var log vmware imc tools deploy package log from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1547, "name": "ansible_gosv_logs_FAILURE_Ansible_Regression_Ubuntu_21_10_Server_ISO-38_logs_failed_tasks_log.0", "raw": "2021-12-09 12:08:39,009 | Failed at Play [gosc_perl_staticip] ************************\n2021-12-09 12:08:39,009 | TASK [Fetch file /tmp/ip_addr_show.txt from VM guest] ******\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Failed to Fetch file from Vm VMware exception : (vim.fault.GuestOperationsUnavailable) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'The guest operations agent could not be contacted.',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) []\n}", "category": "soap_adapter", "processed": "timestamp failed at play go sc perl static ip timestamp task fetch file tmp ip address show text from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed failed to fetch file from vm vmware exception vim fault guest operations unavailable dynamic property vmodl dynamic property message the guest operations agent could not be contacted fault message vmodl localizable message", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1548, "name": "ansible_gosv_logs_FAILURE_Ansible_RockyLinux_8_x_70U1-3_logs_failed_tasks_log.2", "raw": "2021-12-10 04:50:55,010 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-10 04:50:55,010 | TASK [Fetch file /tmp/readlink_etc_localtime.txt from VM guest] \ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70U1/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Failed to Fetch file from Vm VMware exception : (vim.fault.GuestOperationsUnavailable) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'The guest operations agent could not be contacted.',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) []\n}", "category": "soap_adapter", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task fetch file tmp read link etc local time text from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed failed to fetch file from vm vmware exception vim fault guest operations unavailable dynamic property vmodl dynamic property message the guest operations agent could not be contacted fault message vmodl localizable message", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1549, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_Main_NVMe_EFI-22_logs_failed_tasks_log.0", "raw": "2022-01-21 05:15:40,021 | Failed at Play [gosc_sanity_staticip] **********************\n2022-01-21 05:15:40,021 | TASK [Execute powershell command in Windows guest] *********\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_Main_NVMe_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost -> 10.187.96.110]: FAILED! => non-zero return code when Remove-AppxProvisionedPackage\n2022-01-21 05:16:07,021 | TASK [Fetch file C:\\Windows\\Temp\\vmware-imc\\guestcust.log from VM guest] \ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_Main_NVMe_EFI/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Guest file C:\\Windows\\Temp\\vmware-imc\\guestcust.log does not exist : File C:\\Windows\\Temp\\vmware-imc\\guestcust.log was not found", "category": "soap_adapter", "processed": "timestamp failed at play go sc sanity static ip timestamp task execute powershell command in windows guest fatal localhost ip address failed non zero return code when remove appx provisioned package timestamp task fetch file c windows temp vmware imc guest cust log from vm guest exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed guest file c windows temp vmware imc guest cust log does not exist file c windows temp vmware imc guest cust log was not found", "solution": "deepdive", "target": "testcase", "version": 202205240000}, {"id": 1196, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_Server_LTSC_64bit_70U1_IDE_BIOS-4_logs_failed_tasks_log.0", "raw": "2021-12-09 04:15:32,009 | Failed at Play [testbed_deploy_nimbus] *********************\n2021-12-09 04:15:32,009 | TASK [Transfer nimbus testbed deploy spec to dbc server] ***\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_64bit_70U1_IDE_BIOS/newgos_testing_internal/testbed_deploy/deploy_from_dbc_prepare.yml:52\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added 'wdc-dbc2108.eng.vmware.com' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nsvc.gosv-automation@wdc-dbc2108.eng.vmware.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play testbed deploy nimbus timestamp task transfer nimbus testbed deploy spec to database c server fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added wdc eng vmware com to the list of known hosts permission denied please try again permission denied please try again svc go sv automation wdc eng vmware com permission denied public key gss api k eye x gss api with mic password", "solution": "deepdive", "target": "infra", "version": 202205240000}, {"id": 1197, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Photon_4_x_ISO_MAIN_NVME_E1000E_EFI-13_failed_tasks_log.0", "raw": "2022-03-04 11:45:45,004 | Failed at Play [ovt_verify_uninstall] **********************\n2022-03-04 11:45:45,004 | TASK [Check testbed deploy results folder exists] **********\ntask path: /home/worker/workspace/Ansible_Photon_4.x_ISO_MAIN_NVME_E1000E_EFI/newgos_testing_internal/testbed_deploy/testbed_cleanup.yml:65\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added 'wdc-dbc2108.eng.vmware.com' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nsvc.gosv-automation@wdc-dbc2108.eng.vmware.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play ovt verify un install timestamp task check testbed deploy results folder exists fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added wdc eng vmware com to the list of known hosts permission denied please try again permission denied please try again svc go sv automation wdc eng vmware com permission denied public key gss api k eye x gss api with mic password", "solution": "deepdive", "target": "infra", "version": 202205240000}, {"id": 1198, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Cycle_Photon_4_0_ISO-41_failed_tasks_log.2", "raw": "2022-03-02 03:37:59,002 | Failed at Play [gosc_perl_staticip] ************************\n2022-03-02 03:37:59,002 | TASK [Check testbed deploy results folder exists] **********\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.0_ISO/newgos_testing_internal/testbed_deploy/testbed_cleanup.yml:65\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added 'wdc-dbc2108.eng.vmware.com' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nsvc.gosv-automation@wdc-dbc2108.eng.vmware.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play go sc perl static ip timestamp task check testbed deploy results folder exists fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added wdc eng vmware com to the list of known hosts permission denied please try again permission denied please try again svc go sv automation wdc eng vmware com permission denied public key gss api k eye x gss api with mic password", "solution": "deepdive", "target": "infra", "version": 202205240000}, {"id": 1199, "name": "ansible_gosv_logs_FAILURE_Ansible_Windows_11_64bit_Main_PVSCSI_BIOS-3_logs_failed_tasks_log.5", "raw": "2021-12-08 18:59:10,008 | Failed at Play [cpu_hot_add_basic] *************************\n2021-12-08 18:59:10,008 | TASK [Check testbed deploy results folder exists] **********\ntask path: /home/worker/workspace/Ansible_Windows_11_64bit_Main_PVSCSI_BIOS/newgos_testing_internal/testbed_deploy/testbed_cleanup.yml:65\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added 'wdc-dbc2108.eng.vmware.com' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nsvc.gosv-automation@wdc-dbc2108.eng.vmware.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play cpu hot add basic timestamp task check testbed deploy results folder exists fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added wdc eng vmware com to the list of known hosts permission denied please try again permission denied please try again svc go sv automation wdc eng vmware com permission denied public key gss api k eye x gss api with mic password", "solution": "deepdive", "target": "infra", "version": 202205240000}, {"id": 1200, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Debian_10_x_32bit_MAIN_NVME_VMXNET3_EFI-6_failed_tasks_log.2", "raw": "2022-03-05 16:37:17,005 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-03-05 16:37:17,005 | TASK [Check testbed deploy results folder exists] **********\ntask path: /home/worker/workspace/Ansible_Debian_10.x_32bit_MAIN_NVME_VMXNET3_EFI/newgos_testing_internal/testbed_deploy/testbed_cleanup.yml:65\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added 'wdc-dbc2108.eng.vmware.com' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nsvc.gosv-automation@wdc-dbc2108.eng.vmware.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play go sc cloud init static ip timestamp task check testbed deploy results folder exists fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added wdc eng vmware com to the list of known hosts permission denied please try again permission denied please try again svc go sv automation wdc eng vmware com permission denied public key gss api k eye x gss api with mic password", "solution": "deepdive", "target": "infra", "version": 202205240000}, {"id": 1201, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Photon_4_x_ISO_70GA_SATA_E1000E_BIOS-17_failed_tasks_log.0", "raw": "2022-03-31 17:34:39,031 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-03-31 17:34:39,031 | TASK [Rescan all scsi devices] *****************************\ntask path: /home/worker/workspace/Ansible_Photon_4.x_ISO_70GA_SATA_E1000E_BIOS/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:30\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.206.85.113' (ECDSA) to the list of known hosts.\nroot@10.206.85.113: Permission denied (publickey,keyboard-interactive).", "category": "login_lockout", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task re scan all scsi devices fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1202, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI-31_failed_tasks_log.0", "raw": "2022-03-31 15:03:29,031 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-03-31 15:03:29,031 | TASK [Run iozone test on new added disk] *******************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/run_iozone_test.yml:14\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.206.98.221' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nroot@10.206.98.221: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play para virtual v hba device ops timestamp task run io zone test on new added disk fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again permission denied please try again root ip address permission denied public key gss api k eye x gss api with mic password", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1203, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI-31_failed_tasks_log.1", "raw": "2022-03-31 15:06:14,031 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-03-31 15:06:14,031 | TASK [Run iozone test on new added disk] *******************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/run_iozone_test.yml:14\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.206.98.221' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nroot@10.206.98.221: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task run io zone test on new added disk fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again permission denied please try again root ip address permission denied public key gss api k eye x gss api with mic password", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1204, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI-31_failed_tasks_log.2", "raw": "2022-03-31 15:08:52,031 | Failed at Play [sata_vhba_device_ops] **********************\n2022-03-31 15:08:52,031 | TASK [Run iozone test on new added disk] *******************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/run_iozone_test.yml:14\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.206.98.221' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nroot@10.206.98.221: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play sata v hba device ops timestamp task run io zone test on new added disk fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again permission denied please try again root ip address permission denied public key gss api k eye x gss api with mic password", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1205, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_OVA_MAIN-7_failed_tasks_log.0", "raw": "2022-03-07 11:52:50,007 | Failed at Play [e1000e_network_device_ops] *****************\n2022-03-07 11:52:50,007 | TASK [Apply netplan configuration file for new added nic ens224 in Ubuntu] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_MAIN/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:86\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.185.2.170' (ECDSA) to the list of known hosts.\nroot@10.185.2.170: Permission denied (publickey,keyboard-interactive).", "category": "login_lockout", "processed": "timestamp failed at play network device ops timestamp task apply net plan configuration file for new added nic in ubuntu fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1206, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_OVA_67GA-10_failed_tasks_log.1", "raw": "2022-03-07 13:55:07,007 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-03-07 13:55:07,007 | TASK [Apply netplan configuration file for new added nic ens224 in Ubuntu] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_67GA/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:86\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.186.66.64' (ECDSA) to the list of known hosts.\nroot@10.186.66.64: Permission denied (publickey,keyboard-interactive).", "category": "login_lockout", "processed": "timestamp failed at play vmxnet number network device ops timestamp task apply net plan configuration file for new added nic in ubuntu fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1207, "name": "ansible_gosv_logs_202203_FAILURE_Ansible_Ubuntu_LTS_Server_OVA_67GA-9_failed_tasks_log.0", "raw": "2022-03-07 06:20:10,007 | Failed at Play [e1000e_network_device_ops] *****************\n2022-03-07 06:20:10,007 | TASK [Apply netplan configuration file for new added nic ens224 in Ubuntu] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_67GA/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:86\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.186.66.64' (RSA) to the list of known hosts.\nroot@10.186.66.64: Permission denied (publickey,keyboard-interactive).", "category": "login_lockout", "processed": "timestamp failed at play network device ops timestamp task apply net plan configuration file for new added nic in ubuntu fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address rsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1208, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS-36_failed_tasks_log.0", "raw": "2022-04-01 06:10:07,001 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-04-01 06:10:07,001 | TASK [Get block devices] ***********************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/get_vm_device_list.yml:8\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.170.66.69' (ECDSA) to the list of known hosts.\nroot@10.170.66.69: Permission denied (publickey,keyboard-interactive).", "category": "login_lockout", "processed": "timestamp failed at play para virtual v hba device ops timestamp task get block devices fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1209, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Ubuntu_LTS_Server_ISO_MAIN_LSILOGIC_E1000E_EFI-17_failed_tasks_log.0", "raw": "2022-04-28 04:32:52,028 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-04-28 04:32:52,028 | TASK [Get link 'ens192' status] ****************************\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_MAIN_LSILOGIC_E1000E_EFI/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:138\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.78.112.161' (ECDSA) to the list of known hosts.\nroot@10.78.112.161: Permission denied (publickey,keyboard-interactive).", "category": "login_lockout", "processed": "timestamp failed at play vmxnet number network device ops timestamp task get link status fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1210, "name": "ansible_gosv_logs_202205_FAILURE_Ansible_RHEL_8_x_67GA_PARAVIRTUAL_E1000E_EFI-13_failed_tasks_log.0", "raw": "2022-05-04 05:07:27,004 | Failed at Play [ovt_verify_install] ************************\n2022-05-04 05:07:27,004 | TASK [Uninstall packages ['open-vm-tools', 'open-vm-tools-desktop']] \ntask path: /home/worker/workspace/Ansible_RHEL_8.x_67GA_PARAVIRTUAL_E1000E_EFI/ansible-vsphere-gos-validation/linux/open_vm_tools/uninstall_ovt.yml:12\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: mux_client_request_session: read from master failed: Broken pipe\nWarning: Permanently added '10.186.28.173' (RSA) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nroot@10.186.28.173: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", "category": "login_lockout", "processed": "timestamp failed at play ovt verify install timestamp task un install packages open vm tools open vm tools desktop fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout mux client request session read from master failed broken pipe warning permanently added ip address rsa to the list of known hosts permission denied please try again permission denied please try again root ip address permission denied public key gss api k eye x gss api with mic password", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1211, "name": "ansible_gosv_logs_FAILURE_Ansible_Ubuntu_Server_ISO_70U1-1_logs_failed_tasks_log.1", "raw": "2021-12-17 11:52:20,017 | Failed at Play [vmxnet3_network_device_ops] ****************\n2021-12-17 11:52:20,017 | TASK [Apply netplan configuration file for new added nic ens224] \ntask path: /home/worker/workspace/Ansible_Ubuntu_Server_ISO_70U1/ansible-vsphere-gos-validation/linux/network_device_ops/enable_new_ethernet.yml:62\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.206.98.67' (RSA) to the list of known hosts.\nroot@10.206.98.67: Permission denied (publickey,keyboard-interactive).", "category": "login_lockout", "processed": "timestamp failed at play vmxnet number network device ops timestamp task apply net plan configuration file for new added nic fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address rsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1401, "name": "__Ansible_Regression_Ubuntu_21_10_Server_ISO-22_logs_failed_tasks_log.0", "raw": "\n\n2021-12-02 09:17:10,002 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2021-12-02 09:17:10,002 | TASK [Collect filtered guest information for '10.180.101.53'] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_21.10_Server_ISO/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.180.101.53' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nroot@10.180.101.53: Permission denied (publickey,password).", "category": "login_lockout", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task collect filtered guest information for ip address fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again permission denied please try again root ip address permission denied public key password", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1402, "name": "__Ansible_Ubuntu_Server_ISO_70GA-8_logs_failed_tasks_log.0", "raw": "2021-12-01 07:42:05,001 | Failed at Play [gosc_perl_dhcp] ****************************\n2021-12-01 07:42:05,001 | TASK [Collect filtered guest information for '10.78.127.216'] \ntask path: /home/worker/workspace/Ansible_Ubuntu_Server_ISO_70GA/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.78.127.216' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nroot@10.78.127.216: Permission denied (publickey,password).", "category": "login_lockout", "processed": "timestamp failed at play go sc perl dhcp timestamp task collect filtered guest information for ip address fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again permission denied please try again root ip address permission denied public key password", "solution": "retry", "target": "targetvm", "version": 202205240000}, {"id": 1158, "name": "ansible_gosv_logs_202204_FAILURE_Ansible_Debian_11_x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI-39_failed_tasks_log.0", "raw": "2022-04-21 01:24:12,021 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-04-21 01:24:12,021 | TASK [Copy testbed spec file to dbc server failed] *********\ntask path: /home/worker/workspace/Ansible_Debian_11.x_64bit_MAIN_PARAVIRTUAL_VMXNET3_EFI/newgos_testing_internal/testbed_deploy/deploy_from_dbc_prepare.yml:70\nfatal: [localhost]: FAILED! => Copy nimbus testbed spec to dbc server sc-dbc2154.eng.vmware.com failed, can not execute nimbus command on it", "category": "copy_nimbus_spec_fail_0509", "processed": "timestamp failed at play testbed deploy nimbus timestamp task copy testbed spec file to database c server failed fatal localhost failed copy nimbus testbed spec to database c servers c eng vmware com failed can not execute nimbus command on it", "solution": "deepdive", "target": "infra", "version": 202205240000}, {"id": 1535, "name": "ansible_gosv_logs_FAILURE_Ansible_AlmaLinux_8_x_67U3-2_logs_failed_tasks_log.0", "raw": "2021-12-10 17:54:49,010 | Failed at Play [deploy_vm_efi_sata_vmxnet3] ****************\n2021-12-10 17:54:49,010 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_67U3/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.187.118.239:22\n2021-12-10 17:56:07,010 | TASK [Exit testing when exit_testing_when_fail is set True] \ntask path: /home/worker/workspace/Ansible_AlmaLinux_8.x_67U3/ansible-vsphere-gos-validation/linux/setup/test_rescue.yml:52\nfatal: [localhost]: FAILED! => Failed to run test case deploy_vm_efi_sata_vmxnet3", "category": "timeout_openssh__2", "processed": "timestamp failed at play deploy vm efi sata vmxnet number timestamp task wait for port number to become open or contain specific keyword fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task exit testing when exit testing when fail is set true fatal localhost failed failed to run test case deploy vm efi sata vmxnet number", "solution": "deepdive", "target": "targetvm", "version": 202205240000}, {"id": 1378, "name": "__Ansible_Regression_RockyLinux_8_x-5_logs_failed_tasks_log.0", "raw": "2021-11-26 07:24:36,026 | Failed at Play [env_setup] *********************************\n2021-11-26 07:24:36,026 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Regression_RockyLinux_8.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "vm_same_name", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202205240000}, {"id": 1613, "name": "22.txt", "raw": "2022-05-17 08:20:47,017 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-17 08:20:47,017 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220517070407.log] \ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-05-17 08:21:26,017 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3\n", "category": "output_hidden_no_log", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1614, "name": "26.txt", "raw": "2022-05-16 15:14:19,016 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-16 15:14:19,016 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220516135726.log] \ntask path: /home/worker/workspace/Ansible_CentOS_8.x_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-05-16 15:14:51,016 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_CentOS_8.x_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "output_hidden_no_log", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible centos number x main para virtual vmxnet number efi ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible centos number x main para virtual vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1615, "name": "27.txt", "raw": "2022-05-17 05:42:48,017 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2022-05-17 05:42:48,017 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220517042722.log] \ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-05-17 05:43:21,017 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_nvme_vmxnet3", "category": "output_hidden_no_log", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible rocky linux number x nvme vmxnet number efi ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible rocky linux number x nvme vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1616, "name": "39.txt", "raw": "2022-05-17 06:01:20,017 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-17 06:01:20,017 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220517044602.log] \ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-05-17 06:01:52,017 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_RockyLinux_8.x_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "output_hidden_no_log", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible rocky linux number x main para virtual vmxnet number efi ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible rocky linux number x main para virtual vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1628, "name": "19.txt", "raw": "2022-06-06 08:39:53,006 | Failed at Play [vgauth_check_service] **********************\n2022-06-06 08:39:53,006 | TASK [Skip testcase: vgauth_check_service, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'vgauth_check_service' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play vg auth check service timestamp task skip test case vg auth check service reason blocked task path home worker workspace ansible windows number main para virtual vmxnet number efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case vg auth check service is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1617, "name": "47.txt", "raw": "2022-05-17 19:06:08,017 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-17 19:06:08,017 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220517175148.log] \ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_9.x/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-05-17 19:06:41,017 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_9.x/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "output_hidden_no_log", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle rhel number x ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible cycle rhel number x ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1618, "name": "48.txt", "raw": "2022-05-17 19:21:54,017 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-17 19:21:54,017 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220517180421.log] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-05-17 19:22:28,017 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "output_hidden_no_log", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1619, "name": "80.txt", "raw": "2022-05-30 07:33:38,030 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-30 07:33:38,030 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220530054052.log] \ntask path: /home/worker/workspace/Ansible_RHEL_9.x_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-05-30 07:34:10,030 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_RHEL_9.x_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "output_hidden_no_log", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible rhel number x main para virtual vmxnet number efi ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible rhel number x main para virtual vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1625, "name": "1.txt", "raw": "2022-06-06 07:38:54,006 | Failed at Play [mouse_driver_vmtools] **********************\n2022-06-06 07:38:54,006 | TASK [Skip testcase: mouse_driver_vmtools, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_PARAVIRTUAL_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'mouse_driver_vmtools' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play mouse driver vm tools timestamp task skip test case mouse driver vm tools reason blocked task path home worker workspace ansible windows server lts c main para virtual vmxnet number bios ansible vsphere gos validation common skip test case yml number fatal localhost failed test case mouse driver vm tools is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1620, "name": "89.txt", "raw": "2022-06-03 00:50:07,003 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-06-03 00:50:07,003 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220602233434.log] \ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-06-03 00:50:42,003 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "output_hidden_no_log", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle centos number x ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible cycle centos number x ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1621, "name": "58.txt", "raw": "2022-05-23 16:42:16,023 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-05-23 16:42:16,023 | TASK [Wait for new device to be present] *******************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:80\nfatal: [localhost]: UNREACHABLE! => Failed to create temporary directory. In some cases, you may have been able to authenticate and did not have permissions on the target directory. Consider changing the remote tmp path in ansible.cfg to a path rooted in \"/tmp\", for more error information use -vvv. Failed command was: ( umask 77 && mkdir -p \"` echo /tmp `\"&& mkdir \"` echo /tmp/ansible-tmp-1653324136.7846885-16090-258133457335772 `\" && echo ansible-tmp-1653324136.7846885-16090-258133457335772=\"` echo /tmp/ansible-tmp-1653324136.7846885-16090-258133457335772 `\" ), exited with result 1\n2022-05-23 16:42:16,023 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:91\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': 'Failed to create temporary directory. In some cases, you may have been able to authenticate and did not have permissions on the target directory. Consider changing the remote tmp path in ansible.cfg to a path rooted in \"/tmp\", for more error information use -vvv. Failed command was: ( umask 77 && mkdir -p \"` echo /tmp `\"&& mkdir \"` echo /tmp/ansible-tmp-1653324136.7846885-16090-258133457335772 `\" && echo ansible-tmp-1653324136.7846885-16090-258133457335772=\"` echo /tmp/ansible-tmp-1653324136.7846885-16090-258133457335772 `\" ), exited with result 1', 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "fail_to_create_tem_dir", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task wait for new device to be present task path home worker workspace ansible regression ubuntu number server iso ansible vsphere gos validation linux v hba hot add remove wait device list changed yml number fatal localhost un reachable failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo tmp mkdir echo tmp ansible tmp hex id number timestamp echo ansible tmp hex id number timestamp echo tmp ansible tmp hex id number timestamp exited with result number timestamp task guest os un reachable task path home worker workspace ansible regression ubuntu number server iso ansible vsphere gos validation linux v hba hot add remove wait device list changed yml number fatal localhost failed changed false message failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo tmp mkdir echo tmp ansible tmp hex id number timestamp echo ansible tmp hex id number timestamp echo tmp ansible tmp hex id number timestamp exited with result number skip reason host localhost is un reachable un reachable true", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1624, "name": "0.txt", "raw": "2022-06-06 06:03:18,006 | Failed at Play [mouse_driver_vmtools] **********************\n2022-06-06 06:03:18,006 | TASK [Skip testcase: mouse_driver_vmtools, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'mouse_driver_vmtools' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play mouse driver vm tools timestamp task skip test case mouse driver vm tools reason blocked task path home worker workspace ansible windows server lts c main nvme bios ansible vsphere gos validation common skip test case yml number fatal localhost failed test case mouse driver vm tools is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1626, "name": "17.txt", "raw": "2022-06-06 08:39:01,006 | Failed at Play [vgauth_check_service] **********************\n2022-06-06 08:39:01,006 | TASK [Skip testcase: vgauth_check_service, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'vgauth_check_service' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play vg auth check service timestamp task skip test case vg auth check service reason blocked task path home worker workspace ansible windows number main nvme efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case vg auth check service is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1627, "name": "18.txt", "raw": "2022-06-06 07:44:14,006 | Failed at Play [vgauth_check_service] **********************\n2022-06-06 07:44:14,006 | TASK [Skip testcase: vgauth_check_service, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'vgauth_check_service' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play vg auth check service timestamp task skip test case vg auth check service reason blocked task path home worker workspace ansible windows server lts c main nvme bios ansible vsphere gos validation common skip test case yml number fatal localhost failed test case vg auth check service is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1629, "name": "2.txt", "raw": "2022-06-06 06:22:35,006 | Failed at Play [mouse_driver_vmtools] **********************\n2022-06-06 06:22:35,006 | TASK [Skip testcase: mouse_driver_vmtools, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'mouse_driver_vmtools' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play mouse driver vm tools timestamp task skip test case mouse driver vm tools reason blocked task path home worker workspace ansible windows number main para virtual vmxnet number efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case mouse driver vm tools is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1630, "name": "3.txt", "raw": "2022-06-06 07:38:49,006 | Failed at Play [mouse_driver_vmtools] **********************\n2022-06-06 07:38:49,006 | TASK [Skip testcase: mouse_driver_vmtools, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'mouse_driver_vmtools' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play mouse driver vm tools timestamp task skip test case mouse driver vm tools reason blocked task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case mouse driver vm tools is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1631, "name": "4.txt", "raw": "2022-06-06 08:37:33,006 | Failed at Play [mouse_driver_vmtools] **********************\n2022-06-06 08:37:33,006 | TASK [Skip testcase: mouse_driver_vmtools, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'mouse_driver_vmtools' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play mouse driver vm tools timestamp task skip test case mouse driver vm tools reason blocked task path home worker workspace ansible windows number main nvme efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case mouse driver vm tools is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1632, "name": "5.txt", "raw": "2022-06-06 08:41:44,006 | Failed at Play [stat_balloon] ******************************\n2022-06-06 08:41:44,006 | TASK [Skip testcase: stat_balloon, reason: Blocked] ********\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'stat_balloon' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play stat balloon timestamp task skip test case stat balloon reason blocked task path home worker workspace ansible windows number main para virtual vmxnet number efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case stat balloon is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1633, "name": "6.txt", "raw": "2022-06-06 07:42:00,006 | Failed at Play [stat_balloon] ******************************\n2022-06-06 07:42:00,006 | TASK [Skip testcase: stat_balloon, reason: Blocked] ********\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_PARAVIRTUAL_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'stat_balloon' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play stat balloon timestamp task skip test case stat balloon reason blocked task path home worker workspace ansible windows server lts c main para virtual vmxnet number bios ansible vsphere gos validation common skip test case yml number fatal localhost failed test case stat balloon is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1683, "name": "10.txt", "raw": "2022-05-25 16:49:06,025 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-25 16:49:06,025 | TASK [Testbed deploy result is not PASS] *******************\ntask path: /home/worker/workspace/Ansible_SLED_15SP4_MAIN_NVME_E1000E_BIOS/newgos_testing_internal/testbed_deploy/parse_testbed_info.yml:10\nfatal: [localhost]: FAILED! => Get deployment result in testbedInfo.json is 'FAIL', not PASS", "category": "testbedinfo_fail", "processed": "timestamp failed at play testbed deploy nimbus timestamp task testbed deploy result is not pass task path home worker workspace ansible sled main nvme bios new gos testing internal testbed deploy parse testbed info yml number fatal localhost failed get deployment result in testbed info json is fail not pass", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1634, "name": "7.txt", "raw": "2022-06-06 06:06:32,006 | Failed at Play [stat_balloon] ******************************\n2022-06-06 06:06:32,006 | TASK [Skip testcase: stat_balloon, reason: Blocked] ********\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'stat_balloon' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play stat balloon timestamp task skip test case stat balloon reason blocked task path home worker workspace ansible windows server lts c main nvme bios ansible vsphere gos validation common skip test case yml number fatal localhost failed test case stat balloon is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1635, "name": "70.txt", "raw": "2022-05-25 14:40:06,025 | Failed at Play [stat_balloon] ******************************\n2022-05-25 14:40:06,025 | TASK [Skip testcase: stat_balloon, reason: Blocked] ********\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'stat_balloon' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play stat balloon timestamp task skip test case stat balloon reason blocked task path home worker workspace ansible cycle windows number ansible vsphere gos validation common skip test case yml number fatal localhost failed test case stat balloon is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1636, "name": "8.txt", "raw": "2022-06-06 07:40:32,006 | Failed at Play [stat_balloon] ******************************\n2022-06-06 07:40:32,006 | TASK [Skip testcase: stat_balloon, reason: Blocked] ********\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'stat_balloon' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play stat balloon timestamp task skip test case stat balloon reason blocked task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case stat balloon is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1637, "name": "9.txt", "raw": "2022-06-06 08:40:53,006 | Failed at Play [stat_balloon] ******************************\n2022-06-06 08:40:53,006 | TASK [Skip testcase: stat_balloon, reason: Blocked] ********\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'stat_balloon' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play stat balloon timestamp task skip test case stat balloon reason blocked task path home worker workspace ansible windows number main nvme efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case stat balloon is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1638, "name": "92.txt", "raw": "2022-06-06 07:40:59,006 | Failed at Play [vgauth_check_service] **********************\n2022-06-06 07:40:59,006 | TASK [Skip testcase: vgauth_check_service, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_PARAVIRTUAL_VMXNET3_BIOS/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'vgauth_check_service' is blocked because VMware tools installed: False, running: False", "category": "vmtools_not_installed", "processed": "timestamp failed at play vg auth check service timestamp task skip test case vg auth check service reason blocked task path home worker workspace ansible windows server lts c main para virtual vmxnet number bios ansible vsphere gos validation common skip test case yml number fatal localhost failed test case vg auth check service is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1639, "name": "11.txt", "raw": "2022-05-17 16:43:54,017 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-17 16:43:54,017 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_9.x/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Cycle_AlmaLinux_9.x-1/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible cycle alma linux number x new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible cycle alma linux number x number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1640, "name": "12.txt", "raw": "2022-05-17 16:45:07,017 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-17 16:45:07,017 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Cycle_RockyLinux_8.x/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Cycle_RockyLinux_8.x-88/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible cycle rocky linux number x new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible cycle rocky linux number x number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1641, "name": "13.txt", "raw": "2022-05-17 17:38:03,017 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-17 17:38:03,017 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Cycle_Windows_11_64-119/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible cycle windows number new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible cycle windows number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1642, "name": "14.txt", "raw": "2022-05-17 19:23:08,017 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-17 19:23:08,017 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Cycle_SLED_15.x/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Cycle_SLED_15.x-82/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible cycle sled number x new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible cycle sled number x number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1643, "name": "54.txt", "raw": "2022-05-16 13:43:47,016 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-16 13:43:47,016 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Flatcar_main/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Flatcar_main-39/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible flatcar main new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible flatcar main number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1686, "name": "50.txt", "raw": "2022-05-16 08:04:47,016 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-16 08:04:47,016 | TASK [Testbed deploy result is not PASS] *******************\ntask path: /home/worker/workspace/Ansible_Flatcar_70U3/newgos_testing_internal/testbed_deploy/parse_testbed_info.yml:10\nfatal: [localhost]: FAILED! => Get deployment result in testbedInfo.json is 'INVALID', not PASS", "category": "testbedinfo_fail", "processed": "timestamp failed at play testbed deploy nimbus timestamp task testbed deploy result is not pass task path home worker workspace ansible flatcar new gos testing internal testbed deploy parse testbed info yml number fatal localhost failed get deployment result in testbed info json is invalid not pass", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1644, "name": "64.txt", "raw": "2022-05-24 08:22:04,024 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-24 08:22:04,024 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_7.x/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Cycle_RHEL_7.x-85/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible cycle rhel number x new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible cycle rhel number x number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1645, "name": "65.txt", "raw": "2022-05-17 16:43:37,017 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-17 16:43:37,017 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Cycle_OracleLinux_8.x/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Cycle_OracleLinux_8.x-77/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible cycle oracle linux number x new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible cycle oracle linux number x number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1646, "name": "67.txt", "raw": "2022-05-25 05:40:55,025 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-25 05:40:55,025 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U1_IDE_E1000E_BIOS/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Windows_Server_LTSC_70U1_IDE_E1000E_BIOS-32/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible windows server lts c ide bios new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible windows server lts c ide bios number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1647, "name": "74.txt", "raw": "2022-05-26 05:43:00,026 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-26 05:43:00,026 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U1_SATA_E1000E_EFI/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Windows_Server_LTSC_70U1_SATA_E1000E_EFI-31/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible windows server lts c sata efi new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible windows server lts c sata efi number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1648, "name": "77.txt", "raw": "2022-05-26 17:55:18,026 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-26 17:55:18,026 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_AlmaLinux_9.x_70U3_NVME_VMXNET3_EFI/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_AlmaLinux_9.x_70U3_NVME_VMXNET3_EFI-18/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible alma linux number x nvme vmxnet number efi new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible alma linux number x nvme vmxnet number efi number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1649, "name": "78.txt", "raw": "2022-05-26 17:55:33,026 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-26 17:55:33,026 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_AlmaLinux_9.x_70GA_IDE_VMXNET3_BIOS/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_AlmaLinux_9.x_70GA_IDE_VMXNET3_BIOS-12/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible alma linux number x number ga ide vmxnet number bios new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible alma linux number x number ga ide vmxnet number bios number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1650, "name": "87.txt", "raw": "2022-06-01 07:32:44,001 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-06-01 07:32:44,001 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_64/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Regression_Windows_10_64-65/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible regression windows number new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible regression windows number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1651, "name": "93.txt", "raw": "2022-06-06 15:46:07,006 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-06-06 15:46:07,006 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Regression_Photon_4.0_OVA-73/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible regression photon number ova new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible regression photon number ova number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1652, "name": "95.txt", "raw": "2022-06-07 10:51:56,007 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-06-07 10:51:56,007 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/newgos_testing_internal/testbed_deploy/deploy_from_dbc_run.yml:75\nfatal: [localhost]: FAILED! => Failed to fetch nimbus testbed deploy result http://sc-dbc2154.eng.vmware.com/qiz/nimbus/Ansible_Windows_11_MAIN_NVME_E1000E_EFI-43/testbed_result/testbedInfo.json from dbc server sc-dbc2154.eng.vmware.com. Nimbus testbed deployment failed.", "category": "fail_fetch_nimbus_result", "processed": "timestamp failed at play testbed deploy nimbus timestamp task fail task path home worker workspace ansible windows number main nvme efi new gos testing internal testbed deploy deploy from database c run yml number fatal localhost failed failed to fetch nimbus testbed deploy result http sc eng vmware com qiz nimbus ansible windows number main nvme efi number testbed result testbed info json from database c servers c eng vmware com nimbus testbed deployment failed", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1653, "name": "23.txt", "raw": "2022-02-06 14:48:45,006 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-02-06 14:48:45,006 | TASK [Execute powershell command in Windows guest] *********task path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nConnectionResetError: [Errno 104] Connection reset by peer\nurllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\nrequests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, ''Connection reset by peer'))\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.1232123", "category": "connect_reset_unexpect_failure", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task execute powershell command in windows guest task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number connection reset error error number connection reset by peer url library number exceptions protocol error connection aborted connection reset error number connection reset by peer requests exceptions connection error connection aborted connection reset error number connection reset by peer fatal localhost failed unexpected failure during module execution number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1654, "name": "69.txt", "raw": "2022-05-25 06:50:25,025 | Failed at Play [wintools_complete_install_verify] **********\n2022-05-25 06:50:25,025 | TASK [Get VM 'test_vm' snapshot facts] *********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_snapshot_facts.yml:4\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.170.69.228:443 : [Errno 110] Connection timed out", "category": "unknown_connect_vc", "processed": "timestamp failed at play win tools complete install verify timestamp task get vm test vm snapshot facts task path home worker workspace ansible windows server lts c main nvme bios ansible vsphere gos validation common vm get snapshot facts yml number exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number connection timed out", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1655, "name": "76.txt", "raw": "2022-05-26 10:18:37,026 | Failed at Play [vmlibrary_main] ****************************\n2022-05-26 10:18:37,026 | TASK [Execute powershell command 'C:\\vmlibrary\\winVMlibrary.ps1 -Config -CleanupFiles -ExeSdelete'] \ntask path: /home/worker/workspace/test_vmlibrary/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost -> 10.191.137.205]: FAILED! => non-zero return code when C:\\vmlibrary\\winVMlibrary.ps1\n2022-05-26 10:19:50,026 | TASK [Fail the task and quit] ******************************\ntask path: /home/worker/workspace/test_vmlibrary/newgos_testing_internal/vmlibrary/vmlibrary_main.yml:41\nfatal: [localhost]: FAILED! => Failed to export windows-11-25126-64bit as VMLibrary template from 10.191.141.87", "category": "fail_export_lib_template", "processed": "timestamp failed at play vm library main timestamp task execute powershell command c vm library win vm library ps number configuration cleanup files exes delete task path home worker workspace test vm library ansible vsphere gos validation windows utilities win execute command yml number fatal localhost ip address failed nonzero return code when c vm library win vm library ps number timestamp task fail the task and quit task path home worker workspace test vm library new gos testing internal vm library vm library main yml number fatal localhost failed failed to export windows number b it as vm library template from ip address", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1656, "name": "91.txt", "raw": "2022-06-06 02:31:46,006 | Failed at Play [deploy_vm_efi_lsilogic_vmxnet3] ************\n2022-06-06 02:31:46,006 | TASK [Datastore file operation] ****************************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_ISO/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => File 'OS/Linux/Ubuntu/22.04/GA/ubuntu-22.04-live-server-amd64.iso' is absent, cannot continue\n2022-06-06 02:31:47,006 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_ISO/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogic_vmxnet3", "category": "absent_cannot_continue", "processed": "timestamp failed at play deploy vm efi lsi logic vmxnet number timestamp task data store file operation task path home worker workspace ansible regression ubuntu number server iso ansible vsphere gos validation common esxi check delete data store file yml number fatal localhost failed file os linux ubuntu number ga ubuntu number live server amd number i so is absent can not continue timestamp task testing exit due to failure task path home worker workspace ansible regression ubuntu number server iso ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic vmxnet number", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1657, "name": "20.txt", "raw": "2022-05-23 04:57:25,023 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-05-23 04:57:25,023 | TASK [Wait for new device to be absent] ********************\ntask path: /home/worker/workspace/Ansible_Regression_Flatcar_OVA/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:80\nfatal: [localhost -> 10.191.154.59]: FAILED! =>  when lsblk", "category": "failed_when_lsblk", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task wait for new device to be absent task path home worker workspace ansible regression flatcar ova ansible vsphere gos validation linux v hba hot add remove wait device list changed yml number fatal localhost ip address failed when ls blk", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1658, "name": "79.txt", "raw": "2022-05-28 04:24:47,028 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-05-28 04:24:47,028 | TASK [Wait for new device to be absent] ********************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_LTS/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:80\nfatal: [localhost -> 10.180.106.131]: FAILED! =>  when lsblk", "category": "failed_when_lsblk", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task wait for new device to be absent task path home worker workspace ansible cycle flatcar lts ansible vsphere gos validation linux v hba hot add remove wait device list changed yml number fatal localhost ip address failed when ls blk", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1687, "name": "85.txt", "raw": "2022-06-02 07:26:17,002 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-06-02 07:26:17,002 | TASK [Testbed deploy result is not PASS] *******************\ntask path: /home/worker/workspace/test_vmlibrary/newgos_testing_internal/testbed_deploy/parse_testbed_info.yml:10\nfatal: [localhost]: FAILED! => Get deployment result in testbedInfo.json is 'FAIL', not PASS", "category": "testbedinfo_fail", "processed": "timestamp failed at play testbed deploy nimbus timestamp task testbed deploy result is not pass task path home worker workspace test vm library new gos testing internal testbed deploy parse testbed info yml number fatal localhost failed get deployment result in testbed info json is fail not pass", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1682, "name": "83.txt", "raw": "2022-05-30 16:49:53,030 | Failed at Play [check_quiesce_snapshot] ********************\n2022-05-30 16:49:53,030 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_64/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "fail_to_revert_base_snap", "processed": "timestamp failed at play check quiesce snapshot timestamp task revert snapshot failed task path home worker workspace ansible regression windows number ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1684, "name": "15.txt", "raw": "2022-05-25 17:16:26,025 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-25 17:16:26,025 | TASK [Testbed deploy result is not PASS] *******************\ntask path: /home/worker/workspace/Ansible_SLES_15SP4_MAIN_PARAVIRTUAL_VMXNET3_EFI/newgos_testing_internal/testbed_deploy/parse_testbed_info.yml:10\nfatal: [localhost]: FAILED! => Get deployment result in testbedInfo.json is 'FAIL', not PASS", "category": "testbedinfo_fail", "processed": "timestamp failed at play testbed deploy nimbus timestamp task testbed deploy result is not pass task path home worker workspace ansible sles main para virtual vmxnet number efi new gos testing internal testbed deploy parse testbed info yml number fatal localhost failed get deployment result in testbed info json is fail not pass", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1685, "name": "16.txt", "raw": "2022-05-25 16:54:11,025 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-25 16:54:11,025 | TASK [Testbed deploy result is not PASS] *******************\ntask path: /home/worker/workspace/Ansible_SLES_15SP4_MAIN_NVME_E1000E_BIOS/newgos_testing_internal/testbed_deploy/parse_testbed_info.yml:10\nfatal: [localhost]: FAILED! => Get deployment result in testbedInfo.json is 'FAIL', not PASS", "category": "testbedinfo_fail", "processed": "timestamp failed at play testbed deploy nimbus timestamp task testbed deploy result is not pass task path home worker workspace ansible sles main nvme bios new gos testing internal testbed deploy parse testbed info yml number fatal localhost failed get deployment result in testbed info json is fail not pass", "solution": "retry", "target": "nimbus", "version": 202206171000}, {"id": 1674, "name": "68.txt", "raw": "2022-05-25 06:58:17,025 | Failed at Play [memory_hot_add_basic] **********************\n2022-05-25 06:58:17,025 | TASK [Execute powershell command '(get-wmiobject win32_computersystem | select numberoflogicalprocessors, numberofprocessors | ft -hide | Out-String).trim()'] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nsocket.timeout: The read operation timed out\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='10.191.225.51', port=5986): Read timed out. (read timeout=600)\nrequests.exceptions.ReadTimeout: HTTPSConnectionPool(host='10.191.225.51', port=5986): Read timed out. (read timeout=600)\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "socket_timeout", "processed": "timestamp failed at play memory hot add basic timestamp task execute powershell command get wmi object win number computer system select number of logical processors number of processors fth ide out string trim task path home worker workspace ansible windows server lts c lsi logic sas bios ansible vsphere gos validation windows utilities win execute command yml number socket timeout the read operation timed out url library number exceptions read timeout error https connection pool host ip address port number read timed out read timeout number requests exceptions read timeout https connection pool host ip address port number read timed out read timeout number fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1675, "name": "72.txt", "raw": "2022-05-26 03:14:26,026 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-05-26 03:14:26,026 | TASK [Execute powershell command '(Get-Disk | measure).Count'] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nsocket.timeout: The read operation timed out\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='10.191.154.92', port=5986): Read timed out. (read timeout=600)\nrequests.exceptions.ReadTimeout: HTTPSConnectionPool(host='10.191.154.92', port=5986): Read timed out. (read timeout=600)\nfatal: [localhost]: FAILED! => Unexpected failure during module execution.", "category": "socket_timeout", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task execute powershell command get disk measure count task path home worker workspace ansible windows server lts c number ga ide efi ansible vsphere gos validation windows utilities win execute command yml number socket timeout the read operation timed out url library number exceptions read timeout error https connection pool host ip address port number read timed out read timeout number requests exceptions read timeout https connection pool host ip address port number read timed out read timeout number fatal localhost failed unexpected failure during module execution", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1676, "name": "51.txt", "raw": "2022-05-16 08:17:27,016 | Failed at Play [gosc_perl_dhcp] ****************************\n2022-05-16 08:17:27,016 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Flatcar_main/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "fail_to_revert_base_snap", "processed": "timestamp failed at play go sc perl dhcp timestamp task revert snapshot failed task path home worker workspace ansible flatcar main ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1677, "name": "52.txt", "raw": "2022-05-16 08:18:01,016 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-05-16 08:18:01,016 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Flatcar_main/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "fail_to_revert_base_snap", "processed": "timestamp failed at play go sc cloud init dhcp timestamp task revert snapshot failed task path home worker workspace ansible flatcar main ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1678, "name": "53.txt", "raw": "2022-05-16 08:18:38,016 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-05-16 08:18:38,016 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Flatcar_main/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "fail_to_revert_base_snap", "processed": "timestamp failed at play para virtual v hba device ops timestamp task revert snapshot failed task path home worker workspace ansible flatcar main ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1679, "name": "56.txt", "raw": "2022-05-16 08:18:57,016 | Failed at Play [lsilogicsas_vhba_device_ops] ***************\n2022-05-16 08:18:57,016 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Flatcar_main/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "fail_to_revert_base_snap", "processed": "timestamp failed at play lsi logic sas v hba device ops timestamp task revert snapshot failed task path home worker workspace ansible flatcar main ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1680, "name": "71.txt", "raw": "2022-05-26 03:18:39,026 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-05-26 03:18:39,026 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "fail_to_revert_base_snap", "processed": "timestamp failed at play vmxnet number network device ops timestamp task revert snapshot failed task path home worker workspace ansible windows server lts c number ga ide efi ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1681, "name": "73.txt", "raw": "2022-05-26 03:22:52,026 | Failed at Play [memory_hot_add_basic] **********************\n2022-05-26 03:22:52,026 | TASK [Revert snapshot failed] ******************************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_revert_snapshot.yml:46\nfatal: [localhost]: FAILED! => Revert to snapshot 'BaseSnapshot' failed", "category": "fail_to_revert_base_snap", "processed": "timestamp failed at play memory hot add basic timestamp task revert snapshot failed task path home worker workspace ansible windows server lts c number ga ide efi ansible vsphere gos validation common vm revert snapshot yml number fatal localhost failed revert to snapshot base snapshot failed", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1690, "name": "38.txt", "raw": "2022-05-16 14:44:39,016 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-16 14:44:39,016 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping\n2022-05-16 14:45:11,016 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "non_zero_when_ping_2", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task try to ping ip task path home worker workspace ansible rhel number x main para virtual vmxnet number efi ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping timestamp task testing exit due to failure task path home worker workspace ansible rhel number x main para virtual vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1691, "name": "57.txt", "raw": "2022-05-17 19:27:19,017 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-17 19:27:19,017 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping\n2022-05-17 19:27:49,017 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "non_zero_when_ping_2", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task try to ping ip task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping timestamp task testing exit due to failure task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1694, "name": "37.txt", "raw": "2022-05-16 14:34:30,016 | Failed at Play [check_efi_firmware] ************************\n2022-05-16 14:34:30,016 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_vm", "category": "no_info_from_not_exist_vm", "processed": "timestamp failed at play check efi firmware timestamp task get specified property info for vm test vm task path home worker workspace ansible windows number main para virtual vmxnet number efi ansible vsphere gos validation common vm get configuration yml number fatal localhost failed unable to gather information for non existing vm test vm", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1695, "name": "81.txt", "raw": "2022-05-30 07:52:59,030 | Failed at Play [check_os_fullname] *************************\n2022-05-30 07:52:59,030 | TASK [Get specified property info for VM 'test_vm'] ********\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_vm", "category": "no_info_from_not_exist_vm", "processed": "timestamp failed at play check os full name timestamp task get specified property info for vm test vm task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation common vm get configuration yml number fatal localhost failed unable to gather information for non existing vm test vm", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1697, "name": "84.txt", "raw": "2022-05-30 16:56:19,030 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-05-30 16:56:19,030 | TASK [Set VM power state to 'shutdown-guest'] **************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_64/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => Timeout while waiting for VM power off.", "category": "timeout_while_waiting", "processed": "timestamp failed at play cpu multi cores per socket timestamp task set vm power state to shutdown guest task path home worker workspace ansible regression windows number ansible vsphere gos validation common vm set power state yml number fatal localhost failed timeout while waiting for vm power off", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1698, "name": "30.txt", "raw": "2022-05-23 04:28:18,023 | Failed at Play [paravirtual_vhba_device_ops] ***************\n2022-05-23 04:28:18,023 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table", "category": "origin", "processed": "timestamp failed at play para virtual v hba device ops timestamp task wait for vmware tools collecting guest info task path home worker workspace ansible regression sled number x ansible vsphere gos validation common vm wait guest ip yml number fatal localhost failed hardware configuration table", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1699, "name": "40.txt", "raw": "2022-05-23 06:16:02,023 | Failed at Play [cpu_hot_add_basic] *************************\n2022-05-23 06:16:02,023 | TASK [VM log info check failure] ***************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_Server_LTSC/ansible-vsphere-gos-validation/windows/utils/win_check_winbsod.yml:19\nfatal: [localhost]: FAILED! => Get Windows guest BSOD keyword 'WinBSOD:' in vmware.log.", "category": "origin", "processed": "timestamp failed at play cpu hot add basic timestamp task vm log info check failure task path home worker workspace ansible regression windows server lts c ansible vsphere gos validation windows utilities win check win bsod yml number fatal localhost failed get windows guest bsod keyword win bsod in vmware log", "solution": "deepdive", "target": "product", "version": 202206171000}, {"id": 1700, "name": "86.txt", "raw": "2022-06-03 02:03:55,003 | Failed at Play [ovt_verify_install] ************************\n2022-06-03 02:03:55,003 | TASK [Install packages ['open-vm-tools']] ******************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update/ansible-vsphere-gos-validation/linux/open_vm_tools/install_ovt.yml:35\nfatal: [localhost -> 10.180.111.126]: FAILED! => non-zero return code when tdnf\n2022-06-03 02:04:37,003 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case ovt_verify_install", "category": "origin", "processed": "timestamp failed at play ovt verify install timestamp task install packages open vm tools task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation linux open vm tools install ovt yml number fatal localhost ip address failed nonzero return code when tdnf timestamp task testing exit due to failure task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case ovt verify install", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1692, "name": "59.txt", "raw": "2022-05-23 08:04:33,023 | Failed at Play [secureboot_enable_disable] *****************\n2022-05-23 08:04:33,023 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Regression_CentOS_8.x/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "non_zero_when_ping_2", "processed": "timestamp failed at play secure boot enable disable timestamp task try to ping ip task path home worker workspace ansible regression centos number x ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping", "solution": "deepdive", "target": "targetvm", "version": 202206171000}, {"id": 1701, "name": "90.txt", "raw": "2022-06-03 02:29:30,003 | Failed at Play [deploy_vm_efi_lsilogic_vmxnet3] ************\n2022-06-03 02:29:30,003 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_ISO/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-06-03 02:29:58,003 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_ISO/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogic_vmxnet3", "category": "origin", "processed": "timestamp failed at play deploy vm efi lsi logic vmxnet number timestamp task wait for vmware tools collecting guest info task path home worker workspace ansible regression photon number iso ansible vsphere gos validation common vm wait guest ip yml number fatal localhost failed hardware configuration table timestamp task testing exit due to failure task path home worker workspace ansible regression photon number iso ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1702, "name": "29.txt", "raw": "2022-05-23 04:00:26,023 | Failed at Play [lsilogic_vhba_device_ops] ******************\n2022-05-23 04:00:26,023 | TASK [Wait for new device to be present] *******************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_OVA/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:80\nfatal: [localhost]: UNREACHABLE! => Failed to create temporary directory.In some cases, you may have been able to authenticate and did not have permissions on the target directory. Consider changing the remote tmp path in ansible.cfg to a path rooted in \"/tmp\", for more error information use -vvv. Failed command was: ( umask 77 && mkdir -p \"` echo /tmp `\"&& mkdir \"` echo /tmp/ansible-tmp-1653278426.1675-6193-215757058899332 `\" && echo ansible-tmp-1653278426.1675-6193-215757058899332=\"` echo /tmp/ansible-tmp-1653278426.1675-6193-215757058899332 `\" ), exited with result 1\n2022-05-23 04:00:26,023 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_OVA/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/wait_device_list_changed.yml:91\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': 'Failed to create temporary directory.In some cases, you may have been able to authenticate and did not have permissions on the target directory. Consider changing the remote tmp path in ansible.cfg to a path rooted in \"/tmp\", for more error information use -vvv. Failed command was: ( umask 77 && mkdir -p \"` echo /tmp `\"&& mkdir \"` echo /tmp/ansible-tmp-1653278426.1675-6193-215757058899332 `\" && echo ansible-tmp-1653278426.1675-6193-215757058899332=\"` echo /tmp/ansible-tmp-1653278426.1675-6193-215757058899332 `\" ), exited with result 1', 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "fail_create_temporary_dir_auth", "processed": "timestamp failed at play lsi logic v hba device ops timestamp task wait for new device to be present task path home worker workspace ansible regression ubuntu number server ova ansible vsphere gos validation linux v hba hot add remove wait device list changed yml number fatal localhost un reachable failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo tmp mkdir echo tmp ansible tmp hex id timestamp echo ansible tmp hex id timestamp echo tmp ansible tmp hex id timestamp exited with result number timestamp task guest os un reachable task path home worker workspace ansible regression ubuntu number server ova ansible vsphere gos validation linux v hba hot add remove wait device list changed yml number fatal localhost failed changed false message failed to create temporary directory in some cases you may have been able to authenticate and did not have permissions on the target directory consider changing the remote tmp path in ansible configuration to a path rooted in tmp for more error information use v v v failed command was u mask number mkdir p echo tmp mkdir echo tmp ansible tmp hex id timestamp echo ansible tmp hex id timestamp echo tmp ansible tmp hex id timestamp exited with result number skip reason host localhost is un reachable un reachable true", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1703, "name": "32.txt", "raw": "2022-05-16 04:08:01,016 | Failed at Play [gosc_sanity_dhcp] **************************\n2022-05-16 04:08:01,016 | TASK [Get the absolute path in Windows guest] **************\ntask path: /home/worker/workspace/Ansible_Windows_11_67U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_get_path.yml:10\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "unreachable_host", "processed": "timestamp failed at play go sc sanity dhcp timestamp task get the absolute path in windows guest task path home worker workspace ansible windows number lsi logic sas efi ansible vsphere gos validation windows utilities win get path yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1704, "name": "96.txt", "raw": "2022-06-10 06:54:11,010 | Failed at Play [gosc_sanity_dhcp] **************************\n2022-06-10 06:54:11,010 | TASK [Shutdown guest OS inside OS] *************************\ntask path: /home/worker/workspace/Ansible_Windows_11_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/windows/utils/win_shutdown_restart.yml:8\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))", "category": "unreachable_host", "processed": "timestamp failed at play go sc sanity dhcp timestamp task shutdown guest os inside os task path home worker workspace ansible windows number ga ide efi ansible vsphere gos validation windows utilities win shutdown restart yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1705, "name": "49.txt", "raw": "2022-05-23 03:57:01,023 | Failed at Play [deploy_vm_efi_nvme_e1000e] *****************\n2022-05-23 03:57:01,023 | TASK [Check VM 'test_windows11_22538' IP address] **********\ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_windows11_22538' IP Address\n2022-05-23 03:58:21,023 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_11_64/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_nvme_e1000e", "category": "fail_to_get_vm", "processed": "timestamp failed at play deploy vm efi nvme timestamp task check vm test windows number ip address task path home worker workspace ansible regression windows number ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test windows number ip address timestamp task testing exit due to failure task path home worker workspace ansible regression windows number ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi nvme e number e", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1706, "name": "75.txt", "raw": "2022-05-26 05:02:19,026 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2022-05-26 05:02:19,026 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-05-26 05:02:56,026 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_e1000e", "category": "fail_to_get_vm", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task check vm test vm ip address task path home worker workspace ansible cycle windows number ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible cycle windows number ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual e number e", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1707, "name": "94.txt", "raw": "2022-06-07 02:17:42,007 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-06-07 02:17:42,007 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/test_vmlibrary/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-06-07 02:18:16,007 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/test_vmlibrary/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "fail_to_get_vm", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task check vm test vm ip address task path home worker workspace test vm library ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace test vm library ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1708, "name": "25.txt", "raw": "2022-05-16 11:19:43,016 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-05-16 11:19:43,016 | TASK [Parameter error] *************************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update/newgos_testing_internal/testbed_deploy/testbed_deploy_nimbus.yml:60\nfatal: [localhost]: FAILED! => Please specify vCenter build number in command line or in vars/internal_test.yml using 'vcenter_build_num' parameter", "category": "no_vcenter_number", "processed": "timestamp failed at play testbed deploy nimbus timestamp task parameter error task path home worker workspace ansible cycle photon number x update new gos testing internal testbed deploy testbed deploy nimbus yml number fatal localhost failed please specify vcenter build number in command line or in vars internal test yml using vcenter build number parameter", "solution": "deepdive", "target": "usererror", "version": 202206171000}, {"id": 1709, "name": "60.txt", "raw": "2022-05-17 18:47:02,017 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-05-17 18:47:02,017 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.191.184.117:22\n2022-05-17 18:47:39,017 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "timeout_waiting_search_openssh", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for port number to become open or contain specific keyword task path home worker workspace ansible cycle centos number x ansible vsphere gos validation common vm wait ssh yml number fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task testing exit due to failure task path home worker workspace ansible cycle centos number x ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1710, "name": "100.txt", "raw": "2022-06-10 05:51:17,010 | Failed at Play [deploy_vm_efi_sata_vmxnet3] ****************\n2022-06-10 05:51:17,010 | TASK [Datastore file operation] ****************************\ntask path: /home/worker/workspace/dw_RHEL9_ARM/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => Failed to query for file 'ISO/rhel-baseos-9.0-aarch64-boot.iso'\n2022-06-10 05:51:18,010 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/dw_RHEL9_ARM/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_sata_vmxnet3", "category": "manual", "processed": "timestamp failed at play deploy vm efi sata vmxnet number timestamp task data store file operation task path home worker workspace dw rhel number arm ansible vsphere gos validation common esxi check delete data store file yml number fatal localhost failed failed to query for file iso rhel base os number a arch number boot iso timestamp task testing exit due to failure task path home worker workspace dw rhel number arm ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi sata vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1711, "name": "101.txt", "raw": "2022-06-08 07:21:26,008 | Failed at Play [deploy_vm_efi_sata_vmxnet3] ****************\n2022-06-08 07:21:26,008 | TASK [Set VM power state to 'powered-on'] ******************\ntask path: /home/worker/workspace/dw_RHEL9_ARM/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => The serial port output file \"serial-20220608072106.log\" already exists. Do you want to replace it with new content or append new content to the end of the file?\n2022-06-08 07:21:51,008 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/dw_RHEL9_ARM/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_sata_vmxnet3", "category": "manual", "processed": "timestamp failed at play deploy vm efi sata vmxnet number timestamp task set vm power state to powered on task path home worker workspace dw rhel number arm ansible vsphere gos validation common vm set power state yml number fatal localhost failed the serial port output file serial timestamp log already exists do you want to replace it with new content or append new content to the end of the file timestamp task testing exit due to failure task path home worker workspace dw rhel number arm ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi sata vmxnet number", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1622, "name": "66.txt", "raw": "2022-05-24 09:04:09,024 | Failed at Play [gosc_perl_staticip] ************************\n2022-05-24 09:04:09,024 | TASK [Fetch file /tmp/resolv.conf from VM guest] ***********\ntask path: /home/worker/workspace/Ansible_Cycle_Debian_11.x_32bit/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Failed to Fetch file from Vm VMware exception : (vim.fault.GuestOperationsUnavailable) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'The guest operations agent could not be contacted.',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) []\n}", "category": "guestos_not_contacted", "processed": "timestamp failed at play go sc perl static ip timestamp task fetch file tmp resolve configuration from vm guest task path home worker workspace ansible cycle debian number x number b it ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed failed to fetch file from vm vmware exception vim fault guest operations unavailable dynamic type un set dynamic property vmodl dynamic property message the guest operations agent could not be contacted fault cause un set fault message vmodl localizable message ", "solution": "retry", "target": "targetvm", "version": 202206171000}, {"id": 1623, "name": "97.txt", "raw": "2022-06-10 07:38:49,010 | Failed at Play [gosc_sanity_staticip] **********************\n2022-06-10 07:38:49,010 | TASK [Customize Windows guest OS] **************************\ntask path: /home/worker/workspace/Ansible_Windows_11_70U1_SATA_E1000E_EFI/ansible-vsphere-gos-validation/windows/guest_customization/win_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization failed. For detailed information see warnings Waiting for customization result event timed out.\n2022-06-10 07:39:35,010 | TASK [Fetch file C:\\Windows\\Temp\\vmware-imc\\guestcust.log from VM guest] \ntask path: /home/worker/workspace/Ansible_Windows_11_70U1_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Failed to Fetch file from Vm VMware exception : (vim.fault.GuestOperationsUnavailable) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'The guest operations agent could not be contacted.',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) []\n}", "category": "guestos_not_contacted", "processed": "timestamp failed at play go sc sanity static ip timestamp task customize windows guest os task path home worker workspace ansible windows number sata efi ansible vsphere gos validation windows guest customization win go sc execution yml number fatal localhost failed customization failed for detailed information see warnings waiting for customization result event timed out timestamp task fetch file c windows temp vmware imc guest cust log from vm guest task path home worker workspace ansible windows number sata efi ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed failed to fetch file from vm vmware exception vim fault guest operations unavailable dynamic type un set dynamic property vmodl dynamic property message the guest operations agent could not be contacted fault cause un set fault message vmodl localizable message ", "solution": "deepdive", "target": "testcase", "version": 202206171000}, {"id": 1696, "name": "82.txt", "raw": "2022-05-30 16:46:51,030 | Failed at Play [memory_hot_add_basic] **********************\n2022-05-30 16:46:51,030 | TASK [Set VM power state to 'shutdown-guest'] **************\ntask path: /home/worker/workspace/Ansible_Regression_Windows_10_64/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:34\nfatal: [localhost]: FAILED! => Timeout while waiting for VM power off.", "category": "timeout_while_waiting", "processed": "timestamp failed at play memory hot add basic timestamp task set vm power state to shutdown guest task path home worker workspace ansible regression windows number ansible vsphere gos validation common vm set power state yml number fatal localhost failed timeout while waiting for vm power off", "solution": "deepdive", "target": "targetvm", "version": 202206171000}, {"id": 1688, "name": "31.txt", "raw": "2022-05-23 08:49:41,023 | Failed at Play [secureboot_enable_disable] *****************\n2022-05-23 08:49:41,023 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_7.x/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "non_zero_when_ping_2", "processed": "timestamp failed at play secure boot enable disable timestamp task try to ping ip task path home worker workspace ansible regression rhel number x ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping", "solution": "deepdive", "target": "targetvm", "version": 202206171000}, {"id": 1689, "name": "36.txt", "raw": "2022-05-16 11:50:01,016 | Failed at Play [secureboot_enable_disable] *****************\n2022-05-16 11:50:01,016 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "non_zero_when_ping_2", "processed": "timestamp failed at play secure boot enable disable timestamp task try to ping ip task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping", "solution": "deepdive", "target": "targetvm", "version": 202206171000}, {"id": 1693, "name": "88.txt", "raw": "2022-06-03 05:14:47,003 | Failed at Play [secureboot_enable_disable] *****************\n2022-06-03 05:14:47,003 | TASK [Try to ping IP] **************************************\ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_7.x/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "non_zero_when_ping_2", "processed": "timestamp failed at play secure boot enable disable timestamp task try to ping ip task path home worker workspace ansible cycle rhel number x ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping", "solution": "deepdive", "target": "targetvm", "version": 202206171000}, {"id": 5419, "name": "log-3171", "raw": "2022-07-18 08:14:34,018 | Failed at Play [vbs_enable_disable] ************************\n2022-07-18 08:14:34,018 | TASK [Check VM 'dw0409_win10_v21H2' IP address] ************\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'dw0409_win10_v21H2' IP Address", "category": "", "processed": "timestamp failed at play vbs enable disable timestamp task check vm v number h number ip address task path home worker workspace ansible windows number main nvme efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm v number h number ip address", "solution": "deepdive", "target": "testcase", "version": 202207021500}, {"id": 5395, "name": "log-2838", "raw": "2022-07-12 08:05:33,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:05:33,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_9.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle alma linux number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5396, "name": "log-2839", "raw": "2022-07-12 08:06:08,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:06:08,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle centos number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5397, "name": "log-2841", "raw": "2022-07-12 08:06:47,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:06:47,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Debian_11.x_64bit/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle debian number x number b it ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5398, "name": "log-2842", "raw": "2022-07-12 08:07:12,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:12,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_LTS/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle flatcar lts ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5399, "name": "log-2843", "raw": "2022-07-12 08:07:14,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:14,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_Stable/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle flatcar stable ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5400, "name": "log-2844", "raw": "2022-07-12 08:07:23,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:23,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update_OVA/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle photon number x update ova ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5401, "name": "log-2847", "raw": "2022-07-12 08:07:34,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:34,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle photon number x update iso ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5402, "name": "log-2848", "raw": "2022-07-12 08:07:37,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:37,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_OracleLinux_8.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle oracle linux number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5403, "name": "log-2849", "raw": "2022-07-12 08:07:48,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:48,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.0_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle photon number iso ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5404, "name": "log-2932", "raw": "2022-07-12 14:01:09,012 | Failed at Play [env_setup] *********************************\n2022-07-12 14:01:09,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_9.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle rhel number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5405, "name": "log-2852", "raw": "2022-07-12 08:09:46,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:09:46,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_SLED_15.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle sled number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5406, "name": "log-2853", "raw": "2022-07-12 08:10:51,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:10:51,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_RockyLinux_8.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle rocky linux number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5407, "name": "log-2854", "raw": "2022-07-12 08:11:06,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:11:06,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_SLES_15.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle sles number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5408, "name": "log-2931", "raw": "2022-07-12 14:00:27,012 | Failed at Play [env_setup] *********************************\n2022-07-12 14:00:27,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle ubuntu version id iso ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5409, "name": "log-2858", "raw": "2022-07-12 08:13:55,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:13:55,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle windows number ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5410, "name": "log-2930", "raw": "2022-07-12 14:00:23,012 | Failed at Play [env_setup] *********************************\n2022-07-12 14:00:23,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207021500}, {"id": 5411, "name": "log-2944", "raw": "2022-07-13 02:02:56,013 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-07-13 02:02:56,013 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220713004650.log] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-07-13 02:03:06,013 | TASK [Fetch file /tmp/cloud-init_2022-07-13-02-02-59.tar.gz from VM guest] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task fetch file tmp cloud init timestamp number tar gz from vm guest task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "testbed", "version": 202207021500}, {"id": 5412, "name": "log-2962", "raw": "2022-07-13 04:18:23,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 04:18:23,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.185.229.209' (ECDSA) to the list of known hosts.\nroot@10.185.229.209: Permission denied (publickey,keyboard-interactive).", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle photon number iso ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202207021500}, {"id": 5413, "name": "log-3007", "raw": "2022-07-13 05:05:25,013 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-07-13 05:05:25,013 | TASK [Collect filtered guest information for '10.185.110.153'] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.185.110.153' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nroot@10.185.110.153: Permission denied (publickey,password).", "category": "", "processed": "timestamp failed at play nvme v hba device ops timestamp task collect filtered guest information for ip address task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation common get system info yml number fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again permission denied please try again root ip address permission denied public key password", "solution": "retry", "target": "targetvm", "version": 202207021500}, {"id": 5414, "name": "log-3046", "raw": "2022-07-13 08:57:53,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 08:57:53,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update_OVA/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.78.116.253' (ECDSA) to the list of known hosts.\nroot@10.78.116.253: Permission denied (publickey,keyboard-interactive).", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle photon number x update ova ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202207021500}, {"id": 5415, "name": "log-3148", "raw": "2022-07-14 00:31:12,014 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-07-14 00:31:12,014 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220713231750.log] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-07-14 00:31:23,014 | TASK [Fetch file /tmp/cloud-init_2022-07-14-00-31-15.tar.gz from VM guest] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle ubuntu version id iso ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task fetch file tmp cloud init timestamp number tar gz from vm guest task path home worker workspace ansible cycle ubuntu version id iso ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "testbed", "version": 202207021500}, {"id": 5416, "name": "log-3150", "raw": "2022-07-14 13:39:59,014 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-07-14 13:39:59,014 | TASK [Collect filtered guest information for '10.182.132.140'] \ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_Stable/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.182.132.140' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nReceived disconnect from 10.182.132.140 port 22:2: Too many authentication failures\nDisconnected from 10.182.132.140 port 22", "category": "", "processed": "timestamp failed at play nvme v hba device ops timestamp task collect filtered guest information for ip address task path home worker workspace ansible cycle flatcar stable ansible vsphere gos validation common get system info yml number fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again received disconnect from ip address port number too many authentication failures disconnected from ip address port number", "solution": "retry", "target": "targetvm", "version": 202207021500}, {"id": 5417, "name": "log-3151", "raw": "2022-07-15 03:02:59,015 | Failed at Play [env_setup] *********************************\n2022-07-15 03:02:59,015 | TASK [Enable debug log by default] *************************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/env_setup/set_default_variables.yml:13\nfatal: [localhost]: FAILED! => The variable name 'enable_ansible.builtin.debug' is not valid. Variables must start with a letter or underscore character, and contain only letters, numbers and underscores.", "category": "", "processed": "timestamp failed at play environment setup timestamp task enable debug log by default task path home worker workspace ansible regression rhel number x ansible vsphere gos validation environment setup set default variables yml number fatal localhost failed the variable name enable ansible builtin debug is not valid variables must start with a letter or underscore character and contain only letters numbers and underscores", "solution": "deepdive", "target": "testcase", "version": 202207021500}, {"id": 5418, "name": "log-3166", "raw": "2022-07-15 16:44:29,015 | Failed at Play [deploy_vm_efi_sata_e1000e] *****************\n2022-07-15 16:44:29,015 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_RockyLinux_9.x_70GA_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-07-15 16:45:08,015 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_RockyLinux_9.x_70GA_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_sata_e1000e", "category": "", "processed": "timestamp failed at play deploy vm efi sata timestamp task wait for vmware tools collecting guest info task path home worker workspace ansible rocky linux number x number ga sata efi ansible vsphere gos validation common vm wait guest ip yml number fatal localhost failed hardware configuration table timestamp task testing exit due to failure task path home worker workspace ansible rocky linux number x number ga sata efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi sata e number e", "solution": "retry", "target": "targetvm", "version": 202207021500}, {"id": 5420, "name": "log-3180", "raw": "2022-07-19 10:37:30,019 | Failed at Play [nvme_vhba_device_ops_spec13] ***************\n2022-07-19 10:37:30,019 | TASK [Hot add or remove VM disk controller] ****************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_2022_64/ansible-vsphere-gos-validation/common/vm_hot_add_remove_disk_ctrl.yml:12\nexception in /vmware_guest_controller.py when configure_disk_controllers in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => ('The guest operating system did not respond to a hot-remove request for device nvme0 in a timely manner.', None)", "category": "", "processed": "timestamp failed at play nvme v hba device ops spec number timestamp task hot add or remove vm disk controller task path home worker workspace ansible cycle windows server number ansible vsphere gos validation common vm hot add remove disk ctrl yml number exception in vmware guest controller python when configure disk controllers in vmware python when wait for task fatal localhost failed the guest operating system did not respond to a hot remove request for device nvme number in a timely manner none", "solution": "deepdive", "target": "product", "version": 202207021500}, {"id": 5421, "name": "log-3181", "raw": "2022-07-19 10:22:17,019 | Failed at Play [nvme_vhba_device_ops_spec13] ***************\n2022-07-19 10:22:17,019 | TASK [Hot add or remove VM disk controller] ****************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_hot_add_remove_disk_ctrl.yml:12\nexception in /vmware_guest_controller.py when configure_disk_controllers in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => ('The guest operating system did not respond to a hot-remove request for device nvme0 in a timely manner.', None)", "category": "", "processed": "timestamp failed at play nvme v hba device ops spec number timestamp task hot add or remove vm disk controller task path home worker workspace ansible cycle windows number ansible vsphere gos validation common vm hot add remove disk ctrl yml number exception in vmware guest controller python when configure disk controllers in vmware python when wait for task fatal localhost failed the guest operating system did not respond to a hot remove request for device nvme number in a timely manner none", "solution": "deepdive", "target": "product", "version": 202207021500}, {"id": 5422, "name": "log-3184", "raw": "2022-07-20 02:50:38,020 | Failed at Play [vmlibrary_main] ****************************\n2022-07-20 02:50:38,020 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Create_New_VMLibrary_Template/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:69\nfatal: [localhost]: FAILED! => (vmodl.fault.SystemError) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'A general system error occurred: Invalid fault',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) [],\n   reason = 'Invalid fault'\n} ", "category": "", "processed": "timestamp failed at play vm library main timestamp task fail task path home worker workspace create new vm library template ansible vsphere gos validation common vm set power state yml number fatal localhost failed vmodl fault system error dynamic type un set dynamic property vmodl dynamic property message a general system error occurred invalid fault fault cause un set fault message vmodl localizable message reason invalid fault ", "solution": "deepdive", "target": "testcase", "version": 202207021500}, {"id": 3513, "name": "log-2332", "raw": "2022-06-28 14:27:33,028 | Failed at Play [check_ip_address] **************************\n2022-06-28 14:27:33,028 | TASK [Skip testcase: check_ip_address, reason: Blocked] ****\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'check_ip_address' is blocked because VMware tools installed: False, running: False", "category": "", "processed": "timestamp failed at play check ip address timestamp task skip test case check ip address reason blocked task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation common skip test case yml number fatal localhost failed test case check ip address is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202207041600}, {"id": 3514, "name": "log-2380", "raw": "2022-06-30 06:40:43,030 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-06-30 06:40:43,030 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3515, "name": "log-2371", "raw": "2022-06-30 04:33:26,030 | Failed at Play [deploy_vmwarephoton_ova] *******************\n2022-06-30 04:33:26,030 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Photon_3.x_OVA_65U3/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.185.228.195:22\n2022-06-30 04:34:08,030 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Photon_3.x_OVA_65U3/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vmwarephoton_ova", "category": "", "processed": "timestamp failed at play deploy vmware photon ova timestamp task wait for port number to become open or contain specific keyword task path home worker workspace ansible photon number x ova ansible vsphere gos validation common vm wait ssh yml number fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task testing exit due to failure task path home worker workspace ansible photon number x ova ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vmware photon ova", "solution": "deepdive", "target": "testcase", "version": 202207041600}, {"id": 3516, "name": "log-2338", "raw": "2022-06-29 06:56:46,029 | Failed at Play [deploy_vmwarephoton_ova] *******************\n2022-06-29 06:56:46,029 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Photon_3.x_OVA_67GA/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.186.85.86:22\n2022-06-29 06:57:19,029 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Photon_3.x_OVA_67GA/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vmwarephoton_ova", "category": "", "processed": "timestamp failed at play deploy vmware photon ova timestamp task wait for port number to become open or contain specific keyword task path home worker workspace ansible photon number x ova number ga ansible vsphere gos validation common vm wait ssh yml number fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task testing exit due to failure task path home worker workspace ansible photon number x ova number ga ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vmware photon ova", "solution": "deepdive", "target": "testcase", "version": 202207041600}, {"id": 3517, "name": "log-2450", "raw": "2022-07-02 11:29:05,002 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-07-02 11:29:05,002 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows number main para virtual vmxnet number efi ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3518, "name": "log-2372", "raw": "2022-06-30 06:01:47,030 | Failed at Play [vmlibrary_main] ****************************\n2022-06-30 06:01:47,030 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Create_New_VMLibrary_Template/newgos_testing_internal/vmlibrary/download_and_execute_script.yml:164\nfatal: [localhost]: FAILED! => ['At least one guest configuration is incorrect in 111563-Photon-3.0-Rev3U1-64-EFI-Open-VM-Tools', '2022-06-30 06:01:35 UTC |  ERROR| Check 2(SERVFAIL) is set in /etc/hostname ... NO!', '2022-06-30 06:01:35 UTC |  ERROR| Check STAF is running ... NO!', '2022-06-30 06:01:35 UTC |  ERROR| Check staf 10.168.218.1 ping ping get PONG ... NO!', '2022-06-30 06:01:45 UTC |  ERROR| Fail to download http://gosvpub.eng.vmware.com/GOSV-OVF/Scripts/apps/linux/vetSendIP.pl']", "category": "", "processed": "timestamp failed at play vm library main timestamp task fail task path home worker workspace create new vm library template new gos testing internal vm library download and execute script yml number fatal localhost failed at least one guest configuration is incorrect in number photon number efi open vm tools timestamp utc error check number serv fail is set in etc hostname no timestamp utc error check sta f is running no timestamp utc error check sta f ip address ping ping get pong no timestamp utc error fail to download http go sv pub eng vmware com go sv ovf scripts apps linux vet send ip pl", "solution": "deepdive", "target": "testcase", "version": 202207041600}, {"id": 3519, "name": "log-2381", "raw": "2022-06-30 06:40:50,030 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-06-30 06:40:50,030 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_PARAVIRTUAL_VMXNET3_BIOS/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows server lts c main para virtual vmxnet number bios ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3520, "name": "log-2382", "raw": "2022-06-30 06:40:35,030 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-06-30 06:40:35,030 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_NVME_E1000E_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows server lts c nvme efi ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3521, "name": "log-2384", "raw": "2022-06-30 06:41:13,030 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-06-30 06:41:13,030 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_PARAVIRTUAL_E1000E_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows server lts c para virtual efi ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3522, "name": "log-2383", "raw": "2022-06-30 06:41:01,030 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-06-30 06:41:01,030 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows server lts c lsi logic sas bios ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3523, "name": "log-2385", "raw": "2022-06-30 06:41:12,030 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-06-30 06:41:12,030 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows server lts c main nvme bios ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3524, "name": "log-2386", "raw": "2022-06-30 07:20:31,030 | Failed at Play [vmlibrary_main] ****************************\n2022-06-30 07:20:31,030 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Create_New_VMLibrary_Template/newgos_testing_internal/vmlibrary/download_and_execute_script.yml:164\nfatal: [localhost]: FAILED! => ['At least one guest configuration is incorrect in 111563-Photon-3.0-Rev3U1-64-EFI-Open-VM-Tools', '2022-06-30 07:20:19 UTC |  ERROR| Check reached is set in /etc/hostname ... NO!', '2022-06-30 07:20:19 UTC |  ERROR| Check STAF is running ... NO!', '2022-06-30 07:20:19 UTC |  ERROR| Check staf 10.168.218.1 ping ping get PONG ... NO!', '2022-06-30 07:20:30 UTC |  ERROR| Fail to download http://gosvpub.eng.vmware.com/GOSV-OVF/Scripts/apps/linux/vetSendIP.pl']", "category": "", "processed": "timestamp failed at play vm library main timestamp task fail task path home worker workspace create new vm library template new gos testing internal vm library download and execute script yml number fatal localhost failed at least one guest configuration is incorrect in number photon number efi open vm tools timestamp utc error check reached is set in etc hostname no timestamp utc error check sta f is running no timestamp utc error check sta f ip address ping ping get pong no timestamp utc error fail to download http go sv pub eng vmware com go sv ovf scripts apps linux vet send ip pl", "solution": "deepdive", "target": "testcase", "version": 202207041600}, {"id": 3525, "name": "log-2429", "raw": "2022-07-02 02:10:56,002 | Failed at Play [deploy_vm_ovf] *****************************\n2022-07-02 02:10:56,002 | TASK [Deploy VM from ovf template] *************************\ntask path: /home/worker/workspace/Ansible_Windows_MS_Template_70U2/ansible-vsphere-gos-validation/common/ovf_deploy.yml:4\nexception in /vmware_deploy_ovf.py when run in /request.py when do_open\nfatal: [localhost]: FAILED! => <urlopen error The write operation timed out> Problem validating OVF import spec: Line 98: Invalid value 'hostonly' for element 'Connection'.\n2022-07-02 02:10:57,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_MS_Template_70U2/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_ovf", "category": "", "processed": "timestamp failed at play deploy vm ovf timestamp task deploy vm from ovf template task path home worker workspace ansible windows ms template ansible vsphere gos validation common ovf deploy yml number exception in vmware deploy ovf python when run in request python when do open fatal localhost failed url open error the write operation timed out problem validating ovf import spec line number invalid value host only for element connection timestamp task testing exit due to failure task path home worker workspace ansible windows ms template ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm ovf", "solution": "retry", "target": "targetvm", "version": 202207041600}, {"id": 3526, "name": "log-2514", "raw": "2022-07-04 00:11:31,004 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-07-04 00:11:31,004 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_2022_64/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible cycle windows server number ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3527, "name": "log-2519", "raw": "2022-07-04 00:21:16,004 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-07-04 00:21:16,004 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3528, "name": "log-2517", "raw": "2022-07-04 00:13:53,004 | Failed at Play [nvme_vhba_device_ops_spec13] ***************\n2022-07-04 00:13:53,004 | TASK [Verify disk number increases in guest OS] ************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hotadd_vm_disk_existing_ctrl.yml:35\nfatal: [localhost]: FAILED! => Disk number not increase 2, before hotadd: 1, after hotadd: 2", "category": "", "processed": "timestamp failed at play nvme v hba device ops spec number timestamp task verify disk number increases in guest os task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows v hba hot add remove hot add vm disk existing ctrl yml number fatal localhost failed disk number not increase number before hot add number after hot add number", "solution": "deepdive", "target": "usererror", "version": 202207041600}, {"id": 3529, "name": "log-2444", "raw": "2022-07-02 04:51:48,002 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-07-02 04:51:48,002 | TASK [Wait for port 22 to become stopped] ******************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update/ansible-vsphere-gos-validation/linux/utils/shutdown.yml:13\nfatal: [localhost]: FAILED! => Timeout when waiting for 10.182.58.98:22 to stop.", "category": "", "processed": "timestamp failed at play cpu multi cores per socket timestamp task wait for port number to become stopped task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation linux utilities shutdown yml number fatal localhost failed timeout when waiting for ip address to stop", "solution": "retry", "target": "targetvm", "version": 202207041600}, {"id": 3530, "name": "log-2449", "raw": "2022-07-02 11:28:51,002 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-07-02 11:28:51,002 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_11_70U3_PARAVIRTUAL_E1000E_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows number para virtual efi ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3531, "name": "log-2451", "raw": "2022-07-02 11:29:19,002 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-07-02 11:29:19,002 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_11_70U3_LSILOGICSAS_VMXNET3_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows number lsi logic sas vmxnet number efi ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3532, "name": "log-2452", "raw": "2022-07-02 11:29:20,002 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-07-02 11:29:20,002 | TASK [Check disk size after hot extend] ********************\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/windows/vhba_hot_add_remove/hot_extend_disk_test.yml:40\nfatal: [localhost]: FAILED! => Got disk size '1' GB in guest OS after hot extend to 2GB.", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task check disk size after hot extend task path home worker workspace ansible windows number main nvme efi ansible vsphere gos validation windows v hba hot add remove hot extend disk test yml number fatal localhost failed got disk size number gb in guest os after hot extend to number gb", "solution": "deepdive", "target": "product", "version": 202207041600}, {"id": 3533, "name": "log-2498", "raw": "2022-07-03 06:01:04,003 | Failed at Play [check_quiesce_snapshot] ********************\n2022-07-03 06:01:04,003 | TASK [Skip testcase: check_quiesce_snapshot, reason: Blocked] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'check_quiesce_snapshot' is blocked because VMware tools installed: False, running: False", "category": "", "processed": "timestamp failed at play check quiesce snapshot timestamp task skip test case check quiesce snapshot reason blocked task path home worker workspace ansible cycle windows number ansible vsphere gos validation common skip test case yml number fatal localhost failed test case check quiesce snapshot is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202207041600}, {"id": 3534, "name": "log-2488", "raw": "2022-07-03 04:23:18,003 | Failed at Play [check_ip_address] **************************\n2022-07-03 04:23:18,003 | TASK [Skip testcase: check_ip_address, reason: Blocked] ****\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/common/skip_test_case.yml:20\nfatal: [localhost]: FAILED! => Test case 'check_ip_address' is blocked because VMware tools installed: False, running: False", "category": "", "processed": "timestamp failed at play check ip address timestamp task skip test case check ip address reason blocked task path home worker workspace ansible cycle windows number ansible vsphere gos validation common skip test case yml number fatal localhost failed test case check ip address is blocked because vmware tools installed false running false", "solution": "deepdive", "target": "usererror", "version": 202207041600}, {"id": 3535, "name": "log-2527", "raw": "2022-07-04 07:20:55,004 | Failed at Play [deploy_vmwarephoton_ova] *******************\n2022-07-04 07:20:55,004 | TASK [Wait for port 22 to become open or contain specific keyword] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/vm_wait_ssh.yml:19\nfatal: [localhost]: FAILED! => Timeout when waiting for search string OpenSSH in 10.185.229.182:22\n2022-07-04 07:21:14,004 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vmwarephoton_ova", "category": "", "processed": "timestamp failed at play deploy vmware photon ova timestamp task wait for port number to become open or contain specific keyword task path home worker workspace ansible regression photon number ova ansible vsphere gos validation common vm wait ssh yml number fatal localhost failed timeout when waiting for search string openssh in ip address timestamp task testing exit due to failure task path home worker workspace ansible regression photon number ova ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vmware photon ova", "solution": "deepdive", "target": "testcase", "version": 202207041600}, {"id": 3536, "name": "log-2534", "raw": "2022-07-04 17:09:20,004 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-07-04 17:09:20,004 | TASK [Create a new VM 'zyh_ansible_ubuntu_2204_desktop_autoinstall' on server '10.185.45.140'] \ntask path: /home/worker/workspace/zyh_ansible_ubuntu_existing_testbed_3.1/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : A component of the virtual machine is not accessible on the host.\n2022-07-04 17:09:22,004 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/zyh_ansible_ubuntu_existing_testbed_3.1/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_vmxnet3", "category": "", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task create a new vm zyh ansible ubuntu number desktop auto install on server ip address task path home worker workspace zyh ansible ubuntu existing testbed number ansible vsphere gos validation common vm create yml number fatal localhost failed failed to create a virtual machine a component of the virtual machine is not accessible on the host timestamp task testing exit due to failure task path home worker workspace zyh ansible ubuntu existing testbed number ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number", "solution": "deepdive", "target": "usererror", "version": 202207041600}, {"id": 3537, "name": "log-2535", "raw": "2022-07-05 05:13:14,005 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-07-05 05:13:14,005 | TASK [Fetch file /var/log/cloud-init.log from VM guest] ****\ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_ISO/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nfatal: [localhost]: FAILED! => Failed to fetch file : Request failed: <urlopen error timed out>", "category": "", "processed": "timestamp failed at play go sc cloud init static ip timestamp task fetch file var log cloud init log from vm guest task path home worker workspace ansible regression ubuntu number server iso ansible vsphere gos validation common vm guest file operation yml number fatal localhost failed failed to fetch file request failed url open error timed out", "solution": "retry", "target": "targetvm", "version": 202207041600}, {"id": 4464, "name": "log-2908", "raw": "2022-07-12 13:23:36,012 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-12 13:23:36,012 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.187.131.94 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle ubuntu version id iso ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4465, "name": "log-2984", "raw": "2022-07-13 04:37:22,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 04:37:22,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_9.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.187.157.231 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle rhel number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4432, "name": "log-3013", "raw": "2022-07-13 08:17:23,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 08:17:23,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_Stable/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.168.207.54 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle flatcar stable ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4433, "name": "log-3062", "raw": "2022-07-13 09:15:10,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:15:10,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Debian_11.x_64bit/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.168.212.147 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle debian number x number b it ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4434, "name": "log-3137", "raw": "2022-07-13 13:00:08,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 13:00:08,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.78.120.117 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle centos number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4435, "name": "log-3075", "raw": "2022-07-13 09:22:23,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:22:23,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_9.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.184.104.196 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle alma linux number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4436, "name": "log-3095", "raw": "2022-07-13 09:52:38,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:52:38,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.78.237.191 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle photon number x update iso ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4437, "name": "log-3071", "raw": "2022-07-13 09:20:15,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:20:15,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_8.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.78.119.71 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle rhel number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4438, "name": "log-2744", "raw": "2022-07-11 14:25:34,011 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-11 14:25:34,011 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.184.80.131 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle photon number iso ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4439, "name": "log-3078", "raw": "2022-07-13 09:25:19,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:25:19,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Debian_11.x_32bit/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.186.45.163 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle debian number x number b it ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4440, "name": "log-2611", "raw": "2022-07-10 15:47:27,010 | Failed at Play [wintools_complete_install_verify] **********\n2022-07-10 15:47:27,010 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address", "category": "", "processed": "timestamp failed at play win tools complete install verify timestamp task check vm test vm ip address task path home worker workspace ansible cycle windows number ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address", "solution": "deepdive", "target": "testcase", "version": 202207151000}, {"id": 4466, "name": "log-2946", "raw": "2022-07-13 01:21:10,013 | Failed at Play [check_ip_address] **************************\n2022-07-13 01:21:10,013 | TASK [Execute powershell command '(Get-NetAdapter | where-object {$_.Name -notmatch 'vEthernet'}).Name'] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n2022-07-13 01:21:30,013 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:39\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': \"Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\", 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "", "processed": "timestamp failed at play check ip address timestamp task execute powershell command get net adapter where object name not match v ethernet name task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer timestamp task guest os un reachable task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost failed changed false message failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer skip reason host localhost is un reachable un reachable true", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4467, "name": "log-2947", "raw": "2022-07-13 01:43:50,013 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-07-13 01:43:50,013 | TASK [Execute powershell command '(Get-WmiObject Win32_SCSIController | where-object {$_.Name -like '*NVM Express*'} | measure).Count'] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n2022-07-13 01:44:08,013 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:39\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': \"Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\", 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "", "processed": "timestamp failed at play nvme v hba device ops timestamp task execute powershell command get wmi object win number scsi controller where object name like nvm express measure count task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer timestamp task guest os un reachable task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost failed changed false message failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer skip reason host localhost is un reachable un reachable true", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4429, "name": "log-2569", "raw": "2022-07-06 01:07:51,006 | Failed at Play [deploy_vmwarephoton_ova] *******************\n2022-07-06 01:07:51,006 | TASK [Wait for VMware Tools collecting guest OS fullname] **\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update_OVA/ansible-vsphere-gos-validation/common/vm_wait_guest_fullname.yml:17\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-07-06 01:08:10,006 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update_OVA/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vmwarephoton_ova", "category": "", "processed": "timestamp failed at play deploy vmware photon ova timestamp task wait for vmware tools collecting guest os full name task path home worker workspace ansible cycle photon number x update ova ansible vsphere gos validation common vm wait guest full name yml number fatal localhost failed hardware configuration table timestamp task testing exit due to failure task path home worker workspace ansible cycle photon number x update ova ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vmware photon ova", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4430, "name": "log-3027", "raw": "2022-07-13 08:29:26,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 08:29:26,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_LTS/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.168.186.92 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle flatcar lts ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4431, "name": "log-3016", "raw": "2022-07-13 06:53:02,013 | Failed at Play [nvme_vhba_device_ops_spec13] ***************\n2022-07-13 06:53:02,013 | TASK [Execute powershell command '(Get-WmiObject Win32_SCSIController | where-object {$_.Name -like '*NVM Express*'} | measure).Count'] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n2022-07-13 06:53:27,013 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:39\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': \"Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\", 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "", "processed": "timestamp failed at play nvme v hba device ops spec number timestamp task execute powershell command get wmi object win number scsi controller where object name like nvm express measure count task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer timestamp task guest os un reachable task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost failed changed false message failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer skip reason host localhost is un reachable un reachable true", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4441, "name": "log-2762", "raw": "2022-07-11 14:36:58,011 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-11 14:36:58,011 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_9.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.168.187.97 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle alma linux number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4442, "name": "log-2910", "raw": "2022-07-12 13:24:36,012 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-12 13:24:36,012 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.186.109.116 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4443, "name": "log-3079", "raw": "2022-07-13 09:25:34,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:25:34,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_SLED_15.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.186.55.32 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle sled number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4444, "name": "log-3089", "raw": "2022-07-13 09:43:59,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:43:59,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_OracleLinux_9.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.182.134.215 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle oracle linux number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4445, "name": "log-3081", "raw": "2022-07-13 09:37:33,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:37:33,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_RockyLinux_8.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.78.114.221 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle rocky linux number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4446, "name": "log-3006", "raw": "2022-07-13 04:55:02,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 04:55:02,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_SLES_15.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.162.90.4 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle sles number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4449, "name": "log-2661", "raw": "2022-07-11 00:14:20,011 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-07-11 00:14:20,011 | TASK [Execute powershell command '(Get-Disk | measure).Count'] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_2022_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n2022-07-11 00:14:39,011 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_2022_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:39\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': \"Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\", 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task execute powershell command get disk measure count task path home worker workspace ansible cycle windows server number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer timestamp task guest os un reachable task path home worker workspace ansible cycle windows server number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost failed changed false message failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer skip reason host localhost is un reachable un reachable true", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4451, "name": "log-3103", "raw": "2022-07-13 10:22:22,013 | Failed at Play [nvme_disk_hot_extend_spec13] ***************\n2022-07-13 10:22:22,013 | TASK [Execute powershell command '(Get-WmiObject Win32_SCSIController | where-object {$_.Name -like '*NVM Express*'} | measure).Count'] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n2022-07-13 10:22:44,013 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:39\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': \"Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\", 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "", "processed": "timestamp failed at play nvme disk hot extend spec number timestamp task execute powershell command get wmi object win number scsi controller where object name like nvm express measure count task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer timestamp task guest os un reachable task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost failed changed false message failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer skip reason host localhost is un reachable un reachable true", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4452, "name": "log-3037", "raw": "2022-07-13 08:37:48,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 08:37:48,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_Stable/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.78.126.169 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle flatcar stable ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4453, "name": "log-2722", "raw": "2022-07-11 13:42:50,011 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-11 13:42:50,011 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_LTS/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.186.53.55 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle flatcar lts ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4454, "name": "log-2749", "raw": "2022-07-11 14:28:33,011 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-11 14:28:33,011 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.184.86.75 port 22: Connection timed out", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle ubuntu version id iso ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number connection timed out", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4455, "name": "log-2751", "raw": "2022-07-11 14:29:07,011 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-11 14:29:07,011 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_SLED_15.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.168.191.15 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle sled number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4456, "name": "log-2765", "raw": "2022-07-11 14:40:34,011 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-11 14:40:34,011 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_RockyLinux_8.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.187.119.176 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle rocky linux number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4457, "name": "log-3041", "raw": "2022-07-13 08:44:54,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 08:44:54,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update_OVA/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.187.114.134 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle photon number x update ova ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4458, "name": "log-3069", "raw": "2022-07-13 09:19:19,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:19:19,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_OracleLinux_8.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.187.151.29 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle oracle linux number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4460, "name": "log-2873", "raw": "2022-07-12 11:40:10,012 | Failed at Play [cpu_multicores_per_socket] *****************\n2022-07-12 11:40:10,012 | TASK [Execute powershell command '(get-wmiobject win32_computersystem | select numberoflogicalprocessors, numberofprocessors | ft -hide | Out-String).trim()'] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n2022-07-12 11:40:33,012 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:39\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': \"Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\", 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "", "processed": "timestamp failed at play cpu multi cores per socket timestamp task execute powershell command get wmi object win number computer system select number of logical processors number of processors fth ide out string trim task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer timestamp task guest os un reachable task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost failed changed false message failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer skip reason host localhost is un reachable un reachable true", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4461, "name": "log-2882", "raw": "2022-07-12 10:10:16,012 | Failed at Play [check_os_fullname] *************************\n2022-07-12 10:10:16,012 | TASK [Execute powershell command '(Get-WmiObject win32_OperatingSystem).name'] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost]: UNREACHABLE! => Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n2022-07-12 10:10:38,012 | TASK [Guest OS unreachable] ********************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:39\nfatal: [localhost]: FAILED! => {'changed': False, 'msg': \"Failed to connect to the host via PSRP: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\", 'skip_reason': 'Host localhost is unreachable', 'unreachable': True}", "category": "", "processed": "timestamp failed at play check os full name timestamp task execute powershell command get wmi object win number operating system name task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost un reachable failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer timestamp task guest os un reachable task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows utilities win execute command yml number fatal localhost failed changed false message failed to connect to the host via psrp connection aborted connection reset error number connection reset by peer skip reason host localhost is un reachable un reachable true", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4462, "name": "log-3061", "raw": "2022-07-13 09:14:52,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 09:14:52,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.168.168.111 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle photon number iso ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4463, "name": "log-2903", "raw": "2022-07-12 13:16:30,012 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-12 13:16:30,012 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Failed to connect to the host via ssh: ssh: connect to host 10.187.148.32 port 22: No route to host", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle centos number x ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed failed to connect to the host via ssh ssh connect to host ip address port number no route to host", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4448, "name": "log-2813", "raw": "2022-07-12 00:06:32,012 | Failed at Play [env_setup] *********************************\n2022-07-12 00:06:32,012 | TASK [Get shell executable on ESXi server] *****************\ntask path: /home/worker/workspace/Ansible_Cycle_OracleLinux_8.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:54\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.78.127.199' (ECDSA) to the list of known hosts.\nShared connection to 10.78.127.199 closed.", "category": "", "processed": "timestamp failed at play environment setup timestamp task get shell executable on esxi server task path home worker workspace ansible cycle oracle linux number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts shared connection to ip address closed", "solution": "retry", "target": "nimbus", "version": 202207151000}, {"id": 4450, "name": "log-2830", "raw": "2022-07-12 01:03:37,012 | Failed at Play [gosc_sanity_staticip] **********************\n2022-07-12 01:03:37,012 | TASK [Customize Windows guest OS] **************************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/windows/guest_customization/win_gosc_execution.yml:4\nfatal: [localhost]: FAILED! => Customization failed. For detailed information see warnings Waiting for customization result event timed out.\n2022-07-12 01:04:36,012 | TASK [Fetch file C:\\Windows\\Temp\\vmware-imc\\guestcust.log from VM guest] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_11_64/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user Administrator", "category": "", "processed": "timestamp failed at play go sc sanity static ip timestamp task customize windows guest os task path home worker workspace ansible cycle windows number ansible vsphere gos validation windows guest customization win go sc execution yml number fatal localhost failed customization failed for detailed information see warnings waiting for customization result event timed out timestamp task fetch file c windows temp vmware imc guest cust log from vm guest task path home worker workspace ansible cycle windows number ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user administrator", "solution": "deepdive", "target": "testcase", "version": 202207151000}, {"id": 4459, "name": "log-2929", "raw": "2022-07-12 13:56:36,012 | Failed at Play [check_inbox_driver] ************************\n2022-07-12 13:56:36,012 | TASK [Collect filtered guest information for '10.182.11.84'] \ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_Stable/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.182.11.84' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nReceived disconnect from 10.182.11.84 port 22:2: Too many authentication failures\nDisconnected from 10.182.11.84 port 22", "category": "", "processed": "timestamp failed at play check inbox driver timestamp task collect filtered guest information for ip address task path home worker workspace ansible cycle flatcar stable ansible vsphere gos validation common get system info yml number fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again received disconnect from ip address port number too many authentication failures disconnected from ip address port number", "solution": "retry", "target": "targetvm", "version": 202207151000}, {"id": 4447, "name": "log-2837", "raw": "2022-07-12 07:56:11,012 | Failed at Play [env_setup] *********************************\n2022-07-12 07:56:11,012 | TASK [Get shell executable on ESXi server] *****************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_9.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:54\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.168.191.210' (ECDSA) to the list of known hosts.\nShared connection to 10.168.191.210 closed.", "category": "", "processed": "timestamp failed at play environment setup timestamp task get shell executable on esxi server task path home worker workspace ansible cycle alma linux number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts shared connection to ip address closed", "solution": "retry", "target": "nimbus", "version": 202207151000}, {"id": 5391, "name": "log-3171", "raw": "2022-07-18 08:14:34,018 | Failed at Play [vbs_enable_disable] ************************\n2022-07-18 08:14:34,018 | TASK [Check VM 'dw0409_win10_v21H2' IP address] ************\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'dw0409_win10_v21H2' IP Address", "category": "", "processed": "timestamp failed at play vbs enable disable timestamp task check vm v number h number ip address task path home worker workspace ansible windows number main nvme efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm v number h number ip address", "solution": "deepdive", "target": "testcase", "version": 202207221500}, {"id": 5367, "name": "log-2838", "raw": "2022-07-12 08:05:33,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:05:33,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_AlmaLinux_9.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle alma linux number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5368, "name": "log-2839", "raw": "2022-07-12 08:06:08,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:06:08,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_CentOS_8.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle centos number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5392, "name": "log-3180", "raw": "2022-07-19 10:37:30,019 | Failed at Play [nvme_vhba_device_ops_spec13] ***************\n2022-07-19 10:37:30,019 | TASK [Hot add or remove VM disk controller] ****************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_Server_2022_64/ansible-vsphere-gos-validation/common/vm_hot_add_remove_disk_ctrl.yml:12\nexception in /vmware_guest_controller.py when configure_disk_controllers in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => ('The guest operating system did not respond to a hot-remove request for device nvme0 in a timely manner.', None)", "category": "", "processed": "timestamp failed at play nvme v hba device ops spec number timestamp task hot add or remove vm disk controller task path home worker workspace ansible cycle windows server number ansible vsphere gos validation common vm hot add remove disk ctrl yml number exception in vmware guest controller python when configure disk controllers in vmware python when wait for task fatal localhost failed the guest operating system did not respond to a hot remove request for device nvme number in a timely manner none", "solution": "deepdive", "target": "product", "version": 202207221500}, {"id": 5393, "name": "log-3181", "raw": "2022-07-19 10:22:17,019 | Failed at Play [nvme_vhba_device_ops_spec13] ***************\n2022-07-19 10:22:17,019 | TASK [Hot add or remove VM disk controller] ****************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_hot_add_remove_disk_ctrl.yml:12\nexception in /vmware_guest_controller.py when configure_disk_controllers in /vmware.py when wait_for_task\nfatal: [localhost]: FAILED! => ('The guest operating system did not respond to a hot-remove request for device nvme0 in a timely manner.', None)", "category": "", "processed": "timestamp failed at play nvme v hba device ops spec number timestamp task hot add or remove vm disk controller task path home worker workspace ansible cycle windows number ansible vsphere gos validation common vm hot add remove disk ctrl yml number exception in vmware guest controller python when configure disk controllers in vmware python when wait for task fatal localhost failed the guest operating system did not respond to a hot remove request for device nvme number in a timely manner none", "solution": "deepdive", "target": "product", "version": 202207221500}, {"id": 5394, "name": "log-3184", "raw": "2022-07-20 02:50:38,020 | Failed at Play [vmlibrary_main] ****************************\n2022-07-20 02:50:38,020 | TASK [fail] ************************************************\ntask path: /home/worker/workspace/Create_New_VMLibrary_Template/ansible-vsphere-gos-validation/common/vm_set_power_state.yml:69\nfatal: [localhost]: FAILED! => (vmodl.fault.SystemError) {\n   dynamicType = <unset>,\n   dynamicProperty = (vmodl.DynamicProperty) [],\n   msg = 'A general system error occurred: Invalid fault',\n   faultCause = <unset>,\n   faultMessage = (vmodl.LocalizableMessage) [],\n   reason = 'Invalid fault'\n} ", "category": "", "processed": "timestamp failed at play vm library main timestamp task fail task path home worker workspace create new vm library template ansible vsphere gos validation common vm set power state yml number fatal localhost failed vmodl fault system error dynamic type un set dynamic property vmodl dynamic property message a general system error occurred invalid fault fault cause un set fault message vmodl localizable message reason invalid fault ", "solution": "deepdive", "target": "testcase", "version": 202207221500}, {"id": 5369, "name": "log-2841", "raw": "2022-07-12 08:06:47,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:06:47,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Debian_11.x_64bit/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle debian number x number b it ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5370, "name": "log-2842", "raw": "2022-07-12 08:07:12,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:12,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_LTS/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle flatcar lts ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5371, "name": "log-2843", "raw": "2022-07-12 08:07:14,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:14,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_Stable/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle flatcar stable ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5372, "name": "log-2844", "raw": "2022-07-12 08:07:23,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:23,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_3.x_Update_OVA/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle photon number x update ova ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5373, "name": "log-2847", "raw": "2022-07-12 08:07:34,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:34,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle photon number x update iso ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5374, "name": "log-2848", "raw": "2022-07-12 08:07:37,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:37,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_OracleLinux_8.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle oracle linux number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5375, "name": "log-2849", "raw": "2022-07-12 08:07:48,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:07:48,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.0_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle photon number iso ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5378, "name": "log-2853", "raw": "2022-07-12 08:10:51,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:10:51,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_RockyLinux_8.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle rocky linux number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5376, "name": "log-2932", "raw": "2022-07-12 14:01:09,012 | Failed at Play [env_setup] *********************************\n2022-07-12 14:01:09,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_RHEL_9.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle rhel number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5377, "name": "log-2852", "raw": "2022-07-12 08:09:46,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:09:46,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_SLED_15.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle sled number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5379, "name": "log-2854", "raw": "2022-07-12 08:11:06,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:11:06,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_SLES_15.x/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle sles number x ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5380, "name": "log-2931", "raw": "2022-07-12 14:00:27,012 | Failed at Play [env_setup] *********************************\n2022-07-12 14:00:27,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle ubuntu version id iso ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5381, "name": "log-2858", "raw": "2022-07-12 08:13:55,012 | Failed at Play [env_setup] *********************************\n2022-07-12 08:13:55,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle windows number ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5382, "name": "log-2930", "raw": "2022-07-12 14:00:23,012 | Failed at Play [env_setup] *********************************\n2022-07-12 14:00:23,012 | TASK [Check VM 'test_vm' does not exist] *******************\ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/env_setup/env_setup.yml:25\nfatal: [localhost]: FAILED! => Cann't deploy VM as a VM with same name 'test_vm' already exists. Please provide a new vm_name.", "category": "", "processed": "timestamp failed at play environment setup timestamp task check vm test vm does not exist task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation environment setup environment setup yml number fatal localhost failed can n t deploy vm as a vm with same name test vm already exists please provide a new vm name", "solution": "deepdive", "target": "usererror", "version": 202207221500}, {"id": 5383, "name": "log-2944", "raw": "2022-07-13 02:02:56,013 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-07-13 02:02:56,013 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220713004650.log] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-07-13 02:03:06,013 | TASK [Fetch file /tmp/cloud-init_2022-07-13-02-02-59.tar.gz from VM guest] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task fetch file tmp cloud init timestamp number tar gz from vm guest task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "testbed", "version": 202207221500}, {"id": 5384, "name": "log-2962", "raw": "2022-07-13 04:18:23,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 04:18:23,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.0_ISO/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.185.229.209' (ECDSA) to the list of known hosts.\nroot@10.185.229.209: Permission denied (publickey,keyboard-interactive).", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle photon number iso ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202207221500}, {"id": 5385, "name": "log-3007", "raw": "2022-07-13 05:05:25,013 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-07-13 05:05:25,013 | TASK [Collect filtered guest information for '10.185.110.153'] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_22.04_ISO/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.185.110.153' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nPermission denied, please try again.\nroot@10.185.110.153: Permission denied (publickey,password).", "category": "", "processed": "timestamp failed at play nvme v hba device ops timestamp task collect filtered guest information for ip address task path home worker workspace ansible cycle ubuntu number iso ansible vsphere gos validation common get system info yml number fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again permission denied please try again root ip address permission denied public key password", "solution": "retry", "target": "targetvm", "version": 202207221500}, {"id": 5386, "name": "log-3046", "raw": "2022-07-13 08:57:53,013 | Failed at Play [sata_vhba_device_ops] **********************\n2022-07-13 08:57:53,013 | TASK [Create ext4 file system] *****************************\ntask path: /home/worker/workspace/Ansible_Cycle_Photon_4.x_Update_OVA/ansible-vsphere-gos-validation/linux/vhba_hot_add_remove/prepare_new_disk.yml:50\nfatal: [localhost]: FAILED! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.78.116.253' (ECDSA) to the list of known hosts.\nroot@10.78.116.253: Permission denied (publickey,keyboard-interactive).", "category": "", "processed": "timestamp failed at play sata v hba device ops timestamp task create ext number file system task path home worker workspace ansible cycle photon number x update ova ansible vsphere gos validation linux v hba hot add remove prepare new disk yml number fatal localhost failed invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address ecdsa to the list of known hosts root ip address permission denied public key keyboard interactive", "solution": "retry", "target": "targetvm", "version": 202207221500}, {"id": 5387, "name": "log-3148", "raw": "2022-07-14 00:31:12,014 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-07-14 00:31:12,014 | TASK [Wait for message 'Autoinstall is completed.' appear in VM log serial-20220713231750.log] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-07-14 00:31:23,014 | TASK [Fetch file /tmp/cloud-init_2022-07-14-00-31-15.tar.gz from VM guest] \ntask path: /home/worker/workspace/Ansible_Cycle_Ubuntu_20.04.4_ISO/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:93\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle ubuntu version id iso ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task fetch file tmp cloud init timestamp number tar gz from vm guest task path home worker workspace ansible cycle ubuntu version id iso ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "retry", "target": "testbed", "version": 202207221500}, {"id": 5388, "name": "log-3150", "raw": "2022-07-14 13:39:59,014 | Failed at Play [nvme_vhba_device_ops] **********************\n2022-07-14 13:39:59,014 | TASK [Collect filtered guest information for '10.182.132.140'] \ntask path: /home/worker/workspace/Ansible_Cycle_Flatcar_Stable/ansible-vsphere-gos-validation/common/get_system_info.yml:22\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect username/password. Skipping remaining 5 retries to prevent account lockout: Warning: Permanently added '10.182.132.140' (ED25519) to the list of known hosts.\nPermission denied, please try again.\nReceived disconnect from 10.182.132.140 port 22:2: Too many authentication failures\nDisconnected from 10.182.132.140 port 22", "category": "", "processed": "timestamp failed at play nvme v hba device ops timestamp task collect filtered guest information for ip address task path home worker workspace ansible cycle flatcar stable ansible vsphere gos validation common get system info yml number fatal localhost un reachable invalid incorrect username password skipping remaining number retries to prevent account lockout warning permanently added ip address to the list of known hosts permission denied please try again received disconnect from ip address port number too many authentication failures disconnected from ip address port number", "solution": "retry", "target": "targetvm", "version": 202207221500}, {"id": 5389, "name": "log-3151", "raw": "2022-07-15 03:02:59,015 | Failed at Play [env_setup] *********************************\n2022-07-15 03:02:59,015 | TASK [Enable debug log by default] *************************\ntask path: /home/worker/workspace/Ansible_Regression_RHEL_9.x/ansible-vsphere-gos-validation/env_setup/set_default_variables.yml:13\nfatal: [localhost]: FAILED! => The variable name 'enable_ansible.builtin.debug' is not valid. Variables must start with a letter or underscore character, and contain only letters, numbers and underscores.", "category": "", "processed": "timestamp failed at play environment setup timestamp task enable debug log by default task path home worker workspace ansible regression rhel number x ansible vsphere gos validation environment setup set default variables yml number fatal localhost failed the variable name enable ansible builtin debug is not valid variables must start with a letter or underscore character and contain only letters numbers and underscores", "solution": "deepdive", "target": "testcase", "version": 202207221500}, {"id": 5390, "name": "log-3166", "raw": "2022-07-15 16:44:29,015 | Failed at Play [deploy_vm_efi_sata_e1000e] *****************\n2022-07-15 16:44:29,015 | TASK [Wait for VMware Tools collecting guest info] *********\ntask path: /home/worker/workspace/Ansible_RockyLinux_9.x_70GA_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_wait_guest_ip.yml:22\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-07-15 16:45:08,015 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_RockyLinux_9.x_70GA_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_sata_e1000e", "category": "", "processed": "timestamp failed at play deploy vm efi sata timestamp task wait for vmware tools collecting guest info task path home worker workspace ansible rocky linux number x number ga sata efi ansible vsphere gos validation common vm wait guest ip yml number fatal localhost failed hardware configuration table timestamp task testing exit due to failure task path home worker workspace ansible rocky linux number x number ga sata efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi sata e number e", "solution": "retry", "target": "targetvm", "version": 202207221500}, {"id": 5423, "name": "3189", "raw": "2022-07-20 13:42:04,020 | Failed at Play [vbs_enable_disable] ************************\n2022-07-20 13:42:04,020 | TASK [Check VBS and running security service status] *******\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/windows/vbs_enable_disable/vbs_enable_test.yml:41\nfatal: [localhost]: FAILED! => VBS is not running '2', or HVCI is not running '['1', ' 2']'.", "category": null, "processed": "timestamp failed at play vbs enable disable timestamp task check vbs and running security service status task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation windows vbs enable disable vbs enable test yml number fatal localhost failed vbs is not running number or h vci is not running number number", "solution": "deepdive", "target": "testcase", "version": 202207260728}, {"id": 5424, "name": "3190", "raw": "2022-07-20 14:38:04,020 | Failed at Play [vbs_enable_disable] ************************\n2022-07-20 14:38:04,020 | TASK [Check VBS and running security service status] *******\ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/windows/vbs_enable_disable/vbs_enable_test.yml:41\nfatal: [localhost]: FAILED! => VBS is not running '2', or HVCI is not running '['1', ' 2']'.", "category": null, "processed": "timestamp failed at play vbs enable disable timestamp task check vbs and running security service status task path home worker workspace ansible windows number main nvme efi ansible vsphere gos validation windows vbs enable disable vbs enable test yml number fatal localhost failed vbs is not running number or h vci is not running number number", "solution": "deepdive", "target": "testcase", "version": 202207260728}, {"id": 5425, "name": "3187", "raw": "2022-07-20 04:27:02,020 | Failed at Play [env_setup] *********************************\n2022-07-20 04:27:02,020 | TASK [Check variables for new VM settings] *****************\ntask path: /home/worker/workspace/Create_New_VMLibrary_Template/ansible-vsphere-gos-validation/env_setup/check_testing_vars.yml:57\nfatal: [localhost]: FAILED! => Invalid variables for new VM settings", "category": null, "processed": "timestamp failed at play environment setup timestamp task check variables for new vm settings task path home worker workspace create new vm library template ansible vsphere gos validation environment setup check testing vars yml number fatal localhost failed invalid variables for new vm settings", "solution": "deepdive", "target": "testcase", "version": 202207260728}, {"id": 5427, "name": "3270", "raw": "2022-07-27 02:32:30,027 | Failed at Play [env_setup] *********************************\n2022-07-27 02:32:30,027 | TASK [Get all registerd VMs and templates on 10.78.127.86] *\ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_check_exist.yml:14\nhttp.client.HTTPException: 503 Service Unavailable\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": null, "processed": "timestamp failed at play environment setup timestamp task get all register dv ms and templates on ip address task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation common vm check exist yml number http client http exception number service unavailable fatal localhost failed module failure see stdout stderr for the exact error", "solution": "retry", "target": "testbed", "version": 202208031141}, {"id": 5426, "name": "3276", "raw": "2022-07-27 07:21:22,027 | Failed at Play [deploy_ova] ********************************\n2022-07-27 07:21:22,027 | TASK [Deploy VM from ovf template] *************************\ntask path: /home/worker/workspace/Hyrule_OVF/ansible-vsphere-gos-validation/common/ovf_deploy.yml:4\nfatal: [localhost]: FAILED! => Datastore 'datasore2' could not be located on specified ESXi host or datacenter\n2022-07-27 07:21:24,027 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Hyrule_OVF/ansible-vsphere-gos-validation/common/test_rescue.yml:55\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_ova\n2022-07-27 07:21:26,027 | TASK [Get specified property info for VM 'test_hyrule_ovf'] \ntask path: /home/worker/workspace/Hyrule_OVF/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_hyrule_ovf", "category": null, "processed": "timestamp failed at play deploy ova timestamp task deploy vm from ovf template task path home worker workspace hy rule ovf ansible vsphere gos validation common ovf deploy yml number fatal localhost failed data store data sore number could not be located on specified esxi host or data center timestamp task testing exit due to failure task path home worker workspace hy rule ovf ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy ova timestamp task get specified property info for vm test hy rule ovf task path home worker workspace hy rule ovf ansible vsphere gos validation common vm get configuration yml number fatal localhost failed unable to gather information for non existing vm test hy rule ovf", "solution": "deepdive", "target": "usererror", "version": 202208031141}, {"id": 5428, "name": "3336", "raw": "2022-08-02 08:30:39,002 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-08-02 08:30:39,002 | TASK [Check VM 'test_vm_1659424377814' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_70U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424377814' IP Address\n2022-08-02 08:31:15,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_70U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it lsi logic sas efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it lsi logic sas efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5430, "name": "3337", "raw": "2022-08-02 08:30:27,002 | Failed at Play [deploy_vm_efi_sata_e1000e] *****************\n2022-08-02 08:30:27,002 | TASK [Check VM 'test_vm_1659424395015' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67U2_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424395015' IP Address\n2022-08-02 08:31:17,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67U2_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_sata_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi sata timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it sata efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it sata efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi sata e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5432, "name": "3310", "raw": "2022-08-02 06:43:58,002 | Failed at Play [deploy_vm_bios_ide_e1000e] *****************\n2022-08-02 06:43:58,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67U2_IDE_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:44:51,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67U2_IDE_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_ide_e1000e", "category": null, "processed": "timestamp failed at play deploy vm bios ide timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it ide bios ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it ide bios ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios ide e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5429, "name": "3313", "raw": "2022-08-02 06:46:05,002 | Failed at Play [deploy_vm_efi_ide_e1000e] ******************\n2022-08-02 06:46:05,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:46:42,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_ide_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi ide timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it number ga ide efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it number ga ide efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi ide e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5431, "name": "3311", "raw": "2022-08-02 06:44:40,002 | Failed at Play [deploy_vm_efi_sata_e1000e] *****************\n2022-08-02 06:44:40,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67U2_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:45:37,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67U2_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_sata_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi sata timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it sata efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it sata efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi sata e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5433, "name": "3324", "raw": "2022-08-02 08:28:35,002 | Failed at Play [deploy_vm_efi_sata_e1000e] *****************\n2022-08-02 08:28:35,002 | TASK [Check VM 'test_vm_1659424345087' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_70U1_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424345087' IP Address\n2022-08-02 08:29:17,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_70U1_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_sata_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi sata timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it sata efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it sata efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi sata e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5435, "name": "3331", "raw": "2022-08-02 08:30:14,002 | Failed at Play [deploy_vm_bios_paravirtual_e1000e] *********\n2022-08-02 08:30:14,002 | TASK [Check VM 'test_vm_1659424394338' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70U3_PARAVIRTUAL_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424394338' IP Address\n2022-08-02 08:30:42,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70U3_PARAVIRTUAL_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_paravirtual_e1000e", "category": null, "processed": "timestamp failed at play deploy vm bios para virtual timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it para virtual bios ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it para virtual bios ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios para virtual e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5434, "name": "3309", "raw": "2022-08-02 06:43:19,002 | Failed at Play [deploy_vm_efi_sata_e1000e] *****************\n2022-08-02 06:43:19,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_70U1_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:43:56,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_70U1_SATA_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_sata_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi sata timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it sata efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it sata efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi sata e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5436, "name": "3307", "raw": "2022-08-02 06:43:46,002 | Failed at Play [deploy_vm_bios_paravirtual_e1000e] *********\n2022-08-02 06:43:46,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70U3_PARAVIRTUAL_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:44:12,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70U3_PARAVIRTUAL_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_paravirtual_e1000e", "category": null, "processed": "timestamp failed at play deploy vm bios para virtual timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it para virtual bios ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it para virtual bios ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios para virtual e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5439, "name": "3340", "raw": "2022-08-02 08:25:39,002 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-08-02 08:25:39,002 | TASK [Check VM 'test_vm_1659424562274' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424562274' IP Address\n2022-08-02 08:26:01,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it lsi logic sas efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it lsi logic sas efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5441, "name": "3302", "raw": "2022-08-02 06:41:24,002 | Failed at Play [deploy_vm_bios_nvme_e1000e] ****************\n2022-08-02 06:41:24,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70GA_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:42:10,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70GA_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_nvme_e1000e", "category": null, "processed": "timestamp failed at play deploy vm bios nvme timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it number ga nvme bios ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it number ga nvme bios ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios nvme e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5443, "name": "3325", "raw": "2022-08-02 08:29:32,002 | Failed at Play [deploy_vm_efi_ide_e1000e] ******************\n2022-08-02 08:29:32,002 | TASK [Check VM 'test_vm_1659424375453' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_67GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424375453' IP Address\n2022-08-02 08:29:42,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_67GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_ide_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi ide timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it number ga ide efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it number ga ide efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi ide e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5437, "name": "3333", "raw": "2022-08-02 08:29:56,002 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-08-02 08:29:56,002 | TASK [Check VM 'test_vm_1659424423700' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424423700' IP Address\n2022-08-02 08:30:48,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it number ga lsi logic sas efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it number ga lsi logic sas efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5438, "name": "3304", "raw": "2022-08-02 06:41:54,002 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-08-02 06:41:54,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:42:48,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_67GA_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it number ga lsi logic sas efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it number ga lsi logic sas efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5440, "name": "3326", "raw": "2022-08-02 08:29:38,002 | Failed at Play [deploy_vm_bios_nvme_e1000e] ****************\n2022-08-02 08:29:38,002 | TASK [Check VM 'test_vm_1659424419696' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70GA_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424419696' IP Address\n2022-08-02 08:30:22,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70GA_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_nvme_e1000e", "category": null, "processed": "timestamp failed at play deploy vm bios nvme timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it number ga nvme bios ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it number ga nvme bios ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios nvme e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5442, "name": "3301", "raw": "2022-08-02 06:40:31,002 | Failed at Play [deploy_vm_bios_ide_e1000e] *****************\n2022-08-02 06:40:31,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_67U3_IDE_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:41:24,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_67U3_IDE_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_bios_ide_e1000e", "category": null, "processed": "timestamp failed at play deploy vm bios ide timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it ide bios ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it ide bios ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm bios ide e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5444, "name": "3300", "raw": "2022-08-02 06:39:30,002 | Failed at Play [deploy_vm_efi_ide_e1000e] ******************\n2022-08-02 06:39:30,002 | TASK [Check VM 'test_vm' IP address] ***********************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_67GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address\n2022-08-02 06:40:48,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_67GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_ide_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi ide timestamp task check vm test vm ip address task path home worker workspace ansible windows number b it number ga ide efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it number ga ide efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi ide e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5445, "name": "3321", "raw": "2022-08-02 08:27:54,002 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-08-02 08:27:54,002 | TASK [Check VM 'test_vm_1659424362336' IP address] *********\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_67U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm_1659424362336' IP Address\n2022-08-02 08:28:44,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_32bit_67U3_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_e1000e", "category": null, "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task check vm test vm number ip address task path home worker workspace ansible windows number b it lsi logic sas efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm number ip address timestamp task testing exit due to failure task path home worker workspace ansible windows number b it lsi logic sas efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas e number e", "solution": "retry", "target": "targetvm", "version": 202208031141}, {"id": 5469, "name": "log-3509", "raw": "2022-08-15 08:13:15,015 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-08-15 08:13:15,015 | TASK [vmxnet3_network_device_ops][Try to ping IP] **********\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "", "processed": "timestamp failed at play vmxnet number network device ops timestamp task vmxnet number network device ops try to ping ip task path home worker workspace ansible ubuntu lts server iso nvme vmxnet number efi ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping", "solution": "retry", "target": "targetvm", "version": 202208172100}, {"id": 5470, "name": "log-3519", "raw": "2022-08-15 14:03:22,015 | Failed at Play [deploy_vm_efi_nvme_vmxnet3] ****************\n2022-08-15 14:03:22,015 | TASK [deploy_vm_efi_nvme_vmxnet3][Configure VM CDROM to 'client'] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_configure_cdrom.yml:14\nexception in /vmware.py when connect_to_api in /ssl.py when do_handshake\nfatal: [localhost]: FAILED! => Unable to connect to vCenter or ESXi API at 10.191.149.181 on TCP/443: EOF occurred in violation of protocol (_ssl.c:1123)\n2022-08-15 14:04:02,015 | TASK [deploy_vm_efi_nvme_vmxnet3][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U3_NVME_VMXNET3_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_nvme_vmxnet3", "category": "", "processed": "timestamp failed at play deploy vm efi nvme vmxnet number timestamp task deploy vm efi nvme vmxnet number configure vm cdrom to client task path home worker workspace ansible ubuntu lts server iso nvme vmxnet number efi ansible vsphere gos validation common vm configure cdrom yml number exception in vmware python when connect to api in ssl python when do handshake fatal localhost failed unable to connect to vcenter or esxi api at ip address on tcp number eof occurred in violation of protocol ssl c number timestamp task deploy vm efi nvme vmxnet number testing exit due to failure task path home worker workspace ansible ubuntu lts server iso nvme vmxnet number efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi nvme vmxnet number", "solution": "retry", "target": "nimbus", "version": 202208172100}, {"id": 5471, "name": "log-3520", "raw": "2022-08-15 14:38:00,015 | Failed at Play [deploy_vm_bios_lsilogicsas_e1000e] *********\n2022-08-15 14:38:00,015 | TASK [deploy_vm_bios_lsilogicsas_e1000e][Wait for message 'Autoinstall is completed.' appear in VM log serial-20220815132317.log] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-08-15 14:38:13,015 | TASK [deploy_vm_bios_lsilogicsas_e1000e][Fetch file /tmp/cloud-init_2022-08-15-14-38-04.tar.gz from VM guest] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70U1_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:91\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "", "processed": "timestamp failed at play deploy vm bios lsi logic sas timestamp task deploy vm bios lsi logic sas wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible ubuntu lts server iso lsi logic sas bios ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task deploy vm bios lsi logic sas fetch file tmp cloud init timestamp number tar gz from vm guest task path home worker workspace ansible ubuntu lts server iso lsi logic sas bios ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "deepdive", "target": "targetvm", "version": 202208172100}, {"id": 5472, "name": "log-3521", "raw": "2022-08-15 14:43:58,015 | Failed at Play [deploy_vm_bios_sata_e1000e] ****************\n2022-08-15 14:43:58,015 | TASK [deploy_vm_bios_sata_e1000e][Wait for message 'Autoinstall is completed.' appear in VM log serial-20220815132730.log] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70GA_SATA_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-08-15 14:44:12,015 | TASK [deploy_vm_bios_sata_e1000e][Fetch file /tmp/cloud-init_2022-08-15-14-44-03.tar.gz from VM guest] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_70GA_SATA_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:91\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "", "processed": "timestamp failed at play deploy vm bios sata timestamp task deploy vm bios sata wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible ubuntu lts server iso number ga sata bios ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task deploy vm bios sata fetch file tmp cloud init timestamp number tar gz from vm guest task path home worker workspace ansible ubuntu lts server iso number ga sata bios ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "deepdive", "target": "targetvm", "version": 202208172100}, {"id": 5450, "name": "log-3364", "raw": "2022-08-03 13:09:49,003 | Failed at Play [secureboot_enable_disable] *****************\n2022-08-03 13:09:49,003 | TASK [secureboot_enable_disable][Check secure boot enable and disable test results] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_OVA/ansible-vsphere-gos-validation/linux/secureboot_enable_disable/secureboot_enable_disable.yml:96\nfatal: [localhost]: FAILED! => Enable secureboot result: False, disable secureboot result: True", "category": "", "processed": "timestamp failed at play secure boot enable disable timestamp task secure boot enable disable check secure boot enable and disable test results task path home worker workspace ansible regression photon number ova ansible vsphere gos validation linux secure boot enable disable secure boot enable disable yml number fatal localhost failed enable secure boot result false disable secure boot result true", "solution": "deepdive", "target": "product", "version": 202208172100}, {"id": 5451, "name": "log-3369", "raw": "2022-08-04 23:07:54,004 | Failed at Play [testbed_deploy_nimbus] *********************\n2022-08-04 23:07:54,004 | TASK [testbed_deploy_nimbus][Get ESXi datastores info] *****\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/common/esxi_get_datastores.yml:5\nexception in /vmware.py when connect_to_api in /socket.py when create_connection\nfatal: [localhost]: FAILED! => Unknown error while connecting to vCenter or ESXi API at 10.206.190.129:443 : [Errno 113] No route to host", "category": "", "processed": "timestamp failed at play testbed deploy nimbus timestamp task testbed deploy nimbus get esxi data stores info task path home worker workspace ansible cycle windows number ansible vsphere gos validation common esxi get data stores yml number exception in vmware python when connect to api in socket python when create connection fatal localhost failed unknown error while connecting to vcenter or esxi api at ip address error number no route to host", "solution": "retry", "target": "nimbus", "version": 202208172100}, {"id": 5447, "name": "log-3294", "raw": "2022-08-02 02:11:43,002 | Failed at Play [wintools_complete_install_verify] **********\n2022-08-02 02:11:43,002 | TASK [Execute powershell command 'get-service -Name VMTools | foreach {$_.Status}'] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/windows/utils/win_execute_cmd.yml:18\nfatal: [localhost -> 10.185.13.217]: FAILED! => non-zero return code when get-service", "category": "", "processed": "timestamp failed at play win tools complete install verify timestamp task execute powershell command get service name vm tools for each status task path home worker workspace ansible windows server lts c main para virtual vmxnet number efi ansible vsphere gos validation windows utilities win execute command yml number fatal localhost ip address failed nonzero return code when get service", "solution": "retry", "target": "targetvm", "version": 202208172100}, {"id": 5467, "name": "log-3495", "raw": "2022-08-15 07:56:43,015 | Failed at Play [e1000e_network_device_ops] *****************\n2022-08-15 07:56:43,015 | TASK [e1000e_network_device_ops][Try to ping IP] ***********\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_MAIN_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "", "processed": "timestamp failed at play network device ops timestamp task network device ops try to ping ip task path home worker workspace ansible ubuntu lts server iso main nvme bios ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping", "solution": "retry", "target": "targetvm", "version": 202208172100}, {"id": 5446, "name": "log-3288", "raw": "2022-08-01 08:28:53,001 | Failed at Play [env_setup] *********************************\n2022-08-01 08:28:53,001 | TASK [Get all registerd VMs and templates on 10.117.17.83] *\ntask path: /home/worker/workspace/Ansible_RHEL_8.x_70U3_PARAVIRTUAL_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_check_exist.yml:14\nAttributeError: 'NoneType' object has no attribute 'datastoreUrl'\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "", "processed": "timestamp failed at play environment setup timestamp task get all register dv ms and templates on ip address task path home worker workspace ansible rhel number x para virtual bios ansible vsphere gos validation common vm check exist yml number attribute error none type object has no attribute data store url fatal localhost failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testbed", "version": 202208172100}, {"id": 5448, "name": "log-3319", "raw": "2022-08-02 07:16:33,002 | Failed at Play [deploy_vm_efi_ide_e1000e] ******************\n2022-08-02 07:16:33,002 | TASK [Add IDE boot disk] ***********************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_create_with_ide_disk.yml:49\nfatal: [localhost -> 10.78.89.80]: FAILED! => non-zero return code when vim-cmd\n2022-08-02 07:16:34,002 | TASK [Testing exit due to failure] *************************\ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_70GA_IDE_E1000E_EFI/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_ide_e1000e", "category": "", "processed": "timestamp failed at play deploy vm efi ide timestamp task add ide boot disk task path home worker workspace ansible windows number b it number ga ide efi ansible vsphere gos validation common vm create with ide disk yml number fatal localhost ip address failed nonzero return code when vim command timestamp task testing exit due to failure task path home worker workspace ansible windows number b it number ga ide efi ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi ide e number e", "solution": "deepdive", "target": "targetvm", "version": 202208172100}, {"id": 5449, "name": "log-3363", "raw": "2022-08-03 12:22:06,003 | Failed at Play [ovt_verify_install] ************************\n2022-08-03 12:22:06,003 | TASK [ovt_verify_install][Wait for port 22 to become stopped] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/linux/utils/shutdown.yml:13\nfatal: [localhost]: FAILED! => Timeout when waiting for 10.170.67.119:22 to stop.\n2022-08-03 12:22:20,003 | TASK [ovt_verify_install][Testing exit due to failure] *****\ntask path: /home/worker/workspace/Ansible_Regression_Photon_4.0_OVA/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case ovt_verify_install", "category": "", "processed": "timestamp failed at play ovt verify install timestamp task ovt verify install wait for port number to become stopped task path home worker workspace ansible regression photon number ova ansible vsphere gos validation linux utilities shutdown yml number fatal localhost failed timeout when waiting for ip address to stop timestamp task ovt verify install testing exit due to failure task path home worker workspace ansible regression photon number ova ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case ovt verify install", "solution": "retry", "target": "targetvm", "version": 202208172100}, {"id": 5452, "name": "log-3381", "raw": "2022-08-05 03:57:53,005 | Failed at Play [deploy_vm_efi_paravirtual_e1000e] **********\n2022-08-05 03:57:53,005 | TASK [deploy_vm][Datastore file operation] *****************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => File 'OS/Other/Windows/Windows10/v22H2/19045.1826/Windows10_InsiderPreview_EnterpriseVL_x32_en-us_19045.1826.iso' is absent, cannot continue\n2022-08-05 03:57:54,005 | TASK [deploy_vm][Testing exit due to failure] **************\ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_32/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_paravirtual_e1000e", "category": "", "processed": "timestamp failed at play deploy vm efi para virtual timestamp task deploy vm data store file operation task path home worker workspace ansible cycle windows number ansible vsphere gos validation common esxi check delete data store file yml number fatal localhost failed file os other windows windows number v number h number windows number insider preview enterprise vl en us number i so is absent can not continue timestamp task deploy vm testing exit due to failure task path home worker workspace ansible cycle windows number ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual e number e", "solution": "deepdive", "target": "testbed", "version": 202208172100}, {"id": 5453, "name": "log-3413", "raw": "2022-08-09 05:38:57,009 | Failed at Play [check_inbox_driver] ************************\n2022-08-09 05:38:57,009 | TASK [check_inbox_driver][Check inbox driver's filename is valid] \ntask path: /home/worker/workspace/Ansible_Regression_SLES_15.x/ansible-vsphere-gos-validation/linux/check_inbox_driver/get_inbox_drivers.yml:123\nfailed: [localhost] => (item=vmxnet3 is /lib/modules/5.14.21-150400.22-default/kernel/drivers/net/vmxnet3/vmxnet3.ko.zst) => Invalid inbox driver vmxnet3 filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/net/vmxnet3/vmxnet3.ko.zst and vmxnet3 is /lib/modules/5.14.21-150400.22-default/kernel/drivers/net/vmxnet3/vmxnet3.ko.zst\nfailed: [localhost] => (item=vmw_vmci is /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_vmci/vmw_vmci.ko.zst) => Invalid inbox driver vmw_vmci filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_vmci/vmw_vmci.ko.zst and vmw_vmci is /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_vmci/vmw_vmci.ko.zst\nfailed: [localhost] => (item=vsock is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vsock.ko.zst) => Invalid inbox driver vsock filename /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vsock.ko.zst and vsock is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vsock.ko.zst\nfailed: [localhost] => (item=vmw_vsock_vmci_transport is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_vmci_transport.ko.zst) => Invalid inbox driver vmw_vsock_vmci_transport filename /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_vmci_transport.ko.zst and vmw_vsock_vmci_transport is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_vmci_transport.ko.zst\nfailed: [localhost] => (item=vmw_vsock_virtio_transport_common is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_virtio_transport_common.ko.zst) => Invalid inbox driver vmw_vsock_virtio_transport_common filename /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_virtio_transport_common.ko.zst and vmw_vsock_virtio_transport_common is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_virtio_transport_common.ko.zst\nfailed: [localhost] => (item=vmw_pvscsi is /lib/modules/5.14.21-150400.22-default/kernel/drivers/scsi/vmw_pvscsi.ko.zst) => Invalid inbox driver vmw_pvscsi filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/scsi/vmw_pvscsi.ko.zst and vmw_pvscsi is /lib/modules/5.14.21-150400.22-default/kernel/drivers/scsi/vmw_pvscsi.ko.zst\nfailed: [localhost] => (item=vmw_balloon is /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_balloon.ko.zst) => Invalid inbox driver vmw_balloon filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_balloon.ko.zst and vmw_balloon is /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_balloon.ko.zst\nfailed: [localhost] => (item=vmwgfx is /lib/modules/5.14.21-150400.22-default/kernel/drivers/gpu/drm/vmwgfx/vmwgfx.ko.zst) => Invalid inbox driver vmwgfx filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/gpu/drm/vmwgfx/vmwgfx.ko.zst and vmwgfx is /lib/modules/5.14.21-150400.22-default/kernel/drivers/gpu/drm/vmwgfx/vmwgfx.ko.zst\nfailed: [localhost] => (item=vmw_pvrdma is /lib/modules/5.14.21-150400.22-default/kernel/drivers/infiniband/hw/vmw_pvrdma/vmw_pvrdma.ko.zst) => Invalid inbox driver vmw_pvrdma filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/infiniband/hw/vmw_pvrdma/vmw_pvrdma.ko.zst and vmw_pvrdma is /lib/modules/5.14.21-150400.22-default/kernel/drivers/infiniband/hw/vmw_pvrdma/vmw_pvrdma.ko.zst\nfailed: [localhost] => (item=ptp_vmw is /lib/modules/5.14.21-150400.22-default/kernel/drivers/ptp/ptp_vmw.ko.zst) => Invalid inbox driver ptp_vmw filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/ptp/ptp_vmw.ko.zst and ptp_vmw is /lib/modules/5.14.21-150400.22-default/kernel/drivers/ptp/ptp_vmw.ko.zst", "category": "", "processed": "timestamp failed at play check inbox driver timestamp task check inbox driver check inbox driver s filename is valid task path home worker workspace ansible regression sles number x ansible vsphere gos validation linux check inbox driver get inbox drivers yml number failed localhost item vmxnet number is library modules version id number default kernel drivers net vmxnet number vmxnet number ko z st invalid inbox driver vmxnet number filename library modules version id number default kernel drivers net vmxnet number vmxnet number ko z st and vmxnet number is library modules version id number default kernel drivers net vmxnet number vmxnet number ko z st failed localhost item vmware vmci is library modules version id number default kernel drivers misc vmware vmci vmware vmci ko z st invalid inbox driver vmware vmci filename library modules version id number default kernel drivers misc vmware vmci vmware vmci ko z st and vmware vmci is library modules version id number default kernel drivers misc vmware vmci vmware vmci ko z st failed localhost item vsock is library modules version id number default kernel net vmware vsock vsock ko z st invalid inbox driver vsock filename library modules version id number default kernel net vmware vsock vsock ko z st and vsock is library modules version id number default kernel net vmware vsock vsock ko z st failed localhost item vmware vsock vmci transport is library modules version id number default kernel net vmware vsock vmware vsock vmci transport ko z st invalid inbox driver vmware vsock vmci transport filename library modules version id number default kernel net vmware vsock vmware vsock vmci transport ko z st and vmware vsock vmci transport is library modules version id number default kernel net vmware vsock vmware vsock vmci transport ko z st failed localhost item vmware vsock virtio transport common is library modules version id number default kernel net vmware vsock vmware vsock virtio transport common ko z st invalid inbox driver vmware vsock virtio transport common filename library modules version id number default kernel net vmware vsock vmware vsock virtio transport common ko z st and vmware vsock virtio transport common is library modules version id number default kernel net vmware vsock vmware vsock virtio transport common ko z st failed localhost item vmware pvscsi is library modules version id number default kernel drivers scsi vmware pvscsi ko z st invalid inbox driver vmware pvscsi filename library modules version id number default kernel drivers scsi vmware pvscsi ko z st and vmware pvscsi is library modules version id number default kernel drivers scsi vmware pvscsi ko z st failed localhost item vmware balloon is library modules version id number default kernel drivers misc vmware balloon ko z st invalid inbox driver vmware balloon filename library modules version id number default kernel drivers misc vmware balloon ko z st and vmware balloon is library modules version id number default kernel drivers misc vmware balloon ko z st failed localhost item vmware gfx is library modules version id number default kernel drivers gpu drm vmware gfx vmware gfx ko z st invalid inbox driver vmware gfx filename library modules version id number default kernel drivers gpu drm vmware gfx vmware gfx ko z st and vmware gfx is library modules version id number default kernel drivers gpu drm vmware gfx vmware gfx ko z st failed localhost item vmware pvrdma is library modules version id number default kernel drivers infiniband hw vmware pvrdma vmware pvrdma ko z st invalid inbox driver vmware pvrdma filename library modules version id number default kernel drivers infiniband hw vmware pvrdma vmware pvrdma ko z st and vmware pvrdma is library modules version id number default kernel drivers infiniband hw vmware pvrdma vmware pvrdma ko z st failed localhost item p tp vmware is library modules version id number default kernel drivers p tp p tp vmware ko z st invalid inbox driver p tp vmware filename library modules version id number default kernel drivers p tp p tp vmware ko z st and p tp vmware is library modules version id number default kernel drivers p tp p tp vmware ko z st", "solution": "deepdive", "target": "testcase", "version": 202208172100}, {"id": 5454, "name": "log-3414", "raw": "2022-08-09 05:42:22,009 | Failed at Play [check_inbox_driver] ************************\n2022-08-09 05:42:22,009 | TASK [check_inbox_driver][Check inbox driver's filename is valid] \ntask path: /home/worker/workspace/Ansible_Regression_SLED_15.x/ansible-vsphere-gos-validation/linux/check_inbox_driver/get_inbox_drivers.yml:123\nfailed: [localhost] => (item=vmxnet3 is /lib/modules/5.14.21-150400.22-default/kernel/drivers/net/vmxnet3/vmxnet3.ko.zst) => Invalid inbox driver vmxnet3 filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/net/vmxnet3/vmxnet3.ko.zst and vmxnet3 is /lib/modules/5.14.21-150400.22-default/kernel/drivers/net/vmxnet3/vmxnet3.ko.zst\nfailed: [localhost] => (item=vmw_vmci is /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_vmci/vmw_vmci.ko.zst) => Invalid inbox driver vmw_vmci filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_vmci/vmw_vmci.ko.zst and vmw_vmci is /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_vmci/vmw_vmci.ko.zst\nfailed: [localhost] => (item=vsock is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vsock.ko.zst) => Invalid inbox driver vsock filename /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vsock.ko.zst and vsock is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vsock.ko.zst\nfailed: [localhost] => (item=vmw_vsock_vmci_transport is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_vmci_transport.ko.zst) => Invalid inbox driver vmw_vsock_vmci_transport filename /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_vmci_transport.ko.zst and vmw_vsock_vmci_transport is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_vmci_transport.ko.zst\nfailed: [localhost] => (item=vmw_vsock_virtio_transport_common is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_virtio_transport_common.ko.zst) => Invalid inbox driver vmw_vsock_virtio_transport_common filename /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_virtio_transport_common.ko.zst and vmw_vsock_virtio_transport_common is /lib/modules/5.14.21-150400.22-default/kernel/net/vmw_vsock/vmw_vsock_virtio_transport_common.ko.zst\nfailed: [localhost] => (item=vmw_pvscsi is /lib/modules/5.14.21-150400.22-default/kernel/drivers/scsi/vmw_pvscsi.ko.zst) => Invalid inbox driver vmw_pvscsi filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/scsi/vmw_pvscsi.ko.zst and vmw_pvscsi is /lib/modules/5.14.21-150400.22-default/kernel/drivers/scsi/vmw_pvscsi.ko.zst\nfailed: [localhost] => (item=vmw_balloon is /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_balloon.ko.zst) => Invalid inbox driver vmw_balloon filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_balloon.ko.zst and vmw_balloon is /lib/modules/5.14.21-150400.22-default/kernel/drivers/misc/vmw_balloon.ko.zst\nfailed: [localhost] => (item=vmwgfx is /lib/modules/5.14.21-150400.22-default/kernel/drivers/gpu/drm/vmwgfx/vmwgfx.ko.zst) => Invalid inbox driver vmwgfx filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/gpu/drm/vmwgfx/vmwgfx.ko.zst and vmwgfx is /lib/modules/5.14.21-150400.22-default/kernel/drivers/gpu/drm/vmwgfx/vmwgfx.ko.zst\nfailed: [localhost] => (item=vmw_pvrdma is /lib/modules/5.14.21-150400.22-default/kernel/drivers/infiniband/hw/vmw_pvrdma/vmw_pvrdma.ko.zst) => Invalid inbox driver vmw_pvrdma filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/infiniband/hw/vmw_pvrdma/vmw_pvrdma.ko.zst and vmw_pvrdma is /lib/modules/5.14.21-150400.22-default/kernel/drivers/infiniband/hw/vmw_pvrdma/vmw_pvrdma.ko.zst\nfailed: [localhost] => (item=ptp_vmw is /lib/modules/5.14.21-150400.22-default/kernel/drivers/ptp/ptp_vmw.ko.zst) => Invalid inbox driver ptp_vmw filename /lib/modules/5.14.21-150400.22-default/kernel/drivers/ptp/ptp_vmw.ko.zst and ptp_vmw is /lib/modules/5.14.21-150400.22-default/kernel/drivers/ptp/ptp_vmw.ko.zst", "category": "", "processed": "timestamp failed at play check inbox driver timestamp task check inbox driver check inbox driver s filename is valid task path home worker workspace ansible regression sled number x ansible vsphere gos validation linux check inbox driver get inbox drivers yml number failed localhost item vmxnet number is library modules version id number default kernel drivers net vmxnet number vmxnet number ko z st invalid inbox driver vmxnet number filename library modules version id number default kernel drivers net vmxnet number vmxnet number ko z st and vmxnet number is library modules version id number default kernel drivers net vmxnet number vmxnet number ko z st failed localhost item vmware vmci is library modules version id number default kernel drivers misc vmware vmci vmware vmci ko z st invalid inbox driver vmware vmci filename library modules version id number default kernel drivers misc vmware vmci vmware vmci ko z st and vmware vmci is library modules version id number default kernel drivers misc vmware vmci vmware vmci ko z st failed localhost item vsock is library modules version id number default kernel net vmware vsock vsock ko z st invalid inbox driver vsock filename library modules version id number default kernel net vmware vsock vsock ko z st and vsock is library modules version id number default kernel net vmware vsock vsock ko z st failed localhost item vmware vsock vmci transport is library modules version id number default kernel net vmware vsock vmware vsock vmci transport ko z st invalid inbox driver vmware vsock vmci transport filename library modules version id number default kernel net vmware vsock vmware vsock vmci transport ko z st and vmware vsock vmci transport is library modules version id number default kernel net vmware vsock vmware vsock vmci transport ko z st failed localhost item vmware vsock virtio transport common is library modules version id number default kernel net vmware vsock vmware vsock virtio transport common ko z st invalid inbox driver vmware vsock virtio transport common filename library modules version id number default kernel net vmware vsock vmware vsock virtio transport common ko z st and vmware vsock virtio transport common is library modules version id number default kernel net vmware vsock vmware vsock virtio transport common ko z st failed localhost item vmware pvscsi is library modules version id number default kernel drivers scsi vmware pvscsi ko z st invalid inbox driver vmware pvscsi filename library modules version id number default kernel drivers scsi vmware pvscsi ko z st and vmware pvscsi is library modules version id number default kernel drivers scsi vmware pvscsi ko z st failed localhost item vmware balloon is library modules version id number default kernel drivers misc vmware balloon ko z st invalid inbox driver vmware balloon filename library modules version id number default kernel drivers misc vmware balloon ko z st and vmware balloon is library modules version id number default kernel drivers misc vmware balloon ko z st failed localhost item vmware gfx is library modules version id number default kernel drivers gpu drm vmware gfx vmware gfx ko z st invalid inbox driver vmware gfx filename library modules version id number default kernel drivers gpu drm vmware gfx vmware gfx ko z st and vmware gfx is library modules version id number default kernel drivers gpu drm vmware gfx vmware gfx ko z st failed localhost item vmware pvrdma is library modules version id number default kernel drivers infiniband hw vmware pvrdma vmware pvrdma ko z st invalid inbox driver vmware pvrdma filename library modules version id number default kernel drivers infiniband hw vmware pvrdma vmware pvrdma ko z st and vmware pvrdma is library modules version id number default kernel drivers infiniband hw vmware pvrdma vmware pvrdma ko z st failed localhost item p tp vmware is library modules version id number default kernel drivers p tp p tp vmware ko z st invalid inbox driver p tp vmware filename library modules version id number default kernel drivers p tp p tp vmware ko z st and p tp vmware is library modules version id number default kernel drivers p tp p tp vmware ko z st", "solution": "deepdive", "target": "testcase", "version": 202208172100}, {"id": 5455, "name": "log-3435", "raw": "2022-08-10 06:16:36,010 | Failed at Play [secureboot_enable_disable] *****************\n2022-08-10 06:16:36,010 | TASK [secureboot_enable_disable][Check VM 'test_vm' IP address] \ntask path: /home/worker/workspace/Ansible_Cycle_Windows_10_64/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address", "category": "", "processed": "timestamp failed at play secure boot enable disable timestamp task secure boot enable disable check vm test vm ip address task path home worker workspace ansible cycle windows number ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address", "solution": "deepdive", "target": "targetvm", "version": 202208172100}, {"id": 5456, "name": "log-3441", "raw": "2022-08-11 02:57:18,011 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-08-11 02:57:18,011 | TASK [deploy_vm_efi_lsilogicsas_e1000e][Wait for getting VM 'dw_test_winsrv_ansible' IP address on ESXi 'pek2-hs1-a0410.eng.vmware.com'] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip_esxcli.yml:51\nfatal: [localhost]: UNREACHABLE! => Invalid/incorrect password: Warning: Permanently added 'pek2-hs1-a0410.eng.vmware.com' (ECDSA) to the list of known hosts.", "category": "", "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task deploy vm efi lsi logic sas wait for getting vm dw test win srv ansible ip address on esxi pe k number hs number eng vmware com task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation common vm get ip esx cli yml number fatal localhost un reachable invalid incorrect password warning permanently added pe k number hs number eng vmware com ecdsa to the list of known hosts", "solution": "retry", "target": "nimbus", "version": 202208172100}, {"id": 5457, "name": "log-3442", "raw": "2022-08-11 04:22:33,011 | Failed at Play [vbs_enable_disable] ************************\n2022-08-11 04:22:33,011 | TASK [vbs_enable_disable][Check VM 'dw_test_winsrv_ansible' IP address] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_LSILOGICSAS_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'dw_test_winsrv_ansible' IP Address", "category": "", "processed": "timestamp failed at play vbs enable disable timestamp task vbs enable disable check vm dw test win srv ansible ip address task path home worker workspace ansible windows server lts c main lsi logic sas efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm dw test win srv ansible ip address", "solution": "deepdive", "target": "targetvm", "version": 202208172100}, {"id": 5458, "name": "log-3444", "raw": "2022-08-11 04:33:38,011 | Failed at Play [check_inbox_driver] ************************\n2022-08-11 04:33:38,011 | TASK [check_inbox_driver][Check all mandatory inbox drivers exists in Ubuntu] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_OVA/ansible-vsphere-gos-validation/linux/check_inbox_driver/get_inbox_drivers.yml:181\nfailed: [localhost] => (item=None) => Unexpected templating type error occurred on ({{ mandatory_drivers - ['vmw_balloon']}}): unsupported operand type(s) for -: 'list' and 'list'", "category": "", "processed": "timestamp failed at play check inbox driver timestamp task check inbox driver check all mandatory inbox drivers exists in ubuntu task path home worker workspace ansible regression ubuntu number server ova ansible vsphere gos validation linux check inbox driver get inbox drivers yml number failed localhost item none unexpected templating type error occurred on mandatory drivers vmware balloon un supported operand type s for list and list", "solution": "deepdive", "target": "testcase", "version": 202208172100}, {"id": 5459, "name": "log-3448", "raw": "2022-08-11 04:39:41,011 | Failed at Play [check_inbox_driver] ************************\n2022-08-11 04:39:41,011 | TASK [check_inbox_driver][Check all mandatory inbox drivers exists in Ubuntu] \ntask path: /home/worker/workspace/Ansible_Regression_Ubuntu_22.04_Server_ISO/ansible-vsphere-gos-validation/linux/check_inbox_driver/get_inbox_drivers.yml:181\nfailed: [localhost] => (item=None) => Unexpected templating type error occurred on ({{ mandatory_drivers - ['vmw_balloon']}}): unsupported operand type(s) for -: 'list' and 'list'", "category": "", "processed": "timestamp failed at play check inbox driver timestamp task check inbox driver check all mandatory inbox drivers exists in ubuntu task path home worker workspace ansible regression ubuntu number server iso ansible vsphere gos validation linux check inbox driver get inbox drivers yml number failed localhost item none unexpected templating type error occurred on mandatory drivers vmware balloon un supported operand type s for list and list", "solution": "deepdive", "target": "testcase", "version": 202208172100}, {"id": 5460, "name": "log-3461", "raw": "2022-08-11 04:58:51,011 | Failed at Play [check_inbox_driver] ************************\n2022-08-11 04:58:51,011 | TASK [check_inbox_driver][Check all mandatory inbox drivers exists in OracleLinux] \ntask path: /home/worker/workspace/Ansible_Regression_OracleLinux_8.x/ansible-vsphere-gos-validation/linux/check_inbox_driver/get_inbox_drivers.yml:181\nfailed: [localhost] => (item=None) => Unexpected templating type error occurred on ({{ mandatory_drivers - ['vmw_balloon']}}): unsupported operand type(s) for -: 'list' and 'list'", "category": "", "processed": "timestamp failed at play check inbox driver timestamp task check inbox driver check all mandatory inbox drivers exists in oracle linux task path home worker workspace ansible regression oracle linux number x ansible vsphere gos validation linux check inbox driver get inbox drivers yml number failed localhost item none unexpected templating type error occurred on mandatory drivers vmware balloon un supported operand type s for list and list", "solution": "deepdive", "target": "testcase", "version": 202208172100}, {"id": 5468, "name": "log-3496", "raw": "2022-08-15 08:36:18,015 | Failed at Play [vmxnet3_network_device_ops] ****************\n2022-08-15 08:36:18,015 | TASK [vmxnet3_network_device_ops][Try to ping IP] **********\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_MAIN_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_wait_ping.yml:14\nfatal: [localhost]: FAILED! => non-zero return code when ping", "category": "", "processed": "timestamp failed at play vmxnet number network device ops timestamp task vmxnet number network device ops try to ping ip task path home worker workspace ansible ubuntu lts server iso main nvme bios ansible vsphere gos validation common vm wait ping yml number fatal localhost failed nonzero return code when ping", "solution": "retry", "target": "targetvm", "version": 202208172100}, {"id": 5461, "name": "log-3464", "raw": "2022-08-11 06:25:20,011 | Failed at Play [deploy_vm_efi_paravirtual_vmxnet3] *********\n2022-08-11 06:25:20,011 | TASK [deploy_vm][Datastore file operation] *****************\ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/common/esxi_check_delete_datastore_file.yml:24\nfatal: [localhost]: FAILED! => File 'OS/Linux/Photon/3.0/Rev3U1/photon-3.0-913b49438.iso' is absent, cannot continue\n2022-08-11 06:25:21,011 | TASK [deploy_vm][Get specified property info for VM 'test_photon3_iso_1660198989405'] \ntask path: /home/worker/workspace/Ansible_Regression_Photon_3.0_ISO/ansible-vsphere-gos-validation/common/vm_get_config.yml:4\nfatal: [localhost]: FAILED! => Unable to gather information for non-existing VM test_photon3_iso_1660198989405", "category": "", "processed": "timestamp failed at play deploy vm efi para virtual vmxnet number timestamp task deploy vm data store file operation task path home worker workspace ansible regression photon number iso ansible vsphere gos validation common esxi check delete data store file yml number fatal localhost failed file os linux photon number photon number b number i so is absent can not continue timestamp task deploy vm get specified property info for vm test photon number iso number task path home worker workspace ansible regression photon number iso ansible vsphere gos validation common vm get configuration yml number fatal localhost failed unable to gather information for non existing vm test photon number iso number", "solution": "deepdive", "target": "testbed", "version": 202208172100}, {"id": 5462, "name": "log-3471", "raw": "2022-08-11 10:38:54,011 | Failed at Play [check_quiesce_snapshot] ********************\n2022-08-11 10:38:54,011 | TASK [check_quiesce_snapshot][Check pre-freeze script executed after snapshot take] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_MAIN_NVME_E1000E_BIOS/ansible-vsphere-gos-validation/windows/check_quiesce_snapshot/check_custom_scripts_executed.yml:46\nfatal: [localhost]: FAILED! => Assertion failed", "category": "", "processed": "timestamp failed at play check quiesce snapshot timestamp task check quiesce snapshot check pre freeze script executed after snapshot take task path home worker workspace ansible windows server lts c main nvme bios ansible vsphere gos validation windows check quiesce snapshot check custom scripts executed yml number fatal localhost failed assertion failed", "solution": "deepdive", "target": "testcase", "version": 202208172100}, {"id": 5463, "name": "log-3480", "raw": "2022-08-15 03:40:05,015 | Failed at Play [secureboot_enable_disable] *****************\n2022-08-15 03:40:05,015 | TASK [secureboot_enable_disable][Check VM 'test_vm' IP address] \ntask path: /home/worker/workspace/Ansible_Windows_10_64bit_MAIN_NVME_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_get_ip.yml:36\nfatal: [localhost]: FAILED! => Failed to get VM 'test_vm' IP Address", "category": "", "processed": "timestamp failed at play secure boot enable disable timestamp task secure boot enable disable check vm test vm ip address task path home worker workspace ansible windows number b it main nvme efi ansible vsphere gos validation common vm get ip yml number fatal localhost failed failed to get vm test vm ip address", "solution": "deepdive", "target": "targetvm", "version": 202208172100}, {"id": 5464, "name": "log-3493", "raw": "2022-08-15 07:41:17,015 | Failed at Play [deploy_ubuntu_ova] *************************\n2022-08-15 07:41:17,015 | TASK [deploy_ubuntu_ova][Configure VM CDROM to 'client'] ***\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_67GA/ansible-vsphere-gos-validation/common/vm_configure_cdrom.yml:14\nfatal: [localhost]: FAILED! => Connection control operation failed for disk 'sata0:0'.\n2022-08-15 07:41:41,015 | TASK [deploy_ubuntu_ova][Testing exit due to failure] ******\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_67GA/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_ubuntu_ova", "category": "", "processed": "timestamp failed at play deploy ubuntu ova timestamp task deploy ubuntu ova configure vm cdrom to client task path home worker workspace ansible ubuntu lts server ova number ga ansible vsphere gos validation common vm configure cdrom yml number fatal localhost failed connection control operation failed for disk sata number timestamp task deploy ubuntu ova testing exit due to failure task path home worker workspace ansible ubuntu lts server ova number ga ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy ubuntu ova", "solution": "deepdive", "target": "testcase", "version": 202208172100}, {"id": 5465, "name": "log-3507", "raw": "2022-08-15 08:48:56,015 | Failed at Play [deploy_ubuntu_ova] *************************\n2022-08-15 08:48:56,015 | TASK [deploy_ubuntu_ova][Configure VM CDROM to 'client'] ***\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_MAIN/ansible-vsphere-gos-validation/common/vm_configure_cdrom.yml:14\nfatal: [localhost]: FAILED! => Connection control operation failed for disk 'sata0:0'.\n2022-08-15 08:49:18,015 | TASK [deploy_ubuntu_ova][Testing exit due to failure] ******\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_MAIN/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_ubuntu_ova", "category": "", "processed": "timestamp failed at play deploy ubuntu ova timestamp task deploy ubuntu ova configure vm cdrom to client task path home worker workspace ansible ubuntu lts server ova main ansible vsphere gos validation common vm configure cdrom yml number fatal localhost failed connection control operation failed for disk sata number timestamp task deploy ubuntu ova testing exit due to failure task path home worker workspace ansible ubuntu lts server ova main ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy ubuntu ova", "solution": "deepdive", "target": "testcase", "version": 202208172100}, {"id": 5466, "name": "log-3488", "raw": "2022-08-15 07:30:33,015 | Failed at Play [deploy_vm_efi_lsilogic_e1000e] *************\n2022-08-15 07:30:33,015 | TASK [deploy_vm_efi_lsilogic_e1000e][Wait for message 'Autoinstall is completed.' appear in VM log serial-20220815061646.log] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_MAIN_LSILOGIC_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_wait_log_msg.yml:35\nfatal: [localhost]: FAILED! => {\n    \"attempts\": 720,\n    \"censored\": \"the output has been hidden due to the fact that 'no_log: true' was specified for this result\",\n    \"changed\": false\n}\n2022-08-15 07:30:46,015 | TASK [deploy_vm_efi_lsilogic_e1000e][Fetch file /tmp/cloud-init_2022-08-15-07-30-37.tar.gz from VM guest] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_ISO_MAIN_LSILOGIC_E1000E_EFI/ansible-vsphere-gos-validation/common/vm_guest_file_operation.yml:91\nexception in /vmware_guest_file_operation.py when fetch in /SoapAdapter.py when InvokeMethod\nfatal: [localhost]: FAILED! => Invalid guest login for user root", "category": "", "processed": "timestamp failed at play deploy vm efi lsi logic timestamp task deploy vm efi lsi logic wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible ubuntu lts server iso main lsi logic efi ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task deploy vm efi lsi logic fetch file tmp cloud init timestamp number tar gz from vm guest task path home worker workspace ansible ubuntu lts server iso main lsi logic efi ansible vsphere gos validation common vm guest file operation yml number exception in vmware guest file operation python when fetch in soap adapter python when invoke method fatal localhost failed invalid guest login for user root", "solution": "deepdive", "target": "targetvm", "version": 202208172100}, {"id": 5473, "name": "log-3524", "raw": "2022-08-16 07:38:39,016 | Failed at Play [env_setup] *********************************\n2022-08-16 07:38:39,016 | TASK [env_setup][Get all registerd VMs and templates on gosv-vc-70update.eng.vmware.com] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_check_exist.yml:14\nAttributeError: 'NoneType' object has no attribute 'datastoreUrl'\nfatal: [localhost]: FAILED! => MODULE FAILURE\nSee stdout/stderr for the exact error", "category": "", "processed": "timestamp failed at play environment setup timestamp task environment setup get all register dv ms and templates on go sv vc number update eng vmware com task path home worker workspace ansible windows server lts c lsi logic sas bios ansible vsphere gos validation common vm check exist yml number attribute error none type object has no attribute data store url fatal localhost failed module failure see stdout stderr for the exact error", "solution": "deepdive", "target": "testbed", "version": 202208172100}, {"id": 5474, "name": "log-3526", "raw": "2022-08-16 08:35:19,016 | Failed at Play [deploy_vm_efi_lsilogicsas_e1000e] **********\n2022-08-16 08:35:19,016 | TASK [deploy_vm_efi_lsilogicsas_e1000e][Create a new VM 'test_vm' on server 'gosv-vc-70update.eng.vmware.com'] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/common/vm_create.yml:30\nfatal: [localhost]: FAILED! => Failed to create a virtual machine : Invalid configuration for device '4'.\n2022-08-16 08:35:20,016 | TASK [deploy_vm_efi_lsilogicsas_e1000e][Testing exit due to failure] \ntask path: /home/worker/workspace/Ansible_Windows_Server_LTSC_70U3_LSILOGICSAS_E1000E_BIOS/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_vm_efi_lsilogicsas_e1000e", "category": "", "processed": "timestamp failed at play deploy vm efi lsi logic sas timestamp task deploy vm efi lsi logic sas create a new vm test vm on server go sv vc number update eng vmware com task path home worker workspace ansible windows server lts c lsi logic sas bios ansible vsphere gos validation common vm create yml number fatal localhost failed failed to create a virtual machine invalid configuration for device number timestamp task deploy vm efi lsi logic sas testing exit due to failure task path home worker workspace ansible windows server lts c lsi logic sas bios ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi lsi logic sas e number e", "solution": "deepdive", "target": "usererror", "version": 202208172100}, {"id": 5477, "name": "3522", "raw": "2022-08-15 14:06:09,015 | Failed at Play [wintools_complete_install_verify] **********\n2022-08-15 14:06:09,015 | TASK [wintools_complete_install_verify][Create snapshot 'BaseSnapshot' on 'test_vm'] \ntask path: /home/worker/workspace/Ansible_Windows_11_MAIN_PARAVIRTUAL_VMXNET3_EFI/ansible-vsphere-gos-validation/common/vm_take_snapshot.yml:4\nfatal: [localhost]: FAILED! => An error occurred while communicating with the remote host.", "category": null, "processed": "timestamp failed at play win tools complete install verify timestamp task win tools complete install verify create snapshot base snapshot on test vm task path home worker workspace ansible windows number main para virtual vmxnet number efi ansible vsphere gos validation common vm take snapshot yml number fatal localhost failed an error occurred while communicating with the remote host", "solution": "deepdive", "target": "targetvm", "version": 202208190706}, {"id": 5478, "name": "3510", "raw": "2022-08-15 10:02:25,015 | Failed at Play [deploy_ubuntu_ova] *************************\n2022-08-15 10:02:25,015 | TASK [deploy_ubuntu_ova][Wait for VMware Tools collecting guest OS fullname] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_70U1/ansible-vsphere-gos-validation/common/vm_wait_guest_fullname.yml:17\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-08-15 10:02:49,015 | TASK [deploy_ubuntu_ova][Testing exit due to failure] ******\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_70U1/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_ubuntu_ova", "category": null, "processed": "timestamp failed at play deploy ubuntu ova timestamp task deploy ubuntu ova wait for vmware tools collecting guest os full name task path home worker workspace ansible ubuntu lts server ova ansible vsphere gos validation common vm wait guest full name yml number fatal localhost failed hardware configuration table timestamp task deploy ubuntu ova testing exit due to failure task path home worker workspace ansible ubuntu lts server ova ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy ubuntu ova", "solution": "retry", "target": "targetvm", "version": 202208190706}, {"id": 5479, "name": "3515", "raw": "2022-08-15 12:12:35,015 | Failed at Play [deploy_ubuntu_ova] *************************\n2022-08-15 12:12:35,015 | TASK [deploy_ubuntu_ova][Wait for VMware Tools collecting guest OS fullname] \ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_70U1/ansible-vsphere-gos-validation/common/vm_wait_guest_fullname.yml:17\nfatal: [localhost]: FAILED! => hardware configuration table\n2022-08-15 12:12:58,015 | TASK [deploy_ubuntu_ova][Testing exit due to failure] ******\ntask path: /home/worker/workspace/Ansible_Ubuntu_LTS_Server_OVA_70U1/ansible-vsphere-gos-validation/common/test_rescue.yml:54\nfatal: [localhost]: FAILED! => Exit testing when 'exit_testing_when_fail' is set to True in test case deploy_ubuntu_ova", "category": null, "processed": "timestamp failed at play deploy ubuntu ova timestamp task deploy ubuntu ova wait for vmware tools collecting guest os full name task path home worker workspace ansible ubuntu lts server ova ansible vsphere gos validation common vm wait guest full name yml number fatal localhost failed hardware configuration table timestamp task deploy ubuntu ova testing exit due to failure task path home worker workspace ansible ubuntu lts server ova ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy ubuntu ova", "solution": "retry", "target": "targetvm", "version": 202208190706}, {"id": 5480, "name": "3535", "raw": "2022-08-17 05:36:31,017 | Failed at Play [gosc_cloudinit_staticip] *******************\n2022-08-17 05:36:31,017 | TASK [gosc_cloudinit_staticip][Install package on Ubuntu 22.04] \ntask path: /home/worker/workspace/zyh_ansible_ubuntu_existing_testbed_3.1/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:103\nfatal: [localhost -> 10.117.16.148]: FAILED! => Failed to update apt cache: unknown reason", "category": null, "processed": "timestamp failed at play go sc cloud init static ip timestamp task go sc cloud init static ip install package on ubuntu number task path home worker workspace zyh ansible ubuntu existing testbed number ansible vsphere gos validation linux utilities install un install package yml number fatal localhost ip address failed failed to update apt cache unknown reason", "solution": "deepdive", "target": "testcase", "version": 202208240500}, {"id": 5481, "name": "3534", "raw": "2022-08-17 05:32:53,017 | Failed at Play [gosc_cloudinit_dhcp] ***********************\n2022-08-17 05:32:53,017 | TASK [gosc_cloudinit_dhcp][Install package on Ubuntu 22.04] \ntask path: /home/worker/workspace/zyh_ansible_ubuntu_existing_testbed_3.1/ansible-vsphere-gos-validation/linux/utils/install_uninstall_package.yml:103\nfatal: [localhost -> 10.117.16.148]: FAILED! => Failed to update apt cache: unknown reason", "category": null, "processed": "timestamp failed at play go sc cloud init dhcp timestamp task go sc cloud init dhcp install package on ubuntu number task path home worker workspace zyh ansible ubuntu existing testbed number ansible vsphere gos validation linux utilities install un install package yml number fatal localhost ip address failed failed to update apt cache unknown reason", "solution": "deepdive", "target": "testcase", "version": 202208240500}]