{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d58c648-2efe-41bb-8a3c-92c6df978fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from /opt/conda/lib/python3.8/site-packages/transformers/trainer.py and modified at 2310,2311 and 2335, 2336\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2131e5ae-2317-43e0-9e0b-8cd91450aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DistilBertTokenizer, DistilBertForMaskedLM, DataCollatorForLanguageModeling, Trainer, EarlyStoppingCallback, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM, DataCollatorForLanguageModeling, EarlyStoppingCallback, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import evaluate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e547e1bf-6f83-47d7-aae4-a3f6e2e53871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7132db8d-bac5-47b9-84e5-023cbe01b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model = 'distilbert-base-uncased'\n",
    "model = DistilBertForMaskedLM.from_pretrained(name_model)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(name_model)\n",
    "collator = DataCollatorForLanguageModeling(tokenizer, mlm_probability=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f119017-f039-40a1-b397-649b072a87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_one_row(tokens_raw, seq_max):\n",
    "    tokens_0 = [101] + tokens_raw + [102]\n",
    "    indexs_special_0 = [1] + [0 for _ in range(len(tokens_0) - 2)]+ [1]\n",
    "    \n",
    "    sample_0 = {'input_ids': tokens_0, 'special_tokens_mask': indexs_special_0}    # return_special_tokens_mask=True\n",
    "    return sample_0\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade01434-c367-4a37-a359-0fda4d6b2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLMDataset(torch.utils.data.Dataset):\n",
    "    TOKEN_CLS = 101\n",
    "    TOKEN_SEP = 102\n",
    "    SEQ_MAX = 258\n",
    "    \n",
    "    def __init__(self, paths_file, len_dataset=-1):\n",
    "        self.paths_file_all = paths_file\n",
    "        self.seq_max = SimpleMLMDataset.SEQ_MAX\n",
    "        \n",
    "        self.index_file = -1 \n",
    "        \n",
    "        self.file_current = None\n",
    "        self.rows_current = []\n",
    "        self.len_dataset = len_dataset\n",
    "    # end\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):   # should not have problem now\n",
    "        \n",
    "        row_current = None\n",
    "        \n",
    "        while not row_current:\n",
    "            try:\n",
    "                if not self.rows_current:\n",
    "                    self.index_file = (self.index_file + 1) % len(self.paths_file_all)\n",
    "                    path_file_current = self.paths_file_all[self.index_file]\n",
    "                    # print('procceed to: {}'.format(path_file_current))\n",
    "                    with open(path_file_current, 'r') as file:\n",
    "                        self.rows_current = json.load(file)\n",
    "                    # end\n",
    "                # end\n",
    "\n",
    "                row_current = self.rows_current.pop()\n",
    "            except Exception as ex:\n",
    "                continue\n",
    "            # end\n",
    "        # end\n",
    "        \n",
    "        \n",
    "        sample = self.transfer_one_row_to_sample(row_current, self.seq_max) #[2335, 15464,  2361,   103,  8654,  2188,  7309,  2573, ...] -> 258 (should be 256 but has bug)\n",
    "\n",
    "        return sample\n",
    "    # end\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_dataset\n",
    "    # end\n",
    "    \n",
    "    def transfer_one_row_to_sample(self, tokens_raw, seq_max):\n",
    "        tokens_0 = [101] + tokens_raw + [102]\n",
    "        indexs_special_0 = [1] + [0 for _ in range(len(tokens_0) - 2)]+ [1]\n",
    "\n",
    "        num_padding = seq_max - len(tokens_0)\n",
    "        if num_padding < 0:\n",
    "            num_padding = 0\n",
    "        # end\n",
    "\n",
    "        if num_padding:\n",
    "            tokens_padded = tokens_0 + [0] * num_padding\n",
    "            indexs_special_padded = indexs_special_0 + [1] * num_padding\n",
    "        else:\n",
    "            tokens_padded = tokens_0\n",
    "            indexs_special_padded = indexs_special_0\n",
    "        # end\n",
    "\n",
    "        sample_0 = {'input_ids': tokens_padded, 'special_tokens_mask': indexs_special_padded}    # return_special_tokens_mask=True\n",
    "        return sample_0\n",
    "    # end\n",
    "\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e1faee-15e5-4222-871f-98fdd4922cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_folder_data = 'data'\n",
    "path_folder_data = 'full_debug_encoded_all_half_01'\n",
    "num_data_train = 4634404\n",
    "\n",
    "filenames_data_train = [name for name in os.listdir(path_folder_data) if name[0] != '.']\n",
    "paths_file_train = [os.path.join(path_folder_data, filename_data_train) for filename_data_train in filenames_data_train]\n",
    "\n",
    "# path_folder_data_eval = 'data_eval_2023'\n",
    "# num_data_eval = 209\n",
    "\n",
    "path_folder_data_eval = 'data_eval'\n",
    "num_data_eval = 813\n",
    "\n",
    "filenames_data_eval = [name for name in os.listdir(path_folder_data_eval) if name[0] != '.']\n",
    "paths_file_eval = [os.path.join(path_folder_data_eval, filename_data_eval) for filename_data_eval in filenames_data_eval]\n",
    "\n",
    "dataset_train = SimpleMLMDataset(paths_file_train, num_data_train)\n",
    "dataset_eval = SimpleMLMDataset(paths_file_eval, num_data_eval)  # 2022: 604, 2023:209, data_eval: 813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38797de0-1b9f-44cf-a2e3-634d7c5d7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # Depending on the model and config, logits may contain extra tensors,\n",
    "        # like past_key_values, but logits always come first\n",
    "        logits = logits[0]\n",
    "    return logits.argmax(dim=-1)\n",
    "# end\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# compute_metrics for the trainer\n",
    "# check np_test for detail\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    # end\n",
    "    \n",
    "    # preds = logits.argmax(dim=-1)\n",
    "    # preds = logits.argmax(axis=-1)\n",
    "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "    # by preprocess_logits_for_metrics\n",
    "    labels = labels.reshape(-1)\n",
    "    preds = preds.reshape(-1)\n",
    "    mask = labels != -100\n",
    "    labels = labels[mask]\n",
    "    preds = preds[mask]\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "# end\n",
    "\n",
    "# original compute_metrics\n",
    "# def compute_metrics(eval_preds):\n",
    "#     logits, labels = eval_preds\n",
    "    \n",
    "#     if isinstance(logits, tuple):\n",
    "#         logits = logits[0]\n",
    "#     # end\n",
    "    \n",
    "#     # preds = logits.argmax(dim=-1)\n",
    "#     preds = logits.argmax(axis=-1)\n",
    "#     # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
    "#     # by preprocess_logits_for_metrics\n",
    "#     labels = labels.reshape(-1)\n",
    "#     preds = preds.reshape(-1)\n",
    "#     mask = labels != -100\n",
    "#     labels = labels[mask]\n",
    "#     preds = preds[mask]\n",
    "#     return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973f231d-934e-4c37-b1c9-d630f356d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./outputs',  # output directory\n",
    "    num_train_epochs=4,  # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,  # batch size for evaluation\n",
    "    warmup_steps=0,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='./logs',  # directory for storing logs\n",
    "    load_best_model_at_end=True,\n",
    "    # load the best model when finished training (default metric is loss)    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=10,  # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"epoch\",  # evaluate each `logging_steps`\n",
    "    learning_rate=2e-5,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model='accuracy',\n",
    "    eval_accumulation_steps=16\n",
    "    # prediction_loss_only=True\n",
    "    # predict_with_generate=True,\n",
    "    # auto_find_batch_size=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7ae278-3bc5-4ebf-97e6-61d4001d2efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2969' max='2317204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2969/2317204 05:26 < 70:45:02, 9.09 it/s, Epoch 0.01/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/20231001+/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 if (\n",
      "\u001b[0;32m~/20231001+/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8e2e4-cb09-41e9-8af0-17caff1344d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e6762-d93d-4692-98f5-34020573aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.trainer_pt_utils import nested_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24187d27-087f-4638-8eab-49e06c7c58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested_concat.__code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29f0c1-f5fd-46a3-b394-f1e97ae3663e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
