{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bdf1e6-4f8a-4b18-a29a-601a468fcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DistilBertTokenizer, DistilBertForMaskedLM, DataCollatorForLanguageModeling, Trainer, EarlyStoppingCallback, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertForMaskedLM, DataCollatorForLanguageModeling, EarlyStoppingCallback, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import evaluate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "892f8c7e-8686-41e5-9c6d-19626009f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_model = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e12f6dde-dab8-45d1-b62e-92b03b3ba792",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForLanguageModeling(tokenizer, mlm_probability=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cfde90ab-a42a-443d-a522-fefaad8ea4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoded = {\n",
    "    'input_ids': [101, 2335, 15464, 2361, 3478, 2012, 2377, 28093, 13212, 2335, 15464, 2361, 4708, 13558, 3231, 2553, 28093, 13212, 3114, 8534, 4708, 4130, 2188, 7309, 2573, 15327, 2019, 19307, 3645, 2193, 2364, 11498, 7484, 1058, 22984, 7159, 2193, 1041, 8873, 2019, 19307, 5443, 27921, 2063, 2175, 2015, 27354, 2691, 13558, 3231, 2553, 1061, 19968, 2193, 10611, 2334, 15006, 2102, 3478, 3231, 2553, 28093, 13212, 2003, 8534, 2138, 1058, 2213, 8059, 5906, 5361, 6270, 2770, 6270, 0, 102],\n",
    "    'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
    "}\n",
    "\n",
    "sample_encoded2 = {\n",
    "    'input_ids': [101, 2335, 15464, 2361,  102, 0],\n",
    "    'special_tokens_mask': [1, 0, 0, 0, 1, 1],\n",
    "    'attention_mask': [1, 1, 1, 1, 1, 0]\n",
    "}\n",
    "\n",
    "\n",
    "sample = '[MASK] [MASK] at play deploy vm efi para virtual vmxnet number timestamp task wait for message auto install is completed appear in vm log serial timestamp log task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation common vm wait log message yml number fatal localhost failed attempts number censored the output has been hidden due to the fact that no log true was specified for this result changed false timestamp task testing exit due to failure task path home worker workspace ansible cycle photon number x update ansible vsphere gos validation common test rescue yml number fatal localhost failed exit testing when exit testing when fail is set to true in test case deploy vm efi para virtual vmxnet number'\n",
    "encoded = [2335, 15464, 2361, 3478, 2012, 2377, 28093, 13212, 2335, 15464, 2361, 4708, 13558, 3231, 2553, 28093, 13212, 3114, 8534, 4708, 4130, 2188, 7309, 2573, 15327, 2019, 19307, 3645, 2193, 2364, 11498, 7484, 1058, 22984, 7159, 2193, 1041, 8873, 2019, 19307, 5443, 27921, 2063, 2175, 2015, 27354, 2691, 13558, 3231, 2553, 1061, 19968, 2193, 10611, 2334, 15006, 2102, 3478, 3231, 2553, 28093, 13212, 2003, 8534, 2138, 1058, 2213, 8059, 5906, 5361, 6270, 2770, 6270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a389c73f-68ad-4148-9fd1-ac5550ff85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator([{\n",
    "    'input_ids': [101, 2335, 15464, 2361, 3478, 2012, 2377, 28093, 13212, 2335, 15464, 2361, 4708, 13558, 3231, 2553, 28093, 13212, 3114, 8534, 4708, 4130, 2188, 7309, 2573, 15327, 2019, 19307, 3645, 2193, 2364, 11498, 7484, 1058, 22984, 7159, 2193, 1041, 8873, 2019, 19307, 5443, 27921, 2063, 2175, 2015, 27354, 2691, 13558, 3231, 2553, 1061, 19968, 2193, 10611, 2334, 15006, 2102, 3478, 3231, 2553, 28093, 13212, 2003, 8534, 2138, 1058, 2213, 8059, 5906, 5361, 6270, 2770, 6270, 102],\n",
    "    'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "639deec2-2215-4cca-885e-f211d360d0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<code object __call__ at 0x7f480f6e43a0, file \"/opt/conda/lib/python3.8/site-packages/transformers/data/data_collator.py\", line 35>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collator.__call__.__code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d4c4b07-a270-4ff5-8915-47a7daf672e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode_plus(sample, padding=\"max_length\", max_length=200, truncation=True, return_special_tokens_mask=True)\n",
    "# tokenizer.pad([sample_encoded, sample_encoded2])\n",
    "# tokenizer.pad([sample_encoded2])\n",
    "# tokenizer.pad\n",
    "# tokenizer.decode([2335, 15464, 2361, 3478, 2012, 2377])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b9aada3-42b2-49c8-ae74-e2b6398b5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_one_row_to_sample(tokens_raw, seq_max):\n",
    "    tokens_0 = [101] + tokens_raw + [102]\n",
    "    indexs_special_0 = [1] + [0 for _ in range(len(tokens_0) - 2)]+ [1]\n",
    "\n",
    "    num_padding = seq_max - len(tokens_0)\n",
    "\n",
    "    if num_padding:\n",
    "        tokens_padded = tokens_0 + [0] * num_padding\n",
    "        indexs_special_padded = indexs_special_0 + [1] * num_padding\n",
    "    else:\n",
    "        tokens_padded = tokens_0\n",
    "        indexs_special_padded = indexs_special_0\n",
    "    # end\n",
    "\n",
    "    sample_0 = {'input_ids': tokens_padded, 'special_tokens_mask': indexs_special_padded}    # return_special_tokens_mask=True\n",
    "    return sample_0\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "528c79e1-fbb6-4472-9301-ec8b04001797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transfer_one_row_to_sample(encoded, 258)['special_tokens_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c68382-600b-43f3-ac12-05e96a5ba761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
