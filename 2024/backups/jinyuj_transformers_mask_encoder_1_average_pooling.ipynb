{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a36c05-aa20-4909-a5e9-a172529e22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from os.path import exists\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad, one_hot\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "### utils.py ###\n",
    "\n",
    "class Dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "# end\n",
    "\n",
    "### utils.py ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### core.py ###\n",
    "\n",
    "\"Produce N identical layers.\"\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "\n",
    "    \"Take in model size and number of heads.\"\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    # end\n",
    "\n",
    "\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    def attention(self, query, key, value, mask=None, dropout=None):\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            # print('jinyuj: scores: {}, mask: {}'.format(scores.shape, mask.shape))\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        # end\n",
    "        p_attn = scores.softmax(dim=-1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        # end\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "    # end\n",
    "\n",
    "\n",
    "    \"Implements Figure 2\"\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = self.attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (\n",
    "            x.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)\n",
    "    # end\n",
    "# end class\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A residual connection followed by a layer norm.\n",
    "Note for code simplicity the norm is first as opposed to last.\n",
    "\"\"\"\n",
    "class ResidualLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, size, dropout=0.1, eps=1e-6):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.norm = torch.nn.LayerNorm(size, eps)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    # end\n",
    "\n",
    "    \"Apply residual connection to any sublayer with the same size.\"\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    # end\n",
    "# end class\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleIDEmbeddings(nn.Module):\n",
    "    def __init__(self, size_vocab, dim_hidden, id_pad):\n",
    "        super(SimpleIDEmbeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(size_vocab, dim_hidden, padding_idx=id_pad)\n",
    "        self.dim_hidden = dim_hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.lut(x)\n",
    "        return result * math.sqrt(self.dim_hidden)\n",
    "    # end\n",
    "\n",
    "    def get_shape(self):\n",
    "        return (self.lut.num_embeddings, self.lut.embedding_dim)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\"Implement the PE function.\"\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_positional, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.dim_positional = dim_positional\n",
    "        pe = torch.zeros(max_len, dim_positional)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, dim_positional, 2) * -(math.log(10000.0) / dim_positional)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).to('cuda')\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return x\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleEmbedder(nn.Module):    # no segment embedder as we do not need that\n",
    "    def __init__(self, size_vocab=None, dim_hidden=128, dropout=0.1, id_pad=0):\n",
    "        super(SimpleEmbedder, self).__init__()\n",
    "        self.size_vocab = size_vocab\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.id_pad = id_pad\n",
    "\n",
    "        self.embedder = nn.Sequential(\n",
    "            SimpleIDEmbeddings(size_vocab, dim_hidden, id_pad),\n",
    "            PositionalEncoding(dim_hidden),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    def forward(self, ids_input):   # (batch, seqs_with_padding)\n",
    "        return self.embedder(ids_input)\n",
    "    # end\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.size_vocab\n",
    "    # end\n",
    "# end\n",
    "\n",
    "### core.py ###\n",
    "\n",
    "\n",
    "\n",
    "class SimpleEncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, dim_feedforward, n_head, dropout=0.1):\n",
    "        super(SimpleEncoderLayer, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.layer_attention = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_feedforward = PositionwiseFeedForward(dim_hidden, dim_feedforward, dropout)\n",
    "        self.layers_residual = clones(ResidualLayer(dim_hidden, dropout), 2)\n",
    "    # end\n",
    "\n",
    "    def forward(self, embeddings, masks, *args):\n",
    "        embeddings = self.layers_residual[0](embeddings, lambda embeddings: self.layer_attention(embeddings, embeddings, embeddings, masks))\n",
    "        return self.layers_residual[1](embeddings, self.layer_feedforward)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class SimpleDecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, dim_feedforward, n_head, dropout=0.1):\n",
    "        super(SimpleDecoderLayer, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.layer_attention_decoder = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_attention_encoder = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_feedforward = PositionwiseFeedForward(dim_hidden, dim_feedforward, dropout)\n",
    "        self.layers_residual = clones(ResidualLayer(dim_hidden, dropout), 3)\n",
    "\n",
    "    def forward(self, embeddings, masks_encoder, output_encoder, masks_decoder, *args):\n",
    "        embeddings = self.layers_residual[0](embeddings, lambda embeddings: self.layer_attention_decoder(embeddings, embeddings, embeddings, masks_decoder))\n",
    "        # print('jinyuj: embeddings.shape {}, masks_encoder.shape {}'.format(embeddings.shape, masks_encoder.shape))\n",
    "        # if embeddings.shape[1] != masks_encoder.shape[1]:\n",
    "        #     masks_encoder = masks_encoder[:,:embeddings.shape[1],:]\n",
    "        # # end\n",
    "        embeddings = self.layers_residual[1](embeddings, lambda embeddings: self.layer_attention_encoder(embeddings, output_encoder, output_encoder, masks_encoder))\n",
    "        return self.layers_residual[2](embeddings, self.layer_feedforward)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleTransformerStack(nn.Module):\n",
    "\n",
    "    def __init__(self, obj_layer, n_layers):\n",
    "        super(SimpleTransformerStack, self).__init__()\n",
    "        self.layers = clones(obj_layer, n_layers)\n",
    "\n",
    "        self.norm = torch.nn.LayerNorm(obj_layer.dim_hidden)\n",
    "        self.keys_cache = ['output']\n",
    "        self.cache = Dotdict({\n",
    "            'outputs': None\n",
    "        })\n",
    "    # end\n",
    "\n",
    "    def forward(self, embedding_encoder=None, masks_encoder=None, output_encoder=None, embedding_decoder=None, masks_decoder=None ,noncache=False, **kwargs):  # input -> (batch, len_seq, vocab)\n",
    "\n",
    "        if output_encoder is not None and embedding_decoder is not None and masks_decoder is not None:\n",
    "            embeddings = embedding_decoder\n",
    "        else:\n",
    "            embeddings = embedding_encoder\n",
    "        # end\n",
    "\n",
    "        for layer in self.layers:\n",
    "            embeddings = layer(embeddings, masks_encoder, output_encoder, masks_decoder)\n",
    "        # end\n",
    "\n",
    "        outputs = self.norm(embeddings)\n",
    "\n",
    "        if not noncache:\n",
    "            self.cache.outputs = outputs\n",
    "        # end\n",
    "\n",
    "        return outputs\n",
    "    # end\n",
    "\n",
    "    # def get_vocab_size(self):\n",
    "    #     return self.embedder.embedder_token.shape[-1]\n",
    "    # # end\n",
    "\n",
    "    def clear_cache(self):\n",
    "        for key_cache in self.keys_cache:\n",
    "            self.cache[key_cache] = None\n",
    "        # end\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleEncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embedder_encoder, embedder_decoder):\n",
    "        super(SimpleEncoderDecoder, self).__init__()\n",
    "\n",
    "        self.embedder_encoder = embedder_encoder\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.embedder_decoder = embedder_decoder\n",
    "        self.decoder = decoder\n",
    "    # end\n",
    "\n",
    "    def forward(self, ids_encoder=None, masks_encoder=None, ids_decoder=None, masks_decoder=None, nocache=False, **kwargs):\n",
    "        \n",
    "        output_encoder = self.embed_and_encode(ids_encoder=ids_encoder, masks_encoder=masks_encoder, nocache=nocache)\n",
    "        output_encoder_refilled = output_encoder.masked_fill(masks_encoder.transpose(-1,-2)==False, 0)\n",
    "        output_encoder_pooled = torch.mean(output_encoder_refilled, dim=-2)\n",
    "        output_encoder_pooled_expanded = output_encoder_pooled.unsqueeze(-2).expand(output_encoder.shape)\n",
    "        output = output_encoder_pooled_expanded\n",
    "        \n",
    "        if self.embedder_decoder and self.decoder:\n",
    "            output_decoder = self.embed_and_decode(ids_decoder=ids_decoder, masks_encoder=masks_encoder, output_encoder=output, masks_decoder=masks_decoder, nocache=nocache)\n",
    "            output = output_decoder\n",
    "        # end if\n",
    "        \n",
    "        return output\n",
    "    # end\n",
    "    \n",
    "    def embed_and_encode(self, ids_encoder=None, masks_encoder=None, nocache=False, **kwargs):\n",
    "        self.encoder.clear_cache()\n",
    "        \n",
    "        embedding_encoder = self.embedder_encoder(ids_encoder)\n",
    "        output_encoder = self.encoder(\n",
    "            embedding_encoder=embedding_encoder,\n",
    "            masks_encoder=masks_encoder,\n",
    "            nocache=nocache\n",
    "        )\n",
    "        \n",
    "        return output_encoder\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def embed_and_decode(self, ids_decoder=None, masks_encoder=None, output_encoder=None, masks_decoder=None, nocache=False, **kwargs):\n",
    "        self.decoder.clear_cache()\n",
    "        \n",
    "        embedding_decoder = self.embedder_decoder(ids_decoder)\n",
    "        output_decoder = self.decoder(\n",
    "            masks_encoder=masks_encoder,\n",
    "            output_encoder=output_encoder,    #(len_seq, dim_hidden) -> (1, dim_hidden)\n",
    "            embedding_decoder=embedding_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            nocache=nocache\n",
    "        )\n",
    "\n",
    "        return output_decoder\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def clear_cache(self):\n",
    "        self.encoder.clear_cache()\n",
    "        if self.decoder:\n",
    "            self.decoder.clear_cache()\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def get_vocab_size(self, name_embedder):\n",
    "        embedder = getattr(self, f'embedder_{name_embedder}')\n",
    "        return embedder.get_vocab_size()\n",
    "    # end\n",
    "\n",
    "# end\n",
    "\n",
    "class LinearAndNorm(nn.Module):\n",
    "    def __init__(self, dim_in = None, dim_out = None, eps_norm=1e-12):\n",
    "        super(LinearAndNorm, self).__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(dim_in, dim_out)\n",
    "        self.norm = torch.nn.LayerNorm(dim_out, eps_norm)\n",
    "    # end\n",
    "\n",
    "    def forward(self, seqs_in):\n",
    "        return self.norm(self.linear(seqs_in).relu())\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, vocab, splitter):\n",
    "        self.splitter = splitter\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.id_pad = len(vocab)\n",
    "        self.id_cls = len(vocab) + 1\n",
    "        self.id_sep = len(vocab) + 2\n",
    "        self.id_mask = len(vocab) + 3\n",
    "        \n",
    "        self.size_vocab = len(vocab) + 4\n",
    "\n",
    "        self.token_pad = '[PAD]'\n",
    "        self.token_cls = '[CLS]'\n",
    "        self.token_sep = '[SEP]'\n",
    "        self.token_mask = '[MASK]'\n",
    "           \n",
    "        self.index_id_token_special = {\n",
    "            self.id_pad: self.token_pad,\n",
    "            self.id_cls: self.token_cls,\n",
    "            self.id_sep: self.token_sep,\n",
    "            self.id_mask: self.token_mask\n",
    "        }\n",
    "        \n",
    "    # end\n",
    "\n",
    "    def encode(self, line):\n",
    "        return self.vocab([doc.text for doc in self.splitter(line)])\n",
    "    # end\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        words = []\n",
    "        for token in tokens:\n",
    "            token = int(token)\n",
    "            \n",
    "            if token in self.index_id_token_special:\n",
    "                word_target = self.index_id_token_special[token]\n",
    "            else:\n",
    "                try:\n",
    "                    word_target = vocab.lookup_token(token)\n",
    "                except:\n",
    "                    word_target = '[ERROR_LOOKUP_{}]'.format(token)\n",
    "                # end\n",
    "            # end\n",
    "            \n",
    "            words.append(word_target)\n",
    "        # end\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        for k, v in kwargs.items():\n",
    "            if v is not None and type(v) is not bool:\n",
    "                self.kwargs[k] = v.to(Batch.DEVICE)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.kwargs\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class Collator_S2S:\n",
    "\n",
    "    def __init__(self, tokenizer, size_seq_max, need_masked=0.3):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size_seq_max = size_seq_max\n",
    "        self.need_masked = need_masked\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def __call__(self, list_corpus_source):\n",
    "\n",
    "        tokens_input_encoder = []\n",
    "        tokens_input_decoder = []\n",
    "        tokens_label_decoder = []\n",
    "        labels_similarity = []\n",
    "\n",
    "        for corpus_source in list_corpus_source: # (line0, line1, sim), output of zip remove single case\n",
    "            if len(corpus_source) == 3:\n",
    "                corpus_line = [courpus_source[0], corpus_source[1]]\n",
    "                labels_similarity.append(corpus_line[2])\n",
    "            else:\n",
    "                corpus_line = [corpus_source[1]]\n",
    "            # end\n",
    "            \n",
    "            for line in corpus_line:\n",
    "                tokens = self.tokenizer.encode(line)\n",
    "\n",
    "                # TODO: check edge\n",
    "                if len(tokens) > self.size_seq_max - 2:\n",
    "                    tokens = tokens[:self.size_seq_max-2]\n",
    "                # end\n",
    "\n",
    "                tokens_input_encoder.append([self.tokenizer.id_cls] + tokens + [self.tokenizer.id_sep])\n",
    "                tokens_input_decoder.append([self.tokenizer.id_cls] + tokens)\n",
    "                tokens_label_decoder.append(tokens + [self.tokenizer.id_sep])\n",
    "            # end\n",
    "            \n",
    "\n",
    "        # end\n",
    "\n",
    "        inputs_encoder, masks_encoder, segments_encoder, labels_encoder = self.pad_sequences(tokens_input_encoder, self.size_seq_max, need_masked=self.need_masked)\n",
    "        inputs_decoder, masks_decoder, segments_decoder, _ = self.pad_sequences(tokens_input_decoder, self.size_seq_max, need_diagonal=True)\n",
    "        labels_decoder, masks_label, segments_label, _ = self.pad_sequences(tokens_label_decoder, self.size_seq_max)\n",
    "        # labels_similarity = torch.Tensor(labels_similarity).unsqueeze(0).transpose(0,1)\n",
    "        labels_similarity = torch.Tensor(labels_similarity)\n",
    "\n",
    "        return Batch(\n",
    "            ids_encoder=inputs_encoder,  # contains [mask]s\n",
    "            masks_encoder=masks_encoder,\n",
    "            labels_encoder=labels_encoder,  # doesn't contain [mask]\n",
    "            segments_encoder=segments_encoder,\n",
    "            ids_decoder=inputs_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            labels_decoder=labels_decoder,\n",
    "            segments_label=segments_label,\n",
    "            labels_similarity=labels_similarity\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    \n",
    "    # return masks_attention?, return masks_segment?\n",
    "    def pad_sequences(self, sequences, size_seq_max, need_diagonal=False, need_masked=0): # need_diagonal and need_masked cannot both set, one for bert seq one for s2s seq\n",
    "        id_pad = self.tokenizer.id_pad\n",
    "        id_mask = self.tokenizer.id_mask\n",
    "\n",
    "        sequences_padded = []\n",
    "        sequences_masked_padded = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            len_seq = len(sequence)\n",
    "\n",
    "            count_pad = size_seq_max - len_seq\n",
    "\n",
    "            sequence = torch.LongTensor(sequence)\n",
    "            sequence_padded = torch.cat((sequence, torch.LongTensor([id_pad] * count_pad)))\n",
    "            sequences_padded.append(sequence_padded)\n",
    "\n",
    "            if need_masked:\n",
    "                index_masked = list(range(1, len_seq-1))\n",
    "                random.shuffle(index_masked)\n",
    "                index_masked = torch.LongTensor(index_masked[:int(need_masked * (len_seq-2))])\n",
    "\n",
    "                sequence_masked = sequence.detach().clone()\n",
    "                sequence_masked.index_fill_(0, index_masked, id_mask)\n",
    "                sequence_masked_padded = torch.cat((sequence_masked, torch.LongTensor([id_pad] * count_pad)))\n",
    "                \n",
    "                sequences_masked_padded.append(sequence_masked_padded)\n",
    "            # end\n",
    "    #   # end for\n",
    "\n",
    "        inputs = torch.stack(sequences_padded)  # (batch, size_seq_max)\n",
    "        if need_masked:\n",
    "            inputs_masked_padded = torch.stack(sequences_masked_padded)\n",
    "        # end\n",
    "\n",
    "        masks_segment = (inputs != self.tokenizer.id_pad).unsqueeze(-2)    #(nbatch, 1, seq)\n",
    "        masks_attention = self.make_std_mask(inputs, self.tokenizer.id_pad) if need_diagonal else masks_segment\n",
    "\n",
    "        if need_masked:\n",
    "            masks_masked = (inputs_masked_padded != id_mask).unsqueeze(-2)\n",
    "            masks_attention = masks_attention & masks_masked\n",
    "            return inputs_masked_padded, masks_attention, masks_segment, inputs # (inputs, masks_attention, masks_segment, labels)\n",
    "        else:\n",
    "            return inputs, masks_attention, masks_segment, None\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def subsequent_mask(self, size):\n",
    "        \"Mask out subsequent positions.\"\n",
    "        attn_shape = (1, size, size)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        return subsequent_mask == 0\n",
    "\n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & self.subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51933c37-2474-4ea8-8819-d67e8061c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "def Multi30k(language_pair=None):\n",
    "    corpus_lines_train = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/train.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_train.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_train = list(zip(*corpus_lines_train))\n",
    "\n",
    "    corpus_lines_eval = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/val.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_eval.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_eval = list(zip(*corpus_lines_eval))\n",
    "\n",
    "    return corpus_train, corpus_eval, None\n",
    "# end\n",
    "\n",
    "\n",
    "def load_vocab(spacy_en):\n",
    "    if not os.path.exists(\"vocab.pt\"):\n",
    "        vocab_tgt = build_vocabulary(spacy_en)\n",
    "        torch.save(vocab_tgt, \"vocab.pt\")\n",
    "    else:\n",
    "        vocab_tgt = torch.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes: {}\".format(len(vocab_tgt)))\n",
    "    return vocab_tgt\n",
    "# end\n",
    "\n",
    "def load_spacy():\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_en\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c03c357-ab7a-4589-a7a0-b87c2a3572b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleEncoderHead_MLM(nn.Module):\n",
    "\n",
    "#     def __init__(self, model, size_vocab, dim_hidden=128):\n",
    "#         super(SimpleEncoderHead_MLM, self).__init__()\n",
    "#         self.model = model\n",
    "        \n",
    "#         self.ffn = LinearAndNorm(dim_in=dim_hidden, dim_out=dim_hidden)\n",
    "#         self.extractor = torch.nn.Linear(dim_hidden, size_vocab, bias=False)\n",
    "#         self.extractor.weight = nn.Parameter(model.embedder_encoder.embedder[0].lut.weight)\n",
    "        \n",
    "#         self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "#     # end\n",
    "\n",
    "\n",
    "#     def forward(self, **kwargs):   # labels_input -> (batch, seq, labels)\n",
    "#         labels_mlm = kwargs['labels_encoder']\n",
    "        \n",
    "#         outputs_encoder = self.model(**kwargs)\n",
    "#         outputs_ffn = self.ffn(outputs_encoder)\n",
    "#         outputs_mlm = self.extractor(outputs_ffn) # outputs_mlm = prediction_logits\n",
    "        \n",
    "#         segments_encoder = kwargs['segments_encoder']        \n",
    "#         segments_encoder_2d = segments_encoder.transpose(-1,-2)[:,:,0]\n",
    "\n",
    "#         # loss_segments = self.func_loss(outputs_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(segments_encoder_2d)) / segments_encoder_2d.reshape(-1).shape[0]\n",
    "#         loss_segments = self.func_loss(outputs_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(segments_encoder_2d))\n",
    "        \n",
    "#         masks_encoder = kwargs['masks_encoder']\n",
    "#         masks_masked = torch.logical_xor(masks_encoder, segments_encoder) & segments_encoder # True is masked\n",
    "#         masks_masked_perbatch = masks_masked[:,0,:]\n",
    "#         # loss_masked = self.func_loss(outputs_mlm.masked_select(masks_masked_perbatch.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(masks_masked_perbatch)) / masks_masked_perbatch.reshape(-1).shape[0]\n",
    "#         loss_masked = self.func_loss(outputs_mlm.masked_select(masks_masked_perbatch.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(masks_masked_perbatch))       \n",
    "        \n",
    "#         # loss_mlm = loss_segments + loss_masked * 3\n",
    "#         loss_mlm = loss_segments\n",
    "        \n",
    "#         return outputs_mlm, loss_mlm\n",
    "#     # end\n",
    "\n",
    "# # end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b97fee-21de-4a79-a082-4eb70288e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoderHead_S2S(nn.Module):\n",
    "\n",
    "    def __init__(self, model, size_vocab, dim_hidden=128):\n",
    "        super(SimpleDecoderHead_S2S, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        self.ffn = LinearAndNorm(dim_in=dim_hidden, dim_out=dim_hidden)\n",
    "        \n",
    "        self.extractor = torch.nn.Linear(dim_hidden, size_vocab, bias=False)\n",
    "        self.extractor.weight = nn.Parameter(model.embedder_decoder.embedder[0].lut.weight)\n",
    "\n",
    "        self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def forward(self, **kwargs):   # labels_input -> (batch, seq, labels)\n",
    "        labels_s2s = kwargs['labels_decoder']\n",
    "        \n",
    "        outputs_decoder = self.model(**kwargs)\n",
    "        outputs_ffn = self.ffn(outputs_decoder)\n",
    "        outputs_s2s = self.extractor(outputs_ffn)   # outputs_mlm = prediction_logits\n",
    "        \n",
    "        segments_decoder = kwargs['segments_label']\n",
    "        segments_decoder_2d = segments_decoder.transpose(-1,-2)[:,:,0]\n",
    "\n",
    "        loss_segments = self.func_loss(outputs_s2s.masked_select(segments_decoder_2d.unsqueeze(-1)).reshape(-1, outputs_s2s.shape[-1]), labels_s2s.masked_select(segments_decoder_2d))\n",
    "\n",
    "        return outputs_s2s, loss_segments\n",
    "    # end\n",
    "\n",
    "\n",
    "    def beam_generate(self):\n",
    "        pass\n",
    "    # end\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5dae215-cabb-49ee-9f29-961118e61225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Builder:\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_mlm(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, None, embedder_encoder, None)\n",
    "        head_mlm = SimpleEncoderHead_MLM(model, size_vocab, dim_hidden)\n",
    "\n",
    "        return head_mlm\n",
    "    # end\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_s2s(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "        \n",
    "        embedder_decoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_decoder = SimpleDecoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        decoderstack = SimpleTransformerStack(sample_decoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, decoderstack, embedder_encoder, embedder_decoder)\n",
    "        head_s2s = SimpleDecoderHead_S2S(model, size_vocab, dim_hidden)\n",
    "\n",
    "        return head_s2s\n",
    "    # end\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60b018b-b983-4755-90ce-c07976ccde1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes: 6191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "\n",
    "gpu = 0\n",
    "torch.cuda.set_device(gpu)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "# source\n",
    "seq_max = 16\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# model & head\n",
    "dim_hidden = 512\n",
    "dim_feedforward = 512\n",
    "n_head = 8\n",
    "n_layer = 8\n",
    "\n",
    "# optimizer\n",
    "lr_base_optimizer = 5e-4\n",
    "betas_optimizer = (0.9, 0.999)\n",
    "eps_optimizer = 1e-9\n",
    "\n",
    "# scheduler\n",
    "warmup = 200\n",
    "\n",
    "spacy_en = load_spacy()\n",
    "vocab = load_vocab(spacy_en)\n",
    "tokenizer = TokenizerWrapper(vocab, spacy_en)\n",
    "\n",
    "train_iter, valid_iter, _ = Multi30k(language_pair=(\"de\", \"en\"))\n",
    "train_source = to_map_style_dataset(train_iter)\n",
    "\n",
    "collator = Collator_S2S(tokenizer, seq_max)\n",
    "dataloader_train = DataLoader(train_source, batch_size, shuffle=False, collate_fn=collator)\n",
    "\n",
    "head = Builder.build_model_with_s2s(tokenizer.size_vocab, dim_hidden, dim_feedforward, n_head, n_layer)\n",
    "\n",
    "for p in head.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "head = head.to('cuda')\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(head.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "decayRate = 0.96\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b499ec3-35e4-49c7-952d-5e58d0b899f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_a_batch(batch, head, optimizer=None, scheduler=None):\n",
    "    head.train()\n",
    "    _, loss_s2s = head.forward(**batch())    # save to cache\n",
    "\n",
    "    # crossentropy loss\n",
    "    \n",
    "    loss_all = loss_s2s * 5\n",
    "    loss_all_value = loss_all.item()\n",
    "    \n",
    "    # print(loss_all)\n",
    "    loss_all.backward()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    # end\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    # end\n",
    "    # manager.clear_cache()\n",
    "    return loss_all_value\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fcf19d1-b502-4a47-99dc-66bf2b071347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 0, loss: 10.167180061340332, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 100, loss: 9.927837371826172, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 200, loss: 10.033212661743164, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 300, loss: 7.317790985107422, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 500, loss: 10.785340309143066, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 600, loss: 8.545553207397461, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 700, loss: 10.419483184814453, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 800, loss: 9.846993446350098, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 900, loss: 8.68122386932373, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1000, loss: 10.519095420837402, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1100, loss: 10.496881484985352, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1200, loss: 10.352045059204102, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1300, loss: 9.52810001373291, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1400, loss: 8.53405475616455, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1500, loss: 10.1560640335083, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1600, loss: 8.939900398254395, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1700, loss: 12.070100784301758, rate: 1.2988579352203839e-05\n",
      "Epoch: 0 Batch: 1800, loss: 11.829656600952148, rate: 1.2988579352203839e-05\n",
      "[2023-11-17 15:29:45.108926] Epoch: 0 ends. Average loss: 9.848790366808748\n",
      "Epoch: 1 Batch: 0, loss: 10.139944076538086, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 100, loss: 10.122366905212402, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 200, loss: 9.882415771484375, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 300, loss: 7.850661754608154, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 400, loss: 8.675341606140137, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 500, loss: 10.439275741577148, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 600, loss: 8.58324146270752, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 700, loss: 10.475248336791992, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 800, loss: 9.98861026763916, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 900, loss: 9.042462348937988, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1000, loss: 10.246390342712402, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1100, loss: 9.804841041564941, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1200, loss: 10.025869369506836, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1300, loss: 9.384212493896484, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1400, loss: 9.437827110290527, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1500, loss: 9.22874641418457, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1600, loss: 8.948003768920898, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1700, loss: 12.236160278320312, rate: 1.2469036178115684e-05\n",
      "Epoch: 1 Batch: 1800, loss: 11.46258544921875, rate: 1.2469036178115684e-05\n",
      "[2023-11-17 15:35:49.343612] Epoch: 1 ends. Average loss: 9.836345776759387\n",
      "Epoch: 2 Batch: 0, loss: 9.732934951782227, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 100, loss: 10.342849731445312, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 200, loss: 10.041561126708984, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 300, loss: 7.161419868469238, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 400, loss: 8.089641571044922, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 500, loss: 10.253572463989258, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 600, loss: 8.7020902633667, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 700, loss: 10.111915588378906, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 800, loss: 9.671483993530273, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 900, loss: 8.699344635009766, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1000, loss: 9.969104766845703, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1100, loss: 10.086188316345215, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1200, loss: 10.301613807678223, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1300, loss: 9.505096435546875, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1400, loss: 8.688546180725098, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1500, loss: 9.452465057373047, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1600, loss: 9.394793510437012, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1700, loss: 12.655256271362305, rate: 1.1970274730991057e-05\n",
      "Epoch: 2 Batch: 1800, loss: 11.217793464660645, rate: 1.1970274730991057e-05\n",
      "[2023-11-17 15:41:52.835744] Epoch: 2 ends. Average loss: 9.811537584545727\n",
      "Epoch: 3 Batch: 0, loss: 10.102347373962402, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 100, loss: 10.249267578125, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 200, loss: 10.319280624389648, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 300, loss: 7.254815101623535, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 400, loss: 8.557323455810547, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 500, loss: 11.061624526977539, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 600, loss: 8.791031837463379, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 700, loss: 9.955547332763672, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 800, loss: 9.420186042785645, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 900, loss: 9.150449752807617, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1000, loss: 10.026460647583008, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1100, loss: 10.004928588867188, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1200, loss: 10.513069152832031, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1300, loss: 9.020360946655273, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1400, loss: 8.790335655212402, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1500, loss: 9.698326110839844, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1600, loss: 9.032763481140137, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1700, loss: 12.797700881958008, rate: 1.1491463741751414e-05\n",
      "Epoch: 3 Batch: 1800, loss: 11.162944793701172, rate: 1.1491463741751414e-05\n",
      "[2023-11-17 15:47:57.685493] Epoch: 3 ends. Average loss: 9.783992286551676\n",
      "Epoch: 4 Batch: 0, loss: 9.866321563720703, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 100, loss: 10.40176010131836, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 200, loss: 9.653238296508789, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 300, loss: 7.082671642303467, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 400, loss: 8.414321899414062, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 500, loss: 10.556718826293945, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 600, loss: 8.438362121582031, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 700, loss: 10.293140411376953, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 800, loss: 9.479950904846191, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 900, loss: 8.878434181213379, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1000, loss: 9.882015228271484, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1100, loss: 9.950103759765625, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1200, loss: 10.409158706665039, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1300, loss: 9.523017883300781, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1400, loss: 8.87527847290039, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1500, loss: 9.701930046081543, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1600, loss: 8.9802885055542, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1700, loss: 12.521280288696289, rate: 1.1031805192081357e-05\n",
      "Epoch: 4 Batch: 1800, loss: 11.488703727722168, rate: 1.1031805192081357e-05\n",
      "[2023-11-17 15:54:05.182393] Epoch: 4 ends. Average loss: 9.77188540820055\n",
      "Epoch: 5 Batch: 0, loss: 10.295821189880371, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 100, loss: 10.232778549194336, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 200, loss: 9.971126556396484, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 300, loss: 7.569380283355713, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 400, loss: 7.828759670257568, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 500, loss: 10.659636497497559, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 600, loss: 8.642037391662598, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 700, loss: 9.887256622314453, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 800, loss: 9.830571174621582, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 900, loss: 9.093388557434082, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1000, loss: 9.868632316589355, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1100, loss: 10.340910911560059, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1200, loss: 10.663671493530273, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1300, loss: 9.616615295410156, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1400, loss: 8.442768096923828, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1500, loss: 9.736283302307129, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1600, loss: 8.686262130737305, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1700, loss: 12.360055923461914, rate: 1.0590532984398102e-05\n",
      "Epoch: 5 Batch: 1800, loss: 11.316146850585938, rate: 1.0590532984398102e-05\n",
      "[2023-11-17 16:00:10.123596] Epoch: 5 ends. Average loss: 9.745816017735812\n",
      "Epoch: 6 Batch: 0, loss: 10.303053855895996, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 100, loss: 10.027976989746094, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 200, loss: 9.891510009765625, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 300, loss: 6.884411811828613, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 400, loss: 8.030921936035156, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 500, loss: 10.930593490600586, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 600, loss: 8.429071426391602, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 700, loss: 10.19957160949707, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 800, loss: 9.304936408996582, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 900, loss: 9.018972396850586, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1000, loss: 10.241440773010254, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1100, loss: 10.13204574584961, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1200, loss: 10.215129852294922, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1300, loss: 9.290420532226562, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1400, loss: 8.495720863342285, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1500, loss: 9.964357376098633, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1600, loss: 8.97311782836914, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1700, loss: 12.375906944274902, rate: 1.0166911665022178e-05\n",
      "Epoch: 6 Batch: 1800, loss: 10.850975036621094, rate: 1.0166911665022178e-05\n",
      "[2023-11-17 16:06:14.469726] Epoch: 6 ends. Average loss: 9.732581037351984\n",
      "Epoch: 7 Batch: 0, loss: 10.131690979003906, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 100, loss: 9.84449291229248, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 200, loss: 9.725619316101074, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 300, loss: 7.314022064208984, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 400, loss: 8.463495254516602, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 500, loss: 10.926118850708008, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 600, loss: 8.453797340393066, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 700, loss: 10.307920455932617, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 800, loss: 9.965288162231445, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 900, loss: 9.266263008117676, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1000, loss: 10.009556770324707, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1100, loss: 9.79465103149414, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1200, loss: 10.189998626708984, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1300, loss: 9.149795532226562, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1400, loss: 8.618510246276855, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1500, loss: 9.704568862915039, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1600, loss: 9.018266677856445, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1700, loss: 12.439212799072266, rate: 9.76023519842129e-06\n",
      "Epoch: 7 Batch: 1800, loss: 10.854596138000488, rate: 9.76023519842129e-06\n",
      "[2023-11-17 16:12:28.741100] Epoch: 7 ends. Average loss: 9.725626452614836\n",
      "Epoch: 8 Batch: 0, loss: 10.156936645507812, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 100, loss: 10.137811660766602, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 200, loss: 9.769617080688477, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 300, loss: 7.432089328765869, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 400, loss: 8.362661361694336, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 500, loss: 10.62387466430664, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 600, loss: 8.3189058303833, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 700, loss: 10.495171546936035, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 800, loss: 9.785412788391113, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 900, loss: 9.019896507263184, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 1000, loss: 10.124914169311523, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 1100, loss: 9.624027252197266, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 1200, loss: 10.116659164428711, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 1400, loss: 8.8947114944458, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 1500, loss: 9.485014915466309, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 1600, loss: 8.821632385253906, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 1700, loss: 12.061016082763672, rate: 9.369825790484438e-06\n",
      "Epoch: 8 Batch: 1800, loss: 11.049970626831055, rate: 9.369825790484438e-06\n",
      "[2023-11-17 16:18:38.245890] Epoch: 8 ends. Average loss: 9.703867705566608\n",
      "Epoch: 9 Batch: 0, loss: 9.953721046447754, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 100, loss: 9.905058860778809, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 200, loss: 9.835333824157715, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 300, loss: 7.2501020431518555, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 400, loss: 8.147331237792969, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 500, loss: 10.474610328674316, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 600, loss: 8.24764347076416, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 700, loss: 10.216020584106445, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 800, loss: 9.858255386352539, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 900, loss: 9.299296379089355, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1000, loss: 9.620806694030762, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1100, loss: 10.00963306427002, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1200, loss: 10.561151504516602, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1300, loss: 8.922660827636719, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1400, loss: 8.108564376831055, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1500, loss: 9.514156341552734, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1600, loss: 9.04908275604248, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1700, loss: 12.515033721923828, rate: 8.99503275886506e-06\n",
      "Epoch: 9 Batch: 1800, loss: 11.344196319580078, rate: 8.99503275886506e-06\n",
      "[2023-11-17 16:24:47.942035] Epoch: 9 ends. Average loss: 9.676931016430695\n",
      "Epoch: 10 Batch: 0, loss: 9.947450637817383, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 100, loss: 10.156005859375, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 200, loss: 9.731827735900879, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 300, loss: 7.131793975830078, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 400, loss: 8.124893188476562, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 500, loss: 10.391751289367676, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 600, loss: 7.98097038269043, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 700, loss: 10.020414352416992, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 800, loss: 9.68920612335205, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 900, loss: 9.261270523071289, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1000, loss: 9.913890838623047, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1100, loss: 9.790125846862793, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1200, loss: 9.708080291748047, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1300, loss: 9.06336784362793, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1400, loss: 8.526956558227539, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1500, loss: 9.327281951904297, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1600, loss: 9.07967472076416, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1700, loss: 12.186423301696777, rate: 8.635231448510457e-06\n",
      "Epoch: 10 Batch: 1800, loss: 10.980388641357422, rate: 8.635231448510457e-06\n",
      "[2023-11-17 16:31:00.235937] Epoch: 10 ends. Average loss: 9.668600702049057\n",
      "Epoch: 11 Batch: 0, loss: 10.070833206176758, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 100, loss: 10.472868919372559, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 200, loss: 9.9932279586792, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 300, loss: 7.383825302124023, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 400, loss: 8.181171417236328, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 500, loss: 10.82817554473877, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 600, loss: 8.507613182067871, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 700, loss: 10.566607475280762, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 800, loss: 9.777709007263184, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 900, loss: 9.02687931060791, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1000, loss: 10.343036651611328, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1100, loss: 9.73295783996582, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1200, loss: 10.393306732177734, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1300, loss: 9.145981788635254, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1400, loss: 8.901575088500977, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1500, loss: 9.468179702758789, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1600, loss: 8.719276428222656, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1700, loss: 12.485139846801758, rate: 8.289822190570038e-06\n",
      "Epoch: 11 Batch: 1800, loss: 11.470050811767578, rate: 8.289822190570038e-06\n",
      "[2023-11-17 16:37:10.227652] Epoch: 11 ends. Average loss: 9.662010863809643\n",
      "Epoch: 12 Batch: 0, loss: 10.018665313720703, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 100, loss: 9.956565856933594, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 200, loss: 9.802618980407715, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 300, loss: 7.244688034057617, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 400, loss: 8.059762954711914, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 500, loss: 10.540205001831055, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 600, loss: 8.182899475097656, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 700, loss: 10.046350479125977, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 800, loss: 9.591936111450195, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 900, loss: 9.122446060180664, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1000, loss: 10.271116256713867, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1100, loss: 9.881688117980957, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1200, loss: 10.518404006958008, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1300, loss: 9.53750228881836, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1400, loss: 8.420548439025879, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1500, loss: 9.563776969909668, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1600, loss: 8.503292083740234, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1700, loss: 12.559555053710938, rate: 7.958229302947236e-06\n",
      "Epoch: 12 Batch: 1800, loss: 10.906593322753906, rate: 7.958229302947236e-06\n",
      "[2023-11-17 16:43:21.258921] Epoch: 12 ends. Average loss: 9.64488833606802\n",
      "Epoch: 13 Batch: 0, loss: 10.106101036071777, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 100, loss: 10.07238483428955, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 200, loss: 9.934314727783203, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 300, loss: 7.252505302429199, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 400, loss: 7.994969367980957, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 500, loss: 10.060757637023926, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 600, loss: 8.30521297454834, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 700, loss: 10.0673189163208, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 800, loss: 9.60792350769043, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 900, loss: 8.681108474731445, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1000, loss: 9.838546752929688, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1100, loss: 10.242168426513672, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1200, loss: 10.48886489868164, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1300, loss: 9.021636009216309, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1400, loss: 8.376642227172852, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1500, loss: 9.601701736450195, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1600, loss: 8.80807876586914, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1700, loss: 12.482851028442383, rate: 7.639900130829346e-06\n",
      "Epoch: 13 Batch: 1800, loss: 10.945843696594238, rate: 7.639900130829346e-06\n",
      "[2023-11-17 16:49:34.435893] Epoch: 13 ends. Average loss: 9.621331059991887\n",
      "Epoch: 14 Batch: 0, loss: 10.178193092346191, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 100, loss: 9.759530067443848, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 200, loss: 9.905890464782715, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 300, loss: 7.516116619110107, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 400, loss: 8.13153076171875, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 500, loss: 10.097428321838379, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 600, loss: 8.658038139343262, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 700, loss: 10.137604713439941, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 800, loss: 9.664758682250977, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 900, loss: 9.235116958618164, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1000, loss: 10.045486450195312, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1100, loss: 10.02337646484375, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1200, loss: 10.235628128051758, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1300, loss: 9.109464645385742, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1400, loss: 8.30597972869873, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1500, loss: 9.966405868530273, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1600, loss: 8.976371765136719, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1700, loss: 12.004922866821289, rate: 7.334304125596171e-06\n",
      "Epoch: 14 Batch: 1800, loss: 10.848258972167969, rate: 7.334304125596171e-06\n",
      "[2023-11-17 16:55:47.636020] Epoch: 14 ends. Average loss: 9.616061448919398\n",
      "Epoch: 15 Batch: 0, loss: 9.861645698547363, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 100, loss: 10.113911628723145, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 200, loss: 9.697606086730957, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 300, loss: 7.165966033935547, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 400, loss: 8.230888366699219, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 500, loss: 10.591747283935547, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 600, loss: 8.377667427062988, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 700, loss: 10.020575523376465, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 800, loss: 10.16297721862793, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 900, loss: 8.427288055419922, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1000, loss: 9.981925964355469, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1100, loss: 9.897026062011719, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1200, loss: 10.356074333190918, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1300, loss: 9.035317420959473, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1400, loss: 8.870373725891113, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1500, loss: 9.493642807006836, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1600, loss: 9.239069938659668, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1700, loss: 11.872252464294434, rate: 7.040931960572324e-06\n",
      "Epoch: 15 Batch: 1800, loss: 11.243476867675781, rate: 7.040931960572324e-06\n",
      "[2023-11-17 17:02:06.515112] Epoch: 15 ends. Average loss: 9.608408880575677\n",
      "Epoch: 16 Batch: 0, loss: 10.440945625305176, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 100, loss: 9.746858596801758, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 200, loss: 9.947066307067871, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 300, loss: 7.263150691986084, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 400, loss: 8.311559677124023, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 500, loss: 10.635415077209473, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 600, loss: 8.527894020080566, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 700, loss: 10.156864166259766, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 800, loss: 9.515569686889648, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 900, loss: 8.893014907836914, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1000, loss: 10.074758529663086, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1100, loss: 9.857605934143066, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1200, loss: 10.351547241210938, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1300, loss: 9.101694107055664, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1400, loss: 8.346830368041992, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1500, loss: 9.606633186340332, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1600, loss: 8.769659042358398, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1700, loss: 11.95634651184082, rate: 6.759294682149431e-06\n",
      "Epoch: 16 Batch: 1800, loss: 11.013408660888672, rate: 6.759294682149431e-06\n",
      "[2023-11-17 17:08:19.197287] Epoch: 16 ends. Average loss: 9.581470015820916\n",
      "Epoch: 17 Batch: 0, loss: 9.785514831542969, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 100, loss: 9.765877723693848, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 200, loss: 9.45608901977539, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 300, loss: 7.386031627655029, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 400, loss: 8.213458061218262, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 500, loss: 10.496844291687012, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 600, loss: 8.62524700164795, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 700, loss: 9.961578369140625, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 800, loss: 9.512578964233398, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 900, loss: 8.813714027404785, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1000, loss: 9.799104690551758, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1100, loss: 9.711983680725098, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1200, loss: 9.860422134399414, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1300, loss: 9.098769187927246, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1400, loss: 8.931917190551758, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1500, loss: 9.931029319763184, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1600, loss: 8.901466369628906, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1700, loss: 11.770809173583984, rate: 6.488922894863454e-06\n",
      "Epoch: 17 Batch: 1800, loss: 11.050088882446289, rate: 6.488922894863454e-06\n",
      "[2023-11-17 17:14:33.618550] Epoch: 17 ends. Average loss: 9.57598438173516\n",
      "Epoch: 18 Batch: 0, loss: 10.079537391662598, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 100, loss: 10.023704528808594, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 200, loss: 9.797223091125488, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 300, loss: 6.935635566711426, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 400, loss: 8.327524185180664, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 500, loss: 10.545583724975586, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 600, loss: 8.095246315002441, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 800, loss: 9.708160400390625, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 900, loss: 9.107300758361816, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1000, loss: 9.78064250946045, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1100, loss: 9.919601440429688, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1200, loss: 10.304191589355469, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1300, loss: 8.968917846679688, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1400, loss: 8.880175590515137, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1500, loss: 9.318221092224121, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1600, loss: 8.692766189575195, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1700, loss: 12.455371856689453, rate: 6.229365979068915e-06\n",
      "Epoch: 18 Batch: 1800, loss: 11.3700590133667, rate: 6.229365979068915e-06\n",
      "[2023-11-17 17:20:46.248142] Epoch: 18 ends. Average loss: 9.556298296949972\n",
      "Epoch: 19 Batch: 0, loss: 10.387718200683594, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 100, loss: 9.778303146362305, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 200, loss: 9.738548278808594, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 300, loss: 7.131330966949463, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 400, loss: 8.01229190826416, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 500, loss: 10.643683433532715, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 600, loss: 8.311921119689941, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 700, loss: 9.988668441772461, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 800, loss: 9.38539981842041, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 900, loss: 8.998690605163574, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1000, loss: 9.900753021240234, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1100, loss: 9.562782287597656, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1200, loss: 10.112675666809082, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1300, loss: 9.23898696899414, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1400, loss: 8.937629699707031, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1500, loss: 9.304235458374023, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1600, loss: 8.71444320678711, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1700, loss: 11.945566177368164, rate: 5.980191339906158e-06\n",
      "Epoch: 19 Batch: 1800, loss: 10.693613052368164, rate: 5.980191339906158e-06\n",
      "[2023-11-17 17:26:56.695185] Epoch: 19 ends. Average loss: 9.558467068069888\n",
      "Epoch: 20 Batch: 0, loss: 10.0220947265625, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 100, loss: 9.895406723022461, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 200, loss: 9.621450424194336, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 300, loss: 7.198578834533691, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 400, loss: 8.03961181640625, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 500, loss: 10.419281005859375, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 600, loss: 8.070563316345215, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 700, loss: 10.287569046020508, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 800, loss: 9.482584953308105, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 900, loss: 9.07473087310791, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1000, loss: 9.649980545043945, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1100, loss: 9.276848793029785, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1200, loss: 10.326685905456543, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1300, loss: 8.84716796875, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1400, loss: 8.500654220581055, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1500, loss: 9.660343170166016, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1600, loss: 8.699658393859863, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1700, loss: 11.81734848022461, rate: 5.740983686309912e-06\n",
      "Epoch: 20 Batch: 1800, loss: 10.842458724975586, rate: 5.740983686309912e-06\n",
      "[2023-11-17 17:33:05.440043] Epoch: 20 ends. Average loss: 9.547035063950316\n",
      "Epoch: 21 Batch: 0, loss: 9.779146194458008, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 100, loss: 9.98503589630127, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 200, loss: 9.840789794921875, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 300, loss: 7.100386619567871, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 400, loss: 7.981845855712891, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 500, loss: 10.26043701171875, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 600, loss: 7.9404473304748535, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 700, loss: 9.629727363586426, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 800, loss: 9.471115112304688, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 900, loss: 8.590755462646484, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1000, loss: 9.670766830444336, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1100, loss: 9.681264877319336, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1200, loss: 10.736492156982422, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1300, loss: 8.906900405883789, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1400, loss: 8.532588005065918, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1500, loss: 9.468263626098633, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1600, loss: 8.814562797546387, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1700, loss: 12.372013092041016, rate: 5.511344338857515e-06\n",
      "Epoch: 21 Batch: 1800, loss: 11.309100151062012, rate: 5.511344338857515e-06\n",
      "[2023-11-17 17:39:16.876148] Epoch: 21 ends. Average loss: 9.531589103547237\n",
      "Epoch: 22 Batch: 0, loss: 9.476882934570312, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 100, loss: 10.16369342803955, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 200, loss: 10.124610900878906, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 300, loss: 6.691534042358398, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 400, loss: 7.911708831787109, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 500, loss: 10.687664031982422, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 600, loss: 8.442808151245117, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 700, loss: 10.33627700805664, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 800, loss: 9.355144500732422, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 900, loss: 9.01340103149414, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1000, loss: 9.817984580993652, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1100, loss: 9.999774932861328, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1200, loss: 10.561342239379883, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1300, loss: 8.68743896484375, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1400, loss: 8.623753547668457, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1500, loss: 9.65542984008789, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1600, loss: 8.206435203552246, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1700, loss: 12.00964069366455, rate: 5.290890565303214e-06\n",
      "Epoch: 22 Batch: 1800, loss: 11.15329360961914, rate: 5.290890565303214e-06\n",
      "[2023-11-17 17:45:30.427583] Epoch: 22 ends. Average loss: 9.521259288924607\n",
      "Epoch: 23 Batch: 0, loss: 10.028989791870117, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 100, loss: 9.665979385375977, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 200, loss: 10.216302871704102, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 300, loss: 7.875049114227295, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 400, loss: 8.256098747253418, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 500, loss: 10.378837585449219, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 600, loss: 8.178394317626953, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 700, loss: 9.801706314086914, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 800, loss: 9.395496368408203, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 900, loss: 9.0009765625, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1000, loss: 9.655901908874512, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1100, loss: 9.993525505065918, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1200, loss: 9.996800422668457, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1300, loss: 8.681785583496094, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1400, loss: 8.397059440612793, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1500, loss: 9.227812767028809, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1600, loss: 8.70919418334961, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1700, loss: 12.09836483001709, rate: 5.079254942691085e-06\n",
      "Epoch: 23 Batch: 1800, loss: 11.383028030395508, rate: 5.079254942691085e-06\n",
      "[2023-11-17 17:51:42.284269] Epoch: 23 ends. Average loss: 9.508510367619156\n",
      "Epoch: 24 Batch: 0, loss: 9.572568893432617, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 100, loss: 9.593624114990234, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 200, loss: 9.937511444091797, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 300, loss: 7.1309943199157715, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 400, loss: 8.250218391418457, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 500, loss: 10.359060287475586, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 600, loss: 8.280149459838867, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 700, loss: 10.356348991394043, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 800, loss: 9.463545799255371, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 900, loss: 9.219156265258789, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1000, loss: 10.469590187072754, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1100, loss: 9.597698211669922, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1200, loss: 10.567221641540527, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1300, loss: 8.777114868164062, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1400, loss: 8.394303321838379, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1500, loss: 9.32656192779541, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1600, loss: 8.464237213134766, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1700, loss: 12.256020545959473, rate: 4.876084744983441e-06\n",
      "Epoch: 24 Batch: 1800, loss: 10.859779357910156, rate: 4.876084744983441e-06\n",
      "[2023-11-17 17:57:54.253011] Epoch: 24 ends. Average loss: 9.508328074325334\n",
      "Epoch: 25 Batch: 0, loss: 10.111238479614258, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 100, loss: 9.614060401916504, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 200, loss: 9.675880432128906, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 300, loss: 6.779884338378906, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 400, loss: 8.34605598449707, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 500, loss: 10.352983474731445, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 600, loss: 8.523204803466797, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 700, loss: 10.462780952453613, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 800, loss: 9.867410659790039, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 900, loss: 8.703046798706055, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1000, loss: 9.75744342803955, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1100, loss: 9.921125411987305, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1200, loss: 10.208309173583984, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1300, loss: 9.397624015808105, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1400, loss: 8.550471305847168, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1500, loss: 9.678238868713379, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1600, loss: 8.874258041381836, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1700, loss: 12.269990921020508, rate: 4.681041355184103e-06\n",
      "Epoch: 25 Batch: 1800, loss: 10.685769081115723, rate: 4.681041355184103e-06\n",
      "[2023-11-17 18:04:06.368270] Epoch: 25 ends. Average loss: 9.503650708416846\n",
      "Epoch: 26 Batch: 0, loss: 9.788275718688965, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 100, loss: 9.688251495361328, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 200, loss: 9.305130004882812, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 300, loss: 6.918862342834473, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 400, loss: 7.823455810546875, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 500, loss: 10.228123664855957, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 600, loss: 8.561371803283691, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 700, loss: 9.582371711730957, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 800, loss: 9.297972679138184, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 900, loss: 9.063440322875977, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1000, loss: 9.876629829406738, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1100, loss: 9.745153427124023, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1200, loss: 10.058835983276367, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1300, loss: 9.175289154052734, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1400, loss: 8.471735000610352, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1500, loss: 9.33053207397461, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1600, loss: 8.807028770446777, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1700, loss: 12.098091125488281, rate: 4.493799700976739e-06\n",
      "Epoch: 26 Batch: 1800, loss: 11.29533576965332, rate: 4.493799700976739e-06\n",
      "[2023-11-17 18:10:17.417036] Epoch: 26 ends. Average loss: 9.484492212517512\n",
      "Epoch: 27 Batch: 0, loss: 9.606998443603516, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 100, loss: 9.771525382995605, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 200, loss: 9.4486722946167, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 300, loss: 7.038573741912842, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 400, loss: 8.051047325134277, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 500, loss: 10.534416198730469, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 600, loss: 8.117562294006348, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 700, loss: 10.388174057006836, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 800, loss: 9.792508125305176, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 900, loss: 8.84904956817627, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1000, loss: 10.283843040466309, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1100, loss: 9.543588638305664, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1200, loss: 10.15460205078125, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1300, loss: 9.608105659484863, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1400, loss: 8.6130952835083, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1500, loss: 9.381608963012695, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1600, loss: 8.836870193481445, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1700, loss: 12.002748489379883, rate: 4.31404771293767e-06\n",
      "Epoch: 27 Batch: 1800, loss: 11.465373992919922, rate: 4.31404771293767e-06\n",
      "[2023-11-17 18:16:28.561094] Epoch: 27 ends. Average loss: 9.471866200263502\n",
      "Epoch: 28 Batch: 0, loss: 9.793063163757324, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 100, loss: 9.652748107910156, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 200, loss: 9.669471740722656, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 300, loss: 7.098283290863037, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 400, loss: 8.158044815063477, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 500, loss: 10.229321479797363, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 600, loss: 8.03894329071045, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 700, loss: 9.973499298095703, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 800, loss: 9.511374473571777, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 900, loss: 8.644865036010742, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1000, loss: 9.605971336364746, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1100, loss: 9.839861869812012, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1200, loss: 10.001960754394531, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1300, loss: 8.775530815124512, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1400, loss: 8.434043884277344, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1500, loss: 8.939136505126953, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1600, loss: 8.559666633605957, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1700, loss: 12.419962882995605, rate: 4.141485804420163e-06\n",
      "Epoch: 28 Batch: 1800, loss: 11.270099639892578, rate: 4.141485804420163e-06\n",
      "[2023-11-17 18:22:38.188912] Epoch: 28 ends. Average loss: 9.477899057458792\n",
      "Epoch: 29 Batch: 0, loss: 9.591866493225098, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 100, loss: 10.064680099487305, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 200, loss: 9.726806640625, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 300, loss: 6.874715805053711, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 400, loss: 7.9898552894592285, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 500, loss: 10.331097602844238, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 600, loss: 8.43480396270752, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 700, loss: 11.016769409179688, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 800, loss: 9.367545127868652, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 900, loss: 8.854852676391602, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1000, loss: 9.90756607055664, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1100, loss: 9.689811706542969, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1200, loss: 9.947206497192383, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1300, loss: 9.176872253417969, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1400, loss: 8.779219627380371, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1500, loss: 9.55156421661377, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1600, loss: 8.094576835632324, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1700, loss: 11.876195907592773, rate: 3.9758263722433564e-06\n",
      "Epoch: 29 Batch: 1800, loss: 11.793388366699219, rate: 3.9758263722433564e-06\n",
      "[2023-11-17 18:28:51.248148] Epoch: 29 ends. Average loss: 9.455319608434813\n",
      "Epoch: 30 Batch: 0, loss: 10.55704116821289, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 100, loss: 9.569901466369629, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 200, loss: 10.13557243347168, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 300, loss: 7.087178707122803, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 400, loss: 8.18522834777832, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 500, loss: 10.31794548034668, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 600, loss: 8.015469551086426, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 700, loss: 10.111393928527832, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 800, loss: 9.82697582244873, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 900, loss: 9.010242462158203, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1000, loss: 9.929198265075684, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1100, loss: 9.486552238464355, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1200, loss: 10.15936279296875, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1300, loss: 9.18890380859375, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1400, loss: 8.460805892944336, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1500, loss: 9.07778549194336, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1600, loss: 8.826075553894043, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1700, loss: 12.217255592346191, rate: 3.816793317353622e-06\n",
      "Epoch: 30 Batch: 1800, loss: 11.119216918945312, rate: 3.816793317353622e-06\n",
      "[2023-11-17 18:35:02.856794] Epoch: 30 ends. Average loss: 9.455450520091995\n",
      "Epoch: 31 Batch: 0, loss: 9.888446807861328, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 100, loss: 9.55941390991211, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 200, loss: 9.386116027832031, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 300, loss: 6.874967098236084, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 400, loss: 7.93389892578125, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 500, loss: 10.420947074890137, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 600, loss: 8.102153778076172, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 700, loss: 9.793464660644531, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 800, loss: 9.286232948303223, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 900, loss: 8.51527214050293, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1000, loss: 9.531744956970215, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1100, loss: 9.6442289352417, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1200, loss: 10.041433334350586, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1300, loss: 9.296943664550781, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1400, loss: 8.689719200134277, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1500, loss: 9.283820152282715, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1600, loss: 8.591217041015625, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1700, loss: 12.01352310180664, rate: 3.6641215846594767e-06\n",
      "Epoch: 31 Batch: 1800, loss: 10.870349884033203, rate: 3.6641215846594767e-06\n",
      "[2023-11-17 18:41:11.026705] Epoch: 31 ends. Average loss: 9.448628376152262\n",
      "Epoch: 32 Batch: 0, loss: 9.86630630493164, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 100, loss: 9.675673484802246, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 200, loss: 10.089454650878906, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 300, loss: 7.278794288635254, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 400, loss: 8.051034927368164, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 500, loss: 11.144168853759766, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 600, loss: 8.068220138549805, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 700, loss: 9.89894962310791, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 800, loss: 9.43459701538086, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 900, loss: 8.722613334655762, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1000, loss: 9.64184856414795, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1100, loss: 9.567715644836426, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1200, loss: 10.445045471191406, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1300, loss: 9.079703330993652, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1400, loss: 8.49105453491211, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1500, loss: 9.248479843139648, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1600, loss: 8.552891731262207, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1700, loss: 12.128561973571777, rate: 3.5175567212730974e-06\n",
      "Epoch: 32 Batch: 1800, loss: 10.646484375, rate: 3.5175567212730974e-06\n",
      "[2023-11-17 18:47:24.249666] Epoch: 32 ends. Average loss: 9.453115629479166\n",
      "Epoch: 33 Batch: 0, loss: 9.847967147827148, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 100, loss: 9.757119178771973, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 200, loss: 9.850330352783203, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 300, loss: 6.766875267028809, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 400, loss: 8.318683624267578, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 500, loss: 10.918987274169922, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 600, loss: 7.973974227905273, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 700, loss: 9.565754890441895, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 800, loss: 9.697893142700195, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 900, loss: 8.696669578552246, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1000, loss: 9.649552345275879, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1100, loss: 9.86026668548584, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1200, loss: 10.695036888122559, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1300, loss: 9.150877952575684, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1400, loss: 8.903495788574219, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1500, loss: 9.195246696472168, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1600, loss: 8.510919570922852, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1700, loss: 12.350187301635742, rate: 3.3768544524221733e-06\n",
      "Epoch: 33 Batch: 1800, loss: 10.995526313781738, rate: 3.3768544524221733e-06\n",
      "[2023-11-17 18:53:36.468023] Epoch: 33 ends. Average loss: 9.429788522936006\n",
      "Epoch: 34 Batch: 0, loss: 9.726842880249023, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 100, loss: 9.418570518493652, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 200, loss: 9.559429168701172, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 300, loss: 7.493997573852539, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 400, loss: 8.31220531463623, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 500, loss: 10.390973091125488, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 600, loss: 7.961237907409668, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 700, loss: 9.735279083251953, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 800, loss: 9.226268768310547, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 900, loss: 8.928936004638672, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1000, loss: 9.853909492492676, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1100, loss: 10.086204528808594, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1200, loss: 10.310962677001953, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1300, loss: 8.726051330566406, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1400, loss: 8.730097770690918, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1500, loss: 9.030604362487793, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1600, loss: 8.712804794311523, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1700, loss: 12.205754280090332, rate: 3.2417802743252863e-06\n",
      "Epoch: 34 Batch: 1800, loss: 10.898059844970703, rate: 3.2417802743252863e-06\n",
      "[2023-11-17 18:59:51.567648] Epoch: 34 ends. Average loss: 9.430721650120967\n",
      "Epoch: 35 Batch: 0, loss: 9.784754753112793, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 100, loss: 9.664168357849121, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 200, loss: 10.142044067382812, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 300, loss: 7.064746856689453, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 400, loss: 7.563483715057373, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 500, loss: 10.034419059753418, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 600, loss: 7.900655746459961, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 700, loss: 10.04981517791748, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 800, loss: 9.149383544921875, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 900, loss: 8.750831604003906, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1000, loss: 10.310449600219727, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1100, loss: 9.35362720489502, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1200, loss: 9.863251686096191, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1300, loss: 9.099174499511719, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1400, loss: 8.75832748413086, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1500, loss: 9.393966674804688, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1600, loss: 8.574210166931152, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1700, loss: 11.928892135620117, rate: 3.112109063352275e-06\n",
      "Epoch: 35 Batch: 1800, loss: 11.056697845458984, rate: 3.112109063352275e-06\n",
      "[2023-11-17 19:06:03.741134] Epoch: 35 ends. Average loss: 9.433222211531625\n",
      "Epoch: 36 Batch: 0, loss: 9.805985450744629, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 100, loss: 9.7061185836792, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 200, loss: 9.538115501403809, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 300, loss: 6.582008361816406, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 400, loss: 8.078268051147461, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 500, loss: 10.488003730773926, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 600, loss: 8.13277816772461, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 700, loss: 10.00100040435791, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 800, loss: 9.344810485839844, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 900, loss: 8.75177001953125, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1000, loss: 9.9045991897583, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1100, loss: 9.840370178222656, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1200, loss: 10.607705116271973, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1300, loss: 9.017525672912598, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1400, loss: 8.31771183013916, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1500, loss: 9.568876266479492, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1600, loss: 8.846717834472656, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1700, loss: 12.176902770996094, rate: 2.9876247008181837e-06\n",
      "Epoch: 36 Batch: 1800, loss: 10.735754013061523, rate: 2.9876247008181837e-06\n",
      "[2023-11-17 19:12:15.634907] Epoch: 36 ends. Average loss: 9.418296932582361\n",
      "Epoch: 37 Batch: 0, loss: 9.732114791870117, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 100, loss: 9.549449920654297, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 200, loss: 9.846771240234375, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 300, loss: 7.001866340637207, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 400, loss: 8.269388198852539, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 500, loss: 10.429841995239258, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 600, loss: 8.06605339050293, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 700, loss: 9.89018440246582, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 800, loss: 9.148261070251465, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 900, loss: 9.039380073547363, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1000, loss: 10.261415481567383, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1100, loss: 9.379586219787598, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1200, loss: 10.060039520263672, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1300, loss: 8.80947494506836, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1400, loss: 8.18400764465332, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1500, loss: 9.131562232971191, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1600, loss: 8.501113891601562, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1700, loss: 12.424528121948242, rate: 2.8681197127854562e-06\n",
      "Epoch: 37 Batch: 1800, loss: 11.044073104858398, rate: 2.8681197127854562e-06\n",
      "[2023-11-17 19:18:26.269947] Epoch: 37 ends. Average loss: 9.412815475358663\n",
      "Epoch: 38 Batch: 0, loss: 10.066228866577148, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 100, loss: 9.674867630004883, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 200, loss: 9.476409912109375, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 300, loss: 7.103187561035156, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 400, loss: 7.861872673034668, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 500, loss: 10.39204216003418, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 600, loss: 8.14753246307373, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 700, loss: 10.158880233764648, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 800, loss: 9.500694274902344, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 900, loss: 9.029458999633789, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1000, loss: 9.433547973632812, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1100, loss: 9.698899269104004, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1200, loss: 10.310297012329102, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1300, loss: 9.425615310668945, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1400, loss: 8.486515045166016, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1500, loss: 9.44398307800293, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1600, loss: 8.395356178283691, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1700, loss: 12.26371955871582, rate: 2.753394924274038e-06\n",
      "Epoch: 38 Batch: 1800, loss: 10.92522144317627, rate: 2.753394924274038e-06\n",
      "[2023-11-17 19:24:36.386442] Epoch: 38 ends. Average loss: 9.398930313438589\n",
      "Epoch: 39 Batch: 0, loss: 9.524694442749023, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 200, loss: 9.466906547546387, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 300, loss: 7.277233600616455, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 400, loss: 7.899690628051758, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 500, loss: 10.311065673828125, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 600, loss: 8.28727912902832, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 700, loss: 9.671082496643066, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 800, loss: 9.787482261657715, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 900, loss: 8.645729064941406, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1000, loss: 9.459866523742676, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1100, loss: 10.064634323120117, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1200, loss: 10.222607612609863, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1300, loss: 9.009167671203613, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1400, loss: 8.148492813110352, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1500, loss: 9.504961967468262, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1600, loss: 8.723576545715332, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1700, loss: 11.93696403503418, rate: 2.6432591273030763e-06\n",
      "Epoch: 39 Batch: 1800, loss: 10.885414123535156, rate: 2.6432591273030763e-06\n",
      "[2023-11-17 19:30:52.870384] Epoch: 39 ends. Average loss: 9.4030986400316\n",
      "Epoch: 40 Batch: 0, loss: 9.836249351501465, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 100, loss: 9.416532516479492, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 200, loss: 9.924518585205078, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 300, loss: 6.7723774909973145, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 400, loss: 7.951234817504883, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 500, loss: 10.128493309020996, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 600, loss: 8.475004196166992, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 700, loss: 10.103301048278809, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 800, loss: 9.673345565795898, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 900, loss: 8.870772361755371, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1000, loss: 9.862883567810059, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1100, loss: 9.612299919128418, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1200, loss: 9.794824600219727, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1300, loss: 8.947128295898438, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1400, loss: 8.490594863891602, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1500, loss: 9.24725341796875, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1600, loss: 8.549586296081543, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1700, loss: 12.06165885925293, rate: 2.537528762210953e-06\n",
      "Epoch: 40 Batch: 1800, loss: 10.681557655334473, rate: 2.537528762210953e-06\n",
      "[2023-11-17 19:37:02.556255] Epoch: 40 ends. Average loss: 9.405191682940744\n",
      "Epoch: 41 Batch: 0, loss: 10.098173141479492, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 100, loss: 9.579169273376465, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 200, loss: 9.699089050292969, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 300, loss: 6.7895355224609375, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 400, loss: 7.72359561920166, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 500, loss: 10.14431095123291, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 600, loss: 8.091117858886719, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 700, loss: 10.172674179077148, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 800, loss: 9.576011657714844, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 900, loss: 9.4767427444458, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1000, loss: 9.638442993164062, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1100, loss: 9.75793743133545, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1200, loss: 9.844745635986328, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1300, loss: 8.477028846740723, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1400, loss: 8.506673812866211, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1500, loss: 9.115835189819336, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1600, loss: 8.581818580627441, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1700, loss: 12.359151840209961, rate: 2.436027611722515e-06\n",
      "Epoch: 41 Batch: 1800, loss: 11.090353965759277, rate: 2.436027611722515e-06\n",
      "[2023-11-17 19:43:08.461053] Epoch: 41 ends. Average loss: 9.390872886413641\n",
      "Epoch: 42 Batch: 0, loss: 9.64533805847168, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 100, loss: 9.845809936523438, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 200, loss: 9.781759262084961, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 300, loss: 6.9020280838012695, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 400, loss: 7.761802673339844, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 500, loss: 10.145750045776367, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 600, loss: 8.187681198120117, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 700, loss: 10.070801734924316, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 800, loss: 9.28727912902832, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 900, loss: 8.792015075683594, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1000, loss: 9.91765022277832, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1100, loss: 9.51910400390625, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1200, loss: 10.042598724365234, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1300, loss: 8.857108116149902, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1400, loss: 8.441161155700684, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1500, loss: 9.365338325500488, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1600, loss: 8.243377685546875, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1700, loss: 11.935443878173828, rate: 2.338586507253614e-06\n",
      "Epoch: 42 Batch: 1800, loss: 10.7295503616333, rate: 2.338586507253614e-06\n",
      "[2023-11-17 19:49:14.051060] Epoch: 42 ends. Average loss: 9.394486968581742\n",
      "Epoch: 43 Batch: 0, loss: 10.019233703613281, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 100, loss: 9.976600646972656, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 200, loss: 9.43393325805664, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 300, loss: 7.326612949371338, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 400, loss: 7.995856285095215, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 500, loss: 10.570911407470703, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 600, loss: 7.884521961212158, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 700, loss: 10.145864486694336, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 800, loss: 9.64780044555664, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 900, loss: 8.451555252075195, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1000, loss: 9.473366737365723, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1100, loss: 9.186259269714355, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1200, loss: 10.626855850219727, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1300, loss: 9.154338836669922, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1400, loss: 8.723433494567871, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1500, loss: 9.253881454467773, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1600, loss: 8.41256046295166, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1700, loss: 11.952372550964355, rate: 2.2450430469634697e-06\n",
      "Epoch: 43 Batch: 1800, loss: 10.901518821716309, rate: 2.2450430469634697e-06\n",
      "[2023-11-17 19:55:18.161057] Epoch: 43 ends. Average loss: 9.388130899167363\n",
      "Epoch: 44 Batch: 0, loss: 10.101400375366211, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 100, loss: 9.759557723999023, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 200, loss: 9.845834732055664, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 300, loss: 7.172610282897949, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 400, loss: 8.073125839233398, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 500, loss: 10.202606201171875, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 600, loss: 8.234125137329102, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 700, loss: 10.087814331054688, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 800, loss: 9.707737922668457, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 900, loss: 8.660429000854492, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1000, loss: 9.93603229522705, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1100, loss: 9.685868263244629, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1200, loss: 10.196161270141602, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1300, loss: 8.820969581604004, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1400, loss: 8.532302856445312, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1500, loss: 9.083281517028809, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1600, loss: 8.565298080444336, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1700, loss: 12.072341918945312, rate: 2.1552413250849307e-06\n",
      "Epoch: 44 Batch: 1800, loss: 10.971150398254395, rate: 2.1552413250849307e-06\n",
      "[2023-11-17 20:01:22.099380] Epoch: 44 ends. Average loss: 9.386275328264274\n",
      "Epoch: 45 Batch: 0, loss: 9.81077766418457, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 100, loss: 9.790977478027344, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 200, loss: 9.401350975036621, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 300, loss: 6.811590671539307, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 400, loss: 7.531337738037109, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 500, loss: 9.958866119384766, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 600, loss: 8.345931053161621, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 700, loss: 9.961623191833496, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 800, loss: 9.328654289245605, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 900, loss: 8.711603164672852, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1000, loss: 9.434596061706543, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1100, loss: 9.636625289916992, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1200, loss: 10.071619987487793, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1300, loss: 8.981305122375488, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1400, loss: 8.185958862304688, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1500, loss: 9.154647827148438, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1600, loss: 8.457374572753906, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1700, loss: 11.995224952697754, rate: 2.0690316720815334e-06\n",
      "Epoch: 45 Batch: 1800, loss: 11.362866401672363, rate: 2.0690316720815334e-06\n",
      "[2023-11-17 20:07:33.883099] Epoch: 45 ends. Average loss: 9.381419462718426\n",
      "Epoch: 46 Batch: 0, loss: 9.60977554321289, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 100, loss: 9.79435920715332, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 200, loss: 9.350011825561523, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 300, loss: 7.014761924743652, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 400, loss: 7.858781337738037, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 500, loss: 10.552262306213379, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 600, loss: 8.127105712890625, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 700, loss: 9.97348403930664, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 800, loss: 9.578768730163574, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 900, loss: 8.503637313842773, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1000, loss: 9.947218894958496, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1100, loss: 9.68991470336914, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1200, loss: 10.095938682556152, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1300, loss: 9.085527420043945, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1400, loss: 9.27227783203125, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1500, loss: 9.223114967346191, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1600, loss: 8.357150077819824, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1700, loss: 11.829780578613281, rate: 1.986270405198272e-06\n",
      "Epoch: 46 Batch: 1800, loss: 11.165224075317383, rate: 1.986270405198272e-06\n",
      "[2023-11-17 20:13:48.901689] Epoch: 46 ends. Average loss: 9.376673039059185\n",
      "Epoch: 47 Batch: 0, loss: 9.759031295776367, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 100, loss: 10.047332763671875, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 200, loss: 9.865253448486328, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 300, loss: 6.64496374130249, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 400, loss: 7.683127403259277, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 500, loss: 10.508484840393066, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 600, loss: 8.4884614944458, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 700, loss: 9.824850082397461, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 800, loss: 9.901495933532715, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 900, loss: 8.608241081237793, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1000, loss: 9.610090255737305, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1100, loss: 9.620136260986328, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1200, loss: 9.842498779296875, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1300, loss: 8.94076156616211, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1400, loss: 8.63646125793457, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1500, loss: 9.195178985595703, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1600, loss: 8.754439353942871, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1700, loss: 11.704591751098633, rate: 1.906819588990341e-06\n",
      "Epoch: 47 Batch: 1800, loss: 10.355667114257812, rate: 1.906819588990341e-06\n",
      "[2023-11-17 20:19:57.508791] Epoch: 47 ends. Average loss: 9.362107464179635\n",
      "Epoch: 48 Batch: 0, loss: 9.9312744140625, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 100, loss: 9.69321346282959, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 200, loss: 9.315667152404785, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 300, loss: 6.751528263092041, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 400, loss: 7.875141620635986, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 500, loss: 10.752707481384277, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 600, loss: 8.126041412353516, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 700, loss: 10.2572021484375, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 800, loss: 9.43255615234375, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 900, loss: 8.786877632141113, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1000, loss: 9.629498481750488, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1100, loss: 9.24688720703125, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1200, loss: 10.178776741027832, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1300, loss: 8.565526962280273, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1400, loss: 8.110774993896484, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1500, loss: 9.262848854064941, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1600, loss: 8.313971519470215, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1700, loss: 12.12658977508545, rate: 1.8305468054307272e-06\n",
      "Epoch: 48 Batch: 1800, loss: 10.604637145996094, rate: 1.8305468054307272e-06\n",
      "[2023-11-17 20:26:08.567077] Epoch: 48 ends. Average loss: 9.363301107782194\n",
      "Epoch: 49 Batch: 0, loss: 9.56534481048584, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 100, loss: 10.01534366607666, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 200, loss: 9.735941886901855, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 300, loss: 6.520552635192871, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 400, loss: 7.990531921386719, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 500, loss: 10.151616096496582, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 600, loss: 8.091212272644043, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 700, loss: 10.173608779907227, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 800, loss: 9.277021408081055, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 900, loss: 8.592366218566895, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1000, loss: 9.685110092163086, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1100, loss: 9.537437438964844, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1200, loss: 10.027315139770508, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1300, loss: 8.801556587219238, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1400, loss: 8.512779235839844, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1500, loss: 8.975552558898926, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1600, loss: 8.583209991455078, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1700, loss: 12.034239768981934, rate: 1.757324933213498e-06\n",
      "Epoch: 49 Batch: 1800, loss: 10.535646438598633, rate: 1.757324933213498e-06\n",
      "[2023-11-17 20:32:21.295694] Epoch: 49 ends. Average loss: 9.362613208768648\n",
      "Epoch: 50 Batch: 0, loss: 10.106325149536133, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 100, loss: 9.97561264038086, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 200, loss: 9.376653671264648, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 300, loss: 6.653192520141602, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 400, loss: 8.20708179473877, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 500, loss: 10.51857852935791, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 600, loss: 8.06960391998291, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 800, loss: 9.362944602966309, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 900, loss: 8.537662506103516, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1000, loss: 9.62667179107666, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1100, loss: 9.840625762939453, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1200, loss: 10.09526252746582, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1300, loss: 8.898821830749512, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1400, loss: 8.41446590423584, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1500, loss: 9.1290283203125, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1600, loss: 8.891624450683594, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1700, loss: 12.202751159667969, rate: 1.687031935884958e-06\n",
      "Epoch: 50 Batch: 1800, loss: 11.078741073608398, rate: 1.687031935884958e-06\n",
      "[2023-11-17 20:38:35.499668] Epoch: 50 ends. Average loss: 9.370613036074168\n",
      "Epoch: 51 Batch: 0, loss: 9.728639602661133, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 100, loss: 9.52824878692627, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 200, loss: 9.565485000610352, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 300, loss: 6.927962779998779, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 400, loss: 7.727091312408447, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 500, loss: 10.543807983398438, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 600, loss: 8.092175483703613, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 700, loss: 10.194618225097656, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 800, loss: 9.236740112304688, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 900, loss: 8.90078353881836, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1000, loss: 9.836158752441406, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1100, loss: 9.360207557678223, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1200, loss: 10.12938117980957, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1300, loss: 8.98067569732666, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1400, loss: 8.40623950958252, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1500, loss: 9.402063369750977, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1600, loss: 8.551316261291504, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1700, loss: 11.818544387817383, rate: 1.6195506584495596e-06\n",
      "Epoch: 51 Batch: 1800, loss: 10.809517860412598, rate: 1.6195506584495596e-06\n",
      "[2023-11-17 20:44:50.388667] Epoch: 51 ends. Average loss: 9.34896115446643\n",
      "Epoch: 52 Batch: 0, loss: 9.290238380432129, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 100, loss: 9.842156410217285, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 200, loss: 9.908900260925293, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 300, loss: 6.942513465881348, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 400, loss: 8.094572067260742, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 500, loss: 10.393735885620117, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 600, loss: 7.9644060134887695, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 700, loss: 9.452954292297363, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 800, loss: 9.157875061035156, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 900, loss: 9.094890594482422, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1000, loss: 9.911456108093262, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1100, loss: 9.81397533416748, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1200, loss: 10.373353004455566, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1300, loss: 9.268912315368652, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1400, loss: 8.940689086914062, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1500, loss: 9.409741401672363, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1600, loss: 7.994541168212891, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1700, loss: 12.143180847167969, rate: 1.5547686321115772e-06\n",
      "Epoch: 52 Batch: 1800, loss: 10.896950721740723, rate: 1.5547686321115772e-06\n",
      "[2023-11-17 20:51:04.214419] Epoch: 52 ends. Average loss: 9.355291144596695\n",
      "Epoch: 53 Batch: 0, loss: 9.83577823638916, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 100, loss: 9.637621879577637, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 200, loss: 9.544005393981934, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 300, loss: 6.893630504608154, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 400, loss: 8.081161499023438, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 500, loss: 10.07439136505127, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 600, loss: 8.165610313415527, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 700, loss: 9.953736305236816, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 800, loss: 9.537508964538574, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 900, loss: 8.668259620666504, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 1000, loss: 9.78289794921875, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 1100, loss: 9.261761665344238, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 1200, loss: 10.536523818969727, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 1300, loss: 8.61383056640625, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 1400, loss: 8.047465324401855, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 1500, loss: 9.443138122558594, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 1600, loss: 8.838735580444336, rate: 1.492577886827114e-06\n",
      "Epoch: 53 Batch: 1800, loss: 10.420931816101074, rate: 1.492577886827114e-06\n",
      "[2023-11-17 20:57:17.633912] Epoch: 53 ends. Average loss: 9.341805517772121\n",
      "Epoch: 54 Batch: 0, loss: 9.55898666381836, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 100, loss: 9.603190422058105, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 200, loss: 9.473361015319824, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 300, loss: 7.157576084136963, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 400, loss: 8.06718921661377, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 500, loss: 10.255475044250488, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 600, loss: 8.138442993164062, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 700, loss: 9.788050651550293, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 800, loss: 9.455316543579102, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 900, loss: 8.662368774414062, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1000, loss: 9.880821228027344, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1100, loss: 9.060994148254395, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1200, loss: 10.263298034667969, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1300, loss: 8.884718894958496, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1400, loss: 8.471108436584473, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1500, loss: 9.379464149475098, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1600, loss: 8.63272476196289, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1700, loss: 11.808613777160645, rate: 1.4328747713540294e-06\n",
      "Epoch: 54 Batch: 1800, loss: 10.52191162109375, rate: 1.4328747713540294e-06\n",
      "[2023-11-17 21:03:30.000294] Epoch: 54 ends. Average loss: 9.341977663613523\n",
      "Epoch: 55 Batch: 0, loss: 9.804054260253906, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 100, loss: 9.673616409301758, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 200, loss: 9.503376960754395, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 300, loss: 6.981088638305664, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 400, loss: 8.472105979919434, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 500, loss: 10.286856651306152, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 600, loss: 8.054088592529297, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 700, loss: 9.877878189086914, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 800, loss: 9.664457321166992, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 900, loss: 8.571231842041016, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1000, loss: 9.568685531616211, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1100, loss: 9.299291610717773, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1200, loss: 9.89219856262207, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1300, loss: 9.201408386230469, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1400, loss: 8.173176765441895, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1500, loss: 9.559120178222656, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1600, loss: 8.28227424621582, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1700, loss: 12.205902099609375, rate: 1.3755597804998682e-06\n",
      "Epoch: 55 Batch: 1800, loss: 10.998912811279297, rate: 1.3755597804998682e-06\n",
      "[2023-11-17 21:09:43.056562] Epoch: 55 ends. Average loss: 9.338350707894191\n",
      "Epoch: 56 Batch: 0, loss: 9.523104667663574, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 100, loss: 9.629129409790039, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 200, loss: 9.365089416503906, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 300, loss: 6.982283115386963, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 400, loss: 8.059106826782227, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 500, loss: 10.587491035461426, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 600, loss: 8.063450813293457, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 700, loss: 9.637693405151367, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 800, loss: 9.710990905761719, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 900, loss: 9.03342056274414, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1000, loss: 9.796035766601562, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1100, loss: 9.418932914733887, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1200, loss: 10.251775741577148, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1300, loss: 8.906164169311523, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1400, loss: 8.664997100830078, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1500, loss: 9.211458206176758, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1600, loss: 8.93678092956543, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1700, loss: 11.806510925292969, rate: 1.3205373892798736e-06\n",
      "Epoch: 56 Batch: 1800, loss: 10.486956596374512, rate: 1.3205373892798736e-06\n",
      "[2023-11-17 21:15:55.312451] Epoch: 56 ends. Average loss: 9.345703235464207\n",
      "Epoch: 57 Batch: 0, loss: 9.468605995178223, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 100, loss: 9.610883712768555, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 200, loss: 9.377068519592285, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 400, loss: 7.7869181632995605, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 500, loss: 10.48139476776123, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 600, loss: 7.939877033233643, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 700, loss: 10.182384490966797, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 800, loss: 9.423479080200195, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 900, loss: 8.562324523925781, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1000, loss: 10.262056350708008, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1100, loss: 9.564181327819824, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1200, loss: 9.832206726074219, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1300, loss: 9.07855224609375, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1400, loss: 8.016069412231445, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1500, loss: 9.199591636657715, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1600, loss: 8.659276008605957, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1700, loss: 11.82497787475586, rate: 1.2677158937086785e-06\n",
      "Epoch: 57 Batch: 1800, loss: 10.463223457336426, rate: 1.2677158937086785e-06\n",
      "[2023-11-17 21:22:06.316435] Epoch: 57 ends. Average loss: 9.338499739100376\n",
      "Epoch: 58 Batch: 0, loss: 9.425766944885254, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 100, loss: 9.586584091186523, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 200, loss: 9.716728210449219, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 300, loss: 7.345551490783691, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 400, loss: 8.187996864318848, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 500, loss: 10.084074974060059, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 600, loss: 8.376762390136719, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 700, loss: 9.941917419433594, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 800, loss: 9.586261749267578, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 900, loss: 8.866742134094238, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1000, loss: 9.492125511169434, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1100, loss: 9.419769287109375, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1200, loss: 9.989224433898926, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1300, loss: 8.929319381713867, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1400, loss: 8.682482719421387, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1500, loss: 9.176178932189941, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1600, loss: 8.436824798583984, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1700, loss: 11.990423202514648, rate: 1.2170072579603314e-06\n",
      "Epoch: 58 Batch: 1800, loss: 10.945676803588867, rate: 1.2170072579603314e-06\n",
      "[2023-11-17 21:28:19.322528] Epoch: 58 ends. Average loss: 9.33366229556505\n",
      "Epoch: 59 Batch: 0, loss: 9.692811012268066, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 100, loss: 9.553561210632324, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 200, loss: 9.689745903015137, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 300, loss: 7.022642135620117, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 400, loss: 7.7596211433410645, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 500, loss: 10.234971046447754, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 600, loss: 8.26726245880127, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 700, loss: 9.853021621704102, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 800, loss: 9.450745582580566, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 900, loss: 8.513776779174805, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1000, loss: 9.619063377380371, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1100, loss: 9.570239067077637, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1200, loss: 9.48009967803955, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1300, loss: 8.731470108032227, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1400, loss: 8.139054298400879, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1500, loss: 9.312442779541016, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1600, loss: 8.281400680541992, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1700, loss: 11.292510032653809, rate: 1.168326967641918e-06\n",
      "Epoch: 59 Batch: 1800, loss: 10.941534042358398, rate: 1.168326967641918e-06\n",
      "[2023-11-17 21:34:29.947630] Epoch: 59 ends. Average loss: 9.33798749711194\n",
      "Epoch: 60 Batch: 0, loss: 9.769049644470215, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 100, loss: 9.674991607666016, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 200, loss: 9.3076810836792, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 300, loss: 6.690785884857178, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 400, loss: 8.20690631866455, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 500, loss: 10.499134063720703, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 600, loss: 8.309874534606934, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 700, loss: 9.500828742980957, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 800, loss: 9.36479663848877, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 900, loss: 8.759014129638672, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1000, loss: 9.794079780578613, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1100, loss: 9.718986511230469, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1200, loss: 10.211262702941895, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1300, loss: 8.74185848236084, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1400, loss: 8.153206825256348, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1500, loss: 9.336824417114258, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1600, loss: 8.662337303161621, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1700, loss: 12.010712623596191, rate: 1.1215938889362412e-06\n",
      "Epoch: 60 Batch: 1800, loss: 11.207767486572266, rate: 1.1215938889362412e-06\n",
      "[2023-11-17 21:40:46.585959] Epoch: 60 ends. Average loss: 9.327034350330502\n",
      "Epoch: 61 Batch: 0, loss: 9.898587226867676, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 100, loss: 9.195178985595703, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 200, loss: 9.596765518188477, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 300, loss: 6.989176273345947, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 400, loss: 8.224879264831543, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 500, loss: 9.932721138000488, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 600, loss: 7.915239334106445, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 700, loss: 10.246047019958496, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 800, loss: 9.506270408630371, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 900, loss: 8.863513946533203, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1000, loss: 9.551648139953613, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1100, loss: 9.33706283569336, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1200, loss: 9.994174003601074, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1300, loss: 8.689857482910156, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1400, loss: 8.33680248260498, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1500, loss: 8.983394622802734, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1600, loss: 8.268507957458496, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1700, loss: 12.442927360534668, rate: 1.0767301333787916e-06\n",
      "Epoch: 61 Batch: 1800, loss: 10.651374816894531, rate: 1.0767301333787916e-06\n",
      "[2023-11-17 21:47:02.261437] Epoch: 61 ends. Average loss: 9.329631647350903\n",
      "Epoch: 62 Batch: 0, loss: 9.371403694152832, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 100, loss: 9.355839729309082, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 200, loss: 9.437711715698242, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 300, loss: 6.921534538269043, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 400, loss: 7.645428657531738, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 500, loss: 10.329959869384766, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 600, loss: 7.978625297546387, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 700, loss: 10.701820373535156, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 800, loss: 9.702779769897461, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 900, loss: 8.51093578338623, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1000, loss: 9.706547737121582, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1100, loss: 9.347477912902832, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1200, loss: 9.824286460876465, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1300, loss: 8.886435508728027, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1400, loss: 8.613221168518066, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1500, loss: 9.144231796264648, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1600, loss: 8.357641220092773, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1700, loss: 12.161663055419922, rate: 1.0336609280436399e-06\n",
      "Epoch: 62 Batch: 1800, loss: 10.674711227416992, rate: 1.0336609280436399e-06\n",
      "[2023-11-17 21:53:14.461791] Epoch: 62 ends. Average loss: 9.333613832024534\n",
      "Epoch: 63 Batch: 0, loss: 9.562274932861328, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 100, loss: 9.350828170776367, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 200, loss: 9.823407173156738, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 300, loss: 6.558075428009033, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 400, loss: 8.063766479492188, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 500, loss: 10.44845962524414, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 600, loss: 7.919525146484375, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 700, loss: 10.031176567077637, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 800, loss: 9.284869194030762, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 900, loss: 8.496960639953613, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1000, loss: 9.886624336242676, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1100, loss: 9.596832275390625, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1200, loss: 10.045294761657715, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1300, loss: 8.862737655639648, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1400, loss: 8.438005447387695, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1500, loss: 9.071756362915039, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1600, loss: 8.401457786560059, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1700, loss: 11.346961975097656, rate: 9.923144909218942e-07\n",
      "Epoch: 63 Batch: 1800, loss: 11.260876655578613, rate: 9.923144909218942e-07\n",
      "[2023-11-17 21:59:25.878779] Epoch: 63 ends. Average loss: 9.32512633023312\n",
      "Epoch: 64 Batch: 0, loss: 9.60757827758789, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 100, loss: 9.393933296203613, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 200, loss: 9.519552230834961, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 300, loss: 6.957149028778076, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 400, loss: 8.059102058410645, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 500, loss: 10.120539665222168, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 600, loss: 8.276918411254883, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 700, loss: 10.287979125976562, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 800, loss: 9.324749946594238, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 900, loss: 8.761502265930176, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1000, loss: 9.571910858154297, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1100, loss: 9.441400527954102, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1200, loss: 10.010610580444336, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1300, loss: 8.808650016784668, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1400, loss: 8.694602966308594, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1500, loss: 9.055975914001465, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1600, loss: 8.197667121887207, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1700, loss: 12.01534652709961, rate: 9.526219112850184e-07\n",
      "Epoch: 64 Batch: 1800, loss: 10.841167449951172, rate: 9.526219112850184e-07\n",
      "[2023-11-17 22:05:37.140986] Epoch: 64 ends. Average loss: 9.324904771648056\n",
      "Epoch: 65 Batch: 0, loss: 9.41506290435791, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 100, loss: 9.497716903686523, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 200, loss: 9.279303550720215, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 300, loss: 7.372372150421143, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 400, loss: 7.999810695648193, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 500, loss: 10.264852523803711, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 600, loss: 8.20756721496582, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 700, loss: 10.140270233154297, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 800, loss: 9.376032829284668, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 900, loss: 8.303401947021484, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1000, loss: 9.690686225891113, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1100, loss: 9.266277313232422, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1200, loss: 10.120006561279297, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1300, loss: 9.040401458740234, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1400, loss: 8.4274263381958, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1500, loss: 9.592044830322266, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1600, loss: 8.35313892364502, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1700, loss: 11.812263488769531, rate: 9.145170348336176e-07\n",
      "Epoch: 65 Batch: 1800, loss: 10.688915252685547, rate: 9.145170348336176e-07\n",
      "[2023-11-17 22:11:47.535182] Epoch: 65 ends. Average loss: 9.321787447805768\n",
      "Epoch: 66 Batch: 0, loss: 9.838032722473145, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 100, loss: 9.894362449645996, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 200, loss: 9.596659660339355, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 300, loss: 7.082982063293457, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 400, loss: 8.233613014221191, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 500, loss: 10.367919921875, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 600, loss: 8.10256576538086, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 700, loss: 9.60636043548584, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 800, loss: 9.1220121383667, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 900, loss: 8.837815284729004, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1000, loss: 9.79810619354248, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1100, loss: 9.64870834350586, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1200, loss: 10.041173934936523, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1300, loss: 8.784645080566406, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1400, loss: 8.344637870788574, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1500, loss: 9.215299606323242, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1600, loss: 8.319534301757812, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1700, loss: 11.89862060546875, rate: 8.779363534402728e-07\n",
      "Epoch: 66 Batch: 1800, loss: 10.6416015625, rate: 8.779363534402728e-07\n",
      "[2023-11-17 22:17:58.925789] Epoch: 66 ends. Average loss: 9.324539847618562\n",
      "Epoch: 67 Batch: 0, loss: 9.658851623535156, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 100, loss: 9.721636772155762, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 200, loss: 9.309831619262695, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 300, loss: 6.824659824371338, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 400, loss: 8.235477447509766, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 500, loss: 10.06747817993164, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 600, loss: 8.168795585632324, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 700, loss: 10.050342559814453, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 800, loss: 9.273282051086426, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 900, loss: 8.51860237121582, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1000, loss: 9.519618034362793, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1100, loss: 9.692097663879395, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1200, loss: 10.083284378051758, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1300, loss: 8.755491256713867, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1400, loss: 8.614852905273438, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1500, loss: 9.155523300170898, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1600, loss: 8.297720909118652, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1700, loss: 12.203771591186523, rate: 8.428188993026619e-07\n",
      "Epoch: 67 Batch: 1800, loss: 11.276710510253906, rate: 8.428188993026619e-07\n",
      "[2023-11-17 22:24:10.771842] Epoch: 67 ends. Average loss: 9.307007908492343\n",
      "Epoch: 68 Batch: 0, loss: 9.435083389282227, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 100, loss: 10.020881652832031, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 300, loss: 7.174858093261719, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 400, loss: 7.66772985458374, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 500, loss: 9.93904972076416, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 600, loss: 8.043758392333984, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 700, loss: 10.177196502685547, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 800, loss: 9.11561107635498, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 900, loss: 8.861870765686035, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1000, loss: 9.563321113586426, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1100, loss: 9.50781536102295, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1200, loss: 9.956808090209961, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1300, loss: 8.624116897583008, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1400, loss: 8.506885528564453, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1500, loss: 9.59065055847168, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1600, loss: 8.695168495178223, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1700, loss: 11.980199813842773, rate: 8.091061433305554e-07\n",
      "Epoch: 68 Batch: 1800, loss: 11.163969993591309, rate: 8.091061433305554e-07\n",
      "[2023-11-17 22:30:21.655188] Epoch: 68 ends. Average loss: 9.306838986890723\n",
      "Epoch: 69 Batch: 0, loss: 9.55628776550293, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 100, loss: 9.303492546081543, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 200, loss: 9.50833511352539, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 300, loss: 6.613473415374756, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 400, loss: 7.930635452270508, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 500, loss: 10.338808059692383, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 600, loss: 8.609728813171387, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 700, loss: 10.277896881103516, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 800, loss: 9.159675598144531, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 900, loss: 8.77791976928711, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1000, loss: 10.081535339355469, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1100, loss: 9.961668014526367, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1200, loss: 10.01733684539795, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1300, loss: 8.938810348510742, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1400, loss: 8.24679946899414, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1500, loss: 8.73219108581543, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1600, loss: 8.47338581085205, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1700, loss: 12.13103199005127, rate: 7.767418975973332e-07\n",
      "Epoch: 69 Batch: 1800, loss: 10.662108421325684, rate: 7.767418975973332e-07\n",
      "[2023-11-17 22:36:36.115896] Epoch: 69 ends. Average loss: 9.312128952045304\n",
      "Epoch: 70 Batch: 0, loss: 9.409004211425781, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 100, loss: 9.425651550292969, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 200, loss: 9.350443840026855, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 300, loss: 6.808567523956299, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 400, loss: 7.988395690917969, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 500, loss: 10.254999160766602, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 600, loss: 8.226715087890625, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 700, loss: 9.679938316345215, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 800, loss: 9.479185104370117, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 900, loss: 9.078390121459961, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1000, loss: 9.6626558303833, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1100, loss: 10.379719734191895, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1200, loss: 10.292749404907227, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1300, loss: 9.220903396606445, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1400, loss: 8.553192138671875, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1500, loss: 9.477001190185547, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1600, loss: 8.190343856811523, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1700, loss: 11.851024627685547, rate: 7.456722216934399e-07\n",
      "Epoch: 70 Batch: 1800, loss: 10.664982795715332, rate: 7.456722216934399e-07\n",
      "[2023-11-17 22:42:48.500738] Epoch: 70 ends. Average loss: 9.308800910627783\n",
      "Epoch: 71 Batch: 0, loss: 9.573701858520508, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 100, loss: 9.875020027160645, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 200, loss: 9.8843994140625, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 300, loss: 7.066091537475586, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 400, loss: 7.749951362609863, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 500, loss: 10.2147216796875, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 600, loss: 8.001792907714844, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 700, loss: 9.801090240478516, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 800, loss: 9.831031799316406, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 900, loss: 8.805988311767578, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1000, loss: 9.715983390808105, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1100, loss: 9.276684761047363, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1200, loss: 9.820460319519043, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1300, loss: 8.63099479675293, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1400, loss: 8.358663558959961, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1500, loss: 9.599374771118164, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1600, loss: 8.335893630981445, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1700, loss: 11.838249206542969, rate: 7.158453328257022e-07\n",
      "Epoch: 71 Batch: 1800, loss: 10.841164588928223, rate: 7.158453328257022e-07\n",
      "[2023-11-17 22:49:01.218373] Epoch: 71 ends. Average loss: 9.314642592418016\n",
      "Epoch: 72 Batch: 0, loss: 9.729828834533691, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 100, loss: 9.936887741088867, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 200, loss: 9.948578834533691, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 300, loss: 6.875152587890625, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 400, loss: 8.084972381591797, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 500, loss: 10.057655334472656, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 600, loss: 7.832169532775879, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 700, loss: 9.916029930114746, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 800, loss: 9.263489723205566, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 900, loss: 8.658934593200684, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1000, loss: 9.830759048461914, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1100, loss: 9.563756942749023, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1200, loss: 10.126982688903809, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1300, loss: 9.07586669921875, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1400, loss: 7.96534538269043, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1500, loss: 8.94346809387207, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1600, loss: 8.233133316040039, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1700, loss: 12.366257667541504, rate: 6.872115195126741e-07\n",
      "Epoch: 72 Batch: 1800, loss: 10.326828956604004, rate: 6.872115195126741e-07\n",
      "[2023-11-17 22:55:14.432528] Epoch: 72 ends. Average loss: 9.3142221617028\n",
      "Epoch: 73 Batch: 0, loss: 9.920156478881836, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 100, loss: 10.029932022094727, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 200, loss: 9.47299575805664, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 300, loss: 7.128591537475586, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 400, loss: 8.030122756958008, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 600, loss: 7.9092864990234375, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 700, loss: 10.108036041259766, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 800, loss: 9.044044494628906, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 900, loss: 9.114770889282227, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1000, loss: 9.785902976989746, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1100, loss: 9.199140548706055, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1200, loss: 10.103606224060059, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1300, loss: 8.383502960205078, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1400, loss: 8.225309371948242, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1500, loss: 9.214082717895508, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1600, loss: 8.32243537902832, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1700, loss: 12.022953033447266, rate: 6.597230587321671e-07\n",
      "Epoch: 73 Batch: 1800, loss: 10.431157112121582, rate: 6.597230587321671e-07\n",
      "[2023-11-17 23:01:24.783899] Epoch: 73 ends. Average loss: 9.300108464330977\n",
      "Epoch: 74 Batch: 0, loss: 9.673260688781738, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 100, loss: 9.444198608398438, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 200, loss: 9.303789138793945, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 300, loss: 6.840465545654297, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 400, loss: 7.821719646453857, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 500, loss: 10.206202507019043, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 600, loss: 8.165821075439453, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 700, loss: 10.378941535949707, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 800, loss: 9.4660062789917, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 900, loss: 8.72193431854248, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1000, loss: 9.823750495910645, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1100, loss: 9.731446266174316, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1200, loss: 10.162920951843262, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1300, loss: 9.013615608215332, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1400, loss: 8.307089805603027, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1500, loss: 9.699871063232422, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1600, loss: 8.164405822753906, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1700, loss: 11.95124626159668, rate: 6.333341363828804e-07\n",
      "Epoch: 74 Batch: 1800, loss: 10.738033294677734, rate: 6.333341363828804e-07\n",
      "[2023-11-17 23:07:39.763935] Epoch: 74 ends. Average loss: 9.298402333877656\n",
      "Epoch: 75 Batch: 0, loss: 9.761313438415527, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 100, loss: 9.807153701782227, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 200, loss: 8.986871719360352, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 300, loss: 6.840970993041992, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 400, loss: 8.02474594116211, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 500, loss: 10.436922073364258, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 600, loss: 8.248337745666504, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 700, loss: 9.970842361450195, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 800, loss: 9.596942901611328, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 900, loss: 8.70937442779541, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1000, loss: 9.49130916595459, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1100, loss: 9.371177673339844, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1200, loss: 9.947778701782227, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1300, loss: 8.843057632446289, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1400, loss: 8.437613487243652, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1500, loss: 8.912775039672852, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1600, loss: 8.531904220581055, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1700, loss: 12.069049835205078, rate: 6.080007709275651e-07\n",
      "Epoch: 75 Batch: 1800, loss: 10.33018684387207, rate: 6.080007709275651e-07\n",
      "[2023-11-17 23:13:53.464099] Epoch: 75 ends. Average loss: 9.309358658083092\n",
      "Epoch: 76 Batch: 0, loss: 9.348337173461914, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 100, loss: 9.75654411315918, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 200, loss: 9.49600887298584, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 300, loss: 6.785848140716553, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 400, loss: 7.931999683380127, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 500, loss: 10.319469451904297, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 600, loss: 8.083948135375977, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 700, loss: 9.542434692382812, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 800, loss: 9.625615119934082, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1000, loss: 9.183265686035156, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1100, loss: 9.076021194458008, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1200, loss: 9.959343910217285, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1300, loss: 9.023283004760742, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1400, loss: 8.465991973876953, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1500, loss: 8.917210578918457, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1600, loss: 8.669210433959961, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1700, loss: 11.69711685180664, rate: 5.836807400904625e-07\n",
      "Epoch: 76 Batch: 1800, loss: 10.804424285888672, rate: 5.836807400904625e-07\n",
      "[2023-11-17 23:20:05.626051] Epoch: 76 ends. Average loss: 9.29906738810426\n",
      "Epoch: 77 Batch: 0, loss: 9.797245979309082, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 100, loss: 9.50053882598877, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 200, loss: 9.640365600585938, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 300, loss: 6.9443159103393555, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 400, loss: 7.893585205078125, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 500, loss: 10.126276016235352, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 600, loss: 7.715732574462891, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 700, loss: 9.881020545959473, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 800, loss: 9.413485527038574, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 900, loss: 8.403060913085938, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1000, loss: 9.60055923461914, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1100, loss: 9.489551544189453, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1200, loss: 10.400506019592285, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1300, loss: 8.669376373291016, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1400, loss: 8.337821960449219, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1500, loss: 9.266925811767578, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1600, loss: 8.614209175109863, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1700, loss: 11.683932304382324, rate: 5.60333510486844e-07\n",
      "Epoch: 77 Batch: 1800, loss: 10.347436904907227, rate: 5.60333510486844e-07\n",
      "[2023-11-17 23:26:11.939953] Epoch: 77 ends. Average loss: 9.302655730008158\n",
      "Epoch: 78 Batch: 0, loss: 9.95773696899414, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 100, loss: 9.26799201965332, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 200, loss: 9.680310249328613, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 300, loss: 6.656949520111084, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 400, loss: 8.03571891784668, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 500, loss: 10.132314682006836, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 600, loss: 7.895751953125, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 700, loss: 10.309266090393066, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 800, loss: 9.06314754486084, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 900, loss: 8.679808616638184, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1000, loss: 9.56269359588623, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1100, loss: 9.634440422058105, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1200, loss: 9.686993598937988, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1300, loss: 8.714568138122559, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1400, loss: 8.924543380737305, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1500, loss: 8.764344215393066, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1600, loss: 8.43135929107666, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1700, loss: 11.825518608093262, rate: 5.379201700673702e-07\n",
      "Epoch: 78 Batch: 1800, loss: 11.452072143554688, rate: 5.379201700673702e-07\n",
      "[2023-11-17 23:32:15.212526] Epoch: 78 ends. Average loss: 9.30739807227798\n",
      "Epoch: 79 Batch: 0, loss: 9.484635353088379, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 100, loss: 9.985954284667969, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 200, loss: 9.562021255493164, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 300, loss: 7.001166343688965, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 400, loss: 7.722310543060303, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 500, loss: 10.098628044128418, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 600, loss: 7.736876487731934, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 700, loss: 9.876381874084473, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 800, loss: 9.174989700317383, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 900, loss: 8.80283260345459, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1000, loss: 9.708144187927246, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1100, loss: 9.688638687133789, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1200, loss: 10.200725555419922, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1300, loss: 9.242459297180176, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1400, loss: 8.47184944152832, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1500, loss: 9.363743782043457, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1600, loss: 8.77086067199707, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1700, loss: 11.85720443725586, rate: 5.164033632646754e-07\n",
      "Epoch: 79 Batch: 1800, loss: 10.890342712402344, rate: 5.164033632646754e-07\n",
      "[2023-11-17 23:38:20.721685] Epoch: 79 ends. Average loss: 9.297430514237266\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "for e in range(80):\n",
    "    losss_per_e = []\n",
    "    for i, batch in enumerate(dataloader_train):\n",
    "        loss_current = train_a_batch(batch, head, optimizer, None)\n",
    "        losss_per_e.append(loss_current)\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} Batch: {}, loss: {}, rate: {}'.format(e, i, loss_current, optimizer.param_groups[0]['lr']))\n",
    "            # break\n",
    "        # end\n",
    "    # end\n",
    "    \n",
    "    loss_average_per_e = sum(losss_per_e) / len(losss_per_e)\n",
    "    print('[{}] Epoch: {} ends. Average loss: {}'.format(datetime.utcnow(), e, loss_average_per_e))\n",
    "    \n",
    "    lr_scheduler.step() # schedule per epoch\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eec954-3671-422e-82d2-5dad9edcb702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "head.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df05c45-ed31-4d3f-ab04-ed182c182027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_generate(head, tokenizer, collator, **kwargs):\n",
    "    id_start = tokenizer.id_cls\n",
    "    id_end = tokenizer.id_sep\n",
    "    size_seq_max = collator.size_seq_max\n",
    "\n",
    "    ids_encoder = kwargs['ids_encoder']\n",
    "    masks_encoder = kwargs['masks_encoder']\n",
    "\n",
    "    outputs_encoder = head.model.embed_and_encode(ids_encoder=ids_encoder, masks_encoder=masks_encoder)\n",
    "    ids_decoder = torch.zeros(1, 1).fill_(id_start).type_as(ids_encoder.data)\n",
    "\n",
    "    for i in range(size_seq_max - 1):\n",
    "        masks_decoder = collator.subsequent_mask(ids_decoder.size(1)).type_as(ids_encoder.data)\n",
    "        outputs_decoder = head.model.embed_and_decode(ids_decoder=ids_decoder, masks_encoder=masks_encoder, output_encoder=outputs_encoder, masks_decoder=masks_decoder)\n",
    "        outputs_ffn = head.ffn(outputs_decoder)\n",
    "        outputs_s2s = head.extractor(outputs_ffn)   # outputs_mlm = prediction_logits\n",
    "\n",
    "        logits_nextword = torch.softmax(outputs_s2s[:, -1], dim=-1)  # mynote: select dim2=-1, remain=all; last is the next\n",
    "        \n",
    "        id_nextword = torch.argmax(logits_nextword, dim=-1)\n",
    "        id_nextword = id_nextword.data[0]\n",
    "\n",
    "        if id_nextword == id_end:\n",
    "            break\n",
    "        # end\n",
    "\n",
    "        ids_decoder = torch.cat([ids_decoder, torch.zeros(1, 1).type_as(ids_encoder.data).fill_(id_nextword)], dim=1)\n",
    "    # end\n",
    "\n",
    "    return ids_decoder\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8928d0f4-eefa-4796-a421-066a330b7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: A group of men are loading cotton onto a truck [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A group of large group of people are hanging out .\n",
      "\n",
      "\n",
      "source: A man sleeping in a green room on a couch . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A green sleeping in a green room in a green room .\n",
      "\n",
      "\n",
      "source: A boy wearing headphones sits on a woman 's shoulders . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A woman sits wearing a sits on a couch as woman .\n",
      "\n",
      "\n",
      "source: Two men setting up a blue ice fishing hut on an iced over lake [SEP] [PAD]\n",
      "target: [CLS] Two men fishing fishing off a fishing net at a river with a fishing\n",
      "\n",
      "\n",
      "source: A balding man wearing a red life jacket is sitting in a small boat [SEP] [PAD]\n",
      "target: [CLS] A small child in red and yellow is sitting on a large boat is\n",
      "\n",
      "\n",
      "source: A lady in a red coat , holding a <unk> hand bag likely of [SEP] [PAD]\n",
      "target: [CLS] A lady in a red shirt and red hat is looking up a hand\n",
      "\n",
      "\n",
      "source: A brown dog is running after the black dog . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] The brown dog is chasing after brown dog black dog .\n",
      "\n",
      "\n",
      "source: A young boy wearing a <unk> jersey swings a baseball bat at an incoming [SEP] [PAD]\n",
      "target: [CLS] A young boy wearing a baseball baseball baseball baseball baseball baseball baseball player wearing\n",
      "\n",
      "\n",
      "source: A man in a cluttered office is using the telephone [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A man in a red hat is riding a bicycle .\n",
      "\n",
      "\n",
      "source: A smiling woman in a peach tank top stands holding a mountain bike [SEP] [PAD] [PAD]\n",
      "target: [CLS] A smiling woman in a high tank top of a high tank top holding\n",
      "\n",
      "\n",
      "source: A young child is standing alone on some jagged rocks . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A young child is rock climbing some rocks in some rocks .\n",
      "\n",
      "\n",
      "source: A person on a snowmobile in mid jump . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A person on a jump jump jump .\n",
      "\n",
      "\n",
      "source: Three young children stand around a blue and white barrel . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] Three young girls are sitting on a white grassy <unk> colored colored .\n",
      "\n",
      "\n",
      "source: A woman is sitting by her dried flower display at an outside market . [SEP] [PAD]\n",
      "target: [CLS] A woman is shopping at her shopping store display window display at a store\n",
      "\n",
      "\n",
      "source: A female playing a song on her violin . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A young female playing a <unk> stage .\n",
      "\n",
      "\n",
      "source: Three people on two dirt - bikes and one four - wheeler are riding [SEP] [PAD]\n",
      "target: [CLS] Three people on a dirt road and two riding bicycles , one two on\n",
      "\n",
      "\n",
      "source: A half naked man is sleeping on his chair outdoors . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A man in his hat is sitting on a chair outdoors .\n",
      "\n",
      "\n",
      "source: A group of people standing in front of a hut in a parking lot [SEP] [PAD]\n",
      "target: [CLS] A group of people standing in a parking lot in a parking lot in\n",
      "\n",
      "\n",
      "source: A young woman is making rugs in the rain forest [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A young young woman is <unk> through a crowded park .\n",
      "\n",
      "\n",
      "source: Three girls make faces as one takes a drink while they stand in a [SEP] [PAD]\n",
      "target: [CLS] Two girls drink as they stand while they look as they look as they\n",
      "\n",
      "\n",
      "source: A single man in a black t - shirt standing above the crowd at [SEP] [PAD]\n",
      "target: [CLS] A guy in a white shirt and a man in the middle of a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_source = to_map_style_dataset(valid_iter)\n",
    "dataloader_eval = DataLoader(eval_source, 1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "for i, batch in enumerate(dataloader_eval):\n",
    "    info_batch = batch()\n",
    "    result = greedy_generate(head, tokenizer, collator, **info_batch)\n",
    "    sentence_predicted = tokenizer.decode(result.cpu().tolist()[0])\n",
    "    sentence_origin = tokenizer.decode(info_batch['labels_decoder'].cpu().tolist()[0])\n",
    "    print('source: {}\\ntarget: {}\\n\\n'.format(sentence_origin, sentence_predicted))\n",
    "    if i >= 20:\n",
    "        break\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df3a99-6f6a-4fee-8e7a-c9ffc168e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_source = to_map_style_dataset(valid_iter)\n",
    "# dataloader_eval = DataLoader(eval_source, 1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "# for i, batch in enumerate(dataloader_eval):\n",
    "#     info_batch = batch()\n",
    "#     output_s2s, loss_s2s = head.forward(**info_batch)\n",
    "#     preds_s2s = torch.argmax(output_s2s,dim=-1)\n",
    "    \n",
    "#     sentence_predicted = tokenizer.decode(preds_s2s.cpu().tolist()[0])\n",
    "#     sentence_origin = tokenizer.decode(info_batch['labels_decoder'].cpu().tolist()[0])\n",
    "#     print('source: {}\\ntarget: {}\\n\\n'.format(sentence_origin, sentence_predicted))\n",
    "#     if i >= 0:\n",
    "#         break\n",
    "#     # end\n",
    "# # end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc3bec-6f6c-4dfc-bb43-78bf90d4ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_encoder = info_batch['ids_encoder']\n",
    "# masks_encoder = info_batch['masks_encoder']\n",
    "\n",
    "# outputs_encoder = head.model.embed_and_encode(ids_encoder=ids_encoder, masks_encoder=masks_encoder)\n",
    "# ids_decoder = torch.zeros(1, 1).fill_(tokenizer.id_cls).type_as(ids_encoder.data)\n",
    "# masks_decoder = collator.subsequent_mask(ids_decoder.size(1)).type_as(ids_encoder.data)\n",
    "\n",
    "# outputs_decoder = head.model.embed_and_decode(ids_decoder=ids_decoder, masks_encoder=masks_encoder, output_encoder=outputs_encoder, masks_decoder=masks_decoder)\n",
    "# outputs_ffn = head.ffn(outputs_decoder)\n",
    "# outputs_s2s = head.extractor(head.ffn(outputs_ffn))   # outputs_mlm = prediction_logits\n",
    "# preds_s2s = torch.argmax(output_s2s,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca7e1e-a7f5-467d-8014-39caad933ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_predicted = tokenizer.decode(preds_s2s.cpu().tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7ff89-5636-47f8-9a06-85654a1e2da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
