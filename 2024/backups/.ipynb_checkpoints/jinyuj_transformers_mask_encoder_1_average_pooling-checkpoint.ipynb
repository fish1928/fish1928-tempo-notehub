{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a36c05-aa20-4909-a5e9-a172529e22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from os.path import exists\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad, one_hot\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "### utils.py ###\n",
    "\n",
    "class Dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "# end\n",
    "\n",
    "### utils.py ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### core.py ###\n",
    "\n",
    "\"Produce N identical layers.\"\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "\n",
    "    \"Take in model size and number of heads.\"\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    # end\n",
    "\n",
    "\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    def attention(self, query, key, value, mask=None, dropout=None):\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            # print('jinyuj: scores: {}, mask: {}'.format(scores.shape, mask.shape))\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        # end\n",
    "        p_attn = scores.softmax(dim=-1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        # end\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "    # end\n",
    "\n",
    "\n",
    "    \"Implements Figure 2\"\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = self.attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (\n",
    "            x.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)\n",
    "    # end\n",
    "# end class\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A residual connection followed by a layer norm.\n",
    "Note for code simplicity the norm is first as opposed to last.\n",
    "\"\"\"\n",
    "class ResidualLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, size, dropout=0.1, eps=1e-6):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.norm = torch.nn.LayerNorm(size, eps)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    # end\n",
    "\n",
    "    \"Apply residual connection to any sublayer with the same size.\"\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    # end\n",
    "# end class\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleIDEmbeddings(nn.Module):\n",
    "    def __init__(self, size_vocab, dim_hidden, id_pad):\n",
    "        super(SimpleIDEmbeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(size_vocab, dim_hidden, padding_idx=id_pad)\n",
    "        self.dim_hidden = dim_hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.lut(x)\n",
    "        return result * math.sqrt(self.dim_hidden)\n",
    "    # end\n",
    "\n",
    "    def get_shape(self):\n",
    "        return (self.lut.num_embeddings, self.lut.embedding_dim)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\"Implement the PE function.\"\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_positional, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.dim_positional = dim_positional\n",
    "        pe = torch.zeros(max_len, dim_positional)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, dim_positional, 2) * -(math.log(10000.0) / dim_positional)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).to('cuda')\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return x\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleEmbedder(nn.Module):    # no segment embedder as we do not need that\n",
    "    def __init__(self, size_vocab=None, dim_hidden=128, dropout=0.1, id_pad=0):\n",
    "        super(SimpleEmbedder, self).__init__()\n",
    "        self.size_vocab = size_vocab\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.id_pad = id_pad\n",
    "\n",
    "        self.embedder = nn.Sequential(\n",
    "            SimpleIDEmbeddings(size_vocab, dim_hidden, id_pad),\n",
    "            PositionalEncoding(dim_hidden),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    def forward(self, ids_input):   # (batch, seqs_with_padding)\n",
    "        return self.embedder(ids_input)\n",
    "    # end\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.size_vocab\n",
    "    # end\n",
    "# end\n",
    "\n",
    "### core.py ###\n",
    "\n",
    "\n",
    "\n",
    "class SimpleEncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, dim_feedforward, n_head, dropout=0.1):\n",
    "        super(SimpleEncoderLayer, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.layer_attention = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_feedforward = PositionwiseFeedForward(dim_hidden, dim_feedforward, dropout)\n",
    "        self.layers_residual = clones(ResidualLayer(dim_hidden, dropout), 2)\n",
    "    # end\n",
    "\n",
    "    def forward(self, embeddings, masks, *args):\n",
    "        embeddings = self.layers_residual[0](embeddings, lambda embeddings: self.layer_attention(embeddings, embeddings, embeddings, masks))\n",
    "        return self.layers_residual[1](embeddings, self.layer_feedforward)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class SimpleDecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, dim_feedforward, n_head, dropout=0.1):\n",
    "        super(SimpleDecoderLayer, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.layer_attention_decoder = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_attention_encoder = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_feedforward = PositionwiseFeedForward(dim_hidden, dim_feedforward, dropout)\n",
    "        self.layers_residual = clones(ResidualLayer(dim_hidden, dropout), 3)\n",
    "\n",
    "    def forward(self, embeddings, masks_encoder, output_encoder, masks_decoder, *args):\n",
    "        embeddings = self.layers_residual[0](embeddings, lambda embeddings: self.layer_attention_decoder(embeddings, embeddings, embeddings, masks_decoder))\n",
    "        # print('jinyuj: embeddings.shape {}, masks_encoder.shape {}'.format(embeddings.shape, masks_encoder.shape))\n",
    "        # if embeddings.shape[1] != masks_encoder.shape[1]:\n",
    "        #     masks_encoder = masks_encoder[:,:embeddings.shape[1],:]\n",
    "        # # end\n",
    "        embeddings = self.layers_residual[1](embeddings, lambda embeddings: self.layer_attention_encoder(embeddings, output_encoder, output_encoder, masks_encoder))\n",
    "        return self.layers_residual[2](embeddings, self.layer_feedforward)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleTransformerStack(nn.Module):\n",
    "\n",
    "    def __init__(self, obj_layer, n_layers):\n",
    "        super(SimpleTransformerStack, self).__init__()\n",
    "        self.layers = clones(obj_layer, n_layers)\n",
    "\n",
    "        self.norm = torch.nn.LayerNorm(obj_layer.dim_hidden)\n",
    "        self.keys_cache = ['output']\n",
    "        self.cache = Dotdict({\n",
    "            'outputs': None\n",
    "        })\n",
    "    # end\n",
    "\n",
    "    def forward(self, embedding_encoder=None, masks_encoder=None, output_encoder=None, embedding_decoder=None, masks_decoder=None ,noncache=False, **kwargs):  # input -> (batch, len_seq, vocab)\n",
    "\n",
    "        if output_encoder is not None and embedding_decoder is not None and masks_decoder is not None:\n",
    "            embeddings = embedding_decoder\n",
    "        else:\n",
    "            embeddings = embedding_encoder\n",
    "        # end\n",
    "\n",
    "        for layer in self.layers:\n",
    "            embeddings = layer(embeddings, masks_encoder, output_encoder, masks_decoder)\n",
    "        # end\n",
    "\n",
    "        outputs = self.norm(embeddings)\n",
    "\n",
    "        if not noncache:\n",
    "            self.cache.outputs = outputs\n",
    "        # end\n",
    "\n",
    "        return outputs\n",
    "    # end\n",
    "\n",
    "    # def get_vocab_size(self):\n",
    "    #     return self.embedder.embedder_token.shape[-1]\n",
    "    # # end\n",
    "\n",
    "    def clear_cache(self):\n",
    "        for key_cache in self.keys_cache:\n",
    "            self.cache[key_cache] = None\n",
    "        # end\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleEncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embedder_encoder, embedder_decoder):\n",
    "        super(SimpleEncoderDecoder, self).__init__()\n",
    "\n",
    "        self.embedder_encoder = embedder_encoder\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.embedder_decoder = embedder_decoder\n",
    "        self.decoder = decoder\n",
    "    # end\n",
    "\n",
    "    def forward(self, ids_encoder=None, masks_encoder=None, ids_decoder=None, masks_decoder=None, nocache=False, **kwargs):\n",
    "        \n",
    "        output_encoder = self.embed_and_encode(ids_encoder=ids_encoder, masks_encoder=masks_encoder, nocache=nocache)\n",
    "        output_encoder_refilled = output_encoder.masked_fill(masks_encoder.transpose(-1,-2)==False, 0)\n",
    "        output_encoder_pooled = torch.mean(output_encoder_refilled, dim=-2)\n",
    "        output_encoder_pooled_expanded = output_encoder_pooled.unsqueeze(-2).expand(output_encoder.shape)\n",
    "        output = output_encoder_pooled_expanded\n",
    "        \n",
    "        if self.embedder_decoder and self.decoder:\n",
    "            output_decoder = self.embed_and_decode(ids_decoder=ids_decoder, masks_encoder=masks_encoder, output_encoder=output_encoder, masks_decoder=masks_decoder, nocache=nocache)\n",
    "            output = output_decoder\n",
    "        # end if\n",
    "        \n",
    "        return output\n",
    "    # end\n",
    "    \n",
    "    def embed_and_encode(self, ids_encoder=None, masks_encoder=None, nocache=False, **kwargs):\n",
    "        self.encoder.clear_cache()\n",
    "        \n",
    "        embedding_encoder = self.embedder_encoder(ids_encoder)\n",
    "        output_encoder = self.encoder(\n",
    "            embedding_encoder=embedding_encoder,\n",
    "            masks_encoder=masks_encoder,\n",
    "            nocache=nocache\n",
    "        )\n",
    "        \n",
    "        return output_encoder\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def embed_and_decode(self, ids_decoder=None, masks_encoder=None, output_encoder=None, masks_decoder=None, nocache=False, **kwargs):\n",
    "        self.decoder.clear_cache()\n",
    "        \n",
    "        embedding_decoder = self.embedder_decoder(ids_decoder)\n",
    "        output_decoder = self.decoder(\n",
    "            masks_encoder=masks_encoder,\n",
    "            output_encoder=output_encoder,    #(len_seq, dim_hidden) -> (1, dim_hidden)\n",
    "            embedding_decoder=embedding_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            nocache=nocache\n",
    "        )\n",
    "\n",
    "        return output_decoder\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def clear_cache(self):\n",
    "        self.encoder.clear_cache()\n",
    "        if self.decoder:\n",
    "            self.decoder.clear_cache()\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def get_vocab_size(self, name_embedder):\n",
    "        embedder = getattr(self, f'embedder_{name_embedder}')\n",
    "        return embedder.get_vocab_size()\n",
    "    # end\n",
    "\n",
    "# end\n",
    "\n",
    "class LinearAndNorm(nn.Module):\n",
    "    def __init__(self, dim_in = None, dim_out = None, eps_norm=1e-12):\n",
    "        super(LinearAndNorm, self).__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(dim_in, dim_out)\n",
    "        self.norm = torch.nn.LayerNorm(dim_out, eps_norm)\n",
    "    # end\n",
    "\n",
    "    def forward(self, seqs_in):\n",
    "        return self.norm(self.linear(seqs_in).relu())\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, vocab, splitter):\n",
    "        self.splitter = splitter\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.id_pad = len(vocab)\n",
    "        self.id_cls = len(vocab) + 1\n",
    "        self.id_sep = len(vocab) + 2\n",
    "        self.id_mask = len(vocab) + 3\n",
    "        \n",
    "        self.size_vocab = len(vocab) + 4\n",
    "\n",
    "        self.token_pad = '[PAD]'\n",
    "        self.token_cls = '[CLS]'\n",
    "        self.token_sep = '[SEP]'\n",
    "        self.token_mask = '[MASK]'\n",
    "           \n",
    "        self.index_id_token_special = {\n",
    "            self.id_pad: self.token_pad,\n",
    "            self.id_cls: self.token_cls,\n",
    "            self.id_sep: self.token_sep,\n",
    "            self.id_mask: self.token_mask\n",
    "        }\n",
    "        \n",
    "    # end\n",
    "\n",
    "    def encode(self, line):\n",
    "        return self.vocab([doc.text for doc in self.splitter(line)])\n",
    "    # end\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        words = []\n",
    "        for token in tokens:\n",
    "            token = int(token)\n",
    "            \n",
    "            if token in self.index_id_token_special:\n",
    "                word_target = self.index_id_token_special[token]\n",
    "            else:\n",
    "                try:\n",
    "                    word_target = vocab.lookup_token(token)\n",
    "                except:\n",
    "                    word_target = '[ERROR_LOOKUP_{}]'.format(token)\n",
    "                # end\n",
    "            # end\n",
    "            \n",
    "            words.append(word_target)\n",
    "        # end\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class Batch:\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        for k, v in kwargs.items():\n",
    "            if v is not None and type(v) is not bool:\n",
    "                self.kwargs[k] = v.to(Batch.DEVICE)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.kwargs\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class Collator_S2S:\n",
    "\n",
    "    def __init__(self, tokenizer, size_seq_max, need_masked=0.3):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size_seq_max = size_seq_max\n",
    "        self.need_masked = need_masked\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def __call__(self, list_corpus_source):\n",
    "\n",
    "        tokens_input_encoder = []\n",
    "        tokens_input_decoder = []\n",
    "        tokens_label_decoder = []\n",
    "        labels_similarity = []\n",
    "\n",
    "        for corpus_source in list_corpus_source: # (line0, line1, sim), output of zip remove single case\n",
    "            if len(corpus_source) == 3:\n",
    "                corpus_line = [courpus_source[0], corpus_source[1]]\n",
    "                labels_similarity.append(corpus_line[2])\n",
    "            else:\n",
    "                corpus_line = [corpus_source[1]]\n",
    "            # end\n",
    "            \n",
    "            for line in corpus_line:\n",
    "                tokens = self.tokenizer.encode(line)\n",
    "\n",
    "                # TODO: check edge\n",
    "                if len(tokens) > self.size_seq_max - 2:\n",
    "                    tokens = tokens[:self.size_seq_max-2]\n",
    "                # end\n",
    "\n",
    "                tokens_input_encoder.append([self.tokenizer.id_cls] + tokens + [self.tokenizer.id_sep])\n",
    "                tokens_input_decoder.append([self.tokenizer.id_cls] + tokens)\n",
    "                tokens_label_decoder.append(tokens + [self.tokenizer.id_sep])\n",
    "            # end\n",
    "            \n",
    "\n",
    "        # end\n",
    "\n",
    "        inputs_encoder, masks_encoder, segments_encoder, labels_encoder = self.pad_sequences(tokens_input_encoder, self.size_seq_max, need_masked=self.need_masked)\n",
    "        inputs_decoder, masks_decoder, segments_decoder, _ = self.pad_sequences(tokens_input_decoder, self.size_seq_max, need_diagonal=True)\n",
    "        labels_decoder, masks_label, segments_label, _ = self.pad_sequences(tokens_label_decoder, self.size_seq_max)\n",
    "        # labels_similarity = torch.Tensor(labels_similarity).unsqueeze(0).transpose(0,1)\n",
    "        labels_similarity = torch.Tensor(labels_similarity)\n",
    "\n",
    "        return Batch(\n",
    "            ids_encoder=inputs_encoder,  # contains [mask]s\n",
    "            masks_encoder=masks_encoder,\n",
    "            labels_encoder=labels_encoder,  # doesn't contain [mask]\n",
    "            segments_encoder=segments_encoder,\n",
    "            ids_decoder=inputs_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            labels_decoder=labels_decoder,\n",
    "            segments_label=segments_label,\n",
    "            labels_similarity=labels_similarity\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    \n",
    "    # return masks_attention?, return masks_segment?\n",
    "    def pad_sequences(self, sequences, size_seq_max, need_diagonal=False, need_masked=0): # need_diagonal and need_masked cannot both set, one for bert seq one for s2s seq\n",
    "        id_pad = self.tokenizer.id_pad\n",
    "        id_mask = self.tokenizer.id_mask\n",
    "\n",
    "        sequences_padded = []\n",
    "        sequences_masked_padded = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            len_seq = len(sequence)\n",
    "\n",
    "            count_pad = size_seq_max - len_seq\n",
    "\n",
    "            sequence = torch.LongTensor(sequence)\n",
    "            sequence_padded = torch.cat((sequence, torch.LongTensor([id_pad] * count_pad)))\n",
    "            sequences_padded.append(sequence_padded)\n",
    "\n",
    "            if need_masked:\n",
    "                index_masked = list(range(1, len_seq-1))\n",
    "                random.shuffle(index_masked)\n",
    "                index_masked = torch.LongTensor(index_masked[:int(need_masked * (len_seq-2))])\n",
    "\n",
    "                sequence_masked = sequence.detach().clone()\n",
    "                sequence_masked.index_fill_(0, index_masked, id_mask)\n",
    "                sequence_masked_padded = torch.cat((sequence_masked, torch.LongTensor([id_pad] * count_pad)))\n",
    "                \n",
    "                sequences_masked_padded.append(sequence_masked_padded)\n",
    "            # end\n",
    "    #   # end for\n",
    "\n",
    "        inputs = torch.stack(sequences_padded)  # (batch, size_seq_max)\n",
    "        if need_masked:\n",
    "            inputs_masked_padded = torch.stack(sequences_masked_padded)\n",
    "        # end\n",
    "\n",
    "        masks_segment = (inputs != self.tokenizer.id_pad).unsqueeze(-2)    #(nbatch, 1, seq)\n",
    "        masks_attention = self.make_std_mask(inputs, self.tokenizer.id_pad) if need_diagonal else masks_segment\n",
    "\n",
    "        if need_masked:\n",
    "            masks_masked = (inputs_masked_padded != id_mask).unsqueeze(-2)\n",
    "            masks_attention = masks_attention & masks_masked\n",
    "            return inputs_masked_padded, masks_attention, masks_segment, inputs # (inputs, masks_attention, masks_segment, labels)\n",
    "        else:\n",
    "            return inputs, masks_attention, masks_segment, None\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def subsequent_mask(self, size):\n",
    "        \"Mask out subsequent positions.\"\n",
    "        attn_shape = (1, size, size)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        return subsequent_mask == 0\n",
    "\n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & self.subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51933c37-2474-4ea8-8819-d67e8061c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "def Multi30k(language_pair=None):\n",
    "    corpus_lines_train = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/train.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_train.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_train = list(zip(*corpus_lines_train))\n",
    "\n",
    "    corpus_lines_eval = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/val.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_eval.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_eval = list(zip(*corpus_lines_eval))\n",
    "\n",
    "    return corpus_train, corpus_eval, None\n",
    "# end\n",
    "\n",
    "\n",
    "def load_vocab(spacy_en):\n",
    "    if not os.path.exists(\"vocab.pt\"):\n",
    "        vocab_tgt = build_vocabulary(spacy_en)\n",
    "        torch.save(vocab_tgt, \"vocab.pt\")\n",
    "    else:\n",
    "        vocab_tgt = torch.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes: {}\".format(len(vocab_tgt)))\n",
    "    return vocab_tgt\n",
    "# end\n",
    "\n",
    "def load_spacy():\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_en\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c03c357-ab7a-4589-a7a0-b87c2a3572b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleEncoderHead_MLM(nn.Module):\n",
    "\n",
    "#     def __init__(self, model, size_vocab, dim_hidden=128):\n",
    "#         super(SimpleEncoderHead_MLM, self).__init__()\n",
    "#         self.model = model\n",
    "        \n",
    "#         self.ffn = LinearAndNorm(dim_in=dim_hidden, dim_out=dim_hidden)\n",
    "#         self.extractor = torch.nn.Linear(dim_hidden, size_vocab, bias=False)\n",
    "#         self.extractor.weight = nn.Parameter(model.embedder_encoder.embedder[0].lut.weight)\n",
    "        \n",
    "#         self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "#     # end\n",
    "\n",
    "\n",
    "#     def forward(self, **kwargs):   # labels_input -> (batch, seq, labels)\n",
    "#         labels_mlm = kwargs['labels_encoder']\n",
    "        \n",
    "#         outputs_encoder = self.model(**kwargs)\n",
    "#         outputs_ffn = self.ffn(outputs_encoder)\n",
    "#         outputs_mlm = self.extractor(outputs_ffn) # outputs_mlm = prediction_logits\n",
    "        \n",
    "#         segments_encoder = kwargs['segments_encoder']        \n",
    "#         segments_encoder_2d = segments_encoder.transpose(-1,-2)[:,:,0]\n",
    "\n",
    "#         # loss_segments = self.func_loss(outputs_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(segments_encoder_2d)) / segments_encoder_2d.reshape(-1).shape[0]\n",
    "#         loss_segments = self.func_loss(outputs_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(segments_encoder_2d))\n",
    "        \n",
    "#         masks_encoder = kwargs['masks_encoder']\n",
    "#         masks_masked = torch.logical_xor(masks_encoder, segments_encoder) & segments_encoder # True is masked\n",
    "#         masks_masked_perbatch = masks_masked[:,0,:]\n",
    "#         # loss_masked = self.func_loss(outputs_mlm.masked_select(masks_masked_perbatch.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(masks_masked_perbatch)) / masks_masked_perbatch.reshape(-1).shape[0]\n",
    "#         loss_masked = self.func_loss(outputs_mlm.masked_select(masks_masked_perbatch.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(masks_masked_perbatch))       \n",
    "        \n",
    "#         # loss_mlm = loss_segments + loss_masked * 3\n",
    "#         loss_mlm = loss_segments\n",
    "        \n",
    "#         return outputs_mlm, loss_mlm\n",
    "#     # end\n",
    "\n",
    "# # end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b97fee-21de-4a79-a082-4eb70288e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecoderHead_S2S(nn.Module):\n",
    "\n",
    "    def __init__(self, model, size_vocab, dim_hidden=128):\n",
    "        super(SimpleDecoderHead_S2S, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        self.ffn = LinearAndNorm(dim_in=dim_hidden, dim_out=dim_hidden)\n",
    "        \n",
    "        self.extractor = torch.nn.Linear(dim_hidden, size_vocab, bias=False)\n",
    "        self.extractor.weight = nn.Parameter(model.embedder_decoder.embedder[0].lut.weight)\n",
    "\n",
    "        self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # end\n",
    "\n",
    "    \n",
    "    def forward(self, **kwargs):   # labels_input -> (batch, seq, labels)\n",
    "        labels_s2s = kwargs['labels_decoder']\n",
    "        \n",
    "        outputs_decoder = self.model(**kwargs)\n",
    "        outputs_ffn = self.ffn(outputs_decoder)\n",
    "        outputs_s2s = self.extractor(outputs_ffn)   # outputs_mlm = prediction_logits\n",
    "        \n",
    "        segments_decoder = kwargs['segments_label']\n",
    "        segments_decoder_2d = segments_decoder.transpose(-1,-2)[:,:,0]\n",
    "\n",
    "        loss_segments = self.func_loss(outputs_s2s.masked_select(segments_decoder_2d.unsqueeze(-1)).reshape(-1, outputs_s2s.shape[-1]), labels_s2s.masked_select(segments_decoder_2d))\n",
    "\n",
    "        return outputs_s2s, loss_segments\n",
    "    # end\n",
    "\n",
    "\n",
    "    def beam_generate(self):\n",
    "        pass\n",
    "    # end\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5dae215-cabb-49ee-9f29-961118e61225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Builder:\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_mlm(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, None, embedder_encoder, None)\n",
    "        head_mlm = SimpleEncoderHead_MLM(model, size_vocab, dim_hidden)\n",
    "\n",
    "        return head_mlm\n",
    "    # end\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_s2s(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "        \n",
    "        embedder_decoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_decoder = SimpleDecoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        decoderstack = SimpleTransformerStack(sample_decoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, decoderstack, embedder_encoder, embedder_decoder)\n",
    "        head_s2s = SimpleDecoderHead_S2S(model, size_vocab, dim_hidden)\n",
    "\n",
    "        return head_s2s\n",
    "    # end\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60b018b-b983-4755-90ce-c07976ccde1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes: 6191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "\n",
    "gpu = 0\n",
    "torch.cuda.set_device(gpu)\n",
    "\n",
    "epochs = 60\n",
    "\n",
    "# source\n",
    "seq_max = 16\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# model & head\n",
    "dim_hidden = 512\n",
    "dim_feedforward = 512\n",
    "n_head = 8\n",
    "n_layer = 8\n",
    "\n",
    "# optimizer\n",
    "lr_base_optimizer = 5e-4\n",
    "betas_optimizer = (0.9, 0.999)\n",
    "eps_optimizer = 1e-9\n",
    "\n",
    "# scheduler\n",
    "warmup = 200\n",
    "\n",
    "spacy_en = load_spacy()\n",
    "vocab = load_vocab(spacy_en)\n",
    "tokenizer = TokenizerWrapper(vocab, spacy_en)\n",
    "\n",
    "train_iter, valid_iter, _ = Multi30k(language_pair=(\"de\", \"en\"))\n",
    "train_source = to_map_style_dataset(train_iter)\n",
    "\n",
    "collator = Collator_S2S(tokenizer, seq_max)\n",
    "dataloader_train = DataLoader(train_source, batch_size, shuffle=False, collate_fn=collator)\n",
    "\n",
    "head = Builder.build_model_with_s2s(tokenizer.size_vocab, dim_hidden, dim_feedforward, n_head, n_layer)\n",
    "\n",
    "for p in head.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "head = head.to('cuda')\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(head.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "decayRate = 0.96\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b499ec3-35e4-49c7-952d-5e58d0b899f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_a_batch(batch, head, optimizer=None, scheduler=None):\n",
    "    head.train()\n",
    "    _, loss_s2s = head.forward(**batch())    # save to cache\n",
    "\n",
    "    # crossentropy loss\n",
    "    \n",
    "    loss_all = loss_s2s * 5\n",
    "    loss_all_value = loss_all.item()\n",
    "    \n",
    "    # print(loss_all)\n",
    "    loss_all.backward()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    # end\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    # end\n",
    "    # manager.clear_cache()\n",
    "    return loss_all_value\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcf19d1-b502-4a47-99dc-66bf2b071347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 0, loss: 43.997989654541016, rate: 0.0001\n",
      "Epoch: 0 Batch: 100, loss: 25.74346923828125, rate: 0.0001\n",
      "Epoch: 0 Batch: 200, loss: 24.688373565673828, rate: 0.0001\n",
      "Epoch: 0 Batch: 300, loss: 19.072385787963867, rate: 0.0001\n",
      "Epoch: 0 Batch: 400, loss: 19.663721084594727, rate: 0.0001\n",
      "Epoch: 0 Batch: 500, loss: 21.98863983154297, rate: 0.0001\n",
      "Epoch: 0 Batch: 600, loss: 17.68052101135254, rate: 0.0001\n",
      "Epoch: 0 Batch: 700, loss: 19.75946044921875, rate: 0.0001\n",
      "Epoch: 0 Batch: 800, loss: 18.86446762084961, rate: 0.0001\n",
      "Epoch: 0 Batch: 900, loss: 17.95880889892578, rate: 0.0001\n",
      "Epoch: 0 Batch: 1000, loss: 18.245805740356445, rate: 0.0001\n",
      "Epoch: 0 Batch: 1100, loss: 17.002105712890625, rate: 0.0001\n",
      "Epoch: 0 Batch: 1200, loss: 16.108827590942383, rate: 0.0001\n",
      "Epoch: 0 Batch: 1300, loss: 13.102991104125977, rate: 0.0001\n",
      "Epoch: 0 Batch: 1400, loss: 12.315221786499023, rate: 0.0001\n",
      "Epoch: 0 Batch: 1500, loss: 13.446344375610352, rate: 0.0001\n",
      "Epoch: 0 Batch: 1600, loss: 12.854312896728516, rate: 0.0001\n",
      "Epoch: 0 Batch: 1700, loss: 13.744497299194336, rate: 0.0001\n",
      "Epoch: 0 Batch: 1800, loss: 13.746389389038086, rate: 0.0001\n",
      "[2023-11-17 02:03:25.791991] Epoch: 0 ends. Average loss: 18.041419096566404\n",
      "Epoch: 1 Batch: 0, loss: 12.089208602905273, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 100, loss: 12.90112018585205, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 200, loss: 12.013113021850586, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 300, loss: 7.2544660568237305, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 400, loss: 8.926231384277344, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 500, loss: 12.261251449584961, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 600, loss: 8.667031288146973, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 700, loss: 11.057071685791016, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 800, loss: 10.55331802368164, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 900, loss: 10.011073112487793, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1000, loss: 11.052719116210938, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1100, loss: 10.289043426513672, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1200, loss: 9.516669273376465, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1300, loss: 7.918927192687988, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1400, loss: 8.653328895568848, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1500, loss: 10.270347595214844, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1600, loss: 9.104391098022461, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1700, loss: 10.705024719238281, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1800, loss: 9.992709159851074, rate: 9.6e-05\n",
      "[2023-11-17 02:09:25.244648] Epoch: 1 ends. Average loss: 9.994654735937608\n",
      "Epoch: 2 Batch: 0, loss: 8.974821090698242, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 100, loss: 9.494831085205078, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 200, loss: 10.033073425292969, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 300, loss: 5.1066083908081055, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 400, loss: 7.305732250213623, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 500, loss: 9.75555419921875, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 600, loss: 6.273664474487305, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 700, loss: 8.8761568069458, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 800, loss: 8.767830848693848, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 900, loss: 7.806453227996826, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1000, loss: 9.156092643737793, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1100, loss: 8.33963680267334, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1200, loss: 8.174293518066406, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1300, loss: 6.541886806488037, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1400, loss: 6.911613464355469, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1500, loss: 8.57408618927002, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1600, loss: 7.8929762840271, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1700, loss: 9.979475021362305, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1800, loss: 8.401509284973145, rate: 9.216e-05\n",
      "[2023-11-17 02:15:22.866823] Epoch: 2 ends. Average loss: 8.348326308518171\n",
      "Epoch: 3 Batch: 0, loss: 8.528460502624512, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 100, loss: 9.364521980285645, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 200, loss: 8.290714263916016, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 300, loss: 4.58836555480957, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 400, loss: 7.470646381378174, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 500, loss: 9.166335105895996, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 600, loss: 6.680366516113281, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 700, loss: 8.571584701538086, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 800, loss: 7.389993667602539, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 900, loss: 7.181539058685303, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1000, loss: 8.791130065917969, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1100, loss: 8.378952980041504, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1200, loss: 7.886356830596924, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1300, loss: 6.428573131561279, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1400, loss: 6.2346954345703125, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1500, loss: 8.402260780334473, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1600, loss: 7.419273376464844, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1700, loss: 10.327360153198242, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1800, loss: 8.732019424438477, rate: 8.847359999999999e-05\n",
      "[2023-11-17 02:21:21.263474] Epoch: 3 ends. Average loss: 7.743874263184805\n",
      "Epoch: 4 Batch: 0, loss: 7.779477119445801, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 100, loss: 7.9807610511779785, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 200, loss: 8.235345840454102, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 300, loss: 4.856625080108643, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 400, loss: 6.877031326293945, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 500, loss: 9.14925479888916, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 600, loss: 5.958642482757568, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 700, loss: 8.11952018737793, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 800, loss: 7.883970260620117, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 900, loss: 7.249298572540283, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1000, loss: 8.204540252685547, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1200, loss: 7.444404602050781, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1300, loss: 6.201834678649902, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1400, loss: 6.4347124099731445, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1500, loss: 7.758115768432617, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1600, loss: 6.968384742736816, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1700, loss: 9.747260093688965, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1800, loss: 8.716663360595703, rate: 8.493465599999999e-05\n",
      "[2023-11-17 02:27:19.877825] Epoch: 4 ends. Average loss: 7.388573570535516\n",
      "Epoch: 5 Batch: 0, loss: 8.545499801635742, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 100, loss: 7.806196212768555, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 200, loss: 7.946655750274658, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 300, loss: 4.505167007446289, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 400, loss: 6.040529251098633, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 500, loss: 9.093072891235352, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 600, loss: 6.320489883422852, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 700, loss: 7.694812297821045, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 800, loss: 7.250555038452148, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 900, loss: 6.508541107177734, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1000, loss: 8.04806137084961, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1100, loss: 7.7436676025390625, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1200, loss: 6.717757225036621, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1300, loss: 5.944721221923828, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1400, loss: 6.090832710266113, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1500, loss: 7.524476528167725, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1600, loss: 6.466214179992676, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1700, loss: 9.47311019897461, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1800, loss: 8.036806106567383, rate: 8.153726975999998e-05\n",
      "[2023-11-17 02:33:20.370396] Epoch: 5 ends. Average loss: 7.13321116532138\n",
      "Epoch: 6 Batch: 0, loss: 7.586627006530762, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 100, loss: 7.495173454284668, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 200, loss: 7.285989761352539, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 300, loss: 4.299234390258789, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 400, loss: 6.124782085418701, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 500, loss: 8.54866886138916, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 600, loss: 6.26499605178833, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 700, loss: 7.348906993865967, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 800, loss: 7.1443023681640625, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 900, loss: 6.571881294250488, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1000, loss: 7.662748336791992, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1100, loss: 7.752894401550293, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1200, loss: 7.649368762969971, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1300, loss: 4.975839614868164, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1400, loss: 6.2003397941589355, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1500, loss: 7.545339584350586, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1600, loss: 6.21412992477417, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1700, loss: 8.89611530303955, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1800, loss: 7.2439188957214355, rate: 7.827577896959998e-05\n",
      "[2023-11-17 02:39:19.746664] Epoch: 6 ends. Average loss: 6.951779895767742\n",
      "Epoch: 7 Batch: 0, loss: 7.211820602416992, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 100, loss: 7.947338104248047, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 200, loss: 7.523955345153809, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 300, loss: 4.234118938446045, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 400, loss: 5.82297420501709, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 500, loss: 8.243202209472656, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 600, loss: 5.740203380584717, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 700, loss: 7.6420207023620605, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 800, loss: 7.620494842529297, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 900, loss: 6.443077087402344, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1000, loss: 7.0573039054870605, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1100, loss: 7.345240116119385, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1200, loss: 7.076554775238037, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1300, loss: 5.081854343414307, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1400, loss: 5.776760101318359, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1500, loss: 7.256560802459717, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1600, loss: 6.259032249450684, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1700, loss: 8.959728240966797, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1800, loss: 8.038655281066895, rate: 7.514474781081598e-05\n",
      "[2023-11-17 02:45:23.109269] Epoch: 7 ends. Average loss: 6.795857461723122\n",
      "Epoch: 8 Batch: 0, loss: 8.059791564941406, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 100, loss: 7.381888389587402, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 200, loss: 7.283106803894043, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 300, loss: 4.106252670288086, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 400, loss: 5.453494071960449, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 500, loss: 7.297393798828125, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 600, loss: 5.066193580627441, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 700, loss: 7.829086780548096, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 800, loss: 7.242569923400879, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 900, loss: 6.707210540771484, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1000, loss: 7.583860397338867, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1100, loss: 7.102865695953369, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1200, loss: 6.850104331970215, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1300, loss: 5.295063018798828, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1400, loss: 6.050844192504883, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1500, loss: 7.452597618103027, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1600, loss: 5.938124656677246, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1700, loss: 8.66521167755127, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1800, loss: 7.325028419494629, rate: 7.213895789838334e-05\n",
      "[2023-11-17 02:51:22.505555] Epoch: 8 ends. Average loss: 6.6095132253081905\n",
      "Epoch: 9 Batch: 0, loss: 7.079263687133789, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 100, loss: 6.7574567794799805, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 200, loss: 6.947807788848877, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 300, loss: 3.943239688873291, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 400, loss: 6.012301445007324, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 500, loss: 8.185733795166016, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 600, loss: 6.045918941497803, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 700, loss: 6.816508769989014, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 800, loss: 6.380932807922363, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 900, loss: 6.262916564941406, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1000, loss: 6.680179119110107, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1100, loss: 7.306085109710693, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1200, loss: 6.020653247833252, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1300, loss: 4.871922492980957, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1400, loss: 5.512032508850098, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1500, loss: 6.94242000579834, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1600, loss: 5.660825729370117, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1700, loss: 8.189739227294922, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1800, loss: 7.116558074951172, rate: 6.9253399582448e-05\n",
      "[2023-11-17 02:57:22.879518] Epoch: 9 ends. Average loss: 6.463888935666681\n",
      "Epoch: 10 Batch: 0, loss: 7.393349647521973, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 100, loss: 7.517424583435059, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 200, loss: 7.667389869689941, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 300, loss: 4.3495893478393555, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 400, loss: 5.262079238891602, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 500, loss: 7.2428460121154785, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 600, loss: 5.288312911987305, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 700, loss: 6.6235246658325195, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 800, loss: 6.313986301422119, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 900, loss: 5.771265983581543, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1000, loss: 7.243680477142334, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1100, loss: 6.399797439575195, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1200, loss: 6.397263526916504, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1300, loss: 4.764743328094482, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1400, loss: 5.533613204956055, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1500, loss: 6.725704193115234, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1700, loss: 8.52552604675293, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1800, loss: 7.038363933563232, rate: 6.648326359915008e-05\n",
      "[2023-11-17 03:03:23.849952] Epoch: 10 ends. Average loss: 6.321229260597713\n",
      "Epoch: 11 Batch: 0, loss: 6.964544773101807, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 100, loss: 6.529050350189209, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 200, loss: 6.35224723815918, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 300, loss: 3.4324698448181152, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 400, loss: 5.035886287689209, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 500, loss: 7.459012031555176, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 600, loss: 5.227832317352295, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 700, loss: 6.527275085449219, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 800, loss: 6.8675737380981445, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 900, loss: 6.098232746124268, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1000, loss: 6.893362998962402, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1100, loss: 6.764817714691162, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1200, loss: 6.315800666809082, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1300, loss: 5.345296382904053, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1400, loss: 5.602719783782959, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1500, loss: 6.047492027282715, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1600, loss: 5.476322174072266, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1700, loss: 8.23853588104248, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1800, loss: 7.389684677124023, rate: 6.382393305518408e-05\n",
      "[2023-11-17 03:09:30.555471] Epoch: 11 ends. Average loss: 6.225714620278806\n",
      "Epoch: 12 Batch: 0, loss: 6.9675726890563965, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 100, loss: 7.053952217102051, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 200, loss: 6.595519065856934, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 300, loss: 3.5441839694976807, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 400, loss: 6.011440277099609, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 500, loss: 6.451010704040527, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 600, loss: 5.508000373840332, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 700, loss: 6.181645393371582, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 800, loss: 6.61466646194458, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 900, loss: 5.845572471618652, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1000, loss: 6.583937644958496, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1100, loss: 6.111670017242432, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1200, loss: 6.764237403869629, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1300, loss: 4.947777271270752, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1400, loss: 4.974313259124756, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1500, loss: 7.074730396270752, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1600, loss: 5.559850692749023, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1700, loss: 7.96341609954834, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1800, loss: 7.328168869018555, rate: 6.127097573297672e-05\n",
      "[2023-11-17 03:15:35.503827] Epoch: 12 ends. Average loss: 6.126698618755772\n",
      "Epoch: 13 Batch: 0, loss: 7.208630561828613, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 100, loss: 7.355875015258789, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 200, loss: 6.4516801834106445, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 300, loss: 3.755145311355591, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 400, loss: 5.601412773132324, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 500, loss: 6.2689924240112305, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 600, loss: 4.924971580505371, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 700, loss: 5.94477653503418, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 800, loss: 5.9005537033081055, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 900, loss: 5.90813684463501, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1000, loss: 6.994832992553711, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1100, loss: 6.205411911010742, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1200, loss: 6.115712642669678, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1300, loss: 4.89186429977417, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1400, loss: 5.556819915771484, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1500, loss: 5.760213851928711, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1600, loss: 5.417799472808838, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1700, loss: 8.217361450195312, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1800, loss: 6.368121147155762, rate: 5.882013670365765e-05\n",
      "[2023-11-17 03:21:42.109707] Epoch: 13 ends. Average loss: 6.00931817671244\n",
      "Epoch: 14 Batch: 0, loss: 6.459393501281738, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 100, loss: 6.302316665649414, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 200, loss: 5.633979797363281, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 300, loss: 4.042576313018799, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 400, loss: 5.203497886657715, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 500, loss: 6.451117515563965, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 600, loss: 5.246273994445801, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 700, loss: 5.839252948760986, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 800, loss: 5.905786037445068, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 900, loss: 5.580286026000977, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1000, loss: 6.393447399139404, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1100, loss: 5.818275451660156, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1200, loss: 6.17165470123291, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1300, loss: 4.842554569244385, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1400, loss: 5.144689083099365, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1500, loss: 5.579543590545654, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1600, loss: 5.576672554016113, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1700, loss: 7.583793640136719, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1800, loss: 7.201765060424805, rate: 5.6467331235511337e-05\n",
      "[2023-11-17 03:27:47.292097] Epoch: 14 ends. Average loss: 5.933970383498396\n",
      "Epoch: 15 Batch: 0, loss: 6.2970428466796875, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 100, loss: 6.939664363861084, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 200, loss: 5.967535972595215, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 300, loss: 3.7813425064086914, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 400, loss: 5.358118534088135, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 500, loss: 6.616232872009277, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 600, loss: 4.9864702224731445, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 700, loss: 6.894721508026123, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 800, loss: 6.114747524261475, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 900, loss: 5.737013339996338, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1000, loss: 5.945808410644531, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1100, loss: 5.916605472564697, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1200, loss: 5.824782848358154, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1300, loss: 5.177112102508545, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1400, loss: 5.4022369384765625, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1500, loss: 6.087874889373779, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1600, loss: 5.078176498413086, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1700, loss: 7.757538795471191, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1800, loss: 6.420630931854248, rate: 5.4208637986090884e-05\n",
      "[2023-11-17 03:33:52.907219] Epoch: 15 ends. Average loss: 5.8362298051231285\n",
      "Epoch: 16 Batch: 0, loss: 6.550870895385742, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 100, loss: 6.579958915710449, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 200, loss: 6.775472164154053, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 300, loss: 3.0792429447174072, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 400, loss: 5.717130661010742, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 500, loss: 6.363091468811035, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 600, loss: 5.136104583740234, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 700, loss: 6.207692623138428, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 800, loss: 5.94891357421875, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 900, loss: 5.605588436126709, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1000, loss: 5.958507537841797, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1100, loss: 6.474209785461426, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1200, loss: 6.29792594909668, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1300, loss: 5.033468246459961, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1400, loss: 5.467348098754883, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1500, loss: 5.676562309265137, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1600, loss: 4.62014102935791, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1700, loss: 7.332200050354004, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1800, loss: 6.126154899597168, rate: 5.2040292466647244e-05\n",
      "[2023-11-17 03:39:58.384364] Epoch: 16 ends. Average loss: 5.766874566501632\n",
      "Epoch: 17 Batch: 0, loss: 6.269830703735352, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 100, loss: 6.699312210083008, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 200, loss: 5.771368026733398, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 300, loss: 3.8735780715942383, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 400, loss: 5.43010139465332, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 500, loss: 6.225852966308594, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 600, loss: 5.08917760848999, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 700, loss: 6.016504764556885, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 800, loss: 5.501825332641602, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 900, loss: 5.59794807434082, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1000, loss: 6.339876651763916, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1100, loss: 6.530416011810303, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1200, loss: 6.292984485626221, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1300, loss: 5.172250270843506, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1400, loss: 5.171186923980713, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1500, loss: 5.947408676147461, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1600, loss: 5.051473617553711, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1700, loss: 7.613722801208496, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1800, loss: 6.833325386047363, rate: 4.995868076798135e-05\n",
      "[2023-11-17 03:45:55.875935] Epoch: 17 ends. Average loss: 5.696269944696485\n",
      "Epoch: 18 Batch: 0, loss: 6.340914726257324, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 100, loss: 6.418524265289307, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 200, loss: 6.265034198760986, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 300, loss: 3.861151933670044, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 400, loss: 5.494141578674316, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 500, loss: 6.969032287597656, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 600, loss: 5.006005764007568, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 700, loss: 6.1508636474609375, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 800, loss: 6.461581707000732, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 900, loss: 5.456218719482422, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1000, loss: 6.306332588195801, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1100, loss: 5.800394535064697, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1200, loss: 5.637740612030029, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1300, loss: 4.688088417053223, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1400, loss: 5.084527015686035, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1500, loss: 6.126989841461182, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1600, loss: 4.79564905166626, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1700, loss: 7.68108606338501, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1800, loss: 6.590188026428223, rate: 4.7960333537262095e-05\n",
      "[2023-11-17 03:51:54.917414] Epoch: 18 ends. Average loss: 5.651446786166158\n",
      "Epoch: 19 Batch: 0, loss: 6.2682366371154785, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 100, loss: 5.783536911010742, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 200, loss: 5.605532646179199, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 300, loss: 3.8116204738616943, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 400, loss: 4.457332611083984, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 500, loss: 6.39100456237793, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 600, loss: 4.847485542297363, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 700, loss: 5.262227535247803, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 800, loss: 5.867990493774414, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 900, loss: 5.392370700836182, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1000, loss: 5.868070125579834, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1100, loss: 6.33962345123291, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1200, loss: 6.08973503112793, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1300, loss: 4.409487724304199, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1400, loss: 5.2022480964660645, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1600, loss: 5.4850969314575195, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1700, loss: 6.579258918762207, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1800, loss: 6.795832633972168, rate: 4.6041920195771606e-05\n",
      "[2023-11-17 03:57:55.394600] Epoch: 19 ends. Average loss: 5.582301712667356\n",
      "Epoch: 20 Batch: 0, loss: 6.654719352722168, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 100, loss: 5.81834077835083, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 200, loss: 5.529677391052246, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 300, loss: 3.627586603164673, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 400, loss: 4.8004865646362305, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 500, loss: 6.461085319519043, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 600, loss: 5.034702301025391, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 700, loss: 6.843307018280029, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 800, loss: 5.360745429992676, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 900, loss: 5.189849853515625, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1000, loss: 5.537038803100586, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1100, loss: 6.465457916259766, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1200, loss: 5.692708969116211, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1300, loss: 4.065374374389648, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1400, loss: 4.75335693359375, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1500, loss: 6.024908542633057, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1600, loss: 4.6729960441589355, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1700, loss: 7.673663139343262, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1800, loss: 6.805217742919922, rate: 4.420024338794074e-05\n",
      "[2023-11-17 04:03:56.042400] Epoch: 20 ends. Average loss: 5.52861170852901\n",
      "Epoch: 21 Batch: 0, loss: 6.350010871887207, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 100, loss: 5.289829254150391, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 200, loss: 5.741434097290039, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 300, loss: 3.492339611053467, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 400, loss: 4.512828350067139, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 500, loss: 6.3773088455200195, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 600, loss: 4.707354545593262, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 700, loss: 6.590951919555664, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 800, loss: 5.906850814819336, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 900, loss: 5.2262115478515625, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1000, loss: 5.8800787925720215, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1100, loss: 5.39386510848999, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1200, loss: 5.741245746612549, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1300, loss: 5.039080619812012, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1400, loss: 4.910501003265381, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1500, loss: 5.483955383300781, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1600, loss: 4.92190408706665, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1700, loss: 7.740729331970215, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1800, loss: 5.8505144119262695, rate: 4.243223365242311e-05\n",
      "[2023-11-17 04:09:57.726597] Epoch: 21 ends. Average loss: 5.481972576568485\n",
      "Epoch: 22 Batch: 0, loss: 5.615602493286133, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 100, loss: 5.3556013107299805, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 200, loss: 5.978908061981201, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 300, loss: 2.8801708221435547, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 400, loss: 5.0408830642700195, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 500, loss: 6.013989448547363, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 600, loss: 5.343177318572998, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 700, loss: 6.038639545440674, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 800, loss: 5.955322265625, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 900, loss: 5.397785186767578, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1000, loss: 6.249914169311523, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1100, loss: 4.752481937408447, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1200, loss: 5.416889190673828, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1300, loss: 4.357735633850098, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1400, loss: 4.284481048583984, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1500, loss: 5.660893440246582, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1600, loss: 5.504586696624756, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1700, loss: 6.9144463539123535, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1800, loss: 6.8192853927612305, rate: 4.073494430632618e-05\n",
      "[2023-11-17 04:15:58.463826] Epoch: 22 ends. Average loss: 5.437994896609417\n",
      "Epoch: 23 Batch: 0, loss: 6.473755359649658, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 100, loss: 5.528935432434082, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 200, loss: 5.393928527832031, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 400, loss: 4.5236897468566895, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 500, loss: 5.799343585968018, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 600, loss: 4.623280048370361, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 700, loss: 6.9292311668396, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 800, loss: 4.901329517364502, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 900, loss: 5.3207879066467285, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1000, loss: 5.681334495544434, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1100, loss: 5.612841606140137, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1200, loss: 5.939484596252441, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1300, loss: 4.791049480438232, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1400, loss: 4.997724533081055, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1500, loss: 5.804712772369385, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1600, loss: 4.972972869873047, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1700, loss: 7.662759304046631, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1800, loss: 6.642890453338623, rate: 3.910554653407313e-05\n",
      "[2023-11-17 04:22:00.908315] Epoch: 23 ends. Average loss: 5.412791329198165\n",
      "Epoch: 24 Batch: 0, loss: 6.608569145202637, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 100, loss: 4.953272819519043, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 200, loss: 5.64290714263916, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 300, loss: 3.3320255279541016, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 400, loss: 4.403523921966553, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 500, loss: 6.617273807525635, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 600, loss: 4.728550434112549, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 700, loss: 5.885034561157227, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 800, loss: 5.56089973449707, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 900, loss: 5.347381591796875, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1000, loss: 5.414349555969238, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1100, loss: 5.458895683288574, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1200, loss: 5.230956554412842, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1300, loss: 4.044066429138184, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1400, loss: 5.217789649963379, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1500, loss: 5.441714286804199, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1600, loss: 4.847015380859375, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1700, loss: 6.743948936462402, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1800, loss: 6.421300888061523, rate: 3.7541324672710204e-05\n",
      "[2023-11-17 04:28:04.357152] Epoch: 24 ends. Average loss: 5.36265128604365\n",
      "Epoch: 25 Batch: 0, loss: 5.987560272216797, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 100, loss: 5.806350231170654, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 200, loss: 5.691563606262207, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 300, loss: 3.0710415840148926, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 400, loss: 5.037038326263428, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 500, loss: 6.508039474487305, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 600, loss: 5.792889595031738, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 700, loss: 5.597882270812988, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 800, loss: 5.501608848571777, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 900, loss: 6.158690452575684, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1000, loss: 6.231418132781982, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1100, loss: 5.532851696014404, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1200, loss: 5.621740818023682, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1300, loss: 4.372591972351074, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1400, loss: 4.679567337036133, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1500, loss: 5.685977935791016, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1600, loss: 4.604300498962402, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1700, loss: 6.539979457855225, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1800, loss: 6.18792724609375, rate: 3.603967168580179e-05\n",
      "[2023-11-17 04:34:03.664692] Epoch: 25 ends. Average loss: 5.319437341274508\n",
      "Epoch: 26 Batch: 0, loss: 6.15108060836792, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 100, loss: 5.947866916656494, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 200, loss: 5.770150184631348, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 300, loss: 2.9957520961761475, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 400, loss: 4.29703426361084, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 500, loss: 5.785289287567139, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 600, loss: 4.73832893371582, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 700, loss: 6.0597333908081055, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 800, loss: 5.852680206298828, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 900, loss: 5.211935520172119, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1000, loss: 5.384350299835205, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1100, loss: 5.645084857940674, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1200, loss: 5.467776775360107, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1300, loss: 4.46937370300293, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1400, loss: 5.056533336639404, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1500, loss: 5.436235427856445, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1600, loss: 5.155196189880371, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1700, loss: 6.824163436889648, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1800, loss: 6.785703659057617, rate: 3.459808481836972e-05\n",
      "[2023-11-17 04:40:06.402945] Epoch: 26 ends. Average loss: 5.2890329843585295\n",
      "Epoch: 27 Batch: 0, loss: 5.80181360244751, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 100, loss: 5.633167266845703, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 200, loss: 5.999538421630859, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 300, loss: 3.5001349449157715, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 400, loss: 4.7343010902404785, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 500, loss: 5.955465316772461, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 600, loss: 4.531839370727539, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 700, loss: 5.757692337036133, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 800, loss: 5.7651896476745605, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 900, loss: 4.849584579467773, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1000, loss: 5.600424766540527, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1100, loss: 5.4806108474731445, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1200, loss: 5.846114635467529, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1300, loss: 4.6902241706848145, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1400, loss: 4.6734113693237305, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1500, loss: 4.94150447845459, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1600, loss: 4.555014610290527, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1700, loss: 7.289973258972168, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1800, loss: 6.130684852600098, rate: 3.321416142563493e-05\n",
      "[2023-11-17 04:46:05.764276] Epoch: 27 ends. Average loss: 5.255323364401942\n",
      "Epoch: 28 Batch: 0, loss: 6.66235876083374, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 100, loss: 5.550968647003174, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 200, loss: 5.758862018585205, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 300, loss: 4.165950775146484, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 400, loss: 4.740560531616211, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 500, loss: 6.87650203704834, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 600, loss: 4.290910720825195, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 700, loss: 6.233635902404785, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 800, loss: 5.387082576751709, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 900, loss: 5.2589826583862305, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1000, loss: 5.257720470428467, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1100, loss: 5.045224189758301, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1200, loss: 5.338077068328857, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1300, loss: 4.474081516265869, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1400, loss: 5.232691764831543, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1500, loss: 5.0174360275268555, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1600, loss: 4.4148688316345215, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1700, loss: 6.336475372314453, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1800, loss: 5.986010551452637, rate: 3.188559496860953e-05\n",
      "[2023-11-17 04:52:09.061104] Epoch: 28 ends. Average loss: 5.213484546458333\n",
      "Epoch: 29 Batch: 0, loss: 5.978064060211182, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 100, loss: 5.826904296875, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 200, loss: 5.272381782531738, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 300, loss: 3.091813087463379, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 400, loss: 4.645298004150391, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 500, loss: 6.015944957733154, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 600, loss: 3.9652979373931885, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 700, loss: 5.5062713623046875, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 800, loss: 5.507382869720459, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 900, loss: 5.191164493560791, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1000, loss: 5.602975368499756, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1100, loss: 6.055178642272949, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1200, loss: 5.596139907836914, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1300, loss: 4.832126617431641, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1400, loss: 4.809321403503418, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1500, loss: 5.559154033660889, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1600, loss: 4.947174072265625, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1700, loss: 7.153343677520752, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1800, loss: 5.956136703491211, rate: 3.0610171169865154e-05\n",
      "[2023-11-17 04:58:15.420393] Epoch: 29 ends. Average loss: 5.20605764333806\n",
      "Epoch: 30 Batch: 0, loss: 6.66644287109375, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 100, loss: 4.9776105880737305, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 200, loss: 5.956123352050781, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 300, loss: 3.4526751041412354, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 400, loss: 4.543443202972412, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 500, loss: 5.899389266967773, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 600, loss: 3.8788363933563232, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 700, loss: 5.8636956214904785, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 800, loss: 4.8588409423828125, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 900, loss: 5.370730400085449, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1000, loss: 5.378684997558594, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1100, loss: 5.226288795471191, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1200, loss: 4.815647125244141, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1300, loss: 4.281707286834717, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1400, loss: 4.625360012054443, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1500, loss: 5.2476935386657715, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1600, loss: 3.905930280685425, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1700, loss: 7.368846416473389, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1800, loss: 6.15518045425415, rate: 2.9385764323070547e-05\n",
      "[2023-11-17 05:04:17.380630] Epoch: 30 ends. Average loss: 5.162497860913242\n",
      "Epoch: 31 Batch: 0, loss: 6.378580093383789, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 100, loss: 5.436469078063965, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 200, loss: 5.663786888122559, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 300, loss: 2.9601051807403564, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 400, loss: 4.410129070281982, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 500, loss: 6.180482387542725, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 600, loss: 4.961157321929932, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 700, loss: 5.4044623374938965, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 800, loss: 5.0055036544799805, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 900, loss: 5.290154457092285, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1000, loss: 5.070038318634033, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1100, loss: 5.118828773498535, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1200, loss: 4.442253589630127, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1300, loss: 4.311443328857422, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1400, loss: 4.666271209716797, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1500, loss: 5.127645015716553, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1600, loss: 4.710018157958984, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1700, loss: 7.141258716583252, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1800, loss: 6.312722682952881, rate: 2.8210333750147723e-05\n",
      "[2023-11-17 05:10:16.182929] Epoch: 31 ends. Average loss: 5.143490972140187\n",
      "Epoch: 32 Batch: 0, loss: 5.791568279266357, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 100, loss: 5.5139970779418945, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 200, loss: 5.399134635925293, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 300, loss: 3.3339505195617676, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 400, loss: 4.924684524536133, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 500, loss: 5.263627052307129, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 600, loss: 4.901726245880127, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 700, loss: 5.172521591186523, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 800, loss: 5.584988594055176, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 900, loss: 5.090491771697998, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1000, loss: 5.853702545166016, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1100, loss: 4.649759769439697, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1200, loss: 6.010456085205078, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1300, loss: 3.85516357421875, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1400, loss: 4.661252021789551, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1500, loss: 4.654360771179199, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1600, loss: 4.116782188415527, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1700, loss: 6.653709888458252, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1800, loss: 5.50830602645874, rate: 2.7081920400141814e-05\n",
      "[2023-11-17 05:16:20.510658] Epoch: 32 ends. Average loss: 5.1272686527239575\n",
      "Epoch: 33 Batch: 0, loss: 5.695303916931152, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 100, loss: 5.20892333984375, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 200, loss: 5.331432342529297, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 300, loss: 3.4926552772521973, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 400, loss: 5.120265483856201, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 500, loss: 5.856273174285889, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 600, loss: 4.578030109405518, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 700, loss: 5.302276134490967, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 800, loss: 4.57451868057251, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 900, loss: 5.1755523681640625, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1000, loss: 5.431706428527832, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1100, loss: 5.3154520988464355, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1200, loss: 5.391560077667236, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1300, loss: 4.677490711212158, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1400, loss: 4.334868907928467, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1500, loss: 4.745601177215576, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1600, loss: 4.83956241607666, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1700, loss: 6.33455228805542, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1800, loss: 5.9000067710876465, rate: 2.599864358413614e-05\n",
      "[2023-11-17 05:22:25.930462] Epoch: 33 ends. Average loss: 5.101837926981401\n",
      "Epoch: 34 Batch: 0, loss: 6.028413772583008, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 100, loss: 5.323488712310791, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 200, loss: 5.523483753204346, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 300, loss: 3.0863542556762695, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 400, loss: 4.793170928955078, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 500, loss: 6.072073459625244, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 600, loss: 4.462908744812012, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 700, loss: 5.949671745300293, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 800, loss: 5.592405796051025, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 900, loss: 4.607429027557373, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1000, loss: 5.6136345863342285, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1100, loss: 5.170646667480469, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1200, loss: 5.023985862731934, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1300, loss: 3.854377269744873, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1400, loss: 4.830132007598877, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1500, loss: 5.128756523132324, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1600, loss: 4.42973518371582, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1700, loss: 6.46993350982666, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1800, loss: 5.631516456604004, rate: 2.4958697840770694e-05\n",
      "[2023-11-17 05:28:26.130893] Epoch: 34 ends. Average loss: 5.083333759234218\n",
      "Epoch: 35 Batch: 0, loss: 6.011996746063232, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 100, loss: 5.359864711761475, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 200, loss: 5.625774383544922, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 300, loss: 3.1973745822906494, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 400, loss: 4.608989715576172, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 500, loss: 5.41965389251709, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 600, loss: 4.905374526977539, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 700, loss: 5.496244430541992, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 800, loss: 4.802230358123779, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 900, loss: 4.571852207183838, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1000, loss: 5.080456256866455, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1100, loss: 4.694408893585205, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1200, loss: 4.975837230682373, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1300, loss: 4.023407936096191, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1400, loss: 4.661285400390625, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1500, loss: 6.131134986877441, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1600, loss: 3.9983010292053223, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1700, loss: 7.017790794372559, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1800, loss: 6.292904853820801, rate: 2.3960349927139864e-05\n",
      "[2023-11-17 05:34:24.035568] Epoch: 35 ends. Average loss: 5.045216791418068\n",
      "Epoch: 36 Batch: 0, loss: 5.829981803894043, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 100, loss: 4.978952884674072, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 200, loss: 4.771313190460205, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 300, loss: 3.463674545288086, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 400, loss: 4.678723335266113, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 500, loss: 5.585461139678955, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 600, loss: 4.713209629058838, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 700, loss: 5.782824516296387, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 800, loss: 5.756117820739746, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 900, loss: 4.51084566116333, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1000, loss: 4.973708152770996, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1100, loss: 4.347357273101807, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1200, loss: 5.563340187072754, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1300, loss: 4.2235260009765625, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1400, loss: 4.7092790603637695, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1500, loss: 5.019497394561768, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1600, loss: 3.91133975982666, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1700, loss: 6.866044044494629, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1800, loss: 5.682387828826904, rate: 2.3001935930054268e-05\n",
      "[2023-11-17 05:40:24.329606] Epoch: 36 ends. Average loss: 5.038073754744574\n",
      "Epoch: 37 Batch: 0, loss: 4.971217155456543, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 100, loss: 5.1044230461120605, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 200, loss: 4.800609588623047, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 300, loss: 3.0304887294769287, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 400, loss: 4.113269329071045, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 500, loss: 6.13313102722168, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 600, loss: 4.154083728790283, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 700, loss: 5.836962699890137, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 800, loss: 5.228886604309082, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 900, loss: 4.518105506896973, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1000, loss: 4.908382415771484, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1100, loss: 5.052241802215576, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1200, loss: 4.7090935707092285, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1300, loss: 4.084533214569092, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1400, loss: 4.723946571350098, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1500, loss: 5.310850620269775, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1600, loss: 4.69034481048584, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1700, loss: 6.156486988067627, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1800, loss: 5.641610622406006, rate: 2.2081858492852098e-05\n",
      "[2023-11-17 05:46:24.034076] Epoch: 37 ends. Average loss: 5.012046008365166\n",
      "Epoch: 38 Batch: 0, loss: 5.740507125854492, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 100, loss: 4.57930850982666, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 200, loss: 5.0768890380859375, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 300, loss: 3.4390206336975098, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 400, loss: 4.486622333526611, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 500, loss: 5.916836738586426, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 600, loss: 4.825435161590576, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 700, loss: 5.037741184234619, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 800, loss: 4.979075908660889, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 900, loss: 4.960860729217529, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1000, loss: 5.583521842956543, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1100, loss: 5.7155914306640625, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1200, loss: 5.922638893127441, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1300, loss: 4.8485212326049805, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1400, loss: 4.463220119476318, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1500, loss: 4.521331787109375, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1600, loss: 5.224932670593262, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1700, loss: 6.850614070892334, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1800, loss: 5.582346439361572, rate: 2.1198584153138014e-05\n",
      "[2023-11-17 05:52:26.313475] Epoch: 38 ends. Average loss: 4.990930716109026\n",
      "Epoch: 39 Batch: 0, loss: 6.3797197341918945, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 100, loss: 5.2923431396484375, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 200, loss: 5.195481777191162, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 300, loss: 2.994577407836914, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 400, loss: 4.211024284362793, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 500, loss: 5.303549289703369, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 600, loss: 4.559372901916504, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 700, loss: 5.271388053894043, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 800, loss: 5.190105438232422, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 900, loss: 4.244665622711182, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1000, loss: 5.3657097816467285, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1100, loss: 5.1381731033325195, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1200, loss: 4.726593017578125, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1300, loss: 4.317486763000488, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1400, loss: 4.15078592300415, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1500, loss: 4.704394817352295, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1600, loss: 4.510097026824951, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1700, loss: 6.771263122558594, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1800, loss: 5.820810794830322, rate: 2.035064078701249e-05\n",
      "[2023-11-17 05:58:29.530708] Epoch: 39 ends. Average loss: 4.975751007188438\n",
      "Epoch: 40 Batch: 0, loss: 5.467371940612793, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 100, loss: 4.334469795227051, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 200, loss: 5.261725425720215, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 300, loss: 3.817037582397461, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 400, loss: 4.119190216064453, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 500, loss: 5.684943199157715, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 600, loss: 4.30754280090332, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 700, loss: 6.118487358093262, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 800, loss: 5.14731502532959, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 900, loss: 4.604108810424805, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1000, loss: 5.532235622406006, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1100, loss: 4.6568732261657715, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1200, loss: 5.236141204833984, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1300, loss: 4.088972568511963, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1400, loss: 4.809249401092529, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1500, loss: 4.991169452667236, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1600, loss: 4.013799667358398, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1700, loss: 7.020290374755859, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1800, loss: 5.821404933929443, rate: 1.953661515553199e-05\n",
      "[2023-11-17 06:04:26.397795] Epoch: 40 ends. Average loss: 4.966555767274994\n",
      "Epoch: 41 Batch: 0, loss: 5.860434055328369, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 100, loss: 5.2183146476745605, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 200, loss: 5.168396949768066, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 300, loss: 2.8208417892456055, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 400, loss: 4.4712605476379395, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 500, loss: 5.584008693695068, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 600, loss: 4.2510504722595215, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 700, loss: 4.902569770812988, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 800, loss: 5.046961784362793, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 900, loss: 5.000727653503418, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1000, loss: 5.371659278869629, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1100, loss: 4.958254337310791, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1200, loss: 5.120993137359619, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1300, loss: 4.315258979797363, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1400, loss: 4.576292991638184, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1500, loss: 5.265469551086426, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1600, loss: 4.121342182159424, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1700, loss: 6.662221908569336, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1800, loss: 6.058904647827148, rate: 1.8755150549310708e-05\n",
      "[2023-11-17 06:10:27.987967] Epoch: 41 ends. Average loss: 4.938909193197799\n",
      "Epoch: 42 Batch: 0, loss: 5.401416301727295, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 100, loss: 5.280259132385254, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 200, loss: 5.185981273651123, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 300, loss: 3.1268672943115234, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 400, loss: 4.375430107116699, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 500, loss: 5.4654927253723145, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 600, loss: 4.013423442840576, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 700, loss: 5.788179397583008, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 800, loss: 4.484773635864258, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 900, loss: 4.70875358581543, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1000, loss: 5.2224225997924805, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1100, loss: 4.735332012176514, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1200, loss: 4.993140697479248, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1300, loss: 3.4786131381988525, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1400, loss: 4.645518779754639, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1500, loss: 5.478747367858887, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1600, loss: 4.611289024353027, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1700, loss: 6.7351884841918945, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1800, loss: 5.729540824890137, rate: 1.800494452733828e-05\n",
      "[2023-11-17 06:16:29.347080] Epoch: 42 ends. Average loss: 4.917792815104809\n",
      "Epoch: 43 Batch: 0, loss: 5.589970588684082, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 100, loss: 4.875176429748535, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 200, loss: 4.333742141723633, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 300, loss: 3.6808571815490723, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 400, loss: 3.9301576614379883, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 500, loss: 5.509369850158691, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 600, loss: 4.377909183502197, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 700, loss: 5.200098991394043, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 800, loss: 4.9398980140686035, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 900, loss: 5.232039451599121, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1000, loss: 5.446444511413574, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1100, loss: 4.702465057373047, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1200, loss: 5.702602386474609, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1300, loss: 3.940319538116455, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1400, loss: 4.725659370422363, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1500, loss: 4.765836238861084, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1600, loss: 4.017784595489502, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1700, loss: 6.563694953918457, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1800, loss: 5.820288181304932, rate: 1.7284746746244747e-05\n",
      "[2023-11-17 06:22:36.407780] Epoch: 43 ends. Average loss: 4.898427135169802\n",
      "Epoch: 44 Batch: 0, loss: 5.423042297363281, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 100, loss: 4.76533317565918, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 200, loss: 5.279573917388916, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 300, loss: 3.703991413116455, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 400, loss: 4.373578071594238, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 500, loss: 6.090659141540527, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 600, loss: 4.39604377746582, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 800, loss: 4.784675121307373, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 900, loss: 4.94201135635376, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1000, loss: 5.533802032470703, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1100, loss: 5.056536674499512, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1200, loss: 5.689924240112305, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1300, loss: 4.475701808929443, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1400, loss: 4.657931804656982, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1500, loss: 4.926164627075195, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1600, loss: 4.590600967407227, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1700, loss: 6.043233871459961, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1800, loss: 5.761150360107422, rate: 1.6593356876394957e-05\n",
      "[2023-11-17 06:28:32.449471] Epoch: 44 ends. Average loss: 4.905504557682675\n",
      "Epoch: 45 Batch: 0, loss: 5.574368476867676, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 100, loss: 5.306403160095215, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 200, loss: 5.222253799438477, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 300, loss: 3.4269566535949707, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 400, loss: 4.5079803466796875, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 500, loss: 5.405309677124023, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 600, loss: 3.4251790046691895, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 700, loss: 5.253219127655029, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 800, loss: 4.914092540740967, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 900, loss: 4.565570831298828, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1000, loss: 6.286650657653809, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1100, loss: 5.363424301147461, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1200, loss: 4.320709705352783, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1300, loss: 4.025515079498291, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1400, loss: 4.506776809692383, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1500, loss: 5.015237808227539, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1600, loss: 3.760085344314575, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1700, loss: 6.521790504455566, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1800, loss: 5.7613205909729, rate: 1.592962260133916e-05\n",
      "[2023-11-17 06:34:35.568878] Epoch: 45 ends. Average loss: 4.889810443516272\n",
      "Epoch: 46 Batch: 0, loss: 5.299592018127441, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 100, loss: 4.716174602508545, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 200, loss: 5.050140380859375, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 300, loss: 3.939318895339966, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 400, loss: 4.536389350891113, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 500, loss: 5.71898889541626, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 600, loss: 4.202922821044922, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 700, loss: 4.9856977462768555, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 800, loss: 4.929326057434082, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 900, loss: 4.702234268188477, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1000, loss: 5.555270195007324, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1100, loss: 5.186245441436768, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1200, loss: 5.191280841827393, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1300, loss: 3.72503662109375, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1400, loss: 5.349634170532227, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1500, loss: 4.980059623718262, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1600, loss: 4.514273643493652, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1700, loss: 6.413564682006836, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1800, loss: 6.169598579406738, rate: 1.5292437697285593e-05\n",
      "[2023-11-17 06:40:41.177258] Epoch: 46 ends. Average loss: 4.883071442302655\n",
      "Epoch: 47 Batch: 0, loss: 5.004708290100098, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 100, loss: 4.813643455505371, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 200, loss: 5.172064304351807, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 300, loss: 3.6205813884735107, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 400, loss: 3.976339340209961, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 500, loss: 5.390369415283203, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 600, loss: 4.672173976898193, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 700, loss: 4.954804420471191, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 800, loss: 4.694537162780762, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 900, loss: 4.879342079162598, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1000, loss: 5.709855079650879, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1100, loss: 4.928034782409668, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1200, loss: 4.506953239440918, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1300, loss: 4.279089450836182, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1400, loss: 4.242011070251465, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1500, loss: 5.174043655395508, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1600, loss: 4.012079238891602, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1700, loss: 6.7541656494140625, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1800, loss: 6.107574462890625, rate: 1.468074018939417e-05\n",
      "[2023-11-17 06:46:43.154797] Epoch: 47 ends. Average loss: 4.865896362924339\n",
      "Epoch: 48 Batch: 0, loss: 5.226559638977051, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 100, loss: 5.403993606567383, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 200, loss: 4.207643508911133, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 300, loss: 3.9183595180511475, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 400, loss: 3.6801748275756836, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 500, loss: 5.259883403778076, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 600, loss: 5.124505996704102, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 700, loss: 6.225633144378662, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 800, loss: 4.8514251708984375, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 900, loss: 4.397818565368652, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1000, loss: 4.910861492156982, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1100, loss: 4.4832658767700195, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1200, loss: 5.8530402183532715, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1300, loss: 4.088550090789795, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1400, loss: 5.492819786071777, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1500, loss: 4.412880897521973, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1600, loss: 4.316514492034912, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1700, loss: 6.438572883605957, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1800, loss: 6.30137825012207, rate: 1.4093510581818402e-05\n",
      "[2023-11-17 06:52:46.575229] Epoch: 48 ends. Average loss: 4.860370693322512\n",
      "Epoch: 49 Batch: 0, loss: 5.801053524017334, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 100, loss: 5.051604270935059, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 200, loss: 5.0279927253723145, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 300, loss: 3.2053632736206055, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 400, loss: 4.16423225402832, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 500, loss: 5.529541969299316, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 600, loss: 4.611290454864502, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 700, loss: 5.826071739196777, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 800, loss: 4.625368595123291, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 900, loss: 4.407214164733887, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1000, loss: 5.230660438537598, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1100, loss: 4.434512615203857, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1200, loss: 4.976459503173828, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1300, loss: 3.7333121299743652, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1400, loss: 4.261533737182617, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1500, loss: 5.585832118988037, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1600, loss: 4.080657005310059, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1700, loss: 6.295178413391113, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1800, loss: 5.405726432800293, rate: 1.3529770158545665e-05\n",
      "[2023-11-17 06:58:43.613852] Epoch: 49 ends. Average loss: 4.833142459819939\n",
      "Epoch: 50 Batch: 0, loss: 6.325552940368652, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 100, loss: 5.127163887023926, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 200, loss: 4.924010753631592, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 300, loss: 3.0366344451904297, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 400, loss: 3.954329013824463, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 500, loss: 5.118645668029785, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 600, loss: 4.492476463317871, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 700, loss: 5.206956386566162, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 800, loss: 5.252387046813965, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 900, loss: 5.214329242706299, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1000, loss: 5.615181922912598, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1100, loss: 4.894713401794434, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1200, loss: 4.6628265380859375, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1300, loss: 4.681317329406738, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1400, loss: 3.6588594913482666, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1500, loss: 4.5244293212890625, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1600, loss: 3.853045701980591, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1700, loss: 6.601863384246826, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1800, loss: 5.593740463256836, rate: 1.2988579352203839e-05\n",
      "[2023-11-17 07:04:43.892320] Epoch: 50 ends. Average loss: 4.838120877907149\n",
      "Epoch: 51 Batch: 0, loss: 5.546993255615234, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 100, loss: 5.003366470336914, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 200, loss: 5.394134998321533, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 300, loss: 3.7857089042663574, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 400, loss: 3.881016254425049, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 500, loss: 5.203150749206543, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 600, loss: 4.964747428894043, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 700, loss: 5.285440444946289, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 800, loss: 4.858813762664795, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 900, loss: 4.5656232833862305, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1000, loss: 5.515786170959473, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1100, loss: 4.836743354797363, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1200, loss: 5.355453968048096, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1300, loss: 4.467085838317871, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1400, loss: 4.105104446411133, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1500, loss: 4.4218902587890625, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1600, loss: 4.239349842071533, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1700, loss: 6.748859405517578, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1800, loss: 5.845800399780273, rate: 1.2469036178115684e-05\n",
      "[2023-11-17 07:10:41.346622] Epoch: 51 ends. Average loss: 4.828267293810121\n",
      "Epoch: 52 Batch: 0, loss: 5.744907855987549, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 100, loss: 5.0187296867370605, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 200, loss: 4.712894439697266, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 300, loss: 3.310593366622925, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 400, loss: 3.607710599899292, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 500, loss: 5.225774765014648, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 600, loss: 5.173723220825195, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 700, loss: 5.604944705963135, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 800, loss: 5.164930820465088, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 900, loss: 4.325376987457275, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1000, loss: 4.997255802154541, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1100, loss: 4.954580783843994, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1200, loss: 4.988753318786621, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1300, loss: 4.065557956695557, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1400, loss: 4.514922142028809, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1500, loss: 4.772531986236572, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1600, loss: 4.350948333740234, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1700, loss: 6.827159881591797, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1800, loss: 5.160210609436035, rate: 1.1970274730991057e-05\n",
      "[2023-11-17 07:16:40.766368] Epoch: 52 ends. Average loss: 4.81011236115049\n",
      "Epoch: 53 Batch: 0, loss: 5.7166666984558105, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 100, loss: 5.184820175170898, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 200, loss: 4.5369648933410645, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 300, loss: 2.865023136138916, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 400, loss: 4.196353912353516, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 500, loss: 4.729308605194092, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 600, loss: 4.017982006072998, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 700, loss: 5.840097427368164, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 800, loss: 5.2391815185546875, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 900, loss: 5.102515697479248, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1000, loss: 4.986421585083008, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1100, loss: 5.683629512786865, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1200, loss: 4.520910263061523, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1300, loss: 4.110996246337891, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1400, loss: 4.708894729614258, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1500, loss: 4.553160190582275, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1600, loss: 4.724878311157227, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1700, loss: 6.210849761962891, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1800, loss: 5.397200584411621, rate: 1.1491463741751414e-05\n",
      "[2023-11-17 07:22:35.449748] Epoch: 53 ends. Average loss: 4.8004407156782785\n",
      "Epoch: 54 Batch: 0, loss: 5.12493371963501, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 100, loss: 5.381346702575684, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 200, loss: 5.122876167297363, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 300, loss: 3.095585823059082, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 400, loss: 4.245652198791504, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 500, loss: 5.813785552978516, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 600, loss: 4.9795241355896, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 800, loss: 4.6600775718688965, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 900, loss: 4.621716022491455, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1000, loss: 5.012836933135986, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1100, loss: 5.537909507751465, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1200, loss: 4.856536388397217, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1300, loss: 4.19584321975708, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1400, loss: 4.457772254943848, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1500, loss: 5.415190696716309, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1600, loss: 4.492399215698242, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1700, loss: 6.759364128112793, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1800, loss: 5.650026798248291, rate: 1.1031805192081357e-05\n",
      "[2023-11-17 07:28:36.225059] Epoch: 54 ends. Average loss: 4.773273810062103\n",
      "Epoch: 55 Batch: 0, loss: 5.682449817657471, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 100, loss: 5.463456153869629, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 200, loss: 5.176635265350342, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 300, loss: 3.164515733718872, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 400, loss: 4.275974273681641, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 500, loss: 5.119668006896973, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 600, loss: 3.9262149333953857, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 700, loss: 5.443591594696045, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 800, loss: 5.280244827270508, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 900, loss: 4.886401653289795, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1000, loss: 5.200161933898926, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1100, loss: 4.727686405181885, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1200, loss: 4.760391712188721, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1300, loss: 4.355639934539795, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1400, loss: 5.5298590660095215, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1500, loss: 5.407115936279297, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1600, loss: 4.271247863769531, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1700, loss: 7.021002769470215, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1800, loss: 5.447946071624756, rate: 1.0590532984398102e-05\n",
      "[2023-11-17 07:34:36.296884] Epoch: 55 ends. Average loss: 4.782237184159478\n",
      "Epoch: 56 Batch: 0, loss: 5.401143550872803, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 100, loss: 5.1750969886779785, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 200, loss: 5.487466335296631, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 300, loss: 2.811756134033203, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 400, loss: 4.235076904296875, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 500, loss: 5.312575340270996, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 600, loss: 4.429988384246826, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 700, loss: 5.215085983276367, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 800, loss: 5.17844295501709, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 900, loss: 4.120718479156494, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1000, loss: 4.479999542236328, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1100, loss: 4.40824556350708, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1200, loss: 4.600289344787598, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1300, loss: 4.406576633453369, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1400, loss: 4.341203689575195, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1500, loss: 5.292694091796875, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1600, loss: 3.9674458503723145, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1700, loss: 6.6458868980407715, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1800, loss: 5.618656158447266, rate: 1.0166911665022178e-05\n",
      "[2023-11-17 07:40:36.384472] Epoch: 56 ends. Average loss: 4.773705182782997\n",
      "Epoch: 57 Batch: 0, loss: 5.671982765197754, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 100, loss: 5.15606164932251, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 200, loss: 4.923871040344238, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 300, loss: 3.1189751625061035, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 400, loss: 3.851804494857788, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 500, loss: 5.205326080322266, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 600, loss: 3.7461318969726562, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 700, loss: 5.201474189758301, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 800, loss: 4.381333351135254, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 900, loss: 4.555888652801514, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1000, loss: 5.407602310180664, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1100, loss: 5.145869731903076, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1200, loss: 5.15199089050293, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1300, loss: 4.498146057128906, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1400, loss: 4.747461318969727, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1500, loss: 5.186181545257568, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1600, loss: 4.5001726150512695, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1700, loss: 6.376809120178223, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1800, loss: 5.561833381652832, rate: 9.76023519842129e-06\n",
      "[2023-11-17 07:46:32.832039] Epoch: 57 ends. Average loss: 4.774925641045673\n",
      "Epoch: 58 Batch: 0, loss: 5.188022136688232, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 100, loss: 4.924114227294922, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 200, loss: 4.6792755126953125, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 300, loss: 3.1932270526885986, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 400, loss: 3.7948694229125977, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 500, loss: 5.213227272033691, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 600, loss: 4.8601603507995605, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 700, loss: 5.155645370483398, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 800, loss: 4.881424903869629, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 900, loss: 4.271346092224121, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1000, loss: 4.000979900360107, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1100, loss: 5.62706995010376, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1200, loss: 4.7149505615234375, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1300, loss: 4.15071439743042, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1400, loss: 3.7214250564575195, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1500, loss: 4.371566295623779, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1600, loss: 4.353105068206787, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1700, loss: 5.861263751983643, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1800, loss: 5.264425277709961, rate: 9.369825790484438e-06\n",
      "[2023-11-17 07:52:32.677840] Epoch: 58 ends. Average loss: 4.728991272169388\n",
      "Epoch: 59 Batch: 0, loss: 5.649021148681641, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 100, loss: 5.366320610046387, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 200, loss: 5.014438152313232, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 300, loss: 3.09399151802063, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 400, loss: 3.952341318130493, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 500, loss: 5.273589134216309, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 600, loss: 4.517724990844727, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 700, loss: 4.83953857421875, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 800, loss: 4.755560874938965, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 900, loss: 4.784071445465088, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1000, loss: 4.69271993637085, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1100, loss: 4.3130598068237305, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1200, loss: 4.477180480957031, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1300, loss: 4.527329444885254, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1400, loss: 4.63920783996582, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1500, loss: 4.216783046722412, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1600, loss: 4.622657775878906, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1700, loss: 7.278587341308594, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1800, loss: 5.728041648864746, rate: 8.99503275886506e-06\n",
      "[2023-11-17 07:58:26.955611] Epoch: 59 ends. Average loss: 4.761996409541918\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    losss_per_e = []\n",
    "    for i, batch in enumerate(dataloader_train):\n",
    "        loss_current = train_a_batch(batch, head, optimizer, None)\n",
    "        losss_per_e.append(loss_current)\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch: {} Batch: {}, loss: {}, rate: {}'.format(e, i, loss_current, optimizer.param_groups[0]['lr']))\n",
    "            # break\n",
    "        # end\n",
    "    # end\n",
    "    \n",
    "    loss_average_per_e = sum(losss_per_e) / len(losss_per_e)\n",
    "    print('[{}] Epoch: {} ends. Average loss: {}'.format(datetime.utcnow(), e, loss_average_per_e))\n",
    "    \n",
    "    lr_scheduler.step() # schedule per epoch\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96eec954-3671-422e-82d2-5dad9edcb702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "head.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df05c45-ed31-4d3f-ab04-ed182c182027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_generate(head, tokenizer, collator, **kwargs):\n",
    "    id_start = tokenizer.id_cls\n",
    "    id_end = tokenizer.id_sep\n",
    "    size_seq_max = collator.size_seq_max\n",
    "\n",
    "    ids_encoder = kwargs['ids_encoder']\n",
    "    masks_encoder = kwargs['masks_encoder']\n",
    "\n",
    "    outputs_encoder = head.model.embed_and_encode(ids_encoder=ids_encoder, masks_encoder=masks_encoder)\n",
    "    ids_decoder = torch.zeros(1, 1).fill_(id_start).type_as(ids_encoder.data)\n",
    "\n",
    "    for i in range(size_seq_max - 1):\n",
    "        masks_decoder = collator.subsequent_mask(ids_decoder.size(1)).type_as(ids_encoder.data)\n",
    "        outputs_decoder = head.model.embed_and_decode(ids_decoder=ids_decoder, masks_encoder=masks_encoder, output_encoder=outputs_encoder, masks_decoder=masks_decoder)\n",
    "        outputs_ffn = head.ffn(outputs_decoder)\n",
    "        outputs_s2s = head.extractor(outputs_ffn)   # outputs_mlm = prediction_logits\n",
    "\n",
    "        logits_nextword = torch.softmax(outputs_s2s[:, -1], dim=-1)  # mynote: select dim2=-1, remain=all; last is the next\n",
    "        \n",
    "        id_nextword = torch.argmax(logits_nextword, dim=-1)\n",
    "        id_nextword = id_nextword.data[0]\n",
    "\n",
    "        if id_nextword == id_end:\n",
    "            break\n",
    "        # end\n",
    "\n",
    "        ids_decoder = torch.cat([ids_decoder, torch.zeros(1, 1).type_as(ids_encoder.data).fill_(id_nextword)], dim=1)\n",
    "    # end\n",
    "\n",
    "    return ids_decoder\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8928d0f4-eefa-4796-a421-066a330b7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: A group of men are loading cotton onto a truck [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A group of people are loading cotton candy truck truck\n",
      "\n",
      "\n",
      "source: A man sleeping in a green room on a couch . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A man standing in a green shirt on a bench .\n",
      "\n",
      "\n",
      "source: A boy wearing headphones sits on a woman 's shoulders . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A boy wearing headphones sits sits a woman 's shoulders .\n",
      "\n",
      "\n",
      "source: Two men setting up a blue ice fishing hut on an iced over lake [SEP] [PAD]\n",
      "target: [CLS] Two women setting up a blue ice fishing hut on an object over over\n",
      "\n",
      "\n",
      "source: A balding man wearing a red life jacket is sitting in a small boat [SEP] [PAD]\n",
      "target: [CLS] A young man wearing a black jacket jacket is sitting in a small small\n",
      "\n",
      "\n",
      "source: A lady in a red coat , holding a <unk> hand bag likely of [SEP] [PAD]\n",
      "target: [CLS] A woman in a red coat , holding a microphone in a space of\n",
      "\n",
      "\n",
      "source: A brown dog is running after the black dog . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A brown dog is running after a black dog .\n",
      "\n",
      "\n",
      "source: A young boy wearing a <unk> jersey swings a baseball bat at an incoming [SEP] [PAD]\n",
      "target: [CLS] A young boy wearing a <unk> jersey and a baseball bat at a ball\n",
      "\n",
      "\n",
      "source: A man in a cluttered office is using the telephone [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A man in in office office is using the telephone\n",
      "\n",
      "\n",
      "source: A smiling woman in a peach tank top stands holding a mountain bike [SEP] [PAD] [PAD]\n",
      "target: [CLS] A smiling woman in a purple tank top stands holding a mountain .\n",
      "\n",
      "\n",
      "source: A young child is standing alone on some jagged rocks . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A young man is standing alone on a ravine rocks .\n",
      "\n",
      "\n",
      "source: A person on a snowmobile in mid jump . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A person on a hillside in mid jump .\n",
      "\n",
      "\n",
      "source: Three young children stand around a blue and white barrel . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] Three young women stand around a table and white barrel .\n",
      "\n",
      "\n",
      "source: A woman is sitting by her dried flower display at an outside market . [SEP] [PAD]\n",
      "target: [CLS] A man is sitting sitting at flower flower display at an outside market .\n",
      "\n",
      "\n",
      "source: A female playing a song on her violin . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A female playing a book on her violin .\n",
      "\n",
      "\n",
      "source: Three people on two dirt - bikes and one four - wheeler are riding [SEP] [PAD]\n",
      "target: [CLS] Two men , two dirt - shirt and one four - wheeler are riding\n",
      "\n",
      "\n",
      "source: A half naked man is sleeping on his chair outdoors . [SEP] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A half naked man is sleeping on his chair chair .\n",
      "\n",
      "\n",
      "source: A group of people standing in front of a hut in a parking lot [SEP] [PAD]\n",
      "target: [CLS] A group of people standing in front of a hut in a parking lot\n",
      "\n",
      "\n",
      "source: A young woman is making rugs in the rain forest [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "target: [CLS] A young woman is cleans her in the background .\n",
      "\n",
      "\n",
      "source: Three girls make faces as one takes a drink while they stand in a [SEP] [PAD]\n",
      "target: [CLS] Three women make faces faces takes takes a drink while they stand in a\n",
      "\n",
      "\n",
      "source: A single man in a black t - shirt standing above the crowd at [SEP] [PAD]\n",
      "target: [CLS] A young man wearing a black t - shirt standing above above a at\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_source = to_map_style_dataset(valid_iter)\n",
    "dataloader_eval = DataLoader(eval_source, 1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "for i, batch in enumerate(dataloader_eval):\n",
    "    info_batch = batch()\n",
    "    result = greedy_generate(head, tokenizer, collator, **info_batch)\n",
    "    sentence_predicted = tokenizer.decode(result.cpu().tolist()[0])\n",
    "    sentence_origin = tokenizer.decode(info_batch['labels_decoder'].cpu().tolist()[0])\n",
    "    print('source: {}\\ntarget: {}\\n\\n'.format(sentence_origin, sentence_predicted))\n",
    "    if i >= 20:\n",
    "        break\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68df3a99-6f6a-4fee-8e7a-c9ffc168e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_source = to_map_style_dataset(valid_iter)\n",
    "# dataloader_eval = DataLoader(eval_source, 1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "# for i, batch in enumerate(dataloader_eval):\n",
    "#     info_batch = batch()\n",
    "#     output_s2s, loss_s2s = head.forward(**info_batch)\n",
    "#     preds_s2s = torch.argmax(output_s2s,dim=-1)\n",
    "    \n",
    "#     sentence_predicted = tokenizer.decode(preds_s2s.cpu().tolist()[0])\n",
    "#     sentence_origin = tokenizer.decode(info_batch['labels_decoder'].cpu().tolist()[0])\n",
    "#     print('source: {}\\ntarget: {}\\n\\n'.format(sentence_origin, sentence_predicted))\n",
    "#     if i >= 0:\n",
    "#         break\n",
    "#     # end\n",
    "# # end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edcc3bec-6f6c-4dfc-bb43-78bf90d4ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_encoder = info_batch['ids_encoder']\n",
    "# masks_encoder = info_batch['masks_encoder']\n",
    "\n",
    "# outputs_encoder = head.model.embed_and_encode(ids_encoder=ids_encoder, masks_encoder=masks_encoder)\n",
    "# ids_decoder = torch.zeros(1, 1).fill_(tokenizer.id_cls).type_as(ids_encoder.data)\n",
    "# masks_decoder = collator.subsequent_mask(ids_decoder.size(1)).type_as(ids_encoder.data)\n",
    "\n",
    "# outputs_decoder = head.model.embed_and_decode(ids_decoder=ids_decoder, masks_encoder=masks_encoder, output_encoder=outputs_encoder, masks_decoder=masks_decoder)\n",
    "# outputs_ffn = head.ffn(outputs_decoder)\n",
    "# outputs_s2s = head.extractor(head.ffn(outputs_ffn))   # outputs_mlm = prediction_logits\n",
    "# preds_s2s = torch.argmax(output_s2s,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca7e1e-a7f5-467d-8014-39caad933ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_predicted = tokenizer.decode(preds_s2s.cpu().tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d7ff89-5636-47f8-9a06-85654a1e2da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
