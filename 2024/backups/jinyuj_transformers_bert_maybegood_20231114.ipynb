{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a36c05-aa20-4909-a5e9-a172529e22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from os.path import exists\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad, one_hot\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "### utils.py ###\n",
    "\n",
    "class Dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "# end\n",
    "\n",
    "### utils.py ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### core.py ###\n",
    "\n",
    "\"Produce N identical layers.\"\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "\n",
    "    \"Take in model size and number of heads.\"\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    # end\n",
    "\n",
    "\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    def attention(self, query, key, value, mask=None, dropout=None):\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        # end\n",
    "        p_attn = scores.softmax(dim=-1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        # end\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "    # end\n",
    "\n",
    "\n",
    "    \"Implements Figure 2\"\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = self.attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (\n",
    "            x.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)\n",
    "    # end\n",
    "# end class\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A residual connection followed by a layer norm.\n",
    "Note for code simplicity the norm is first as opposed to last.\n",
    "\"\"\"\n",
    "class ResidualLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, size, dropout=0.1, eps=1e-6):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.norm = torch.nn.LayerNorm(size, eps)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    # end\n",
    "\n",
    "    \"Apply residual connection to any sublayer with the same size.\"\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    # end\n",
    "# end class\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleIDEmbeddings(nn.Module):\n",
    "    def __init__(self, size_vocab, dim_hidden, id_pad):\n",
    "        super(SimpleIDEmbeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(size_vocab, dim_hidden, padding_idx=id_pad)\n",
    "        self.dim_hidden = dim_hidden\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.lut(x)\n",
    "        return result * math.sqrt(self.dim_hidden)\n",
    "    # end\n",
    "\n",
    "    def get_shape(self):\n",
    "        return (self.lut.num_embeddings, self.lut.embedding_dim)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\"Implement the PE function.\"\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_positional, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.dim_positional = dim_positional\n",
    "        pe = torch.zeros(max_len, dim_positional)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, dim_positional, 2) * -(math.log(10000.0) / dim_positional)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).to('cuda')\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return x\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleEmbedder(nn.Module):    # no segment embedder as we do not need that\n",
    "    def __init__(self, size_vocab=None, dim_hidden=128, dropout=0.1, id_pad=0):\n",
    "        super(SimpleEmbedder, self).__init__()\n",
    "        self.size_vocab = size_vocab\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.id_pad = id_pad\n",
    "\n",
    "        self.embedder = nn.Sequential(\n",
    "            SimpleIDEmbeddings(size_vocab, dim_hidden, id_pad),\n",
    "            PositionalEncoding(dim_hidden),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    def forward(self, ids_input):   # (batch, seqs_with_padding)\n",
    "        return self.embedder(ids_input)\n",
    "    # end\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.size_vocab\n",
    "    # end\n",
    "# end\n",
    "\n",
    "### core.py ###\n",
    "\n",
    "\n",
    "\n",
    "class SimpleEncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, dim_feedforward, n_head, dropout=0.1):\n",
    "        super(SimpleEncoderLayer, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.layer_attention = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_feedforward = PositionwiseFeedForward(dim_hidden, dim_feedforward, dropout)\n",
    "        self.layers_residual = clones(ResidualLayer(dim_hidden, dropout), 2)\n",
    "    # end\n",
    "\n",
    "    def forward(self, embeddings, masks, *args):\n",
    "        embeddings = self.layers_residual[0](embeddings, lambda embeddings: self.layer_attention(embeddings, embeddings, embeddings, masks))\n",
    "        return self.layers_residual[1](embeddings, self.layer_feedforward)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "class SimpleDecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_hidden, dim_feedforward, n_head, dropout=0.1):\n",
    "        super(SimpleDecoderLayer, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "        self.layer_attention_decoder = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_attention_encoder = MultiHeadedAttention(n_head, dim_hidden)\n",
    "        self.layer_feedforward = PositionwiseFeedForward(dim_hidden, dim_feedforward, dropout)\n",
    "        self.layers_residual = clones(ResidualLayer(dim_hidden, dropout), 3)\n",
    "\n",
    "    def forward(self, embeddings, masks_decoder, output_encoder, masks_encoder, *args):\n",
    "        embeddings = self.layers_residual[0](embeddings, lambda embeddings: self.layer_attention_decoder(embeddings, embeddings, embeddings, masks_decoder))\n",
    "        embeddings = self.layers_residual[1](embeddings, lambda embeddings: self.layer_attention_encoder(embeddings, output_encoder, output_encoder, masks_encoder))\n",
    "        return self.layers_residual[2](embeddings, self.layer_feedforward)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleTransformerStack(nn.Module):\n",
    "\n",
    "    def __init__(self, obj_layer, n_layers):\n",
    "        super(SimpleTransformerStack, self).__init__()\n",
    "        self.layers = clones(obj_layer, n_layers)\n",
    "\n",
    "        self.norm = torch.nn.LayerNorm(obj_layer.dim_hidden)\n",
    "        self.keys_cache = ['output']\n",
    "        self.cache = Dotdict({\n",
    "            'outputs': None\n",
    "        })\n",
    "    # end\n",
    "\n",
    "    def forward(self, embedding_encoder=None, masks_encoder=None, output_encoder=None, embedding_decoder=None, masks_decoder=None ,noncache=False, **kwargs):  # input -> (batch, len_seq, vocab)\n",
    "\n",
    "        if output_encoder is not None and embedding_decoder is not None and masks_decoder is not None:\n",
    "            embeddings = embedding_decoder\n",
    "        else:\n",
    "            embeddings = embedding_encoder\n",
    "        # end\n",
    "\n",
    "        for layer in self.layers:\n",
    "            embeddings = layer(embeddings, masks_encoder, output_encoder, masks_decoder)\n",
    "        # end\n",
    "\n",
    "        outputs = self.norm(embeddings)\n",
    "\n",
    "        if not noncache:\n",
    "            self.cache.outputs = outputs\n",
    "        # end\n",
    "\n",
    "        return outputs\n",
    "    # end\n",
    "\n",
    "    # def get_vocab_size(self):\n",
    "    #     return self.embedder.embedder_token.shape[-1]\n",
    "    # # end\n",
    "\n",
    "    def clear_cache(self):\n",
    "        for key_cache in self.keys_cache:\n",
    "            self.cache[key_cache] = None\n",
    "        # end\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class SimpleEncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, embedder_encoder, embedder_decoder):\n",
    "        super(SimpleEncoderDecoder, self).__init__()\n",
    "\n",
    "        self.embedder_encoder = embedder_encoder\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.embedder_decoder = embedder_decoder\n",
    "        self.decoder = decoder\n",
    "    # end\n",
    "\n",
    "    def forward(self, ids_encoder=None, masks_encoder=None, ids_decoder=None, masks_decoder=None, nocache=False, **kwargs):\n",
    "        self.clear_cache()\n",
    "\n",
    "        embedding_encoder = self.embedder_encoder(ids_encoder)\n",
    "        output_encoder = self.encoder(\n",
    "            embedding_encoder=embedding_encoder,\n",
    "            masks_encoder=masks_encoder,\n",
    "            nocache=nocache\n",
    "        )\n",
    "        \n",
    "        output = output_encoder\n",
    "        \n",
    "        if self.embedder_decoder and self.decoder:\n",
    "            embedding_decoder = self.embedder_decoder(ids_decoder)\n",
    "            output_decoder = self.decoder(\n",
    "                masks_encoder=masks_encoder,\n",
    "                output_encoder=output_encoder,\n",
    "                embedding_decoder=embedding_decoder,\n",
    "                masks_decoder=masks_decoder,\n",
    "                nocache=nocache\n",
    "            )\n",
    "            \n",
    "            output = output_decoder\n",
    "        # end if\n",
    "        \n",
    "        return output\n",
    "    # end\n",
    "\n",
    "    def clear_cache(self):\n",
    "        self.encoder.clear_cache()\n",
    "        if self.decoder:\n",
    "            self.decoder.clear_cache()\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def get_vocab_size(self, name_embedder):\n",
    "        embedder = getattr(self, f'embedder_{name_embedder}')\n",
    "        return embedder.get_vocab_size()\n",
    "    # end\n",
    "\n",
    "# end\n",
    "\n",
    "class LinearAndNorm(nn.Module):\n",
    "    def __init__(self, dim_in = None, dim_out = None, eps_norm=1e-12):\n",
    "        super(LinearAndNorm, self).__init__()\n",
    "\n",
    "        self.linear = torch.nn.Linear(dim_in, dim_out)\n",
    "        self.norm = torch.nn.LayerNorm(dim_out, eps_norm)\n",
    "    # end\n",
    "\n",
    "    def forward(self, seqs_in):\n",
    "        return self.norm(self.linear(seqs_in).relu())\n",
    "    # end\n",
    "# end\n",
    "\n",
    "# class LinearAndNorm(nn.Module):\n",
    "#     def __init__(self, dim_in = None, dim_out = None, eps_norm=1e-12):\n",
    "#         super(LinearAndNorm, self).__init__()\n",
    "\n",
    "#         self.linear = torch.nn.Linear(dim_in, dim_out)\n",
    "#         self.norm = torch.nn.LayerNorm(dim_out, eps_norm)\n",
    "#         self.activation = torch.nn.GELU()\n",
    "#     # end\n",
    "\n",
    "#     def forward(self, seqs_in):\n",
    "#         return self.norm(self.activation(self.linear(seqs_in)))\n",
    "#     # end\n",
    "# # end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, vocab, splitter):\n",
    "        self.splitter = splitter\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.id_pad = len(vocab)\n",
    "        self.id_cls = len(vocab) + 1\n",
    "        self.id_sep = len(vocab) + 2\n",
    "        self.id_mask = len(vocab) + 3\n",
    "        \n",
    "        self.size_vocab = len(vocab) + 4\n",
    "\n",
    "        self.token_pad = '[PAD]'\n",
    "        self.token_cls = '[CLS]'\n",
    "        self.token_sep = '[SEP]'\n",
    "        self.token_mask = '[MASK]'\n",
    "           \n",
    "        self.index_id_token_special = {\n",
    "            self.id_pad: self.token_pad,\n",
    "            self.id_cls: self.token_cls,\n",
    "            self.id_sep: self.token_sep,\n",
    "            self.id_mask: self.token_mask\n",
    "        }\n",
    "        \n",
    "    # end\n",
    "\n",
    "    def encode(self, line):\n",
    "        return self.vocab([doc.text for doc in self.splitter(line)])\n",
    "    # end\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        words = []\n",
    "        for token in tokens:\n",
    "            token = int(token)\n",
    "            \n",
    "            if token in self.index_id_token_special:\n",
    "                word_target = self.index_id_token_special[token]\n",
    "            else:\n",
    "                try:\n",
    "                    word_target = vocab.lookup_token(token)\n",
    "                except:\n",
    "                    word_target = '[ERROR_LOOKUP_{}]'.format(token)\n",
    "                # end\n",
    "            # end\n",
    "            \n",
    "            words.append(word_target)\n",
    "        # end\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "class Batch:\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        for k, v in kwargs.items():\n",
    "            self.kwargs[k] = v.to(Batch.DEVICE)\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.kwargs\n",
    "    # end\n",
    "# end\n",
    "\n",
    "\n",
    "class Collator_S2S:\n",
    "\n",
    "    def __init__(self, tokenizer, size_seq_max):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size_seq_max = size_seq_max\n",
    "    # end\n",
    "    \n",
    "\n",
    "    def __call__(self, list_corpus_source):\n",
    "\n",
    "        tokens_input_encoder = []\n",
    "        tokens_input_decoder = []\n",
    "        tokens_label_decoder = []\n",
    "        labels_similarity = []\n",
    "\n",
    "        for corpus_source in list_corpus_source: # (line0, line1, sim), output of zip remove single case\n",
    "            if len(corpus_source) == 3:\n",
    "                corpus_line = [courpus_source[0], corpus_source[1]]\n",
    "                labels_similarity.append(corpus_line[2])\n",
    "            else:\n",
    "                corpus_line = [corpus_source[1]]\n",
    "            # end\n",
    "            \n",
    "            for line in corpus_line:\n",
    "                tokens = self.tokenizer.encode(line)\n",
    "\n",
    "                # TODO: check edge\n",
    "                if len(tokens) > self.size_seq_max - 2:\n",
    "                    tokens = tokens[:self.size_seq_max-2]\n",
    "                # end\n",
    "\n",
    "                tokens_input_encoder.append([self.tokenizer.id_cls] + tokens + [self.tokenizer.id_sep])\n",
    "                tokens_input_decoder.append([self.tokenizer.id_cls] + tokens)\n",
    "                tokens_label_decoder.append(tokens + [self.tokenizer.id_sep])\n",
    "            # end\n",
    "            \n",
    "\n",
    "        # end\n",
    "\n",
    "        inputs_encoder, masks_encoder, segments_encoder, labels_encoder = self.pad_sequences(tokens_input_encoder, self.size_seq_max, need_masked=0.3)\n",
    "        inputs_decoder, masks_decoder, segments_decoder = self.pad_sequences(tokens_input_decoder, self.size_seq_max, need_diagonal=True)\n",
    "        labels_decoder, masks_label, segments_label = self.pad_sequences(tokens_label_decoder, self.size_seq_max)\n",
    "        # labels_similarity = torch.Tensor(labels_similarity).unsqueeze(0).transpose(0,1)\n",
    "        labels_similarity = torch.Tensor(labels_similarity)\n",
    "\n",
    "        return Batch(\n",
    "            ids_encoder=inputs_encoder,  # contains [mask]s\n",
    "            masks_encoder=masks_encoder,\n",
    "            labels_encoder=labels_encoder,  # doesn't contain [mask]\n",
    "            segments_encoder=segments_encoder,\n",
    "            ids_decoder=inputs_decoder,\n",
    "            masks_decoder=masks_decoder,\n",
    "            labels_decoder=labels_decoder,\n",
    "            segments_label=segments_label,\n",
    "            labels_similarity=labels_similarity\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    \n",
    "    # return masks_attention?, return masks_segment?\n",
    "    def pad_sequences(self, sequences, size_seq_max, need_diagonal=False, need_masked=0): # need_diagonal and need_masked cannot both set, one for bert seq one for s2s seq\n",
    "        id_pad = self.tokenizer.id_pad\n",
    "        id_mask = self.tokenizer.id_mask\n",
    "\n",
    "        sequences_padded = []\n",
    "        sequences_masked_padded = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            len_seq = len(sequence)\n",
    "\n",
    "            count_pad = size_seq_max - len_seq\n",
    "\n",
    "            sequence = torch.LongTensor(sequence)\n",
    "            sequence_padded = torch.cat((sequence, torch.LongTensor([id_pad] * count_pad)))\n",
    "            sequences_padded.append(sequence_padded)\n",
    "\n",
    "            if need_masked:\n",
    "                index_masked = list(range(1, len_seq-1))\n",
    "                random.shuffle(index_masked)\n",
    "                index_masked = torch.LongTensor(index_masked[:int(need_masked * (len_seq-2))])\n",
    "\n",
    "                sequence_masked = sequence.detach().clone()\n",
    "                sequence_masked.index_fill_(0, index_masked, id_mask)\n",
    "                sequence_masked_padded = torch.cat((sequence_masked, torch.LongTensor([id_pad] * count_pad)))\n",
    "                \n",
    "                sequences_masked_padded.append(sequence_masked_padded)\n",
    "            # end\n",
    "    #   # end for\n",
    "\n",
    "        inputs = torch.stack(sequences_padded)  # (batch, size_seq_max)\n",
    "        if need_masked:\n",
    "            inputs_masked_padded = torch.stack(sequences_masked_padded)\n",
    "        # end\n",
    "\n",
    "        masks_segment = (inputs != self.tokenizer.id_pad).unsqueeze(-2).expand(inputs.shape[0], inputs.shape[-1], inputs.shape[-1]) #(nbatch, seq, seq)\n",
    "        masks_attention = self.make_std_mask(inputs, self.tokenizer.id_pad) if need_diagonal else masks_segment\n",
    "\n",
    "        if need_masked:\n",
    "            masks_masked = (inputs_masked_padded != id_mask).unsqueeze(-2).expand(inputs.shape[0], inputs.shape[-1], inputs.shape[-1])\n",
    "            masks_attention = masks_attention & masks_masked\n",
    "            return inputs_masked_padded, masks_attention, masks_segment, inputs # (inputs, masks_attention, masks_segment, labels)\n",
    "        else:\n",
    "            return inputs, masks_attention, masks_segment\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def subsequent_mask(self, size):\n",
    "        \"Mask out subsequent positions.\"\n",
    "        attn_shape = (1, size, size)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        return subsequent_mask == 0\n",
    "\n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & self.subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "    # end\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51933c37-2474-4ea8-8819-d67e8061c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "def Multi30k(language_pair=None):\n",
    "    corpus_lines_train = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/train.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_train.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_train = list(zip(*corpus_lines_train))\n",
    "\n",
    "    corpus_lines_eval = []\n",
    "\n",
    "    for lan in language_pair:\n",
    "        with open('text/val.{}'.format(lan), 'r') as file:\n",
    "            corpus_lines_eval.append(file.read().splitlines())\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "    corpus_eval = list(zip(*corpus_lines_eval))\n",
    "\n",
    "    return corpus_train, corpus_eval, None\n",
    "# end\n",
    "\n",
    "\n",
    "def load_vocab(spacy_en):\n",
    "    if not os.path.exists(\"vocab.pt\"):\n",
    "        vocab_tgt = build_vocabulary(spacy_en)\n",
    "        torch.save(vocab_tgt, \"vocab.pt\")\n",
    "    else:\n",
    "        vocab_tgt = torch.load(\"vocab.pt\")\n",
    "    print(\"Finished.\\nVocabulary sizes: {}\".format(len(vocab_tgt)))\n",
    "    return vocab_tgt\n",
    "# end\n",
    "\n",
    "def load_spacy():\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except IOError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    return spacy_en\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a19d7c-9560-46c2-a207-d0dc65c8456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoderHead_MLM(nn.Module):\n",
    "\n",
    "    def __init__(self, model, size_vocab, dim_hidden=128):\n",
    "        super(SimpleEncoderHead_MLM, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        self.ffn = LinearAndNorm(dim_in=dim_hidden, dim_out=dim_hidden)\n",
    "        self.extractor = torch.nn.Linear(dim_hidden, size_vocab, bias=False)\n",
    "        \n",
    "        self.extractor.weight = nn.Parameter(model.embedder_encoder.embedder[0].lut.weight)\n",
    "        self.func_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self, **kwargs):   # labels_input -> (batch, seq, labels)\n",
    "        labels_mlm = kwargs['labels_encoder']\n",
    "        \n",
    "        outputs_encoder = self.model(**kwargs)\n",
    "        outputs_ffn = self.ffn(outputs_encoder)\n",
    "        outputs_mlm = self.extractor(outputs_ffn) # outputs_mlm = prediction_logits\n",
    "        \n",
    "        segments_encoder = kwargs['segments_encoder']        \n",
    "        segments_encoder_2d = segments_encoder.transpose(-1,-2)[:,:,0]\n",
    "\n",
    "        # loss_segments = self.func_loss(outputs_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(segments_encoder_2d)) / segments_encoder_2d.reshape(-1).shape[0]\n",
    "        loss_segments = self.func_loss(outputs_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(segments_encoder_2d))\n",
    "        \n",
    "        masks_encoder = kwargs['masks_encoder']\n",
    "        masks_masked = torch.logical_xor(masks_encoder, segments_encoder) & segments_encoder # True is masked\n",
    "        masks_masked_perbatch = masks_masked[:,0,:]\n",
    "        # loss_masked = self.func_loss(outputs_mlm.masked_select(masks_masked_perbatch.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(masks_masked_perbatch)) / masks_masked_perbatch.reshape(-1).shape[0]\n",
    "        loss_masked = self.func_loss(outputs_mlm.masked_select(masks_masked_perbatch.unsqueeze(-1)).reshape(-1, outputs_mlm.shape[-1]), labels_mlm.masked_select(masks_masked_perbatch))       \n",
    "        \n",
    "        # loss_mlm = loss_segments + loss_masked * 3\n",
    "        loss_mlm = loss_segments\n",
    "        \n",
    "\n",
    "        # loss_mlm = loss_mlm / labels_mlm.view(-1).shape[0]\n",
    "        \n",
    "        return outputs_mlm, loss_mlm\n",
    "    # end\n",
    "\n",
    "    def evaluate(self, **kwargs):\n",
    "        pass\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5dae215-cabb-49ee-9f29-961118e61225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Builder:\n",
    "    \n",
    "    @classmethod\n",
    "    def build_model_with_mlm(cls, size_vocab, dim_hidden, dim_feedforward, n_head, n_layer):\n",
    "        embedder_encoder = SimpleEmbedder(size_vocab=size_vocab, dim_hidden=dim_hidden)\n",
    "        sample_encoder = SimpleEncoderLayer(dim_hidden, dim_feedforward, n_head)\n",
    "        encoderstack = SimpleTransformerStack(sample_encoder, n_layer)\n",
    "\n",
    "        model = SimpleEncoderDecoder(encoderstack, None, embedder_encoder, None)\n",
    "        head_mlm = SimpleEncoderHead_MLM(model, size_vocab, dim_hidden)\n",
    "\n",
    "        return head_mlm\n",
    "    # end\n",
    "\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d4f488-2dbb-4322-8ba1-a3ea476b7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(step, model_size, factor, warmup):\n",
    "    \"\"\"\n",
    "    we have to default the step to 1 for LambdaLR function\n",
    "    to avoid zero raising to negative power.\n",
    "    \"\"\"\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    # end\n",
    "    \n",
    "    rate_final = factor * (model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5)))\n",
    "    # print('jinyuj: rate_final: {}'.format(rate_final))\n",
    "    return rate_final\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60b018b-b983-4755-90ce-c07976ccde1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes: 6191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "\n",
    "gpu = 0\n",
    "torch.cuda.set_device(gpu)\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "# source\n",
    "seq_max = 16\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# model & head\n",
    "dim_hidden = 512\n",
    "dim_feedforward = 512\n",
    "n_head = 8\n",
    "n_layer = 4\n",
    "\n",
    "# optimizer\n",
    "lr_base_optimizer = 5e-4\n",
    "betas_optimizer = (0.9, 0.999)\n",
    "eps_optimizer = 1e-9\n",
    "\n",
    "# scheduler\n",
    "warmup = 200\n",
    "\n",
    "spacy_en = load_spacy()\n",
    "vocab = load_vocab(spacy_en)\n",
    "tokenizer = TokenizerWrapper(vocab, spacy_en)\n",
    "\n",
    "train_iter, valid_iter, _ = Multi30k(language_pair=(\"de\", \"en\"))\n",
    "train_source = to_map_style_dataset(train_iter)\n",
    "\n",
    "collator = Collator_S2S(tokenizer, seq_max)\n",
    "dataloader_train = DataLoader(train_source, batch_size, shuffle=False, collate_fn=collator)\n",
    "\n",
    "head = Builder.build_model_with_mlm(tokenizer.size_vocab, dim_hidden, dim_feedforward, n_head, n_layer)\n",
    "\n",
    "for p in head.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "    # end\n",
    "# end\n",
    "\n",
    "head = head.to('cuda')\n",
    "\n",
    "### if \n",
    "# optimizer = torch.optim.AdamW(head.parameters(), lr=5e-5, betas=betas_optimizer, weight_decay=0.01)\n",
    "# lr_scheduler = transformers.get_scheduler(\n",
    "#     name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=1812 * batch_size * epochs\n",
    "# )\n",
    "### elseif:\n",
    "optimizer = torch.optim.Adam(head.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "decayRate = 0.96\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decayRate)\n",
    "\n",
    "\n",
    "### else:\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     head.parameters(), lr=lr_base_optimizer, betas=betas_optimizer, eps=eps_optimizer, weight_decay=0.01\n",
    "# )\n",
    "\n",
    "# lr_scheduler = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b499ec3-35e4-49c7-952d-5e58d0b899f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_a_batch(batch, head, optimizer=None, scheduler=None):\n",
    "    head.train()\n",
    "    _, loss_mlm = head.forward(**batch())    # save to cache\n",
    "\n",
    "    # crossentropy loss\n",
    "    \n",
    "    loss_all = loss_mlm\n",
    "    loss_all_value = loss_all.item()\n",
    "    \n",
    "    # print(loss_all)\n",
    "    loss_all.backward()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
    "\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    # end\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    # end\n",
    "    # manager.clear_cache()\n",
    "    return loss_all_value\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcf19d1-b502-4a47-99dc-66bf2b071347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Batch: 0, loss: 8.851143836975098, rate: 0.0001\n",
      "Epoch: 0 Batch: 50, loss: 5.530648231506348, rate: 0.0001\n",
      "Epoch: 0 Batch: 100, loss: 4.62185525894165, rate: 0.0001\n",
      "Epoch: 0 Batch: 150, loss: 3.911573886871338, rate: 0.0001\n",
      "Epoch: 0 Batch: 200, loss: 3.7398078441619873, rate: 0.0001\n",
      "Epoch: 0 Batch: 250, loss: 3.541797637939453, rate: 0.0001\n",
      "Epoch: 0 Batch: 300, loss: 2.5278401374816895, rate: 0.0001\n",
      "Epoch: 0 Batch: 350, loss: 2.8547956943511963, rate: 0.0001\n",
      "Epoch: 0 Batch: 400, loss: 2.6133487224578857, rate: 0.0001\n",
      "Epoch: 0 Batch: 450, loss: 2.642364978790283, rate: 0.0001\n",
      "Epoch: 0 Batch: 500, loss: 3.1446545124053955, rate: 0.0001\n",
      "Epoch: 0 Batch: 550, loss: 3.0680181980133057, rate: 0.0001\n",
      "Epoch: 0 Batch: 600, loss: 2.2598137855529785, rate: 0.0001\n",
      "Epoch: 0 Batch: 650, loss: 2.5208895206451416, rate: 0.0001\n",
      "Epoch: 0 Batch: 700, loss: 2.8243205547332764, rate: 0.0001\n",
      "Epoch: 0 Batch: 750, loss: 2.414879083633423, rate: 0.0001\n",
      "Epoch: 0 Batch: 800, loss: 2.512554168701172, rate: 0.0001\n",
      "Epoch: 0 Batch: 850, loss: 2.3818306922912598, rate: 0.0001\n",
      "Epoch: 0 Batch: 900, loss: 2.561695098876953, rate: 0.0001\n",
      "Epoch: 0 Batch: 950, loss: 2.724987506866455, rate: 0.0001\n",
      "Epoch: 0 Batch: 1000, loss: 2.6371898651123047, rate: 0.0001\n",
      "Epoch: 0 Batch: 1050, loss: 2.38698410987854, rate: 0.0001\n",
      "Epoch: 0 Batch: 1100, loss: 2.445300817489624, rate: 0.0001\n",
      "Epoch: 0 Batch: 1150, loss: 2.45257306098938, rate: 0.0001\n",
      "Epoch: 0 Batch: 1200, loss: 2.4496283531188965, rate: 0.0001\n",
      "Epoch: 0 Batch: 1250, loss: 2.1940762996673584, rate: 0.0001\n",
      "Epoch: 0 Batch: 1300, loss: 2.1652328968048096, rate: 0.0001\n",
      "Epoch: 0 Batch: 1350, loss: 2.267777919769287, rate: 0.0001\n",
      "Epoch: 0 Batch: 1400, loss: 2.17867112159729, rate: 0.0001\n",
      "Epoch: 0 Batch: 1450, loss: 2.7161102294921875, rate: 0.0001\n",
      "Epoch: 0 Batch: 1500, loss: 2.5303826332092285, rate: 0.0001\n",
      "Epoch: 0 Batch: 1550, loss: 2.494194269180298, rate: 0.0001\n",
      "Epoch: 0 Batch: 1600, loss: 2.617734432220459, rate: 0.0001\n",
      "Epoch: 0 Batch: 1650, loss: 2.6283607482910156, rate: 0.0001\n",
      "Epoch: 0 Batch: 1700, loss: 2.6286628246307373, rate: 0.0001\n",
      "Epoch: 0 Batch: 1750, loss: 2.429723024368286, rate: 0.0001\n",
      "Epoch: 0 Batch: 1800, loss: 2.4356701374053955, rate: 0.0001\n",
      "[2023-11-13 09:28:04.409625] Epoch: 0 ends. Average loss: 2.835965947229035\n",
      "Epoch: 1 Batch: 0, loss: 2.409236192703247, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 50, loss: 2.2202417850494385, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 100, loss: 2.512802839279175, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 150, loss: 2.3824639320373535, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 200, loss: 2.5511879920959473, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 250, loss: 2.41491436958313, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 300, loss: 1.6261601448059082, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 350, loss: 2.3078572750091553, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 400, loss: 2.1386897563934326, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 450, loss: 2.2158937454223633, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 500, loss: 2.787692070007324, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 550, loss: 2.698530912399292, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 600, loss: 1.901190996170044, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 650, loss: 2.371750831604004, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 700, loss: 2.5246448516845703, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 750, loss: 2.186676263809204, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 800, loss: 2.3680479526519775, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 850, loss: 2.240764856338501, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 900, loss: 2.4340524673461914, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 950, loss: 2.5758697986602783, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1000, loss: 2.5403261184692383, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1050, loss: 2.31089186668396, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1100, loss: 2.4200026988983154, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1150, loss: 2.3979079723358154, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1200, loss: 2.4684600830078125, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1250, loss: 2.1977579593658447, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1300, loss: 2.1374671459198, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1350, loss: 2.258385181427002, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1400, loss: 1.9703714847564697, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1450, loss: 2.608314275741577, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1500, loss: 2.516655921936035, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1550, loss: 2.4011878967285156, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1600, loss: 2.5660600662231445, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1650, loss: 2.6720447540283203, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1700, loss: 2.6152305603027344, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1750, loss: 2.409160614013672, rate: 9.6e-05\n",
      "Epoch: 1 Batch: 1800, loss: 2.363192558288574, rate: 9.6e-05\n",
      "[2023-11-13 09:31:59.023185] Epoch: 1 ends. Average loss: 2.3558900050543583\n",
      "Epoch: 2 Batch: 0, loss: 2.4653143882751465, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 50, loss: 2.2340023517608643, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 100, loss: 2.5560081005096436, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 150, loss: 2.3944664001464844, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 200, loss: 2.572500705718994, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 250, loss: 2.3704042434692383, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 300, loss: 1.7023849487304688, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 350, loss: 2.2119219303131104, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 400, loss: 2.1485977172851562, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 450, loss: 2.273789644241333, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 500, loss: 2.777745485305786, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 550, loss: 2.77461314201355, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 600, loss: 1.9744757413864136, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 650, loss: 2.4171640872955322, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 700, loss: 2.583103895187378, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 750, loss: 2.312652826309204, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 800, loss: 2.3019959926605225, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 850, loss: 2.2540030479431152, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 900, loss: 2.51424241065979, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 950, loss: 2.721558094024658, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1000, loss: 2.5206997394561768, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1050, loss: 2.342501163482666, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1100, loss: 2.429393768310547, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1150, loss: 2.4654932022094727, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1200, loss: 2.474910259246826, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1250, loss: 2.2508392333984375, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1300, loss: 2.1002438068389893, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1350, loss: 2.352360963821411, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1400, loss: 2.150257110595703, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1450, loss: 2.7424254417419434, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1500, loss: 2.5577242374420166, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1550, loss: 2.5295920372009277, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1600, loss: 2.6120874881744385, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1650, loss: 2.7440149784088135, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1700, loss: 2.728501558303833, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1750, loss: 2.524048089981079, rate: 9.216e-05\n",
      "Epoch: 2 Batch: 1800, loss: 2.5111920833587646, rate: 9.216e-05\n",
      "[2023-11-13 09:35:52.747266] Epoch: 2 ends. Average loss: 2.406487492981104\n",
      "Epoch: 3 Batch: 0, loss: 2.5421485900878906, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 50, loss: 2.245384454727173, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 100, loss: 2.6148569583892822, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 150, loss: 2.4585165977478027, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 200, loss: 2.7049944400787354, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 250, loss: 2.5937576293945312, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 300, loss: 1.7862210273742676, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 350, loss: 2.337184429168701, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 400, loss: 2.2543885707855225, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 450, loss: 2.370837450027466, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 500, loss: 2.856971025466919, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 550, loss: 2.7726974487304688, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 600, loss: 2.020933151245117, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 650, loss: 2.392120838165283, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 700, loss: 2.6054022312164307, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 750, loss: 2.303246259689331, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 800, loss: 2.5240275859832764, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 850, loss: 2.4018352031707764, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 900, loss: 2.4673922061920166, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 950, loss: 2.695636749267578, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1000, loss: 2.564908981323242, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1050, loss: 2.3859825134277344, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1100, loss: 2.3786864280700684, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1150, loss: 2.4278690814971924, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1200, loss: 2.484168529510498, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1250, loss: 2.293410062789917, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1300, loss: 2.1362085342407227, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1350, loss: 2.2714152336120605, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1400, loss: 2.131619453430176, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1450, loss: 2.7307660579681396, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1500, loss: 2.5359835624694824, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1550, loss: 2.4824929237365723, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1600, loss: 2.564364433288574, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1650, loss: 2.6242332458496094, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1700, loss: 2.68039608001709, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1750, loss: 2.486522912979126, rate: 8.847359999999999e-05\n",
      "Epoch: 3 Batch: 1800, loss: 2.433917760848999, rate: 8.847359999999999e-05\n",
      "[2023-11-13 09:39:45.899856] Epoch: 3 ends. Average loss: 2.4301938806787353\n",
      "Epoch: 4 Batch: 0, loss: 2.460902214050293, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 50, loss: 2.2049648761749268, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 100, loss: 2.5338287353515625, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 150, loss: 2.374082565307617, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 200, loss: 2.689141035079956, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 250, loss: 2.5145955085754395, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 300, loss: 1.668624758720398, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 350, loss: 2.267331600189209, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 400, loss: 2.124950408935547, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 450, loss: 2.240480661392212, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 500, loss: 2.6784088611602783, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 550, loss: 2.650172233581543, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 600, loss: 1.881048321723938, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 650, loss: 2.2492051124572754, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 700, loss: 2.504671812057495, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 750, loss: 2.145594358444214, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 800, loss: 2.2925572395324707, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 850, loss: 2.1921753883361816, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 900, loss: 2.230961561203003, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 950, loss: 2.551165819168091, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1000, loss: 2.3895740509033203, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1050, loss: 2.244387626647949, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1100, loss: 2.3674938678741455, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1150, loss: 2.217982530593872, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1200, loss: 2.279694080352783, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1250, loss: 2.0732369422912598, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1300, loss: 2.0267300605773926, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1350, loss: 2.1478331089019775, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1400, loss: 1.9977636337280273, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1450, loss: 2.5372674465179443, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1500, loss: 2.4081947803497314, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1550, loss: 2.3011229038238525, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1600, loss: 2.4609081745147705, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1650, loss: 2.5191714763641357, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1700, loss: 2.4484267234802246, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1750, loss: 2.1847310066223145, rate: 8.493465599999999e-05\n",
      "Epoch: 4 Batch: 1800, loss: 2.2838268280029297, rate: 8.493465599999999e-05\n",
      "[2023-11-13 09:43:40.803741] Epoch: 4 ends. Average loss: 2.285866083522824\n",
      "Epoch: 5 Batch: 0, loss: 2.2423362731933594, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 50, loss: 2.008298397064209, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 100, loss: 2.4036865234375, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 150, loss: 2.178748846054077, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 200, loss: 2.437054395675659, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 250, loss: 2.218374252319336, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 300, loss: 1.4908374547958374, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 350, loss: 2.063633680343628, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 400, loss: 2.0481936931610107, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 450, loss: 2.0449740886688232, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 500, loss: 2.606600284576416, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 550, loss: 2.4284892082214355, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 600, loss: 1.7915222644805908, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 650, loss: 2.0688705444335938, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 700, loss: 2.2374143600463867, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 750, loss: 2.052924156188965, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 800, loss: 2.15889835357666, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 850, loss: 2.06183123588562, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 900, loss: 2.217477798461914, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 950, loss: 2.406081199645996, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1000, loss: 2.268799066543579, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1050, loss: 2.0375120639801025, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1100, loss: 2.1414377689361572, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1150, loss: 2.0331671237945557, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1200, loss: 2.073073625564575, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1250, loss: 1.9281511306762695, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1300, loss: 1.8311115503311157, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1350, loss: 1.984336495399475, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1400, loss: 1.9104729890823364, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1450, loss: 2.3477025032043457, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1500, loss: 2.2967474460601807, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1550, loss: 2.164116621017456, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1600, loss: 2.2894766330718994, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1650, loss: 2.2535510063171387, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1700, loss: 2.389940023422241, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1750, loss: 2.0805504322052, rate: 8.153726975999998e-05\n",
      "Epoch: 5 Batch: 1800, loss: 2.051994562149048, rate: 8.153726975999998e-05\n",
      "[2023-11-13 09:47:36.460133] Epoch: 5 ends. Average loss: 2.1202858990881235\n",
      "Epoch: 6 Batch: 0, loss: 2.1496667861938477, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 50, loss: 2.0078108310699463, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 100, loss: 2.1483473777770996, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 150, loss: 1.999056339263916, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 200, loss: 2.216667652130127, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 250, loss: 2.0152587890625, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 300, loss: 1.4242198467254639, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 350, loss: 1.8622249364852905, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 400, loss: 1.9342461824417114, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 450, loss: 1.9250683784484863, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 500, loss: 2.3357744216918945, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 550, loss: 2.3380212783813477, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 600, loss: 1.652098536491394, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 650, loss: 1.8745657205581665, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 700, loss: 2.039581060409546, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 750, loss: 1.983077049255371, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 800, loss: 1.9645640850067139, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 850, loss: 1.9130107164382935, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 900, loss: 1.9164409637451172, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 950, loss: 2.2546634674072266, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1000, loss: 2.126321315765381, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1050, loss: 1.969059705734253, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1100, loss: 2.115452527999878, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1150, loss: 1.99997079372406, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1200, loss: 1.9903563261032104, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1250, loss: 1.7915310859680176, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1300, loss: 1.7186497449874878, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1350, loss: 1.870062232017517, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1400, loss: 1.7537047863006592, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1450, loss: 2.250007390975952, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1500, loss: 2.0894787311553955, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1550, loss: 2.179973840713501, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1600, loss: 2.291743516921997, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1650, loss: 2.2599425315856934, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1700, loss: 2.2691237926483154, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1750, loss: 2.053096294403076, rate: 7.827577896959998e-05\n",
      "Epoch: 6 Batch: 1800, loss: 1.8841832876205444, rate: 7.827577896959998e-05\n",
      "[2023-11-13 09:51:28.019886] Epoch: 6 ends. Average loss: 2.018353621537555\n",
      "Epoch: 7 Batch: 0, loss: 2.014116048812866, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 50, loss: 1.8488069772720337, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 100, loss: 2.102886199951172, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 150, loss: 1.9946160316467285, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 200, loss: 2.1615569591522217, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 250, loss: 1.9562292098999023, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 300, loss: 1.3433318138122559, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 350, loss: 1.7837477922439575, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 400, loss: 1.8152672052383423, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 450, loss: 1.969285011291504, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 500, loss: 2.3583784103393555, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 550, loss: 2.2120749950408936, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 600, loss: 1.5061700344085693, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 650, loss: 1.8860304355621338, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 700, loss: 2.0461645126342773, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 750, loss: 1.942963719367981, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 800, loss: 1.9496791362762451, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 850, loss: 1.8697378635406494, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 900, loss: 1.9004589319229126, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 950, loss: 2.256084442138672, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1000, loss: 2.0894346237182617, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1050, loss: 1.9147135019302368, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1100, loss: 2.0813443660736084, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1150, loss: 2.0574920177459717, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1200, loss: 1.880077600479126, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1250, loss: 1.7645723819732666, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1300, loss: 1.7222156524658203, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1350, loss: 1.714099645614624, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1400, loss: 1.7845884561538696, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1450, loss: 2.243638038635254, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1500, loss: 2.1721715927124023, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1550, loss: 2.155594825744629, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1600, loss: 2.083326578140259, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1650, loss: 2.137807607650757, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1700, loss: 2.2729697227478027, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1750, loss: 1.9109824895858765, rate: 7.514474781081598e-05\n",
      "Epoch: 7 Batch: 1800, loss: 2.006092071533203, rate: 7.514474781081598e-05\n",
      "[2023-11-13 09:55:20.169254] Epoch: 7 ends. Average loss: 1.954605303938982\n",
      "Epoch: 8 Batch: 0, loss: 1.974224328994751, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 50, loss: 1.7437387704849243, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 100, loss: 2.1198530197143555, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 150, loss: 1.9030017852783203, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 200, loss: 2.0449390411376953, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 250, loss: 2.0459532737731934, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 300, loss: 1.4342129230499268, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 350, loss: 1.8009178638458252, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 400, loss: 1.8028819561004639, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 450, loss: 1.895578384399414, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 500, loss: 2.2252185344696045, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 550, loss: 2.1250932216644287, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 600, loss: 1.4657261371612549, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 650, loss: 1.6707696914672852, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 700, loss: 2.1096513271331787, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 750, loss: 1.8378684520721436, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 800, loss: 1.8527668714523315, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 850, loss: 1.9545100927352905, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 900, loss: 1.9385523796081543, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 950, loss: 2.1161885261535645, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1000, loss: 2.1680498123168945, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1050, loss: 1.8182473182678223, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1100, loss: 2.01733136177063, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1150, loss: 1.801970362663269, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1200, loss: 1.9079251289367676, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1250, loss: 1.6890052556991577, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1300, loss: 1.5663882493972778, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1350, loss: 1.734178900718689, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1400, loss: 1.7629311084747314, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1450, loss: 2.170806646347046, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1500, loss: 1.9784715175628662, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1550, loss: 2.022773265838623, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1600, loss: 2.067753791809082, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1650, loss: 2.143421173095703, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1700, loss: 2.21408748626709, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1750, loss: 1.7864294052124023, rate: 7.213895789838334e-05\n",
      "Epoch: 8 Batch: 1800, loss: 1.9918845891952515, rate: 7.213895789838334e-05\n",
      "[2023-11-13 09:59:11.384468] Epoch: 8 ends. Average loss: 1.907493646935212\n",
      "Epoch: 9 Batch: 0, loss: 2.037353754043579, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 50, loss: 1.7657479047775269, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 100, loss: 2.012892246246338, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 150, loss: 1.875086784362793, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 200, loss: 2.0555601119995117, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 250, loss: 1.9137243032455444, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 300, loss: 1.3315774202346802, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 350, loss: 1.6325095891952515, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 400, loss: 1.6896637678146362, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 450, loss: 1.833298921585083, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 500, loss: 2.2375879287719727, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 550, loss: 2.1448378562927246, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 600, loss: 1.5616987943649292, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 650, loss: 1.8979895114898682, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 700, loss: 2.002455711364746, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 750, loss: 1.8496553897857666, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 800, loss: 1.8009779453277588, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 850, loss: 1.8259015083312988, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 900, loss: 1.849841594696045, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 950, loss: 2.047567367553711, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1000, loss: 2.048495292663574, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1050, loss: 1.8197154998779297, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1100, loss: 1.9502772092819214, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1150, loss: 1.8467496633529663, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1200, loss: 1.971381425857544, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1250, loss: 1.7362074851989746, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1300, loss: 1.5929560661315918, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1350, loss: 1.7407572269439697, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1400, loss: 1.750482201576233, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1450, loss: 2.053929328918457, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1500, loss: 2.007061004638672, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1550, loss: 1.8482567071914673, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1600, loss: 1.8748643398284912, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1650, loss: 2.10379958152771, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1700, loss: 2.1737794876098633, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1750, loss: 1.860397458076477, rate: 6.9253399582448e-05\n",
      "Epoch: 9 Batch: 1800, loss: 1.823604702949524, rate: 6.9253399582448e-05\n",
      "[2023-11-13 10:03:01.545191] Epoch: 9 ends. Average loss: 1.8711004090190788\n",
      "Epoch: 10 Batch: 0, loss: 1.908103585243225, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 50, loss: 1.6589168310165405, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 100, loss: 2.0761468410491943, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 150, loss: 1.8557976484298706, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 200, loss: 2.028407096862793, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 250, loss: 1.9070043563842773, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 300, loss: 1.1967614889144897, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 350, loss: 1.6705074310302734, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 400, loss: 1.6549432277679443, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 450, loss: 1.964116096496582, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 500, loss: 2.165534496307373, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 550, loss: 2.083758592605591, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 600, loss: 1.5001858472824097, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 650, loss: 1.7972536087036133, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 700, loss: 1.930837631225586, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 750, loss: 1.9074410200119019, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 800, loss: 1.8699889183044434, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 850, loss: 1.7601139545440674, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 900, loss: 1.7925186157226562, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 950, loss: 1.930935025215149, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1000, loss: 1.965749740600586, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1050, loss: 1.8442177772521973, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1100, loss: 2.0489096641540527, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1150, loss: 1.8575491905212402, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1200, loss: 1.8057997226715088, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1250, loss: 1.6839808225631714, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1300, loss: 1.6201508045196533, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1350, loss: 1.6247429847717285, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1400, loss: 1.73579740524292, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1450, loss: 1.9925906658172607, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1500, loss: 1.9714254140853882, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1550, loss: 1.8782858848571777, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1600, loss: 1.8271206617355347, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1650, loss: 2.1451923847198486, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1700, loss: 2.1767470836639404, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1750, loss: 1.8923144340515137, rate: 6.648326359915008e-05\n",
      "Epoch: 10 Batch: 1800, loss: 1.783414363861084, rate: 6.648326359915008e-05\n",
      "[2023-11-13 10:06:56.329012] Epoch: 10 ends. Average loss: 1.8407765521703343\n",
      "Epoch: 11 Batch: 0, loss: 1.882826805114746, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 50, loss: 1.600821614265442, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 100, loss: 1.943293571472168, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 150, loss: 1.842699646949768, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 200, loss: 2.063687562942505, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 250, loss: 1.8574306964874268, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 300, loss: 1.2836790084838867, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 350, loss: 1.6226197481155396, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 400, loss: 1.6626962423324585, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 450, loss: 1.766113042831421, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 500, loss: 2.2119531631469727, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 550, loss: 2.0313892364501953, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 600, loss: 1.5084688663482666, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 650, loss: 1.8174189329147339, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 700, loss: 1.762636661529541, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 750, loss: 1.8237122297286987, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 800, loss: 1.9116593599319458, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 850, loss: 1.7866181135177612, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 900, loss: 1.7845921516418457, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 950, loss: 1.9842244386672974, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1000, loss: 1.948838472366333, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1050, loss: 1.7371629476547241, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1100, loss: 1.8605576753616333, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1150, loss: 1.7145416736602783, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1200, loss: 1.9224369525909424, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1250, loss: 1.5970051288604736, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1300, loss: 1.6025701761245728, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1350, loss: 1.6474943161010742, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1400, loss: 1.5689526796340942, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1450, loss: 1.9821752309799194, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1500, loss: 1.971860647201538, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1550, loss: 1.8532593250274658, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1600, loss: 1.8435719013214111, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1650, loss: 2.07978892326355, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1700, loss: 2.113112688064575, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1750, loss: 1.8206775188446045, rate: 6.382393305518408e-05\n",
      "Epoch: 11 Batch: 1800, loss: 1.8943681716918945, rate: 6.382393305518408e-05\n",
      "[2023-11-13 10:10:49.855023] Epoch: 11 ends. Average loss: 1.8145423030169445\n",
      "Epoch: 12 Batch: 0, loss: 1.8183557987213135, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 50, loss: 1.7243434190750122, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 100, loss: 1.983062505722046, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 150, loss: 1.8236374855041504, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 200, loss: 2.0945005416870117, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 250, loss: 1.9527620077133179, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 300, loss: 1.3400565385818481, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 350, loss: 1.5826363563537598, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 400, loss: 1.772926688194275, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 450, loss: 1.7822518348693848, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 500, loss: 2.1870474815368652, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 550, loss: 2.0530169010162354, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 600, loss: 1.3736151456832886, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 650, loss: 1.6910061836242676, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 700, loss: 1.8016276359558105, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 750, loss: 1.7628616094589233, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 800, loss: 1.769534945487976, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 850, loss: 1.6050500869750977, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 900, loss: 1.7389010190963745, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 950, loss: 2.0263473987579346, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1000, loss: 1.9272626638412476, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1050, loss: 1.7187488079071045, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1100, loss: 1.8452590703964233, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1150, loss: 1.6436823606491089, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1200, loss: 1.80254065990448, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1250, loss: 1.6864712238311768, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1300, loss: 1.4849772453308105, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1350, loss: 1.6921404600143433, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1400, loss: 1.648474931716919, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1450, loss: 1.9666804075241089, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1500, loss: 1.903110384941101, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1550, loss: 1.979596734046936, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1600, loss: 1.855979561805725, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1650, loss: 2.0929653644561768, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1700, loss: 2.0447795391082764, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1750, loss: 1.706344485282898, rate: 6.127097573297672e-05\n",
      "Epoch: 12 Batch: 1800, loss: 1.8371446132659912, rate: 6.127097573297672e-05\n",
      "[2023-11-13 10:14:44.600712] Epoch: 12 ends. Average loss: 1.79334400598344\n",
      "Epoch: 13 Batch: 0, loss: 1.8225796222686768, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 50, loss: 1.527356743812561, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 100, loss: 1.9711699485778809, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 150, loss: 1.7872775793075562, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 200, loss: 1.959613561630249, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 250, loss: 1.8749507665634155, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 300, loss: 1.3595441579818726, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 350, loss: 1.5936449766159058, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 400, loss: 1.6346545219421387, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 450, loss: 1.7199684381484985, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 500, loss: 2.1203880310058594, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 550, loss: 1.9552122354507446, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 600, loss: 1.435954213142395, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 650, loss: 1.7365636825561523, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 700, loss: 1.8603876829147339, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 750, loss: 1.7060333490371704, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 800, loss: 1.7499358654022217, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 850, loss: 1.5255485773086548, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 900, loss: 1.712544322013855, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 950, loss: 1.9648432731628418, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1000, loss: 1.9393713474273682, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1050, loss: 1.708221435546875, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1100, loss: 1.8462764024734497, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1150, loss: 1.7501262426376343, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1200, loss: 1.935628890991211, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1250, loss: 1.7031993865966797, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1300, loss: 1.4758445024490356, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1350, loss: 1.7265130281448364, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1400, loss: 1.5714505910873413, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1450, loss: 1.9972624778747559, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1500, loss: 1.958160161972046, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1550, loss: 1.798936367034912, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1600, loss: 1.9079219102859497, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1650, loss: 2.0172407627105713, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1700, loss: 2.198667287826538, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1750, loss: 1.6991654634475708, rate: 5.882013670365765e-05\n",
      "Epoch: 13 Batch: 1800, loss: 1.8775955438613892, rate: 5.882013670365765e-05\n",
      "[2023-11-13 10:18:39.794046] Epoch: 13 ends. Average loss: 1.7800986812184414\n",
      "Epoch: 14 Batch: 0, loss: 1.7360750436782837, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 50, loss: 1.5958226919174194, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 100, loss: 1.8838146924972534, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 150, loss: 1.7855854034423828, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 200, loss: 1.8987690210342407, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 250, loss: 1.7854769229888916, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 300, loss: 1.1340886354446411, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 350, loss: 1.6487829685211182, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 400, loss: 1.7002196311950684, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 450, loss: 1.67255699634552, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 500, loss: 2.181030511856079, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 550, loss: 1.912213683128357, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 600, loss: 1.43622887134552, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 650, loss: 1.7211689949035645, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 700, loss: 1.8200827836990356, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 750, loss: 1.8324357271194458, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 800, loss: 1.7062445878982544, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 850, loss: 1.6414754390716553, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 900, loss: 1.6786582469940186, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 950, loss: 1.9124950170516968, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1000, loss: 1.8674832582473755, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1050, loss: 1.6924680471420288, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1100, loss: 1.7481998205184937, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1150, loss: 1.7316819429397583, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1200, loss: 1.7329719066619873, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1250, loss: 1.6461557149887085, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1300, loss: 1.4158555269241333, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1350, loss: 1.5682696104049683, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1400, loss: 1.544795274734497, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1450, loss: 1.959279179573059, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1500, loss: 1.9529443979263306, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1550, loss: 1.736179232597351, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1600, loss: 1.8352468013763428, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1650, loss: 1.9087797403335571, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1700, loss: 2.1107776165008545, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1750, loss: 1.7050281763076782, rate: 5.6467331235511337e-05\n",
      "Epoch: 14 Batch: 1800, loss: 1.8635196685791016, rate: 5.6467331235511337e-05\n",
      "[2023-11-13 10:22:34.464104] Epoch: 14 ends. Average loss: 1.7610396397948858\n",
      "Epoch: 15 Batch: 0, loss: 1.743847370147705, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 50, loss: 1.6957484483718872, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 100, loss: 1.9389034509658813, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 150, loss: 1.7506234645843506, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 200, loss: 1.896054744720459, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 250, loss: 1.6763502359390259, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 300, loss: 1.2579827308654785, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 350, loss: 1.622161626815796, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 400, loss: 1.6094095706939697, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 450, loss: 1.7694993019104004, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 500, loss: 2.0661139488220215, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 550, loss: 1.9254733324050903, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 600, loss: 1.3780235052108765, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 650, loss: 1.7034121751785278, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 700, loss: 1.8157894611358643, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 750, loss: 1.7650260925292969, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 800, loss: 1.7581424713134766, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 850, loss: 1.6295968294143677, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 900, loss: 1.713360071182251, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 950, loss: 1.9175151586532593, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1000, loss: 1.9544512033462524, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1050, loss: 1.6394098997116089, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1100, loss: 1.8298197984695435, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1150, loss: 1.7732632160186768, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1200, loss: 1.6721876859664917, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1250, loss: 1.662261962890625, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1300, loss: 1.4439520835876465, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1350, loss: 1.6072946786880493, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1400, loss: 1.5768388509750366, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1450, loss: 1.9693652391433716, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1500, loss: 1.9217455387115479, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1550, loss: 1.8100429773330688, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1600, loss: 1.9012936353683472, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1650, loss: 1.9501185417175293, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1700, loss: 2.072158098220825, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1750, loss: 1.7807416915893555, rate: 5.4208637986090884e-05\n",
      "Epoch: 15 Batch: 1800, loss: 1.794500708580017, rate: 5.4208637986090884e-05\n",
      "[2023-11-13 10:26:29.004235] Epoch: 15 ends. Average loss: 1.7537876405705422\n",
      "Epoch: 16 Batch: 0, loss: 1.910333514213562, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 50, loss: 1.607372522354126, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 100, loss: 1.8596789836883545, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 150, loss: 1.6594159603118896, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 200, loss: 1.9084705114364624, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 250, loss: 1.9136378765106201, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 300, loss: 1.2743680477142334, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 350, loss: 1.6871159076690674, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 400, loss: 1.6966441869735718, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 450, loss: 1.618497371673584, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 500, loss: 2.0272037982940674, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 550, loss: 1.9121952056884766, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 600, loss: 1.4424301385879517, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 650, loss: 1.7151955366134644, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 700, loss: 1.8360049724578857, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 750, loss: 1.8310837745666504, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 800, loss: 1.7244157791137695, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 850, loss: 1.6244841814041138, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 900, loss: 1.76369047164917, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 950, loss: 1.932621717453003, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1000, loss: 1.9064538478851318, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1050, loss: 1.683396339416504, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1100, loss: 1.832045555114746, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1150, loss: 1.7103509902954102, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1200, loss: 1.845587968826294, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1250, loss: 1.5493671894073486, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1300, loss: 1.4546771049499512, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1350, loss: 1.613237977027893, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1400, loss: 1.6356343030929565, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1450, loss: 1.8977915048599243, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1500, loss: 1.9032700061798096, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1550, loss: 1.9431990385055542, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1600, loss: 1.7945261001586914, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1650, loss: 1.9262615442276, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1700, loss: 2.0685808658599854, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1750, loss: 1.7329963445663452, rate: 5.2040292466647244e-05\n",
      "Epoch: 16 Batch: 1800, loss: 1.860705018043518, rate: 5.2040292466647244e-05\n",
      "[2023-11-13 10:30:22.800564] Epoch: 16 ends. Average loss: 1.74400333982111\n",
      "Epoch: 17 Batch: 0, loss: 1.9058574438095093, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 50, loss: 1.5800946950912476, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 100, loss: 1.7919737100601196, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 150, loss: 1.8799731731414795, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 200, loss: 1.874876856803894, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 250, loss: 1.695634365081787, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 300, loss: 1.2106826305389404, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 350, loss: 1.539292812347412, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 400, loss: 1.5984596014022827, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 450, loss: 1.707972526550293, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 500, loss: 2.084209680557251, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 550, loss: 1.915087342262268, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 600, loss: 1.4182745218276978, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 650, loss: 1.6409202814102173, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 700, loss: 1.8767659664154053, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 750, loss: 1.8217687606811523, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 800, loss: 1.7082408666610718, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 850, loss: 1.6273142099380493, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 900, loss: 1.6461530923843384, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 950, loss: 1.9214024543762207, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1000, loss: 1.9268473386764526, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1050, loss: 1.6828601360321045, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1100, loss: 1.773226022720337, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1150, loss: 1.7281020879745483, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1200, loss: 1.7743138074874878, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1250, loss: 1.6241801977157593, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1300, loss: 1.483620285987854, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1350, loss: 1.6174544095993042, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1400, loss: 1.5540720224380493, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1450, loss: 1.9667057991027832, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1500, loss: 1.8580420017242432, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1550, loss: 1.9045181274414062, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1600, loss: 1.779826283454895, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1650, loss: 1.9892576932907104, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1700, loss: 2.050806999206543, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1750, loss: 1.5937477350234985, rate: 4.995868076798135e-05\n",
      "Epoch: 17 Batch: 1800, loss: 1.937028408050537, rate: 4.995868076798135e-05\n",
      "[2023-11-13 10:34:17.260540] Epoch: 17 ends. Average loss: 1.7366490267418526\n",
      "Epoch: 18 Batch: 0, loss: 1.7556157112121582, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 50, loss: 1.5585049390792847, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 100, loss: 1.7971493005752563, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 150, loss: 1.7752355337142944, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 200, loss: 1.893170952796936, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 250, loss: 1.8218934535980225, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 300, loss: 1.1879764795303345, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 350, loss: 1.5263454914093018, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 400, loss: 1.6101306676864624, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 450, loss: 1.6516765356063843, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 500, loss: 2.0681405067443848, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 550, loss: 1.853327989578247, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 600, loss: 1.3879942893981934, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 650, loss: 1.7229539155960083, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 700, loss: 1.7754862308502197, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 750, loss: 1.7782196998596191, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 800, loss: 1.7873568534851074, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 850, loss: 1.6051170825958252, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 900, loss: 1.694638967514038, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 950, loss: 1.810117483139038, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1000, loss: 1.943017601966858, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1050, loss: 1.6251342296600342, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1100, loss: 1.8625043630599976, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1150, loss: 1.695204496383667, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1200, loss: 1.779112458229065, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1250, loss: 1.5328065156936646, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1300, loss: 1.407363772392273, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1350, loss: 1.5900582075119019, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1400, loss: 1.4951409101486206, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1450, loss: 1.9100981950759888, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1500, loss: 1.7389600276947021, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1550, loss: 1.819520354270935, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1600, loss: 1.8545132875442505, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1650, loss: 1.9034875631332397, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1700, loss: 1.9408947229385376, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1750, loss: 1.800249695777893, rate: 4.7960333537262095e-05\n",
      "Epoch: 18 Batch: 1800, loss: 1.8375003337860107, rate: 4.7960333537262095e-05\n",
      "[2023-11-13 10:38:10.834468] Epoch: 18 ends. Average loss: 1.7293239615598701\n",
      "Epoch: 19 Batch: 0, loss: 1.7755414247512817, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 50, loss: 1.5083616971969604, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 100, loss: 1.8645070791244507, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 150, loss: 1.6325606107711792, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 200, loss: 1.978791356086731, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 250, loss: 1.7846760749816895, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 300, loss: 1.1722896099090576, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 350, loss: 1.4589989185333252, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 400, loss: 1.6210259199142456, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 450, loss: 1.7458230257034302, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 500, loss: 1.9823768138885498, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 550, loss: 2.0424599647521973, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 600, loss: 1.4794749021530151, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 650, loss: 1.6460535526275635, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 700, loss: 1.8636704683303833, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 750, loss: 1.7707833051681519, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 800, loss: 1.733546495437622, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 850, loss: 1.6441723108291626, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 900, loss: 1.6838538646697998, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 950, loss: 1.811726689338684, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1000, loss: 1.8445940017700195, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1050, loss: 1.6532526016235352, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1100, loss: 1.7948616743087769, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1150, loss: 1.6480929851531982, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1200, loss: 1.6804112195968628, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1250, loss: 1.570330262184143, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1300, loss: 1.4764827489852905, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1350, loss: 1.5118334293365479, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1400, loss: 1.7075937986373901, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1450, loss: 1.7311359643936157, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1500, loss: 1.9535850286483765, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1550, loss: 1.8983814716339111, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1600, loss: 1.7139235734939575, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1650, loss: 2.0207326412200928, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1700, loss: 2.047607660293579, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1750, loss: 1.6006996631622314, rate: 4.6041920195771606e-05\n",
      "Epoch: 19 Batch: 1800, loss: 1.7533856630325317, rate: 4.6041920195771606e-05\n",
      "[2023-11-13 10:42:03.415335] Epoch: 19 ends. Average loss: 1.7241002230504832\n",
      "Epoch: 20 Batch: 0, loss: 1.8606294393539429, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 50, loss: 1.6557914018630981, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 100, loss: 1.8270230293273926, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 150, loss: 1.7265880107879639, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 200, loss: 2.017165422439575, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 250, loss: 1.7798349857330322, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 300, loss: 1.2554905414581299, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 350, loss: 1.6018874645233154, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 400, loss: 1.5077929496765137, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 450, loss: 1.7396196126937866, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 500, loss: 2.0843770503997803, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 550, loss: 2.0575368404388428, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 600, loss: 1.5148683786392212, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 650, loss: 1.6615397930145264, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 700, loss: 1.8409849405288696, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 750, loss: 1.7093268632888794, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 800, loss: 1.6746073961257935, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 850, loss: 1.6578205823898315, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 900, loss: 1.6535898447036743, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 950, loss: 1.8682743310928345, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1000, loss: 1.8544529676437378, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1050, loss: 1.6460096836090088, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1100, loss: 1.8673570156097412, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1150, loss: 1.7781469821929932, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1200, loss: 1.812168836593628, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1250, loss: 1.626581072807312, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1300, loss: 1.5121387243270874, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1350, loss: 1.6364221572875977, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1400, loss: 1.5268771648406982, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1450, loss: 1.9510462284088135, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1500, loss: 1.847107172012329, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1550, loss: 1.7612910270690918, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1600, loss: 1.6785571575164795, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1650, loss: 2.0267820358276367, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1700, loss: 2.0162341594696045, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1750, loss: 1.668798804283142, rate: 4.420024338794074e-05\n",
      "Epoch: 20 Batch: 1800, loss: 1.718145728111267, rate: 4.420024338794074e-05\n",
      "[2023-11-13 10:45:50.325392] Epoch: 20 ends. Average loss: 1.7220547908718784\n",
      "Epoch: 21 Batch: 0, loss: 1.8997879028320312, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 50, loss: 1.528700828552246, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 100, loss: 1.745216965675354, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 150, loss: 1.7158167362213135, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 200, loss: 1.9568891525268555, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 250, loss: 1.6983205080032349, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 300, loss: 1.2737493515014648, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 350, loss: 1.5242071151733398, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 400, loss: 1.5653712749481201, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 450, loss: 1.7780300378799438, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 500, loss: 1.99022376537323, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 550, loss: 1.8893951177597046, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 600, loss: 1.3909647464752197, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 650, loss: 1.688353180885315, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 700, loss: 1.9252264499664307, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 750, loss: 1.6412129402160645, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 800, loss: 1.6731940507888794, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 850, loss: 1.6901700496673584, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 900, loss: 1.7802610397338867, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 950, loss: 1.7747032642364502, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1000, loss: 1.7632192373275757, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1050, loss: 1.5806947946548462, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1100, loss: 1.654830813407898, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1150, loss: 1.6830956935882568, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1200, loss: 1.690396785736084, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1250, loss: 1.5566149950027466, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1300, loss: 1.313004493713379, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1350, loss: 1.5483372211456299, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1400, loss: 1.5313669443130493, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1450, loss: 1.876564621925354, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1500, loss: 1.8827991485595703, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1550, loss: 1.9828894138336182, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1600, loss: 1.783341407775879, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1650, loss: 1.920361876487732, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1700, loss: 2.0347542762756348, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1750, loss: 1.7257484197616577, rate: 4.243223365242311e-05\n",
      "Epoch: 21 Batch: 1800, loss: 1.7741131782531738, rate: 4.243223365242311e-05\n",
      "[2023-11-13 10:49:41.446061] Epoch: 21 ends. Average loss: 1.7158507901006026\n",
      "Epoch: 22 Batch: 0, loss: 1.747288703918457, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 50, loss: 1.4692184925079346, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 100, loss: 1.8617750406265259, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 150, loss: 1.7419891357421875, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 200, loss: 1.9369298219680786, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 250, loss: 1.7645601034164429, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 300, loss: 1.2374773025512695, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 350, loss: 1.464113473892212, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 400, loss: 1.5704346895217896, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 450, loss: 1.6749080419540405, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 500, loss: 2.1122665405273438, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 550, loss: 1.7740250825881958, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 600, loss: 1.4593322277069092, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 650, loss: 1.6911282539367676, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 700, loss: 1.8287580013275146, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 750, loss: 1.7019301652908325, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 800, loss: 1.8366847038269043, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 850, loss: 1.7116425037384033, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 900, loss: 1.5371392965316772, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 950, loss: 1.881880521774292, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1000, loss: 1.7564529180526733, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1050, loss: 1.6982096433639526, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1100, loss: 1.9025627374649048, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1150, loss: 1.6185771226882935, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1200, loss: 1.765444278717041, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1250, loss: 1.5954465866088867, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1300, loss: 1.5176969766616821, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1350, loss: 1.4735718965530396, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1400, loss: 1.6230013370513916, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1450, loss: 1.9390746355056763, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1500, loss: 1.915338397026062, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1550, loss: 1.8184115886688232, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1600, loss: 1.7918916940689087, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1650, loss: 1.9213391542434692, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1700, loss: 2.056776523590088, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1750, loss: 1.7134829759597778, rate: 4.073494430632618e-05\n",
      "Epoch: 22 Batch: 1800, loss: 1.7676942348480225, rate: 4.073494430632618e-05\n",
      "[2023-11-13 10:53:31.999583] Epoch: 22 ends. Average loss: 1.7120815185440619\n",
      "Epoch: 23 Batch: 0, loss: 1.7616767883300781, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 50, loss: 1.4932488203048706, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 100, loss: 1.8053040504455566, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 150, loss: 1.6422735452651978, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 200, loss: 1.9463878870010376, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 250, loss: 1.8274747133255005, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 300, loss: 1.242932915687561, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 350, loss: 1.4647936820983887, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 400, loss: 1.6543842554092407, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 450, loss: 1.5778968334197998, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 500, loss: 2.126026153564453, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 550, loss: 1.931835651397705, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 600, loss: 1.3311102390289307, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 650, loss: 1.6867461204528809, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 700, loss: 1.7856358289718628, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 750, loss: 1.747994303703308, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 800, loss: 1.735766053199768, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 850, loss: 1.635067343711853, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 900, loss: 1.6417086124420166, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 950, loss: 1.7805235385894775, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1000, loss: 1.818234920501709, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1050, loss: 1.5687074661254883, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1100, loss: 1.8198109865188599, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1150, loss: 1.7322304248809814, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1200, loss: 1.7184182405471802, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1250, loss: 1.5998042821884155, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1300, loss: 1.4664148092269897, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1350, loss: 1.496851921081543, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1400, loss: 1.5994653701782227, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1450, loss: 1.875626802444458, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1500, loss: 1.7986828088760376, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1550, loss: 1.8542652130126953, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1600, loss: 1.864772081375122, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1650, loss: 1.9602090120315552, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1700, loss: 2.0204505920410156, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1750, loss: 1.7112146615982056, rate: 3.910554653407313e-05\n",
      "Epoch: 23 Batch: 1800, loss: 1.7654510736465454, rate: 3.910554653407313e-05\n",
      "[2023-11-13 10:57:22.648097] Epoch: 23 ends. Average loss: 1.7072850875412635\n",
      "Epoch: 24 Batch: 0, loss: 1.8666815757751465, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 50, loss: 1.593332052230835, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 100, loss: 1.792932391166687, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 150, loss: 1.7563165426254272, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 200, loss: 1.887245535850525, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 250, loss: 1.746720314025879, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 300, loss: 1.2400974035263062, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 350, loss: 1.4764891862869263, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 400, loss: 1.6338332891464233, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 450, loss: 1.7633136510849, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 500, loss: 2.0805091857910156, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 550, loss: 1.9023776054382324, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 600, loss: 1.2787855863571167, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 650, loss: 1.7171822786331177, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 700, loss: 1.7744526863098145, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 750, loss: 1.7825934886932373, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 800, loss: 1.723695993423462, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 850, loss: 1.6791284084320068, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 900, loss: 1.6650310754776, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 950, loss: 1.7925587892532349, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1000, loss: 1.8577399253845215, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1050, loss: 1.6565107107162476, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1100, loss: 1.6789189577102661, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1150, loss: 1.6725105047225952, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1200, loss: 1.7838393449783325, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1250, loss: 1.475606083869934, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1300, loss: 1.470919132232666, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1350, loss: 1.5386139154434204, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1400, loss: 1.6407359838485718, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1450, loss: 1.8502459526062012, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1500, loss: 1.7903807163238525, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1550, loss: 1.7860968112945557, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1600, loss: 1.7570136785507202, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1650, loss: 1.8156217336654663, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1700, loss: 2.076371669769287, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1750, loss: 1.7269937992095947, rate: 3.7541324672710204e-05\n",
      "Epoch: 24 Batch: 1800, loss: 1.7510930299758911, rate: 3.7541324672710204e-05\n",
      "[2023-11-13 11:01:13.289082] Epoch: 24 ends. Average loss: 1.7074634671803015\n",
      "Epoch: 25 Batch: 0, loss: 1.7939220666885376, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 50, loss: 1.5288485288619995, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 100, loss: 1.7381263971328735, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 150, loss: 1.760971188545227, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 200, loss: 1.8891557455062866, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 250, loss: 1.8567984104156494, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 300, loss: 1.201108455657959, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 350, loss: 1.4446911811828613, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 400, loss: 1.553543210029602, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 450, loss: 1.6957314014434814, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 500, loss: 1.9706782102584839, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 550, loss: 1.8446894884109497, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 600, loss: 1.4687291383743286, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 650, loss: 1.6439265012741089, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 700, loss: 1.7822747230529785, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 750, loss: 1.7252923250198364, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 800, loss: 1.6870064735412598, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 850, loss: 1.6818854808807373, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 900, loss: 1.6423622369766235, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 950, loss: 1.8591551780700684, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1000, loss: 1.838335394859314, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1050, loss: 1.5978175401687622, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1100, loss: 1.8829046487808228, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1150, loss: 1.6227470636367798, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1200, loss: 1.6885080337524414, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1250, loss: 1.5995841026306152, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1300, loss: 1.4367598295211792, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1350, loss: 1.4908028841018677, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1400, loss: 1.6286026239395142, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1450, loss: 1.8202252388000488, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1500, loss: 1.846651315689087, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1550, loss: 1.7961633205413818, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1600, loss: 1.6441634893417358, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1650, loss: 1.8855022192001343, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1700, loss: 2.0688529014587402, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1750, loss: 1.65495765209198, rate: 3.603967168580179e-05\n",
      "Epoch: 25 Batch: 1800, loss: 1.7890501022338867, rate: 3.603967168580179e-05\n",
      "[2023-11-13 11:05:03.868256] Epoch: 25 ends. Average loss: 1.7040903564980197\n",
      "Epoch: 26 Batch: 0, loss: 1.7098194360733032, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 50, loss: 1.595220685005188, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 100, loss: 1.7404911518096924, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 150, loss: 1.6371368169784546, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 200, loss: 1.9451721906661987, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 250, loss: 1.864990472793579, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 300, loss: 1.2888959646224976, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 350, loss: 1.4855930805206299, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 400, loss: 1.7262648344039917, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 450, loss: 1.6982917785644531, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 500, loss: 1.9714322090148926, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 550, loss: 1.8745020627975464, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 600, loss: 1.3557963371276855, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 650, loss: 1.600497841835022, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 700, loss: 1.6504789590835571, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 750, loss: 1.7054427862167358, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 800, loss: 1.7722936868667603, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 850, loss: 1.6658439636230469, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 900, loss: 1.6348832845687866, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 950, loss: 1.8474512100219727, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1000, loss: 1.800427794456482, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1050, loss: 1.645302653312683, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1100, loss: 1.6533628702163696, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1150, loss: 1.721432089805603, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1200, loss: 1.764323353767395, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1250, loss: 1.6570935249328613, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1300, loss: 1.4122751951217651, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1350, loss: 1.5674090385437012, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1400, loss: 1.4043655395507812, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1450, loss: 1.8975313901901245, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1500, loss: 1.8397843837738037, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1550, loss: 1.9368268251419067, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1600, loss: 1.793289303779602, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1650, loss: 1.8933624029159546, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1700, loss: 2.0631420612335205, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1750, loss: 1.6737604141235352, rate: 3.459808481836972e-05\n",
      "Epoch: 26 Batch: 1800, loss: 1.7676968574523926, rate: 3.459808481836972e-05\n",
      "[2023-11-13 11:08:53.924893] Epoch: 26 ends. Average loss: 1.7001101051452603\n",
      "Epoch: 27 Batch: 0, loss: 1.6286038160324097, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 50, loss: 1.6114317178726196, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 100, loss: 1.9033437967300415, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 150, loss: 1.7027231454849243, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 200, loss: 1.862173080444336, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 250, loss: 1.7400398254394531, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 300, loss: 1.1292166709899902, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 350, loss: 1.6243922710418701, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 400, loss: 1.5772112607955933, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 450, loss: 1.576585292816162, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 500, loss: 2.016989231109619, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 550, loss: 1.7994216680526733, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 600, loss: 1.3785746097564697, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 650, loss: 1.7972972393035889, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 700, loss: 1.7126232385635376, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 750, loss: 1.7530159950256348, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 800, loss: 1.6054255962371826, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 850, loss: 1.6676892042160034, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 900, loss: 1.6321747303009033, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 950, loss: 1.851548194885254, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1000, loss: 1.7669907808303833, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1050, loss: 1.576877236366272, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1100, loss: 1.856587290763855, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1150, loss: 1.6354581117630005, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1200, loss: 1.7154022455215454, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1250, loss: 1.501871109008789, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1300, loss: 1.4476019144058228, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1350, loss: 1.4908733367919922, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1400, loss: 1.5349202156066895, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1450, loss: 1.787376880645752, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1500, loss: 1.8035473823547363, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1550, loss: 1.8331884145736694, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1600, loss: 1.7311058044433594, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1650, loss: 1.9366499185562134, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1700, loss: 2.094944477081299, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1750, loss: 1.6686371564865112, rate: 3.321416142563493e-05\n",
      "Epoch: 27 Batch: 1800, loss: 1.7345882654190063, rate: 3.321416142563493e-05\n",
      "[2023-11-13 11:12:44.961742] Epoch: 27 ends. Average loss: 1.6964251490764966\n",
      "Epoch: 28 Batch: 0, loss: 1.6947559118270874, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 50, loss: 1.454164743423462, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 100, loss: 1.8861812353134155, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 150, loss: 1.693668007850647, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 200, loss: 1.8443245887756348, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 250, loss: 1.787685751914978, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 300, loss: 1.2571780681610107, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 350, loss: 1.4751136302947998, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 400, loss: 1.606570839881897, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 450, loss: 1.622267484664917, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 500, loss: 1.9833563566207886, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 550, loss: 1.8127115964889526, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 600, loss: 1.4430028200149536, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 650, loss: 1.727339506149292, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 700, loss: 1.8658866882324219, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 750, loss: 1.83795166015625, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 800, loss: 1.7011669874191284, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 850, loss: 1.5136582851409912, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 900, loss: 1.6193733215332031, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 950, loss: 1.7835450172424316, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1000, loss: 1.8511275053024292, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1050, loss: 1.5320018529891968, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1100, loss: 1.8055894374847412, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1150, loss: 1.6932231187820435, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1200, loss: 1.702901840209961, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1250, loss: 1.599592685699463, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1300, loss: 1.4122236967086792, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1350, loss: 1.550518274307251, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1400, loss: 1.4464432001113892, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1450, loss: 1.8531838655471802, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1500, loss: 1.7668371200561523, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1550, loss: 1.713748812675476, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1600, loss: 1.8177142143249512, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1650, loss: 1.8839153051376343, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1700, loss: 1.9749244451522827, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1750, loss: 1.6920595169067383, rate: 3.188559496860953e-05\n",
      "Epoch: 28 Batch: 1800, loss: 1.8335998058319092, rate: 3.188559496860953e-05\n",
      "[2023-11-13 11:16:36.418137] Epoch: 28 ends. Average loss: 1.6960478260973442\n",
      "Epoch: 29 Batch: 0, loss: 1.8382395505905151, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 50, loss: 1.4755182266235352, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 100, loss: 1.8346436023712158, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 150, loss: 1.7481259107589722, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 200, loss: 1.8534376621246338, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 250, loss: 1.6943367719650269, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 300, loss: 1.284731388092041, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 350, loss: 1.6254435777664185, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 400, loss: 1.5727063417434692, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 450, loss: 1.6952093839645386, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 500, loss: 1.9843106269836426, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 550, loss: 1.7952709197998047, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 600, loss: 1.4122015237808228, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 650, loss: 1.6131889820098877, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 700, loss: 1.860521912574768, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 750, loss: 1.7104004621505737, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 800, loss: 1.6942180395126343, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 850, loss: 1.6473203897476196, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 900, loss: 1.6401333808898926, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 950, loss: 1.8539460897445679, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1000, loss: 1.7699451446533203, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1050, loss: 1.453823447227478, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1100, loss: 1.7590938806533813, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1150, loss: 1.7457499504089355, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1200, loss: 1.8112950325012207, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1250, loss: 1.576919436454773, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1300, loss: 1.4923604726791382, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1350, loss: 1.5522507429122925, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1400, loss: 1.526930332183838, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1450, loss: 1.8963160514831543, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1500, loss: 1.8485215902328491, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1550, loss: 1.9947199821472168, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1600, loss: 1.7724666595458984, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1650, loss: 1.9180123805999756, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1700, loss: 1.991053581237793, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1750, loss: 1.6943377256393433, rate: 3.0610171169865154e-05\n",
      "Epoch: 29 Batch: 1800, loss: 1.7872391939163208, rate: 3.0610171169865154e-05\n",
      "[2023-11-13 11:20:27.798162] Epoch: 29 ends. Average loss: 1.6962723004771936\n",
      "Epoch: 30 Batch: 0, loss: 1.8555468320846558, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 50, loss: 1.5513361692428589, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 100, loss: 1.9005595445632935, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 150, loss: 1.7832262516021729, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 200, loss: 1.9529078006744385, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 250, loss: 1.7809215784072876, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 300, loss: 1.2336238622665405, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 350, loss: 1.5632976293563843, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 400, loss: 1.624108910560608, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 450, loss: 1.6269614696502686, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 500, loss: 2.0757956504821777, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 550, loss: 1.8276920318603516, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 600, loss: 1.4503767490386963, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 650, loss: 1.6895396709442139, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 700, loss: 1.8411405086517334, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 750, loss: 1.652788758277893, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 800, loss: 1.7587133646011353, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 850, loss: 1.5737037658691406, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 900, loss: 1.6154403686523438, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 950, loss: 1.8945364952087402, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1000, loss: 1.7782342433929443, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1050, loss: 1.4792791604995728, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1100, loss: 1.7462676763534546, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1150, loss: 1.640010118484497, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1200, loss: 1.7750037908554077, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1250, loss: 1.5624409914016724, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1300, loss: 1.3805673122406006, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1350, loss: 1.6193280220031738, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1400, loss: 1.5521620512008667, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1450, loss: 1.873711109161377, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1500, loss: 1.7491376399993896, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1550, loss: 1.8371855020523071, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1600, loss: 1.8209013938903809, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1650, loss: 2.064441204071045, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1700, loss: 1.9840656518936157, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1750, loss: 1.6636028289794922, rate: 2.9385764323070547e-05\n",
      "Epoch: 30 Batch: 1800, loss: 1.8149964809417725, rate: 2.9385764323070547e-05\n",
      "[2023-11-13 11:24:20.758827] Epoch: 30 ends. Average loss: 1.6953592214279258\n",
      "Epoch: 31 Batch: 0, loss: 1.8719040155410767, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 50, loss: 1.4922685623168945, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 100, loss: 1.8842341899871826, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 150, loss: 1.7163702249526978, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 200, loss: 1.8784639835357666, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 250, loss: 1.8443846702575684, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 300, loss: 1.102752447128296, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 350, loss: 1.414819359779358, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 400, loss: 1.5807212591171265, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 450, loss: 1.6505075693130493, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 500, loss: 2.0570907592773438, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 550, loss: 1.8929898738861084, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 600, loss: 1.3054331541061401, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 650, loss: 1.7294291257858276, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 700, loss: 1.7031532526016235, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 750, loss: 1.67010498046875, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 800, loss: 1.6993887424468994, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 850, loss: 1.6623125076293945, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 900, loss: 1.7076951265335083, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 950, loss: 1.7450147867202759, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1000, loss: 1.8034298419952393, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1050, loss: 1.5015701055526733, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1100, loss: 1.692564606666565, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1150, loss: 1.6635056734085083, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1200, loss: 1.6480379104614258, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1250, loss: 1.6157057285308838, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1300, loss: 1.488877296447754, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1350, loss: 1.5565741062164307, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1400, loss: 1.5087435245513916, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1450, loss: 1.9117242097854614, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1500, loss: 1.7976237535476685, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1550, loss: 1.8031176328659058, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1600, loss: 1.69246244430542, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1650, loss: 1.9405966997146606, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1700, loss: 2.0508806705474854, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1750, loss: 1.7070987224578857, rate: 2.8210333750147723e-05\n",
      "Epoch: 31 Batch: 1800, loss: 1.8503217697143555, rate: 2.8210333750147723e-05\n",
      "[2023-11-13 11:28:15.691202] Epoch: 31 ends. Average loss: 1.6925350313218206\n",
      "Epoch: 32 Batch: 0, loss: 1.817868947982788, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 50, loss: 1.5218454599380493, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 100, loss: 1.7668874263763428, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 150, loss: 1.738327980041504, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 200, loss: 1.9363235235214233, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 250, loss: 1.9316035509109497, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 300, loss: 1.1813867092132568, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 350, loss: 1.5101276636123657, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 400, loss: 1.6396193504333496, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 450, loss: 1.7320492267608643, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 500, loss: 1.9988682270050049, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 550, loss: 1.8058501482009888, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 600, loss: 1.4187923669815063, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 650, loss: 1.6133970022201538, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 700, loss: 1.7516261339187622, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 750, loss: 1.6737418174743652, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 800, loss: 1.6499431133270264, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 850, loss: 1.6213852167129517, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 900, loss: 1.634474515914917, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 950, loss: 1.8097889423370361, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1000, loss: 1.7783901691436768, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1050, loss: 1.655747413635254, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1100, loss: 1.7862823009490967, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1150, loss: 1.5576938390731812, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1200, loss: 1.7600677013397217, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1250, loss: 1.6184628009796143, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1300, loss: 1.3727201223373413, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1350, loss: 1.5031630992889404, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1400, loss: 1.5649479627609253, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1450, loss: 1.8353204727172852, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1500, loss: 1.7743916511535645, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1550, loss: 1.9514853954315186, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1600, loss: 1.8047258853912354, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1650, loss: 2.017538547515869, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1700, loss: 2.0463578701019287, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1750, loss: 1.6520700454711914, rate: 2.7081920400141814e-05\n",
      "Epoch: 32 Batch: 1800, loss: 1.729408621788025, rate: 2.7081920400141814e-05\n",
      "[2023-11-13 11:32:08.860665] Epoch: 32 ends. Average loss: 1.6916495554366957\n",
      "Epoch: 33 Batch: 0, loss: 1.8466359376907349, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 50, loss: 1.5267635583877563, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 100, loss: 1.859926700592041, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 150, loss: 1.799465537071228, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 200, loss: 1.9103537797927856, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 250, loss: 1.7191212177276611, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 300, loss: 1.144935965538025, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 350, loss: 1.590435266494751, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 400, loss: 1.6843281984329224, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 450, loss: 1.6497576236724854, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 500, loss: 1.9302960634231567, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 550, loss: 1.7635269165039062, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 600, loss: 1.4207202196121216, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 650, loss: 1.648193597793579, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 700, loss: 1.7565405368804932, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 750, loss: 1.696396827697754, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 800, loss: 1.662589430809021, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 850, loss: 1.5726665258407593, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 900, loss: 1.5813990831375122, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 950, loss: 1.9175479412078857, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1000, loss: 1.8785916566848755, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1050, loss: 1.665575385093689, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1100, loss: 1.825332522392273, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1150, loss: 1.7543535232543945, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1200, loss: 1.7530598640441895, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1250, loss: 1.5167192220687866, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1300, loss: 1.4047552347183228, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1350, loss: 1.4628905057907104, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1400, loss: 1.4400423765182495, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1450, loss: 1.8953062295913696, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1500, loss: 1.822534441947937, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1550, loss: 1.830798864364624, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1600, loss: 1.7614580392837524, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1650, loss: 1.9468729496002197, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1700, loss: 1.9914376735687256, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1750, loss: 1.6978551149368286, rate: 2.599864358413614e-05\n",
      "Epoch: 33 Batch: 1800, loss: 1.759713053703308, rate: 2.599864358413614e-05\n",
      "[2023-11-13 11:36:00.458016] Epoch: 33 ends. Average loss: 1.68884201057695\n",
      "Epoch: 34 Batch: 0, loss: 1.7664639949798584, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 50, loss: 1.514673113822937, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 100, loss: 1.7606749534606934, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 150, loss: 1.6008155345916748, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 200, loss: 1.8748313188552856, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 250, loss: 1.9078915119171143, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 300, loss: 1.1815977096557617, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 350, loss: 1.517076849937439, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 400, loss: 1.5606166124343872, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 450, loss: 1.6042636632919312, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 500, loss: 2.038149118423462, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 550, loss: 1.8738294839859009, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 600, loss: 1.4252156019210815, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 650, loss: 1.6853886842727661, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 700, loss: 1.6248592138290405, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 750, loss: 1.853211760520935, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 800, loss: 1.7893646955490112, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 850, loss: 1.4794349670410156, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 900, loss: 1.5146663188934326, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 950, loss: 1.766381025314331, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1000, loss: 1.7069284915924072, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1050, loss: 1.5065079927444458, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1100, loss: 1.7758644819259644, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1150, loss: 1.658105731010437, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1200, loss: 1.6313979625701904, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1250, loss: 1.5711649656295776, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1300, loss: 1.3548264503479004, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1350, loss: 1.4635443687438965, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1400, loss: 1.5463287830352783, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1450, loss: 1.8914952278137207, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1500, loss: 1.8009370565414429, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1550, loss: 1.8077361583709717, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1600, loss: 1.7191649675369263, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1650, loss: 1.8042166233062744, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1700, loss: 1.9553757905960083, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1750, loss: 1.6098873615264893, rate: 2.4958697840770694e-05\n",
      "Epoch: 34 Batch: 1800, loss: 1.7714940309524536, rate: 2.4958697840770694e-05\n",
      "[2023-11-13 11:39:51.127759] Epoch: 34 ends. Average loss: 1.6900257409375081\n",
      "Epoch: 35 Batch: 0, loss: 1.8122729063034058, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 50, loss: 1.6037683486938477, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 100, loss: 1.7982709407806396, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 150, loss: 1.6875451803207397, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 200, loss: 1.7540456056594849, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 250, loss: 1.8000738620758057, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 300, loss: 1.1876651048660278, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 350, loss: 1.5891190767288208, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 400, loss: 1.5498663187026978, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 450, loss: 1.7479345798492432, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 500, loss: 2.1961448192596436, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 550, loss: 1.8315215110778809, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 600, loss: 1.3512601852416992, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 650, loss: 1.741094946861267, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 700, loss: 1.7864876985549927, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 750, loss: 1.6911649703979492, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 800, loss: 1.6355692148208618, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 850, loss: 1.6306205987930298, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 900, loss: 1.6998693943023682, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 950, loss: 1.8650342226028442, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1000, loss: 1.831877589225769, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1050, loss: 1.583034634590149, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1100, loss: 1.6372302770614624, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1150, loss: 1.635664463043213, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1200, loss: 1.80289626121521, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1250, loss: 1.5195643901824951, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1300, loss: 1.5185964107513428, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1350, loss: 1.5478358268737793, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1400, loss: 1.686018943786621, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1450, loss: 1.8119350671768188, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1500, loss: 1.7782747745513916, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1550, loss: 1.8080040216445923, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1600, loss: 1.8104032278060913, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1650, loss: 1.8303231000900269, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1700, loss: 1.9588369131088257, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1750, loss: 1.685147762298584, rate: 2.3960349927139864e-05\n",
      "Epoch: 35 Batch: 1800, loss: 1.7624459266662598, rate: 2.3960349927139864e-05\n",
      "[2023-11-13 11:43:43.238327] Epoch: 35 ends. Average loss: 1.687701240338085\n",
      "Epoch: 36 Batch: 0, loss: 1.7200093269348145, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 50, loss: 1.5162601470947266, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 100, loss: 1.8752273321151733, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 150, loss: 1.7017462253570557, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 200, loss: 1.9129241704940796, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 250, loss: 1.7209151983261108, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 300, loss: 1.241661787033081, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 350, loss: 1.6366180181503296, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 400, loss: 1.5938117504119873, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 450, loss: 1.5891673564910889, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 500, loss: 1.988271713256836, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 550, loss: 1.8456157445907593, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 600, loss: 1.4444019794464111, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 650, loss: 1.6149280071258545, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 700, loss: 1.7152432203292847, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 750, loss: 1.6779776811599731, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 800, loss: 1.8278398513793945, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 850, loss: 1.5537666082382202, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 900, loss: 1.6161339282989502, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 950, loss: 1.8626450300216675, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1000, loss: 1.8183648586273193, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1050, loss: 1.5332785844802856, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1100, loss: 1.6615017652511597, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1150, loss: 1.5634211301803589, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1200, loss: 1.8093029260635376, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1250, loss: 1.5627493858337402, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1300, loss: 1.472705602645874, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1350, loss: 1.5541608333587646, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1400, loss: 1.6012530326843262, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1450, loss: 1.8691902160644531, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1500, loss: 1.7504961490631104, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1550, loss: 1.7418333292007446, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1600, loss: 1.6380281448364258, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1650, loss: 1.9532065391540527, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1700, loss: 2.0477118492126465, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1750, loss: 1.5938388109207153, rate: 2.3001935930054268e-05\n",
      "Epoch: 36 Batch: 1800, loss: 1.691413164138794, rate: 2.3001935930054268e-05\n",
      "[2023-11-13 11:47:36.600184] Epoch: 36 ends. Average loss: 1.687926309975352\n",
      "Epoch: 37 Batch: 0, loss: 1.760233998298645, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 50, loss: 1.5086822509765625, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 100, loss: 1.8357487916946411, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 150, loss: 1.6972033977508545, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 200, loss: 1.894113302230835, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 250, loss: 1.8461453914642334, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 300, loss: 1.1202716827392578, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 350, loss: 1.527285099029541, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 400, loss: 1.583695888519287, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 450, loss: 1.6458967924118042, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 500, loss: 2.022209644317627, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 550, loss: 1.922834038734436, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 600, loss: 1.3607834577560425, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 650, loss: 1.6224712133407593, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 700, loss: 1.7910041809082031, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 750, loss: 1.7353802919387817, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 800, loss: 1.6846046447753906, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 850, loss: 1.6350226402282715, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 900, loss: 1.7167350053787231, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 950, loss: 1.9614390134811401, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1000, loss: 1.8297247886657715, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1050, loss: 1.5888577699661255, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1100, loss: 1.7287187576293945, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1150, loss: 1.677080512046814, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1200, loss: 1.6728992462158203, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1250, loss: 1.593112826347351, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1300, loss: 1.4527244567871094, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1350, loss: 1.5700478553771973, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1400, loss: 1.5040088891983032, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1450, loss: 1.8429871797561646, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1500, loss: 1.807739496231079, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1550, loss: 1.7601449489593506, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1600, loss: 1.7810477018356323, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1650, loss: 1.9250473976135254, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1700, loss: 1.9685065746307373, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1750, loss: 1.7110705375671387, rate: 2.2081858492852098e-05\n",
      "Epoch: 37 Batch: 1800, loss: 1.7224466800689697, rate: 2.2081858492852098e-05\n",
      "[2023-11-13 11:51:31.071646] Epoch: 37 ends. Average loss: 1.686553130640355\n",
      "Epoch: 38 Batch: 0, loss: 1.856109380722046, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 50, loss: 1.6003849506378174, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 100, loss: 1.7636806964874268, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 150, loss: 1.755901575088501, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 200, loss: 1.8864537477493286, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 250, loss: 1.660003900527954, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 300, loss: 1.155930995941162, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 350, loss: 1.5514328479766846, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 400, loss: 1.5695083141326904, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 450, loss: 1.5852502584457397, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 500, loss: 1.9655739068984985, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 550, loss: 1.9468830823898315, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 600, loss: 1.4474599361419678, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 650, loss: 1.5324934720993042, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 700, loss: 1.7581511735916138, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 750, loss: 1.7607868909835815, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 800, loss: 1.8031456470489502, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 850, loss: 1.528597116470337, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 900, loss: 1.639159083366394, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 950, loss: 1.8144328594207764, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1000, loss: 1.833094835281372, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1050, loss: 1.612337350845337, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1100, loss: 1.8041383028030396, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1150, loss: 1.6008141040802002, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1200, loss: 1.746019721031189, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1250, loss: 1.570366621017456, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1300, loss: 1.35529363155365, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1350, loss: 1.5361101627349854, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1400, loss: 1.5683928728103638, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1450, loss: 1.8540326356887817, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1500, loss: 1.747085452079773, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1550, loss: 1.7904467582702637, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1600, loss: 1.7324718236923218, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1650, loss: 1.9029428958892822, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1700, loss: 2.0156683921813965, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1750, loss: 1.6613248586654663, rate: 2.1198584153138014e-05\n",
      "Epoch: 38 Batch: 1800, loss: 1.6808749437332153, rate: 2.1198584153138014e-05\n",
      "[2023-11-13 11:55:25.136174] Epoch: 38 ends. Average loss: 1.6868997297429014\n",
      "Epoch: 39 Batch: 0, loss: 1.76043701171875, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 50, loss: 1.487215280532837, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 100, loss: 1.848895788192749, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 150, loss: 1.72580885887146, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 200, loss: 1.9786196947097778, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 250, loss: 1.7083624601364136, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 300, loss: 1.08430016040802, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 350, loss: 1.5836833715438843, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 400, loss: 1.5986586809158325, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 450, loss: 1.7204563617706299, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 500, loss: 1.9423898458480835, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 550, loss: 1.8902674913406372, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 600, loss: 1.411942481994629, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 650, loss: 1.7179157733917236, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 700, loss: 1.7571115493774414, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 750, loss: 1.7030746936798096, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 800, loss: 1.6639881134033203, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 850, loss: 1.6157729625701904, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 900, loss: 1.6574132442474365, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 950, loss: 1.7963063716888428, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1000, loss: 1.882472038269043, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1050, loss: 1.6227227449417114, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1100, loss: 1.7438385486602783, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1150, loss: 1.6228896379470825, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1200, loss: 1.694322943687439, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1250, loss: 1.560952067375183, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1300, loss: 1.371501088142395, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1350, loss: 1.3726426362991333, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1400, loss: 1.5615274906158447, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1450, loss: 1.7529265880584717, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1500, loss: 1.810011863708496, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1550, loss: 1.7309246063232422, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1600, loss: 1.7201616764068604, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1650, loss: 1.9036202430725098, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1700, loss: 2.0107240676879883, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1750, loss: 1.6110666990280151, rate: 2.035064078701249e-05\n",
      "Epoch: 39 Batch: 1800, loss: 1.7136985063552856, rate: 2.035064078701249e-05\n",
      "[2023-11-13 11:59:18.913171] Epoch: 39 ends. Average loss: 1.6836682567922567\n",
      "Epoch: 40 Batch: 0, loss: 1.6731358766555786, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 50, loss: 1.5199552774429321, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 100, loss: 1.8323328495025635, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 150, loss: 1.7857924699783325, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 200, loss: 1.9781482219696045, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 250, loss: 1.7290213108062744, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 300, loss: 1.1002575159072876, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 350, loss: 1.6470236778259277, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 400, loss: 1.652725338935852, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 450, loss: 1.7252613306045532, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 500, loss: 2.02608585357666, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 550, loss: 1.8614600896835327, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 600, loss: 1.4600211381912231, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 650, loss: 1.626354694366455, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 700, loss: 1.7914793491363525, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 750, loss: 1.7233858108520508, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 800, loss: 1.7917041778564453, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 850, loss: 1.6636278629302979, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 900, loss: 1.6414486169815063, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 950, loss: 1.6670938730239868, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1000, loss: 1.7918953895568848, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1050, loss: 1.6655977964401245, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1100, loss: 1.7704689502716064, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1150, loss: 1.66997230052948, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1200, loss: 1.8557593822479248, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1250, loss: 1.5263880491256714, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1300, loss: 1.4685887098312378, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1350, loss: 1.4986484050750732, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1400, loss: 1.4442890882492065, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1450, loss: 1.7748587131500244, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1500, loss: 1.7171337604522705, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1550, loss: 1.8456246852874756, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1600, loss: 1.7881087064743042, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1650, loss: 1.957519292831421, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1700, loss: 2.069695472717285, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1750, loss: 1.7218599319458008, rate: 1.953661515553199e-05\n",
      "Epoch: 40 Batch: 1800, loss: 1.7259001731872559, rate: 1.953661515553199e-05\n",
      "[2023-11-13 12:03:12.064869] Epoch: 40 ends. Average loss: 1.6827042323742134\n",
      "Epoch: 41 Batch: 0, loss: 1.7806994915008545, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 50, loss: 1.5372318029403687, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 100, loss: 1.7901984453201294, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 150, loss: 1.6934669017791748, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 200, loss: 1.889732003211975, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 250, loss: 1.7955714464187622, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 300, loss: 1.202290654182434, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 350, loss: 1.4390671253204346, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 400, loss: 1.5783576965332031, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 450, loss: 1.5875205993652344, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 500, loss: 2.04910945892334, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 550, loss: 1.8867707252502441, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 600, loss: 1.3070093393325806, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 650, loss: 1.7180180549621582, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 700, loss: 1.7272402048110962, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 750, loss: 1.727288842201233, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 800, loss: 1.8268831968307495, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 850, loss: 1.5277904272079468, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 900, loss: 1.490683674812317, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 950, loss: 1.86123788356781, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1000, loss: 1.8114306926727295, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1050, loss: 1.6416419744491577, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1100, loss: 1.8221843242645264, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1150, loss: 1.611674427986145, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1200, loss: 1.6867905855178833, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1250, loss: 1.5107420682907104, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1300, loss: 1.456443190574646, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1350, loss: 1.5578129291534424, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1400, loss: 1.5286346673965454, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1450, loss: 1.8491564989089966, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1500, loss: 1.8614182472229004, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1550, loss: 1.896174430847168, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1600, loss: 1.7911840677261353, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1650, loss: 1.881271481513977, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1700, loss: 1.9397319555282593, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1750, loss: 1.721543312072754, rate: 1.8755150549310708e-05\n",
      "Epoch: 41 Batch: 1800, loss: 1.7063801288604736, rate: 1.8755150549310708e-05\n",
      "[2023-11-13 12:07:06.165517] Epoch: 41 ends. Average loss: 1.6834759075077474\n",
      "Epoch: 42 Batch: 0, loss: 1.6943762302398682, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 50, loss: 1.5436517000198364, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 100, loss: 1.6937063932418823, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 150, loss: 1.7285023927688599, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 200, loss: 1.8272935152053833, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 250, loss: 1.816690444946289, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 300, loss: 1.177786946296692, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 350, loss: 1.5121997594833374, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 400, loss: 1.6273411512374878, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 450, loss: 1.6384023427963257, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 500, loss: 2.061866283416748, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 550, loss: 1.9755388498306274, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 600, loss: 1.3627361059188843, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 650, loss: 1.6249130964279175, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 700, loss: 1.8108409643173218, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 750, loss: 1.7474913597106934, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 800, loss: 1.7238473892211914, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 850, loss: 1.4412060976028442, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 900, loss: 1.715751051902771, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 950, loss: 1.7323507070541382, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1000, loss: 1.8197333812713623, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1050, loss: 1.6083601713180542, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1100, loss: 1.6867752075195312, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1150, loss: 1.6234421730041504, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1200, loss: 1.8024481534957886, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1250, loss: 1.432603120803833, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1300, loss: 1.3709300756454468, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1350, loss: 1.5667377710342407, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1400, loss: 1.5941920280456543, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1450, loss: 1.8739134073257446, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1500, loss: 1.7854480743408203, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1550, loss: 1.88605797290802, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1600, loss: 1.7278252840042114, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1650, loss: 1.919371485710144, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1700, loss: 1.9794917106628418, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1750, loss: 1.6487295627593994, rate: 1.800494452733828e-05\n",
      "Epoch: 42 Batch: 1800, loss: 1.7456176280975342, rate: 1.800494452733828e-05\n",
      "[2023-11-13 12:10:56.640171] Epoch: 42 ends. Average loss: 1.6837228729918197\n",
      "Epoch: 43 Batch: 0, loss: 1.6999214887619019, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 50, loss: 1.4586575031280518, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 100, loss: 1.8064661026000977, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 150, loss: 1.5583685636520386, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 200, loss: 1.871025800704956, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 250, loss: 1.6590940952301025, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 300, loss: 1.166887640953064, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 350, loss: 1.4969812631607056, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 400, loss: 1.5528655052185059, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 450, loss: 1.5885610580444336, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 500, loss: 2.0822837352752686, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 550, loss: 1.882698655128479, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 600, loss: 1.4130610227584839, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 650, loss: 1.6784191131591797, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 700, loss: 1.7803038358688354, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 750, loss: 1.6546783447265625, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 800, loss: 1.8030260801315308, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 850, loss: 1.589415431022644, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 900, loss: 1.6805707216262817, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 950, loss: 1.9000402688980103, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1000, loss: 1.8290311098098755, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1050, loss: 1.5588420629501343, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1100, loss: 1.6745587587356567, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1150, loss: 1.5917800664901733, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1200, loss: 1.7691309452056885, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1250, loss: 1.5140458345413208, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1300, loss: 1.452509880065918, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1350, loss: 1.6531931161880493, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1400, loss: 1.5051379203796387, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1450, loss: 1.778256893157959, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1500, loss: 1.8119778633117676, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1550, loss: 1.822138786315918, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1600, loss: 1.6226533651351929, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1650, loss: 1.9462696313858032, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1700, loss: 1.9593181610107422, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1750, loss: 1.6389684677124023, rate: 1.7284746746244747e-05\n",
      "Epoch: 43 Batch: 1800, loss: 1.721117615699768, rate: 1.7284746746244747e-05\n",
      "[2023-11-13 12:14:45.779917] Epoch: 43 ends. Average loss: 1.6808331186969965\n",
      "Epoch: 44 Batch: 0, loss: 1.7390093803405762, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 50, loss: 1.4723031520843506, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 100, loss: 1.744746208190918, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 150, loss: 1.7501283884048462, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 200, loss: 1.8754756450653076, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 250, loss: 1.7113763093948364, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 300, loss: 1.2422927618026733, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 350, loss: 1.5117945671081543, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 400, loss: 1.584553599357605, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 450, loss: 1.6574351787567139, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 500, loss: 2.0528292655944824, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 550, loss: 1.9196182489395142, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 600, loss: 1.461474895477295, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 650, loss: 1.74358069896698, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 700, loss: 1.7151881456375122, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 750, loss: 1.6321988105773926, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 800, loss: 1.808957815170288, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 850, loss: 1.7255146503448486, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 900, loss: 1.5247889757156372, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 950, loss: 1.75063955783844, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1000, loss: 1.8445239067077637, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1050, loss: 1.5181890726089478, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1100, loss: 1.7131718397140503, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1150, loss: 1.6806306838989258, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1200, loss: 1.733143925666809, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1250, loss: 1.5187939405441284, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1300, loss: 1.3484487533569336, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1350, loss: 1.5674387216567993, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1400, loss: 1.5534497499465942, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1450, loss: 1.8607771396636963, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1500, loss: 1.7928799390792847, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1550, loss: 1.9100342988967896, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1600, loss: 1.8348690271377563, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1650, loss: 1.9856535196304321, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1700, loss: 2.0022048950195312, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1750, loss: 1.6428961753845215, rate: 1.6593356876394957e-05\n",
      "Epoch: 44 Batch: 1800, loss: 1.7529255151748657, rate: 1.6593356876394957e-05\n",
      "[2023-11-13 12:18:36.721479] Epoch: 44 ends. Average loss: 1.681801580948785\n",
      "Epoch: 45 Batch: 0, loss: 1.7230857610702515, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 50, loss: 1.4933327436447144, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 100, loss: 1.798498511314392, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 150, loss: 1.7356785535812378, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 200, loss: 1.8636057376861572, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 250, loss: 1.7280384302139282, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 300, loss: 1.1815935373306274, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 350, loss: 1.6461739540100098, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 400, loss: 1.5018948316574097, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 450, loss: 1.602144718170166, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 500, loss: 1.9981626272201538, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 550, loss: 1.7806092500686646, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 600, loss: 1.4147615432739258, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 650, loss: 1.6326181888580322, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 700, loss: 1.777415156364441, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 750, loss: 1.7185057401657104, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 800, loss: 1.7440346479415894, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 850, loss: 1.6760939359664917, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 900, loss: 1.6446845531463623, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 950, loss: 1.8585336208343506, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1000, loss: 1.8009945154190063, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1050, loss: 1.5861736536026, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1100, loss: 1.7921174764633179, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1150, loss: 1.5785576105117798, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1200, loss: 1.6657813787460327, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1250, loss: 1.506392478942871, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1300, loss: 1.4383633136749268, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1350, loss: 1.571195363998413, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1400, loss: 1.4294475317001343, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1450, loss: 1.790932297706604, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1500, loss: 1.8337128162384033, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1550, loss: 1.826961636543274, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1600, loss: 1.6871205568313599, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1650, loss: 1.8868190050125122, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1700, loss: 2.0743188858032227, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1750, loss: 1.7537283897399902, rate: 1.592962260133916e-05\n",
      "Epoch: 45 Batch: 1800, loss: 1.7723087072372437, rate: 1.592962260133916e-05\n",
      "[2023-11-13 12:22:24.488943] Epoch: 45 ends. Average loss: 1.6777314953690923\n",
      "Epoch: 46 Batch: 0, loss: 1.7703967094421387, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 50, loss: 1.3935333490371704, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 100, loss: 1.810186743736267, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 150, loss: 1.6426966190338135, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 200, loss: 1.8537541627883911, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 250, loss: 1.8210464715957642, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 300, loss: 1.179208517074585, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 350, loss: 1.5088127851486206, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 400, loss: 1.5853271484375, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 450, loss: 1.680671215057373, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 500, loss: 1.9782427549362183, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 550, loss: 1.9232169389724731, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 600, loss: 1.415307641029358, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 650, loss: 1.602074384689331, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 700, loss: 1.6805557012557983, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 750, loss: 1.7045775651931763, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 800, loss: 1.7415269613265991, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 850, loss: 1.6469725370407104, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 900, loss: 1.6244362592697144, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 950, loss: 1.8894357681274414, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1000, loss: 1.8606700897216797, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1050, loss: 1.5414402484893799, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1100, loss: 1.8369948863983154, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1150, loss: 1.6273380517959595, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1200, loss: 1.7935811281204224, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1250, loss: 1.6022590398788452, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1300, loss: 1.335735559463501, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1350, loss: 1.510957956314087, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1400, loss: 1.6313236951828003, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1450, loss: 1.870455265045166, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1500, loss: 1.8208826780319214, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1550, loss: 1.8463226556777954, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1600, loss: 1.811964988708496, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1650, loss: 1.8841410875320435, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1700, loss: 2.0330069065093994, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1750, loss: 1.6488840579986572, rate: 1.5292437697285593e-05\n",
      "Epoch: 46 Batch: 1800, loss: 1.7720407247543335, rate: 1.5292437697285593e-05\n",
      "[2023-11-13 12:26:12.985040] Epoch: 46 ends. Average loss: 1.6811111536199588\n",
      "Epoch: 47 Batch: 0, loss: 1.6875168085098267, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 50, loss: 1.4735692739486694, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 100, loss: 1.817165493965149, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 150, loss: 1.6651546955108643, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 200, loss: 1.871321439743042, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 250, loss: 1.7726988792419434, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 300, loss: 1.1936240196228027, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 350, loss: 1.4359334707260132, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 400, loss: 1.6185643672943115, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 450, loss: 1.678652286529541, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 500, loss: 1.9452613592147827, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 550, loss: 1.8872320652008057, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 600, loss: 1.4843497276306152, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 650, loss: 1.7284061908721924, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 700, loss: 1.758245587348938, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 750, loss: 1.666070580482483, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 800, loss: 1.7522324323654175, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 850, loss: 1.556551456451416, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 900, loss: 1.6909010410308838, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 950, loss: 1.8754981756210327, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1000, loss: 1.7310328483581543, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1050, loss: 1.4758968353271484, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1100, loss: 1.7768179178237915, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1150, loss: 1.7387632131576538, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1200, loss: 1.666707992553711, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1250, loss: 1.4627174139022827, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1300, loss: 1.489827275276184, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1350, loss: 1.5812097787857056, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1400, loss: 1.5672245025634766, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1450, loss: 1.9572802782058716, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1500, loss: 1.9068251848220825, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1550, loss: 1.8575003147125244, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1600, loss: 1.7160801887512207, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1650, loss: 1.8695087432861328, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1700, loss: 1.9040180444717407, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1750, loss: 1.5797145366668701, rate: 1.468074018939417e-05\n",
      "Epoch: 47 Batch: 1800, loss: 1.6183267831802368, rate: 1.468074018939417e-05\n",
      "[2023-11-13 12:30:01.920324] Epoch: 47 ends. Average loss: 1.6807759246047662\n",
      "Epoch: 48 Batch: 0, loss: 1.7739423513412476, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 50, loss: 1.4564565420150757, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 100, loss: 1.7916579246520996, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 150, loss: 1.8380529880523682, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 200, loss: 1.828563928604126, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 250, loss: 1.7018922567367554, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 300, loss: 1.2607421875, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 350, loss: 1.5764496326446533, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 400, loss: 1.6519396305084229, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 450, loss: 1.651157021522522, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 500, loss: 2.0951662063598633, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 550, loss: 1.893619179725647, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 600, loss: 1.2966601848602295, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 650, loss: 1.594326376914978, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 700, loss: 1.7594877481460571, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 750, loss: 1.667960286140442, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 800, loss: 1.6768085956573486, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 850, loss: 1.7101600170135498, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 900, loss: 1.5821892023086548, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 950, loss: 1.7724374532699585, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1000, loss: 1.7965781688690186, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1050, loss: 1.638116717338562, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1100, loss: 1.7299598455429077, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1150, loss: 1.6135478019714355, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1200, loss: 1.6873632669448853, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1250, loss: 1.5530986785888672, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1300, loss: 1.4024633169174194, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1350, loss: 1.4939923286437988, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1400, loss: 1.5961073637008667, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1450, loss: 1.8501806259155273, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1500, loss: 1.7844438552856445, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1550, loss: 1.7565255165100098, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1600, loss: 1.7528542280197144, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1650, loss: 1.9228214025497437, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1700, loss: 2.07893443107605, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1750, loss: 1.717336654663086, rate: 1.4093510581818402e-05\n",
      "Epoch: 48 Batch: 1800, loss: 1.6585030555725098, rate: 1.4093510581818402e-05\n",
      "[2023-11-13 12:33:57.188134] Epoch: 48 ends. Average loss: 1.677751086853646\n",
      "Epoch: 49 Batch: 0, loss: 1.7686519622802734, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 50, loss: 1.5359526872634888, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 100, loss: 1.69602370262146, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 150, loss: 1.7770068645477295, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 200, loss: 1.900051474571228, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 250, loss: 1.7425696849822998, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 300, loss: 1.2088580131530762, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 350, loss: 1.4621533155441284, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 400, loss: 1.618665099143982, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 450, loss: 1.5374113321304321, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 500, loss: 1.9087833166122437, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 550, loss: 1.8457562923431396, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 600, loss: 1.3822169303894043, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 650, loss: 1.7112696170806885, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 700, loss: 1.8215662240982056, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 750, loss: 1.6636359691619873, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 800, loss: 1.6943405866622925, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 850, loss: 1.6101243495941162, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 900, loss: 1.6556172370910645, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 950, loss: 1.84711492061615, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1000, loss: 1.7553527355194092, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1050, loss: 1.6168663501739502, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1100, loss: 1.6729459762573242, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1150, loss: 1.6730172634124756, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1200, loss: 1.8135004043579102, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1250, loss: 1.5255578756332397, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1300, loss: 1.3989132642745972, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1350, loss: 1.630669355392456, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1400, loss: 1.5265511274337769, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1450, loss: 1.8635066747665405, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1500, loss: 1.7475920915603638, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1550, loss: 1.8085836172103882, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1600, loss: 1.7255871295928955, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1650, loss: 1.9538767337799072, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1700, loss: 1.9457143545150757, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1750, loss: 1.6469205617904663, rate: 1.3529770158545665e-05\n",
      "Epoch: 49 Batch: 1800, loss: 1.8557473421096802, rate: 1.3529770158545665e-05\n",
      "[2023-11-13 12:37:51.979545] Epoch: 49 ends. Average loss: 1.6768708700510395\n",
      "Epoch: 50 Batch: 0, loss: 1.7496306896209717, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 50, loss: 1.4767197370529175, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 100, loss: 1.8600704669952393, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 150, loss: 1.798531413078308, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 200, loss: 1.7598202228546143, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 250, loss: 1.7527796030044556, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 300, loss: 1.1802457571029663, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 350, loss: 1.5119677782058716, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 400, loss: 1.627203345298767, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 450, loss: 1.6658052206039429, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 500, loss: 2.0130040645599365, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 550, loss: 1.9573591947555542, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 600, loss: 1.4868618249893188, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 650, loss: 1.5552258491516113, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 700, loss: 1.7054076194763184, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 750, loss: 1.7442381381988525, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 800, loss: 1.676263689994812, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 850, loss: 1.4991835355758667, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 900, loss: 1.670820951461792, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 950, loss: 1.7915419340133667, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1000, loss: 1.7658371925354004, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1050, loss: 1.5493255853652954, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1100, loss: 1.722328543663025, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1150, loss: 1.6097127199172974, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1200, loss: 1.698307752609253, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1250, loss: 1.515654444694519, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1300, loss: 1.5192455053329468, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1350, loss: 1.4320306777954102, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1400, loss: 1.4494616985321045, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1450, loss: 1.7966718673706055, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1500, loss: 1.845119595527649, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1550, loss: 1.906208872795105, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1600, loss: 1.721003770828247, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1650, loss: 2.029204845428467, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1700, loss: 2.0482711791992188, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1750, loss: 1.5899298191070557, rate: 1.2988579352203839e-05\n",
      "Epoch: 50 Batch: 1800, loss: 1.9167770147323608, rate: 1.2988579352203839e-05\n",
      "[2023-11-13 12:41:45.444049] Epoch: 50 ends. Average loss: 1.6767919522520593\n",
      "Epoch: 51 Batch: 0, loss: 1.6829568147659302, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 50, loss: 1.6056842803955078, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 100, loss: 1.861255407333374, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 150, loss: 1.532092571258545, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 200, loss: 1.7574080228805542, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 250, loss: 1.7281876802444458, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 300, loss: 1.2048423290252686, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 350, loss: 1.5032395124435425, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 400, loss: 1.7322616577148438, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 450, loss: 1.6077702045440674, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 500, loss: 2.0161962509155273, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 550, loss: 1.7943916320800781, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 600, loss: 1.2664467096328735, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 650, loss: 1.6323753595352173, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 700, loss: 1.7562248706817627, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 750, loss: 1.697407603263855, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 800, loss: 1.5744417905807495, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 850, loss: 1.5498552322387695, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 900, loss: 1.6284010410308838, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 950, loss: 1.8702061176300049, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1000, loss: 1.7619266510009766, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1050, loss: 1.6011955738067627, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1100, loss: 1.8441396951675415, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1150, loss: 1.6560006141662598, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1200, loss: 1.7002861499786377, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1250, loss: 1.6207419633865356, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1300, loss: 1.3161875009536743, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1350, loss: 1.646331787109375, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1400, loss: 1.4460859298706055, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1450, loss: 1.8360618352890015, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1500, loss: 1.8451621532440186, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1550, loss: 1.9192306995391846, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1600, loss: 1.7486857175827026, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1650, loss: 1.8729034662246704, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1700, loss: 2.042267084121704, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1750, loss: 1.6082006692886353, rate: 1.2469036178115684e-05\n",
      "Epoch: 51 Batch: 1800, loss: 1.6568864583969116, rate: 1.2469036178115684e-05\n",
      "[2023-11-13 12:45:39.601126] Epoch: 51 ends. Average loss: 1.675866106499379\n",
      "Epoch: 52 Batch: 0, loss: 1.7478880882263184, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 50, loss: 1.4422720670700073, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 100, loss: 1.749649167060852, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 150, loss: 1.668381929397583, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 200, loss: 1.8303061723709106, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 250, loss: 1.705161213874817, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 300, loss: 1.2284001111984253, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 350, loss: 1.4204752445220947, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 400, loss: 1.566230058670044, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 450, loss: 1.721240520477295, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 500, loss: 1.9325048923492432, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 550, loss: 1.918797492980957, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 600, loss: 1.320569396018982, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 650, loss: 1.6566972732543945, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 700, loss: 1.6434794664382935, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 750, loss: 1.7700539827346802, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 800, loss: 1.5799376964569092, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 850, loss: 1.5159093141555786, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 900, loss: 1.7090940475463867, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 950, loss: 1.8082470893859863, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1000, loss: 1.8222408294677734, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1050, loss: 1.5747864246368408, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1100, loss: 1.8088243007659912, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1150, loss: 1.621068000793457, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1200, loss: 1.697862148284912, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1250, loss: 1.578896403312683, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1300, loss: 1.4491349458694458, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1350, loss: 1.5089508295059204, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1400, loss: 1.5024734735488892, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1450, loss: 2.0454506874084473, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1500, loss: 1.8079723119735718, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1550, loss: 1.8048679828643799, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1600, loss: 1.808988332748413, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1650, loss: 1.9831019639968872, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1700, loss: 2.0424954891204834, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1750, loss: 1.530738115310669, rate: 1.1970274730991057e-05\n",
      "Epoch: 52 Batch: 1800, loss: 1.7031689882278442, rate: 1.1970274730991057e-05\n",
      "[2023-11-13 12:49:33.303460] Epoch: 52 ends. Average loss: 1.6765070031245506\n",
      "Epoch: 53 Batch: 0, loss: 1.658639907836914, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 50, loss: 1.4719226360321045, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 100, loss: 1.8872448205947876, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 150, loss: 1.7292770147323608, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 200, loss: 1.8297568559646606, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 250, loss: 1.6861366033554077, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 300, loss: 1.2454320192337036, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 350, loss: 1.497125267982483, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 400, loss: 1.5582152605056763, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 450, loss: 1.7377798557281494, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 500, loss: 1.8878408670425415, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 550, loss: 1.8281868696212769, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 600, loss: 1.4092079401016235, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 650, loss: 1.586857795715332, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 700, loss: 1.7125521898269653, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 750, loss: 1.683742642402649, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 800, loss: 1.7053200006484985, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 850, loss: 1.5336039066314697, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 900, loss: 1.694130778312683, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 950, loss: 1.865952491760254, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1000, loss: 1.7721253633499146, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1050, loss: 1.5307695865631104, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1100, loss: 1.7769200801849365, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1150, loss: 1.6718895435333252, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1200, loss: 1.6559933423995972, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1250, loss: 1.608684778213501, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1300, loss: 1.4242511987686157, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1350, loss: 1.5265185832977295, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1400, loss: 1.4884239435195923, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1450, loss: 1.8160721063613892, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1500, loss: 1.7063324451446533, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1550, loss: 1.7978233098983765, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1600, loss: 1.714411735534668, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1650, loss: 1.9742510318756104, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1700, loss: 2.006357192993164, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1750, loss: 1.7394744157791138, rate: 1.1491463741751414e-05\n",
      "Epoch: 53 Batch: 1800, loss: 1.850351333618164, rate: 1.1491463741751414e-05\n",
      "[2023-11-13 12:53:27.699954] Epoch: 53 ends. Average loss: 1.6737216262612236\n",
      "Epoch: 54 Batch: 0, loss: 1.6924506425857544, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 50, loss: 1.4270141124725342, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 100, loss: 1.8235081434249878, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 150, loss: 1.68366277217865, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 200, loss: 1.958010196685791, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 250, loss: 1.6939167976379395, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 300, loss: 1.2168859243392944, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 350, loss: 1.5549236536026, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 400, loss: 1.609307050704956, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 450, loss: 1.6575286388397217, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 500, loss: 1.9512919187545776, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 550, loss: 1.9260332584381104, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 600, loss: 1.3200476169586182, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 650, loss: 1.5738940238952637, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 700, loss: 1.9113986492156982, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 750, loss: 1.8774842023849487, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 800, loss: 1.7847188711166382, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 850, loss: 1.59336256980896, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 900, loss: 1.608718991279602, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 950, loss: 1.8775793313980103, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1000, loss: 1.871169924736023, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1050, loss: 1.5875999927520752, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1100, loss: 1.7576411962509155, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1150, loss: 1.6640238761901855, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1200, loss: 1.744964838027954, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1250, loss: 1.5510039329528809, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1300, loss: 1.3306684494018555, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1350, loss: 1.6113361120224, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1400, loss: 1.519323706626892, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1450, loss: 1.8126457929611206, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1500, loss: 1.830978512763977, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1550, loss: 1.8296325206756592, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1600, loss: 1.7848812341690063, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1650, loss: 1.825896978378296, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1700, loss: 2.016597032546997, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1750, loss: 1.5346397161483765, rate: 1.1031805192081357e-05\n",
      "Epoch: 54 Batch: 1800, loss: 1.8403187990188599, rate: 1.1031805192081357e-05\n",
      "[2023-11-13 12:57:22.291955] Epoch: 54 ends. Average loss: 1.6747079945636334\n",
      "Epoch: 55 Batch: 0, loss: 1.7232253551483154, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 50, loss: 1.3526830673217773, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 100, loss: 1.7873409986495972, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 150, loss: 1.7627757787704468, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 200, loss: 1.8436847925186157, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 250, loss: 1.8135915994644165, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 300, loss: 1.1595523357391357, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 350, loss: 1.4055299758911133, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 400, loss: 1.6974738836288452, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 450, loss: 1.565406084060669, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 500, loss: 2.018749475479126, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 550, loss: 1.8125711679458618, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 600, loss: 1.247117280960083, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 650, loss: 1.725263237953186, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 700, loss: 1.7331969738006592, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 750, loss: 1.7194021940231323, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 800, loss: 1.7086588144302368, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 850, loss: 1.7055904865264893, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 900, loss: 1.70426607131958, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 950, loss: 1.778826355934143, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1000, loss: 1.8224562406539917, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1050, loss: 1.4888036251068115, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1100, loss: 1.8558835983276367, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1150, loss: 1.5921586751937866, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1200, loss: 1.7370381355285645, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1250, loss: 1.5025314092636108, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1300, loss: 1.4582377672195435, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1350, loss: 1.4703868627548218, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1400, loss: 1.5089935064315796, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1450, loss: 1.816178321838379, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1500, loss: 1.7568415403366089, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1550, loss: 1.8078768253326416, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1600, loss: 1.7460471391677856, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1650, loss: 1.9488328695297241, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1700, loss: 2.0242385864257812, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1750, loss: 1.7561132907867432, rate: 1.0590532984398102e-05\n",
      "Epoch: 55 Batch: 1800, loss: 1.7492114305496216, rate: 1.0590532984398102e-05\n",
      "[2023-11-13 13:01:16.443793] Epoch: 55 ends. Average loss: 1.6730079331321737\n",
      "Epoch: 56 Batch: 0, loss: 1.7880237102508545, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 50, loss: 1.4819327592849731, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 100, loss: 1.7300840616226196, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 150, loss: 1.7522673606872559, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 200, loss: 1.8054187297821045, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 250, loss: 1.8180755376815796, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 300, loss: 1.2048993110656738, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 350, loss: 1.5068323612213135, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 400, loss: 1.6406986713409424, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 450, loss: 1.7525575160980225, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 500, loss: 2.0375561714172363, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 550, loss: 1.8472994565963745, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 600, loss: 1.3413602113723755, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 650, loss: 1.6186389923095703, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 700, loss: 1.7303533554077148, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 750, loss: 1.6133065223693848, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 800, loss: 1.7588435411453247, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 850, loss: 1.6216663122177124, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 900, loss: 1.5496912002563477, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 950, loss: 1.8678643703460693, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1000, loss: 1.8337546586990356, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1050, loss: 1.6051656007766724, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1100, loss: 1.7215118408203125, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1150, loss: 1.5366629362106323, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1200, loss: 1.7464245557785034, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1250, loss: 1.5240706205368042, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1300, loss: 1.3652876615524292, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1350, loss: 1.6410866975784302, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1400, loss: 1.4334503412246704, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1450, loss: 1.917443871498108, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1500, loss: 1.9008290767669678, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1550, loss: 1.7338964939117432, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1600, loss: 1.7298095226287842, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1650, loss: 1.9051218032836914, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1700, loss: 2.0403919219970703, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1750, loss: 1.671473741531372, rate: 1.0166911665022178e-05\n",
      "Epoch: 56 Batch: 1800, loss: 1.7405368089675903, rate: 1.0166911665022178e-05\n",
      "[2023-11-13 13:05:11.168827] Epoch: 56 ends. Average loss: 1.6737835702485822\n",
      "Epoch: 57 Batch: 0, loss: 1.8414160013198853, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 50, loss: 1.5685890913009644, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 100, loss: 1.881188154220581, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 150, loss: 1.7603280544281006, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 200, loss: 1.876974105834961, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 250, loss: 1.6071125268936157, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 300, loss: 1.201736330986023, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 350, loss: 1.419557809829712, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 400, loss: 1.532978892326355, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 450, loss: 1.6117732524871826, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 500, loss: 2.0849621295928955, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 550, loss: 1.850454568862915, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 600, loss: 1.340935230255127, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 650, loss: 1.6319363117218018, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 700, loss: 1.6854275465011597, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 750, loss: 1.7090364694595337, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 800, loss: 1.640651822090149, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 850, loss: 1.5655702352523804, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 900, loss: 1.5436917543411255, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 950, loss: 1.7968634366989136, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1000, loss: 1.801405429840088, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1050, loss: 1.5940178632736206, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1100, loss: 1.7736198902130127, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1150, loss: 1.6797637939453125, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1200, loss: 1.7566641569137573, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1250, loss: 1.5410553216934204, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1300, loss: 1.4027462005615234, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1350, loss: 1.5168910026550293, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1400, loss: 1.3943959474563599, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1450, loss: 1.8702529668807983, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1500, loss: 1.7580417394638062, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1550, loss: 1.76216459274292, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1600, loss: 1.654463291168213, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1650, loss: 1.913228154182434, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1700, loss: 2.045109987258911, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1750, loss: 1.6632945537567139, rate: 9.76023519842129e-06\n",
      "Epoch: 57 Batch: 1800, loss: 1.7072759866714478, rate: 9.76023519842129e-06\n",
      "[2023-11-13 13:09:02.303490] Epoch: 57 ends. Average loss: 1.6738458131468237\n",
      "Epoch: 58 Batch: 0, loss: 1.7451252937316895, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 50, loss: 1.5200973749160767, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 100, loss: 1.8177990913391113, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 150, loss: 1.5527961254119873, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 200, loss: 1.8363687992095947, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 250, loss: 1.7936102151870728, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 300, loss: 1.2105034589767456, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 350, loss: 1.5453715324401855, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 400, loss: 1.5655699968338013, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 450, loss: 1.5833224058151245, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 500, loss: 2.028475761413574, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 550, loss: 2.006727457046509, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 600, loss: 1.4477288722991943, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 650, loss: 1.555708408355713, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 700, loss: 1.7320003509521484, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 750, loss: 1.7544738054275513, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 800, loss: 1.714662790298462, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 850, loss: 1.502764344215393, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 900, loss: 1.6522055864334106, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 950, loss: 1.841206669807434, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1000, loss: 1.8354161977767944, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1050, loss: 1.4231410026550293, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1100, loss: 1.7571922540664673, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1150, loss: 1.5885443687438965, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1200, loss: 1.7764867544174194, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1250, loss: 1.5096570253372192, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1300, loss: 1.4322640895843506, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1350, loss: 1.5328097343444824, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1400, loss: 1.5407965183258057, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1450, loss: 1.7859256267547607, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1500, loss: 1.8452552556991577, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1550, loss: 1.7748786211013794, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1600, loss: 1.701459288597107, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1650, loss: 1.8887220621109009, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1700, loss: 1.999029517173767, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1750, loss: 1.6706514358520508, rate: 9.369825790484438e-06\n",
      "Epoch: 58 Batch: 1800, loss: 1.6778044700622559, rate: 9.369825790484438e-06\n",
      "[2023-11-13 13:12:53.980792] Epoch: 58 ends. Average loss: 1.6765600674335166\n",
      "Epoch: 59 Batch: 0, loss: 1.7205227613449097, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 50, loss: 1.464184045791626, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 100, loss: 1.687067985534668, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 150, loss: 1.6573938131332397, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 200, loss: 1.8054473400115967, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 250, loss: 1.7651742696762085, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 300, loss: 1.2686294317245483, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 350, loss: 1.4732388257980347, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 400, loss: 1.5834463834762573, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 450, loss: 1.6049437522888184, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 500, loss: 1.9220247268676758, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 550, loss: 1.827128291130066, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 600, loss: 1.4233477115631104, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 650, loss: 1.4747902154922485, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 700, loss: 1.7273865938186646, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 750, loss: 1.697584629058838, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 800, loss: 1.70357084274292, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 850, loss: 1.6064856052398682, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 900, loss: 1.6918153762817383, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 950, loss: 1.8259137868881226, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1000, loss: 1.7403748035430908, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1050, loss: 1.638497233390808, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1100, loss: 1.706855058670044, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1150, loss: 1.7514584064483643, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1200, loss: 1.7193659543991089, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1250, loss: 1.5134578943252563, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1300, loss: 1.5310152769088745, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1350, loss: 1.6046069860458374, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1400, loss: 1.5508366823196411, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1450, loss: 1.928267478942871, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1500, loss: 1.831484317779541, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1550, loss: 1.7340517044067383, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1600, loss: 1.649419903755188, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1650, loss: 1.989702820777893, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1700, loss: 1.9191924333572388, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1750, loss: 1.593091368675232, rate: 8.99503275886506e-06\n",
      "Epoch: 59 Batch: 1800, loss: 1.7970465421676636, rate: 8.99503275886506e-06\n",
      "[2023-11-13 13:16:44.510198] Epoch: 59 ends. Average loss: 1.6720156535481592\n",
      "Epoch: 60 Batch: 0, loss: 1.7658544778823853, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 50, loss: 1.5102193355560303, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 100, loss: 1.8222811222076416, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 150, loss: 1.594545602798462, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 200, loss: 1.8736077547073364, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 250, loss: 1.6906629800796509, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 300, loss: 1.1512246131896973, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 350, loss: 1.5831058025360107, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 400, loss: 1.6299481391906738, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 450, loss: 1.6211528778076172, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 500, loss: 2.0230963230133057, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 550, loss: 1.8270370960235596, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 600, loss: 1.4284969568252563, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 650, loss: 1.7206990718841553, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 700, loss: 1.7118313312530518, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 750, loss: 1.7780405282974243, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 800, loss: 1.784691333770752, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 850, loss: 1.529456615447998, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 900, loss: 1.6210377216339111, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 950, loss: 1.8942041397094727, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1000, loss: 1.8702301979064941, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1050, loss: 1.5832775831222534, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1100, loss: 1.7278178930282593, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1150, loss: 1.6416455507278442, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1200, loss: 1.8002793788909912, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1250, loss: 1.5180928707122803, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1300, loss: 1.3911303281784058, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1350, loss: 1.6018857955932617, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1400, loss: 1.671644687652588, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1450, loss: 1.8956305980682373, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1500, loss: 1.8762102127075195, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1550, loss: 1.7895678281784058, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1600, loss: 1.6496273279190063, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1650, loss: 2.0509090423583984, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1700, loss: 2.1237666606903076, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1750, loss: 1.6430137157440186, rate: 8.635231448510457e-06\n",
      "Epoch: 60 Batch: 1800, loss: 1.8189092874526978, rate: 8.635231448510457e-06\n",
      "[2023-11-13 13:20:36.983007] Epoch: 60 ends. Average loss: 1.6739441665969235\n",
      "Epoch: 61 Batch: 0, loss: 1.725799560546875, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 50, loss: 1.573184609413147, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 100, loss: 1.8214647769927979, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 150, loss: 1.7123892307281494, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 200, loss: 1.8192148208618164, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 250, loss: 1.7237452268600464, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 300, loss: 1.3060963153839111, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 350, loss: 1.4830106496810913, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 400, loss: 1.578639030456543, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 450, loss: 1.639872431755066, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 500, loss: 1.9912283420562744, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 550, loss: 1.9431232213974, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 600, loss: 1.309739112854004, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 650, loss: 1.627024531364441, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 700, loss: 1.6708616018295288, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 750, loss: 1.6369904279708862, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 800, loss: 1.7105531692504883, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 850, loss: 1.5841130018234253, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 900, loss: 1.6766682863235474, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 950, loss: 1.8349283933639526, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1000, loss: 1.7944202423095703, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1050, loss: 1.5470072031021118, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1100, loss: 1.8133916854858398, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1150, loss: 1.6048500537872314, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1200, loss: 1.7252110242843628, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1250, loss: 1.4893553256988525, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1300, loss: 1.3852301836013794, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1350, loss: 1.4348492622375488, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1400, loss: 1.603765845298767, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1450, loss: 1.9027729034423828, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1500, loss: 1.7670561075210571, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1550, loss: 1.7856823205947876, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1600, loss: 1.6283929347991943, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1650, loss: 1.952264428138733, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1700, loss: 2.0266058444976807, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1750, loss: 1.7109144926071167, rate: 8.289822190570038e-06\n",
      "Epoch: 61 Batch: 1800, loss: 1.8101967573165894, rate: 8.289822190570038e-06\n",
      "[2023-11-13 13:24:30.486674] Epoch: 61 ends. Average loss: 1.6735576614121082\n",
      "Epoch: 62 Batch: 0, loss: 1.7351961135864258, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 50, loss: 1.5226255655288696, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 100, loss: 1.7126199007034302, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 150, loss: 1.7053531408309937, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 200, loss: 1.8228507041931152, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 250, loss: 1.7051235437393188, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 300, loss: 1.1173840761184692, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 350, loss: 1.442291259765625, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 400, loss: 1.4719951152801514, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 450, loss: 1.6406877040863037, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 500, loss: 2.0278124809265137, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 550, loss: 1.8685799837112427, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 600, loss: 1.3065358400344849, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 650, loss: 1.6535463333129883, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 700, loss: 1.6795334815979004, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 750, loss: 1.6093858480453491, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 800, loss: 1.7707371711730957, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 850, loss: 1.5539953708648682, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 900, loss: 1.6185637712478638, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 950, loss: 1.770569086074829, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1000, loss: 1.8310446739196777, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1050, loss: 1.621652603149414, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1100, loss: 1.8343265056610107, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1150, loss: 1.715552806854248, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1200, loss: 1.7395076751708984, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1250, loss: 1.42148756980896, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1300, loss: 1.3560198545455933, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1350, loss: 1.4578959941864014, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1400, loss: 1.4846045970916748, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1450, loss: 1.8091645240783691, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1500, loss: 1.7810704708099365, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1550, loss: 1.763412356376648, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1600, loss: 1.715734601020813, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1650, loss: 1.9247854948043823, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1700, loss: 2.084064245223999, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1750, loss: 1.5510860681533813, rate: 7.958229302947236e-06\n",
      "Epoch: 62 Batch: 1800, loss: 1.8129736185073853, rate: 7.958229302947236e-06\n",
      "[2023-11-13 13:28:24.933454] Epoch: 62 ends. Average loss: 1.6742797780286787\n",
      "Epoch: 63 Batch: 0, loss: 1.8601422309875488, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 50, loss: 1.5665664672851562, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 100, loss: 1.7708475589752197, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 150, loss: 1.6650869846343994, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 200, loss: 1.768009901046753, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 250, loss: 1.6935451030731201, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 300, loss: 1.293628454208374, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 350, loss: 1.4687505960464478, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 400, loss: 1.5690895318984985, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 450, loss: 1.5882911682128906, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 500, loss: 2.026521921157837, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 550, loss: 1.7856879234313965, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 600, loss: 1.4652361869812012, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 650, loss: 1.740826964378357, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 700, loss: 1.7002513408660889, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 750, loss: 1.6424895524978638, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 800, loss: 1.7448440790176392, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 850, loss: 1.5768568515777588, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 900, loss: 1.675302267074585, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 950, loss: 1.8712726831436157, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1000, loss: 1.684343695640564, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1050, loss: 1.6072386503219604, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1100, loss: 1.7703875303268433, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1150, loss: 1.5972623825073242, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1200, loss: 1.7247027158737183, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1250, loss: 1.63422429561615, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1300, loss: 1.412287950515747, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1350, loss: 1.5863374471664429, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1400, loss: 1.5859390497207642, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1450, loss: 1.8663159608840942, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1500, loss: 1.7916351556777954, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1550, loss: 1.8788318634033203, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1600, loss: 1.7042372226715088, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1650, loss: 2.0269644260406494, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1700, loss: 1.9253336191177368, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1750, loss: 1.6842939853668213, rate: 7.639900130829346e-06\n",
      "Epoch: 63 Batch: 1800, loss: 1.7488772869110107, rate: 7.639900130829346e-06\n",
      "[2023-11-13 13:32:18.692788] Epoch: 63 ends. Average loss: 1.6711624227566937\n",
      "Epoch: 64 Batch: 0, loss: 1.733290433883667, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 50, loss: 1.4723471403121948, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 100, loss: 1.7961313724517822, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 150, loss: 1.643399953842163, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 200, loss: 1.8111581802368164, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 250, loss: 1.7524526119232178, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 300, loss: 1.2519892454147339, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 350, loss: 1.5985918045043945, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 400, loss: 1.4871193170547485, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 450, loss: 1.5510793924331665, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 500, loss: 2.0385372638702393, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 550, loss: 2.003734588623047, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 600, loss: 1.3577765226364136, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 650, loss: 1.6859620809555054, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 700, loss: 1.7839024066925049, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 750, loss: 1.7589116096496582, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 800, loss: 1.6777056455612183, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 850, loss: 1.6095314025878906, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 900, loss: 1.6484023332595825, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 950, loss: 1.9096627235412598, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1000, loss: 1.7472150325775146, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1050, loss: 1.6370912790298462, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1100, loss: 1.7084063291549683, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1150, loss: 1.6282776594161987, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1200, loss: 1.750509262084961, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1250, loss: 1.6517800092697144, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1300, loss: 1.468371033668518, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1350, loss: 1.6528023481369019, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1400, loss: 1.4586848020553589, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1450, loss: 1.802079200744629, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1500, loss: 1.8547022342681885, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1550, loss: 1.75242280960083, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1600, loss: 1.6506571769714355, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1650, loss: 1.8386045694351196, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1700, loss: 2.047454595565796, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1750, loss: 1.6463234424591064, rate: 7.334304125596171e-06\n",
      "Epoch: 64 Batch: 1800, loss: 1.7857550382614136, rate: 7.334304125596171e-06\n",
      "[2023-11-13 13:36:12.164001] Epoch: 64 ends. Average loss: 1.671007088449734\n",
      "Epoch: 65 Batch: 0, loss: 1.7242282629013062, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 50, loss: 1.5573967695236206, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 100, loss: 1.8723115921020508, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 150, loss: 1.632167935371399, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 200, loss: 1.7849812507629395, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 250, loss: 1.779450535774231, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 300, loss: 1.160225749015808, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 350, loss: 1.345367193222046, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 400, loss: 1.4727096557617188, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 450, loss: 1.6381603479385376, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 500, loss: 2.008366584777832, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 550, loss: 1.7985011339187622, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 600, loss: 1.3755090236663818, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 650, loss: 1.5797696113586426, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 700, loss: 1.7804229259490967, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 750, loss: 1.628897786140442, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 800, loss: 1.6864176988601685, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 850, loss: 1.5874272584915161, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 900, loss: 1.807416558265686, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 950, loss: 1.884561538696289, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1000, loss: 1.8555253744125366, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1050, loss: 1.5554661750793457, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1100, loss: 1.7307320833206177, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1150, loss: 1.8235474824905396, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1200, loss: 1.8233224153518677, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1250, loss: 1.620169997215271, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1300, loss: 1.4390469789505005, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1350, loss: 1.490778923034668, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1400, loss: 1.4220412969589233, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1450, loss: 1.7995959520339966, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1500, loss: 1.716415286064148, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1550, loss: 1.6857088804244995, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1600, loss: 1.751845359802246, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1650, loss: 1.8867117166519165, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1700, loss: 2.044712543487549, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1750, loss: 1.5940250158309937, rate: 7.040931960572324e-06\n",
      "Epoch: 65 Batch: 1800, loss: 1.7538833618164062, rate: 7.040931960572324e-06\n",
      "[2023-11-13 13:40:03.609220] Epoch: 65 ends. Average loss: 1.6711105940687807\n",
      "Epoch: 66 Batch: 0, loss: 1.7320668697357178, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 50, loss: 1.534401535987854, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 100, loss: 1.7196800708770752, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 150, loss: 1.7093174457550049, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 200, loss: 1.7713372707366943, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 250, loss: 1.6935080289840698, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 300, loss: 1.1294995546340942, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 350, loss: 1.4227126836776733, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 400, loss: 1.636566400527954, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 450, loss: 1.6663168668746948, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 500, loss: 1.882899522781372, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 550, loss: 1.852472186088562, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 600, loss: 1.4492660760879517, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 650, loss: 1.6234372854232788, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 700, loss: 1.7304524183273315, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 750, loss: 1.719118595123291, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 800, loss: 1.6679185628890991, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 850, loss: 1.5567435026168823, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 900, loss: 1.5760531425476074, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 950, loss: 1.7673583030700684, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1000, loss: 1.8972080945968628, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1050, loss: 1.5179634094238281, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1100, loss: 1.7574043273925781, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1150, loss: 1.658707618713379, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1200, loss: 1.8079808950424194, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1250, loss: 1.5280365943908691, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1300, loss: 1.3818893432617188, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1350, loss: 1.5345314741134644, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1400, loss: 1.5130963325500488, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1450, loss: 1.8664337396621704, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1500, loss: 1.8239080905914307, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1550, loss: 1.8267399072647095, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1600, loss: 1.6927636861801147, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1650, loss: 1.927623987197876, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1700, loss: 2.0443055629730225, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1750, loss: 1.682174801826477, rate: 6.759294682149431e-06\n",
      "Epoch: 66 Batch: 1800, loss: 1.8177218437194824, rate: 6.759294682149431e-06\n",
      "[2023-11-13 13:43:54.602113] Epoch: 66 ends. Average loss: 1.6708878729794476\n",
      "Epoch: 67 Batch: 0, loss: 1.770133137702942, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 50, loss: 1.5118430852890015, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 100, loss: 1.7556098699569702, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 150, loss: 1.686112642288208, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 200, loss: 1.863607406616211, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 250, loss: 1.6663306951522827, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 300, loss: 1.2244346141815186, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 350, loss: 1.4603829383850098, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 400, loss: 1.60630202293396, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 450, loss: 1.6779893636703491, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 500, loss: 1.9932081699371338, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 550, loss: 1.8939704895019531, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 600, loss: 1.4380244016647339, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 650, loss: 1.6870505809783936, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 700, loss: 1.6999012231826782, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 750, loss: 1.5961743593215942, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 800, loss: 1.6115999221801758, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 850, loss: 1.6545720100402832, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 900, loss: 1.6740108728408813, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 950, loss: 1.801423192024231, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1000, loss: 1.7171193361282349, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1050, loss: 1.5401500463485718, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1100, loss: 1.7650710344314575, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1150, loss: 1.6436870098114014, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1200, loss: 1.6972190141677856, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1250, loss: 1.7039483785629272, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1300, loss: 1.3762074708938599, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1350, loss: 1.4956672191619873, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1400, loss: 1.548491358757019, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1450, loss: 1.7852208614349365, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1500, loss: 1.807234764099121, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1550, loss: 1.892951250076294, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1600, loss: 1.6543641090393066, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1650, loss: 1.853776454925537, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1700, loss: 1.9580615758895874, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1750, loss: 1.699422001838684, rate: 6.488922894863454e-06\n",
      "Epoch: 67 Batch: 1800, loss: 1.6780685186386108, rate: 6.488922894863454e-06\n",
      "[2023-11-13 13:47:44.131659] Epoch: 67 ends. Average loss: 1.6725689542931348\n",
      "Epoch: 68 Batch: 0, loss: 1.7045600414276123, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 50, loss: 1.4930951595306396, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 100, loss: 1.6744780540466309, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 150, loss: 1.745579481124878, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 200, loss: 1.9236043691635132, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 250, loss: 1.6377538442611694, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 300, loss: 1.1370848417282104, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 350, loss: 1.3945393562316895, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 400, loss: 1.5175623893737793, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 450, loss: 1.646109938621521, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 500, loss: 2.002267360687256, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 550, loss: 1.8954802751541138, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 600, loss: 1.4465546607971191, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 650, loss: 1.5979036092758179, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 700, loss: 1.7579171657562256, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 750, loss: 1.8033289909362793, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 800, loss: 1.6902499198913574, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 850, loss: 1.5655170679092407, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 900, loss: 1.5724958181381226, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 950, loss: 1.8286889791488647, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1000, loss: 1.8349090814590454, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1050, loss: 1.6001572608947754, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1100, loss: 1.7292330265045166, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1150, loss: 1.5385059118270874, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1200, loss: 1.6893703937530518, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1250, loss: 1.4449268579483032, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1300, loss: 1.5354259014129639, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1350, loss: 1.488158941268921, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1400, loss: 1.5268595218658447, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1450, loss: 1.8084070682525635, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1500, loss: 1.7410207986831665, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1550, loss: 1.7027106285095215, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1600, loss: 1.7077276706695557, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1650, loss: 1.851061463356018, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1700, loss: 1.9822731018066406, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1750, loss: 1.6735292673110962, rate: 6.229365979068915e-06\n",
      "Epoch: 68 Batch: 1800, loss: 1.7340179681777954, rate: 6.229365979068915e-06\n",
      "[2023-11-13 13:51:33.870819] Epoch: 68 ends. Average loss: 1.6709557610589105\n",
      "Epoch: 69 Batch: 0, loss: 1.7934304475784302, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 50, loss: 1.5675240755081177, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 100, loss: 1.826682448387146, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 150, loss: 1.6697040796279907, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 200, loss: 1.8781681060791016, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 250, loss: 1.803171157836914, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 300, loss: 1.2347115278244019, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 350, loss: 1.4676685333251953, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 400, loss: 1.538398027420044, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 450, loss: 1.6177263259887695, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 500, loss: 1.9991191625595093, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 550, loss: 1.8249372243881226, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 600, loss: 1.4399523735046387, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 650, loss: 1.5059888362884521, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 700, loss: 1.6748723983764648, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 750, loss: 1.67545747756958, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 800, loss: 1.6810849905014038, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 850, loss: 1.5647857189178467, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 900, loss: 1.5713542699813843, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 950, loss: 1.7722771167755127, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1000, loss: 1.7863746881484985, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1050, loss: 1.549831509590149, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1100, loss: 1.6892173290252686, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1150, loss: 1.552443504333496, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1200, loss: 1.6060086488723755, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1250, loss: 1.6092615127563477, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1300, loss: 1.3813958168029785, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1350, loss: 1.5709567070007324, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1400, loss: 1.5413992404937744, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1450, loss: 1.9044196605682373, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1500, loss: 1.7722581624984741, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1550, loss: 1.7407258749008179, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1600, loss: 1.763149619102478, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1650, loss: 1.8813725709915161, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1700, loss: 1.9724438190460205, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1750, loss: 1.5667394399642944, rate: 5.980191339906158e-06\n",
      "Epoch: 69 Batch: 1800, loss: 1.8024311065673828, rate: 5.980191339906158e-06\n",
      "[2023-11-13 13:55:23.340959] Epoch: 69 ends. Average loss: 1.669739621091928\n",
      "Epoch: 70 Batch: 0, loss: 1.7844552993774414, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 50, loss: 1.5138624906539917, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 100, loss: 1.7547008991241455, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 150, loss: 1.8530566692352295, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 200, loss: 1.827155351638794, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 250, loss: 1.7512202262878418, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 300, loss: 1.199898362159729, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 350, loss: 1.4225884675979614, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 400, loss: 1.659743070602417, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 450, loss: 1.6244691610336304, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 500, loss: 2.103938102722168, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 550, loss: 1.8041259050369263, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 600, loss: 1.448248267173767, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 650, loss: 1.6075993776321411, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 700, loss: 1.7764525413513184, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 750, loss: 1.6697031259536743, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 800, loss: 1.6199663877487183, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 850, loss: 1.6858233213424683, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 900, loss: 1.601442575454712, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 950, loss: 1.7930091619491577, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1000, loss: 1.732256293296814, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1050, loss: 1.5802288055419922, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1100, loss: 1.7270594835281372, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1150, loss: 1.4999881982803345, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1200, loss: 1.6580556631088257, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1250, loss: 1.639899492263794, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1300, loss: 1.3953282833099365, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1350, loss: 1.480040192604065, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1400, loss: 1.5213030576705933, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1450, loss: 1.854802131652832, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1500, loss: 1.780762791633606, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1550, loss: 1.7944447994232178, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1600, loss: 1.67787766456604, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1650, loss: 1.9386770725250244, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1700, loss: 2.092479705810547, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1750, loss: 1.5834925174713135, rate: 5.740983686309912e-06\n",
      "Epoch: 70 Batch: 1800, loss: 1.7695865631103516, rate: 5.740983686309912e-06\n",
      "[2023-11-13 13:59:12.997530] Epoch: 70 ends. Average loss: 1.6717331204306534\n",
      "Epoch: 71 Batch: 0, loss: 1.7915704250335693, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 50, loss: 1.5738427639007568, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 100, loss: 1.7152390480041504, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 150, loss: 1.7023212909698486, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 200, loss: 1.8564040660858154, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 250, loss: 1.6047062873840332, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 300, loss: 1.1658188104629517, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 350, loss: 1.358896017074585, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 400, loss: 1.5716999769210815, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 450, loss: 1.5637590885162354, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 500, loss: 1.97868013381958, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 550, loss: 1.829708218574524, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 600, loss: 1.449756145477295, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 650, loss: 1.694540023803711, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 700, loss: 1.7180856466293335, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 750, loss: 1.588504672050476, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 800, loss: 1.6966328620910645, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 850, loss: 1.514686107635498, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 900, loss: 1.6704182624816895, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 950, loss: 1.870378851890564, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1000, loss: 1.8397419452667236, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1050, loss: 1.5903773307800293, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1100, loss: 1.5595616102218628, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1150, loss: 1.614917278289795, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1200, loss: 1.7514939308166504, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1250, loss: 1.6082953214645386, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1300, loss: 1.3845477104187012, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1350, loss: 1.5596652030944824, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1400, loss: 1.5240072011947632, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1450, loss: 1.8207218647003174, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1500, loss: 1.8331265449523926, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1550, loss: 1.7173441648483276, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1600, loss: 1.7793244123458862, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1650, loss: 1.8969910144805908, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1700, loss: 2.012423038482666, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1750, loss: 1.6141357421875, rate: 5.511344338857515e-06\n",
      "Epoch: 71 Batch: 1800, loss: 1.8359835147857666, rate: 5.511344338857515e-06\n",
      "[2023-11-13 14:03:03.081656] Epoch: 71 ends. Average loss: 1.6735133221973981\n",
      "Epoch: 72 Batch: 0, loss: 1.7128372192382812, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 50, loss: 1.4435474872589111, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 100, loss: 1.7672514915466309, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 150, loss: 1.7602728605270386, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 200, loss: 1.8436213731765747, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 250, loss: 1.7563116550445557, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 300, loss: 1.221257209777832, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 350, loss: 1.4234434366226196, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 400, loss: 1.6650131940841675, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 450, loss: 1.604256272315979, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 500, loss: 1.9740607738494873, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 550, loss: 1.789032220840454, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 600, loss: 1.490197777748108, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 650, loss: 1.649421215057373, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 700, loss: 1.8329541683197021, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 750, loss: 1.6974130868911743, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 800, loss: 1.7910326719284058, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 850, loss: 1.5721938610076904, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 900, loss: 1.6444804668426514, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 950, loss: 1.8715322017669678, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1000, loss: 1.739352822303772, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1050, loss: 1.6202625036239624, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1100, loss: 1.831622838973999, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1150, loss: 1.7089529037475586, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1200, loss: 1.6512155532836914, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1250, loss: 1.6418125629425049, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1300, loss: 1.3057498931884766, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1350, loss: 1.5206668376922607, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1400, loss: 1.4271806478500366, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1450, loss: 1.8429077863693237, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1500, loss: 1.8067151308059692, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1550, loss: 1.847548007965088, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1600, loss: 1.7193028926849365, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1650, loss: 2.0460281372070312, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1700, loss: 1.967487096786499, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1750, loss: 1.6586780548095703, rate: 5.290890565303214e-06\n",
      "Epoch: 72 Batch: 1800, loss: 1.6383448839187622, rate: 5.290890565303214e-06\n",
      "[2023-11-13 14:06:53.229160] Epoch: 72 ends. Average loss: 1.6697481153948952\n",
      "Epoch: 73 Batch: 0, loss: 1.7293351888656616, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 50, loss: 1.4086062908172607, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 100, loss: 1.734346866607666, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 150, loss: 1.6659027338027954, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 200, loss: 1.7692288160324097, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 250, loss: 1.7704797983169556, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 300, loss: 1.1262917518615723, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 350, loss: 1.4817144870758057, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 400, loss: 1.6330697536468506, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 450, loss: 1.6797187328338623, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 500, loss: 1.9455970525741577, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 550, loss: 1.9439314603805542, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 600, loss: 1.416279911994934, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 650, loss: 1.6090681552886963, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 700, loss: 1.705082654953003, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 750, loss: 1.5985385179519653, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 800, loss: 1.6446248292922974, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 850, loss: 1.5287679433822632, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 900, loss: 1.683663010597229, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 950, loss: 1.7503858804702759, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1000, loss: 1.6723334789276123, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1050, loss: 1.574863076210022, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1100, loss: 1.7591171264648438, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1150, loss: 1.5444849729537964, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1200, loss: 1.7033137083053589, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1250, loss: 1.640396237373352, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1300, loss: 1.437831163406372, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1350, loss: 1.5945026874542236, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1400, loss: 1.5927730798721313, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1450, loss: 1.8388690948486328, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1500, loss: 1.7545204162597656, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1550, loss: 1.8513661623001099, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1600, loss: 1.656862497329712, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1650, loss: 1.9125405550003052, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1700, loss: 2.1177401542663574, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1750, loss: 1.6664741039276123, rate: 5.079254942691085e-06\n",
      "Epoch: 73 Batch: 1800, loss: 1.8159691095352173, rate: 5.079254942691085e-06\n",
      "[2023-11-13 14:10:42.698256] Epoch: 73 ends. Average loss: 1.6702372908131957\n",
      "Epoch: 74 Batch: 0, loss: 1.7412029504776, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 50, loss: 1.4504371881484985, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 100, loss: 1.800607681274414, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 150, loss: 1.7125681638717651, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 200, loss: 1.8125969171524048, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 250, loss: 1.6857646703720093, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 300, loss: 1.1573203802108765, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 350, loss: 1.4946917295455933, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 400, loss: 1.6118266582489014, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 450, loss: 1.7131770849227905, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 500, loss: 2.0299932956695557, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 550, loss: 1.7759292125701904, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 600, loss: 1.3983134031295776, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 650, loss: 1.6644452810287476, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 700, loss: 1.6996387243270874, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 750, loss: 1.654664397239685, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 800, loss: 1.65436851978302, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 850, loss: 1.5996534824371338, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 900, loss: 1.6615430116653442, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 950, loss: 1.7565853595733643, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1000, loss: 1.8235266208648682, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1050, loss: 1.5219945907592773, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1100, loss: 1.7590606212615967, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1150, loss: 1.572189450263977, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1200, loss: 1.746233344078064, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1250, loss: 1.551862120628357, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1300, loss: 1.47929847240448, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1350, loss: 1.5237441062927246, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1400, loss: 1.4976296424865723, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1450, loss: 1.8251476287841797, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1500, loss: 1.6583671569824219, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1550, loss: 1.751664161682129, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1600, loss: 1.7120250463485718, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1650, loss: 1.9779767990112305, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1700, loss: 1.8701454401016235, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1750, loss: 1.681910753250122, rate: 4.876084744983441e-06\n",
      "Epoch: 74 Batch: 1800, loss: 1.8489934206008911, rate: 4.876084744983441e-06\n",
      "[2023-11-13 14:14:32.312818] Epoch: 74 ends. Average loss: 1.6682575430846385\n",
      "Epoch: 75 Batch: 0, loss: 1.7695884704589844, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 50, loss: 1.4366356134414673, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 100, loss: 1.8435657024383545, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 150, loss: 1.7667568922042847, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 200, loss: 1.8394850492477417, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 250, loss: 1.6636874675750732, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 300, loss: 1.0671348571777344, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 350, loss: 1.4438717365264893, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 400, loss: 1.5468167066574097, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 450, loss: 1.5950701236724854, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 500, loss: 1.9365540742874146, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 550, loss: 1.8465819358825684, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 600, loss: 1.4019181728363037, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 650, loss: 1.513149619102478, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 700, loss: 1.8116075992584229, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 750, loss: 1.7802741527557373, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 800, loss: 1.7671723365783691, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 850, loss: 1.5362331867218018, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 900, loss: 1.5643798112869263, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 950, loss: 1.8490360975265503, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1000, loss: 1.6663827896118164, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1050, loss: 1.5430530309677124, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1100, loss: 1.7224128246307373, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1150, loss: 1.7120742797851562, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1200, loss: 1.7166012525558472, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1250, loss: 1.5070158243179321, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1300, loss: 1.297346830368042, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1350, loss: 1.5011764764785767, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1400, loss: 1.5933860540390015, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1450, loss: 1.901727557182312, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1500, loss: 1.7794275283813477, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1550, loss: 1.8315147161483765, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1600, loss: 1.6492760181427002, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1650, loss: 2.014925956726074, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1700, loss: 2.051077127456665, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1750, loss: 1.6237682104110718, rate: 4.681041355184103e-06\n",
      "Epoch: 75 Batch: 1800, loss: 1.8675158023834229, rate: 4.681041355184103e-06\n",
      "[2023-11-13 14:18:22.726992] Epoch: 75 ends. Average loss: 1.6718125290063226\n",
      "Epoch: 76 Batch: 0, loss: 1.6508421897888184, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 50, loss: 1.539339303970337, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 100, loss: 1.700944423675537, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 150, loss: 1.6414965391159058, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 200, loss: 1.8953471183776855, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 250, loss: 1.6931259632110596, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 300, loss: 1.0554484128952026, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 350, loss: 1.4762358665466309, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 400, loss: 1.639222502708435, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 450, loss: 1.6259510517120361, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 500, loss: 1.9982537031173706, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 550, loss: 1.9419866800308228, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 600, loss: 1.4135900735855103, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 650, loss: 1.6784454584121704, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 700, loss: 1.8469696044921875, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 750, loss: 1.6547884941101074, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 800, loss: 1.6137722730636597, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 850, loss: 1.5784326791763306, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 900, loss: 1.6542646884918213, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 950, loss: 1.8532745838165283, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1000, loss: 1.8062586784362793, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1050, loss: 1.5759127140045166, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1100, loss: 1.7354339361190796, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1150, loss: 1.6464695930480957, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1200, loss: 1.6119160652160645, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1250, loss: 1.479633092880249, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1300, loss: 1.370895504951477, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1350, loss: 1.4645440578460693, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1400, loss: 1.4739165306091309, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1450, loss: 1.7684992551803589, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1500, loss: 1.7827409505844116, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1550, loss: 1.9045346975326538, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1600, loss: 1.7218512296676636, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1650, loss: 1.872818946838379, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1700, loss: 1.9687103033065796, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1750, loss: 1.6384614706039429, rate: 4.493799700976739e-06\n",
      "Epoch: 76 Batch: 1800, loss: 1.8297617435455322, rate: 4.493799700976739e-06\n",
      "[2023-11-13 14:22:12.700638] Epoch: 76 ends. Average loss: 1.6694656536188561\n",
      "Epoch: 77 Batch: 0, loss: 1.8524096012115479, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 50, loss: 1.3898041248321533, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 100, loss: 1.878099799156189, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 150, loss: 1.686769962310791, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 200, loss: 1.8353906869888306, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 250, loss: 1.6292378902435303, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 300, loss: 1.2378790378570557, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 350, loss: 1.518513798713684, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 400, loss: 1.630469560623169, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 450, loss: 1.6921653747558594, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 500, loss: 1.9176849126815796, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 550, loss: 1.8395013809204102, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 600, loss: 1.3103302717208862, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 650, loss: 1.5958735942840576, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 700, loss: 1.769226312637329, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 750, loss: 1.6438498497009277, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 800, loss: 1.6406573057174683, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 850, loss: 1.5463272333145142, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 900, loss: 1.578011393547058, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 950, loss: 1.8563621044158936, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1000, loss: 1.690285563468933, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1050, loss: 1.6317015886306763, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1100, loss: 1.8045116662979126, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1150, loss: 1.6990761756896973, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1200, loss: 1.7517039775848389, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1250, loss: 1.4570508003234863, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1300, loss: 1.437151551246643, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1350, loss: 1.5412297248840332, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1400, loss: 1.4266681671142578, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1450, loss: 1.8298373222351074, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1500, loss: 1.7741073369979858, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1550, loss: 1.8013529777526855, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1600, loss: 1.744032621383667, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1650, loss: 2.0248212814331055, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1700, loss: 2.0477077960968018, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1750, loss: 1.5830981731414795, rate: 4.31404771293767e-06\n",
      "Epoch: 77 Batch: 1800, loss: 1.7434301376342773, rate: 4.31404771293767e-06\n",
      "[2023-11-13 14:26:03.754298] Epoch: 77 ends. Average loss: 1.6725277556810205\n",
      "Epoch: 78 Batch: 0, loss: 1.706524133682251, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 50, loss: 1.495607614517212, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 100, loss: 1.7268763780593872, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 150, loss: 1.8302441835403442, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 200, loss: 1.8841699361801147, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 250, loss: 1.6540095806121826, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 300, loss: 1.1401376724243164, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 350, loss: 1.4876017570495605, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 400, loss: 1.561692714691162, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 450, loss: 1.6178088188171387, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 500, loss: 2.0035641193389893, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 550, loss: 1.8221824169158936, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 600, loss: 1.3568106889724731, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 650, loss: 1.6395772695541382, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 700, loss: 1.8073920011520386, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 750, loss: 1.6550569534301758, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 800, loss: 1.6020437479019165, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 850, loss: 1.5385483503341675, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 900, loss: 1.6246393918991089, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 950, loss: 1.8224642276763916, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1000, loss: 1.80193293094635, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1050, loss: 1.5075504779815674, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1100, loss: 1.8107725381851196, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1150, loss: 1.570520043373108, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1200, loss: 1.7591845989227295, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1250, loss: 1.483966588973999, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1300, loss: 1.4978431463241577, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1350, loss: 1.527783989906311, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1400, loss: 1.5691921710968018, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1450, loss: 1.7614763975143433, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1500, loss: 1.8113181591033936, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1550, loss: 1.7529726028442383, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1600, loss: 1.81077241897583, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1650, loss: 1.8843518495559692, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1700, loss: 2.094054698944092, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1750, loss: 1.6606175899505615, rate: 4.141485804420163e-06\n",
      "Epoch: 78 Batch: 1800, loss: 1.7830461263656616, rate: 4.141485804420163e-06\n",
      "[2023-11-13 14:29:55.698626] Epoch: 78 ends. Average loss: 1.666686870022104\n",
      "Epoch: 79 Batch: 0, loss: 1.760640025138855, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 50, loss: 1.500540852546692, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 100, loss: 1.770983338356018, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 150, loss: 1.7566710710525513, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 200, loss: 1.795971393585205, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 250, loss: 1.6632715463638306, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 300, loss: 1.185071587562561, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 350, loss: 1.4261274337768555, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 400, loss: 1.7594939470291138, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 450, loss: 1.6418628692626953, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 500, loss: 2.0028398036956787, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 550, loss: 1.827306866645813, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 600, loss: 1.4144388437271118, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 650, loss: 1.695027232170105, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 700, loss: 1.6817132234573364, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 750, loss: 1.6053452491760254, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 800, loss: 1.8537737131118774, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 850, loss: 1.6173347234725952, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 900, loss: 1.7443784475326538, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 950, loss: 1.8414705991744995, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1000, loss: 1.723941445350647, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1050, loss: 1.5064103603363037, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1100, loss: 1.6645660400390625, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1150, loss: 1.4929025173187256, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1200, loss: 1.6521373987197876, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1250, loss: 1.547186255455017, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1300, loss: 1.454833984375, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1350, loss: 1.5326259136199951, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1400, loss: 1.396292805671692, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1450, loss: 1.9228399991989136, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1500, loss: 1.7896672487258911, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1550, loss: 1.837266206741333, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1600, loss: 1.73483145236969, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1650, loss: 1.9265689849853516, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1700, loss: 2.0156409740448, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1750, loss: 1.611221194267273, rate: 3.9758263722433564e-06\n",
      "Epoch: 79 Batch: 1800, loss: 1.703155279159546, rate: 3.9758263722433564e-06\n",
      "[2023-11-13 14:33:46.605556] Epoch: 79 ends. Average loss: 1.6702954064925204\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    losss_per_e = []\n",
    "    for i, batch in enumerate(dataloader_train):\n",
    "        loss_current = train_a_batch(batch, head, optimizer, None)\n",
    "        losss_per_e.append(loss_current)\n",
    "        if i % 50 == 0:\n",
    "            print('Epoch: {} Batch: {}, loss: {}, rate: {}'.format(e, i, loss_current, optimizer.param_groups[0]['lr']))\n",
    "        # end\n",
    "\n",
    "        # if i > 1000:\n",
    "        #     break\n",
    "        # # end\n",
    "    # end\n",
    "    \n",
    "    loss_average_per_e = sum(losss_per_e) / len(losss_per_e)\n",
    "    print('[{}] Epoch: {} ends. Average loss: {}'.format(datetime.utcnow(), e, loss_average_per_e))\n",
    "    \n",
    "    # if loss_average_per_e < 10:\n",
    "    #     break\n",
    "    # # end\n",
    "    \n",
    "    lr_scheduler.step() # schedule per epoch\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c408f182-b2d1-49ae-877a-d81421e75155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "head.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba6d08f-e7d5-48fc-8b3d-9bda6ecd9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collator_S2S:\n",
    "\n",
    "    def __init__(self, tokenizer, size_seq_max):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.size_seq_max = size_seq_max\n",
    "    # end\n",
    "\n",
    "    def __call__(self, list_corpus_source):\n",
    "        # print('get input: {}'.format(list_corpus_source))\n",
    "\n",
    "        tokens_input_encoder = []\n",
    "        tokens_input_decoder = []\n",
    "        tokens_label_decoder = []\n",
    "        labels_similarity = []\n",
    "\n",
    "        for corpus_source in list_corpus_source: # (line0, line1, sim), output of zip remove single case\n",
    "            if corpus_source == 3:\n",
    "                corpus_line = [courpus_source[0], corpus_source[1]]\n",
    "                labels_similarity.append(corpus_line[2])\n",
    "            else:\n",
    "                corpus_line = [corpus_source[1]]\n",
    "            # end\n",
    "            \n",
    "            for line in corpus_line:\n",
    "                tokens = self.tokenizer.encode(line)\n",
    "\n",
    "                # TODO: check edge\n",
    "                if len(tokens) > self.size_seq_max - 2:\n",
    "                    tokens = tokens[:self.size_seq_max-2]\n",
    "                # end\n",
    "\n",
    "                tokens_input_encoder.append([self.tokenizer.id_cls] + tokens + [self.tokenizer.id_sep])\n",
    "                tokens_input_decoder.append([self.tokenizer.id_cls] + tokens)\n",
    "                tokens_label_decoder.append(tokens + [self.tokenizer.id_sep])\n",
    "            # end\n",
    "            \n",
    "\n",
    "        # end\n",
    "\n",
    "        inputs_encoder, masks_encoder, segments_encoder, labels_encoder = self.pad_sequences(tokens_input_encoder, self.size_seq_max, need_masked=0.5)\n",
    "        # inputs_decoder, masks_decoder, segments_decoder = self.pad_sequences(tokens_input_decoder, self.size_seq_max, need_diagonal=True)\n",
    "        # labels_decoder, masks_label, segments_label = self.pad_sequences(tokens_label_decoder, self.size_seq_max)\n",
    "        # labels_similarity = torch.Tensor(labels_similarity).unsqueeze(0).transpose(0,1)\n",
    "        # labels_similarity = torch.Tensor(labels_similarity)\n",
    "\n",
    "        return Batch(\n",
    "            ids_encoder=inputs_encoder,  # contains [mask]s\n",
    "            masks_encoder=masks_encoder,\n",
    "            labels_encoder=labels_encoder,  # doesn't contain [mask]\n",
    "            segments_encoder = segments_encoder,\n",
    "            # ids_decoder=inputs_decoder,\n",
    "            # masks_decoder=masks_decoder,\n",
    "            # labels_decoder=labels_decoder,\n",
    "            # segments_label=segments_label,\n",
    "            # labels_similarity=labels_similarity\n",
    "        )\n",
    "    # end\n",
    "\n",
    "    \n",
    "    # return masks_attention?, return masks_segment?\n",
    "    def pad_sequences(self, sequences, size_seq_max, need_diagonal=False, need_masked=0): # need_diagonal and need_masked cannot both set, one for bert seq one for s2s seq\n",
    "        id_pad = self.tokenizer.id_pad\n",
    "        id_mask = self.tokenizer.id_mask\n",
    "\n",
    "        sequences_padded = []\n",
    "        sequences_masked_padded = []\n",
    "\n",
    "        for sequence in sequences:\n",
    "            len_seq = len(sequence)\n",
    "\n",
    "            count_pad = size_seq_max - len_seq\n",
    "\n",
    "            sequence = torch.LongTensor(sequence)\n",
    "            sequence_padded = torch.cat((sequence, torch.LongTensor([id_pad] * count_pad)))\n",
    "            sequences_padded.append(sequence_padded)\n",
    "\n",
    "            if need_masked:\n",
    "                index_masked = list(range(1, len_seq-1))\n",
    "                random.shuffle(index_masked)\n",
    "                index_masked = torch.LongTensor(index_masked[:int(need_masked * (len_seq-2))])\n",
    "\n",
    "                sequence_masked = sequence.detach().clone()\n",
    "                sequence_masked.index_fill_(0, index_masked, id_mask)\n",
    "                sequence_masked_padded = torch.cat((sequence_masked, torch.LongTensor([id_pad] * count_pad)))\n",
    "                \n",
    "                sequences_masked_padded.append(sequence_masked_padded)\n",
    "            # end\n",
    "    #   # end for\n",
    "\n",
    "        inputs = torch.stack(sequences_padded)  # (batch, size_seq_max)\n",
    "        if need_masked:\n",
    "            inputs_masked_padded = torch.stack(sequences_masked_padded)\n",
    "        # end\n",
    "\n",
    "        masks_segment = (inputs != self.tokenizer.id_pad).unsqueeze(-2).expand(inputs.shape[0], inputs.shape[-1], inputs.shape[-1]) #(nbatch, seq, seq)\n",
    "        masks_attention = self.make_std_mask(inputs, self.tokenizer.id_pad) if need_diagonal else masks_segment\n",
    "\n",
    "        if need_masked:\n",
    "            masks_masked = (inputs_masked_padded != id_mask).unsqueeze(-2).expand(inputs.shape[0], inputs.shape[-1], inputs.shape[-1])\n",
    "            masks_attention = masks_attention & masks_masked\n",
    "            return inputs_masked_padded, masks_attention, masks_segment, inputs # (inputs, masks_attention, masks_segment, labels)\n",
    "        else:\n",
    "            return inputs, masks_attention, masks_segment\n",
    "        # end\n",
    "    # end\n",
    "\n",
    "\n",
    "    def subsequent_mask(self, size):\n",
    "        \"Mask out subsequent positions.\"\n",
    "        attn_shape = (1, size, size)\n",
    "        subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "            torch.uint8\n",
    "        )\n",
    "        return subsequent_mask == 0\n",
    "\n",
    "    def make_std_mask(self, tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & self.subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e5aa8a-8b73-4402-a6b2-a67d72bb6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.2404959201812744, acc: 0.0\n",
      "source: group of men are truck\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man is a a .\n",
      "\n",
      "\n",
      "loss: 1.6444147825241089, acc: 0.4000000059604645\n",
      "source: man sleeping a green on\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man in a a a\n",
      "\n",
      "\n",
      "loss: 1.9017980098724365, acc: 0.20000000298023224\n",
      "source: boy wearing headphones on .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man in a a .\n",
      "\n",
      "\n",
      "loss: 3.655745267868042, acc: 0.0\n",
      "source: setting up ice on iced over lake\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a a a .\n",
      "\n",
      "\n",
      "loss: 2.6446971893310547, acc: 0.1428571492433548\n",
      "source: wearing life jacket is a small boat\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: a a a a a a a\n",
      "\n",
      "\n",
      "loss: 2.4968273639678955, acc: 0.2857142984867096\n",
      "source: A in red coat hand bag of\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A in a a a a a\n",
      "\n",
      "\n",
      "loss: 1.3670650720596313, acc: 0.4000000059604645\n",
      "source: A is after the .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A a a a .\n",
      "\n",
      "\n",
      "loss: 2.702685832977295, acc: 0.1428571492433548\n",
      "source: A wearing <unk> swings baseball at incoming\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A a a a a a a\n",
      "\n",
      "\n",
      "loss: 2.8621256351470947, acc: 0.4000000059604645\n",
      "source: A man office the telephone\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man a . .\n",
      "\n",
      "\n",
      "loss: 2.0429258346557617, acc: 0.3333333432674408\n",
      "source: A smiling woman peach top a\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man in a a a\n",
      "\n",
      "\n",
      "loss: 2.0543370246887207, acc: 0.20000000298023224\n",
      "source: A young child standing jagged\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man in a a\n",
      "\n",
      "\n",
      "loss: 2.3202569484710693, acc: 0.5\n",
      "source: A in jump .\n",
      "input: [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A a . .\n",
      "\n",
      "\n",
      "loss: 2.1081817150115967, acc: 0.20000000298023224\n",
      "source: young children stand a blue\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man in a a a\n",
      "\n",
      "\n",
      "loss: 2.8444831371307373, acc: 0.0\n",
      "source: woman is her dried flower an market\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man in a a a a a\n",
      "\n",
      "\n",
      "loss: 1.5779242515563965, acc: 0.75\n",
      "source: A a her .\n",
      "input: [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A a . .\n",
      "\n",
      "\n",
      "loss: 3.170858860015869, acc: 0.0\n",
      "source: Three people on two dirt - four\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man in a a a a\n",
      "\n",
      "\n",
      "loss: 2.62371563911438, acc: 0.0\n",
      "source: naked man is on his\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a a\n",
      "\n",
      "\n",
      "loss: 2.242248773574829, acc: 0.2857142984867096\n",
      "source: A group standing front a in lot\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man a a a a a\n",
      "\n",
      "\n",
      "loss: 2.3523879051208496, acc: 0.20000000298023224\n",
      "source: A woman making rugs in\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A in a a a\n",
      "\n",
      "\n",
      "loss: 3.2092251777648926, acc: 0.1428571492433548\n",
      "source: make faces as takes a while they\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a a a a\n",
      "\n",
      "\n",
      "loss: 2.5836689472198486, acc: 0.0\n",
      "source: man in black t above the crowd\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a a a a\n",
      "\n",
      "\n",
      "loss: 3.3410913944244385, acc: 0.0\n",
      "source: Woman and man across sign beside it\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man in a a a .\n",
      "\n",
      "\n",
      "loss: 2.117281198501587, acc: 0.6000000238418579\n",
      "source: A man is juggling .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man a . .\n",
      "\n",
      "\n",
      "loss: 2.220315456390381, acc: 0.1428571492433548\n",
      "source: Asian hat and is serving on a\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man a a a a a a\n",
      "\n",
      "\n",
      "loss: 2.443882465362549, acc: 0.20000000298023224\n",
      "source: top of a piece of\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: a a a a a\n",
      "\n",
      "\n",
      "loss: 2.265007972717285, acc: 0.0\n",
      "source: dogs with toy tall grass\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man a a a a\n",
      "\n",
      "\n",
      "loss: 2.6045491695404053, acc: 0.0\n",
      "source: is smiling at child\n",
      "input: [MASK] [MASK] [MASK] [MASK]\n",
      "predict: a a a a\n",
      "\n",
      "\n",
      "loss: 1.4483076333999634, acc: 0.20000000298023224\n",
      "source: are walking on road .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a .\n",
      "\n",
      "\n",
      "loss: 2.353933811187744, acc: 0.0\n",
      "source: is parasailing over large water\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a a\n",
      "\n",
      "\n",
      "loss: 2.7007880210876465, acc: 0.3333333432674408\n",
      "source: is moving to up a .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a a .\n",
      "\n",
      "\n",
      "loss: 1.6776161193847656, acc: 0.4000000059604645\n",
      "source: A young by in a\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man a a a\n",
      "\n",
      "\n",
      "loss: 2.560788869857788, acc: 0.0\n",
      "source: person crosses the street the <unk>\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man in a a a a\n",
      "\n",
      "\n",
      "loss: 3.074876546859741, acc: 0.20000000298023224\n",
      "source: on a playground hanging bars\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a a\n",
      "\n",
      "\n",
      "loss: 2.1678342819213867, acc: 0.2857142984867096\n",
      "source: A wearing red long lying down a\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A in a a a a a\n",
      "\n",
      "\n",
      "loss: 1.8699232339859009, acc: 0.2857142984867096\n",
      "source: A people man in a suit little\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A a a a a a a\n",
      "\n",
      "\n",
      "loss: 1.8449180126190186, acc: 0.25\n",
      "source: woman sits a bar\n",
      "input: [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man in a a\n",
      "\n",
      "\n",
      "loss: 2.4098663330078125, acc: 0.1666666716337204\n",
      "source: walking down sidewalk where market .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a . .\n",
      "\n",
      "\n",
      "loss: 2.2176907062530518, acc: 0.1428571492433548\n",
      "source: man blue the paper while to board\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man a a a a a a\n",
      "\n",
      "\n",
      "loss: 2.5307304859161377, acc: 0.0\n",
      "source: large dog is in the sprinkler\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man a a a a a\n",
      "\n",
      "\n",
      "loss: 2.1384198665618896, acc: 0.2857142984867096\n",
      "source: A blond a blue t shirt stands\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man a a a a a\n",
      "\n",
      "\n",
      "loss: 2.8658134937286377, acc: 0.0\n",
      "source: young white male is sweeping large\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man in a a a a\n",
      "\n",
      "\n",
      "loss: 1.9129323959350586, acc: 0.2857142984867096\n",
      "source: A person the middle of green a\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man a a a a a\n",
      "\n",
      "\n",
      "loss: 1.7625994682312012, acc: 0.4000000059604645\n",
      "source: plays a rock to .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a .\n",
      "\n",
      "\n",
      "loss: 1.9173539876937866, acc: 0.3333333432674408\n",
      "source: man walking a a red leash\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a a a\n",
      "\n",
      "\n",
      "loss: 2.5748112201690674, acc: 0.20000000298023224\n",
      "source: drives an fashioned race .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: in a a a .\n",
      "\n",
      "\n",
      "loss: 2.371798515319824, acc: 0.0\n",
      "source: Young , and black shirts in straight\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A a a a a a a\n",
      "\n",
      "\n",
      "loss: 2.1788582801818848, acc: 0.20000000298023224\n",
      "source: , into calm water .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: a a . . .\n",
      "\n",
      "\n",
      "loss: 2.537658214569092, acc: 0.0\n",
      "source: Two short other the blond one is\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A a a a a a .\n",
      "\n",
      "\n",
      "loss: 3.535039186477661, acc: 0.1666666716337204\n",
      "source: elaborate in of brightly decorated .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: man a a a a .\n",
      "\n",
      "\n",
      "loss: 2.55476450920105, acc: 0.2857142984867096\n",
      "source: A dog small with his mouth .\n",
      "input: [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]\n",
      "predict: A man a a a a .\n",
      "\n",
      "\n",
      "loss: 0.8765453100204468, acc: 0.3333333432674408\n",
      "source: Three <unk> .\n",
      "input: [MASK] [MASK] [MASK]\n",
      "predict: A a .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collator = Collator_S2S(tokenizer, seq_max)\n",
    "eval_source = to_map_style_dataset(valid_iter)\n",
    "dataloader_eval = DataLoader(eval_source, 1, shuffle=False, collate_fn=collator)\n",
    "# dataloader_eval = DataLoader(train_source, 1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "for i, batch in enumerate(dataloader_eval):\n",
    "    info_batch = batch()\n",
    "    out_mlm, loss_mlm = head.forward(**info_batch)\n",
    "    \n",
    "    out_mlm = out_mlm.cpu().detach()\n",
    "    loss_mlm = loss_mlm.cpu().detach()\n",
    "    labels_mlm = info_batch['labels_encoder'].cpu().detach()\n",
    "    masks_encoder = info_batch['masks_encoder'].cpu().detach()\n",
    "    segments_encoder = info_batch['segments_encoder'].cpu().detach()\n",
    "    ids_encoder = info_batch['ids_encoder'].cpu().detach()\n",
    "    \n",
    "    masks_masked = torch.logical_xor(masks_encoder, segments_encoder) & segments_encoder # True is masked\n",
    "    masks_masked_perbatch = masks_masked[:,0,:]\n",
    "    \n",
    "    predicts = out_mlm.softmax(dim=-1).argmax(dim=-1)\n",
    "    # print segments\n",
    "    # sentence_predicts = tokenizer.decode(out_mlm.softmax(dim=-1).argmax(dim=-1).masked_select(segments_encoder[:, 0, :]).numpy().tolist())\n",
    "    # sentence_labels = tokenizer.decode(labels_mlm.masked_select(segments_encoder[:, 0, :]).numpy().tolist())\n",
    "    # sentence_inputs = tokenizer.decode(ids_encoder.masked_select(segments_encoder[:, 0, :]).numpy().tolist())\n",
    "    \n",
    "    # print masks\n",
    "    sentence_predicts = tokenizer.decode(out_mlm.softmax(dim=-1).argmax(dim=-1).masked_select(masks_masked_perbatch).numpy().tolist())\n",
    "    sentence_labels = tokenizer.decode(labels_mlm.masked_select(masks_masked_perbatch).numpy().tolist())\n",
    "    sentence_inputs = tokenizer.decode(ids_encoder.masked_select(masks_masked_perbatch).numpy().tolist())\n",
    "    \n",
    "    \n",
    "#     sentence_predicts = tokenizer.decode(out_mlm.softmax(dim=-1).argmax(dim=-1).numpy().tolist()[0])\n",
    "#     sentence_labels = tokenizer.decode(labels_mlm.numpy().tolist()[0])\n",
    "#     sentence_inputs = tokenizer.decode(ids_encoder.numpy().tolist()[0])\n",
    "    \n",
    "    predicts_masked = out_mlm.softmax(dim=-1).argmax(dim=-1).masked_select(masks_masked_perbatch)\n",
    "    labels_masked = labels_mlm.masked_select(masks_masked_perbatch)\n",
    "    \n",
    "    acc = torch.count_nonzero(predicts_masked == labels_masked) / labels_masked.shape[0]\n",
    "    \n",
    "    # acc = torch.count_nonzero(out_mlm.softmax(dim=-1).argmax(dim=-1).view(-1) == labels_mlm.view(-1)) / labels_mlm.view(-1).shape[0]\n",
    "    print('loss: {}, acc: {}\\nsource: {}\\ninput: {}\\npredict: {}\\n\\n'.format(loss_mlm.item(), acc, sentence_labels, sentence_inputs, sentence_predicts))\n",
    "    \n",
    "    if i >= 50:\n",
    "        break\n",
    "    # end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ebd649b-342f-4cb6-addc-f835bc58b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 6195])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_mlm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7a2a76-29de-423e-a132-fd41c27c7ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_encoder[:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db520799-da23-466b-8818-8ecdc2568ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          False, False, False, False, False, False]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "138bc8bb-89a3-4507-85d5-4b1bc43fedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_encoder_2d = segments_encoder.transpose(-1,-2)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cbf862e-0b22-47c4-8969-ed88da022d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 6195])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, 6195).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3f4b4e0-47a8-4af2-8559-9764b8cb19fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6192,   59,   77,  117,    3,   20,  122,    5, 6193])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_mlm.masked_select(segments_encoder_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f63010fa-c3fe-4e88-9b15-2ca1d6ae4030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8765)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss()(out_mlm.masked_select(segments_encoder_2d.unsqueeze(-1)).reshape(-1, 6195), labels_mlm.masked_select(segments_encoder_2d))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
